Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/24]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2827e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302788
Average KL loss: 0.002289
Average total loss: 2.305076
tensor(3.8331e-06, device='cuda:0') tensor(2.4506e-07, device='cuda:0') tensor(-1.4051e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.303086
Average KL loss: 0.002306
Average total loss: 2.305392
tensor(4.7465e-06, device='cuda:0') tensor(3.1076e-07, device='cuda:0') tensor(-1.0873e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.302923
Average KL loss: 0.002319
Average total loss: 2.305242
tensor(5.1425e-06, device='cuda:0') tensor(4.3080e-07, device='cuda:0') tensor(-9.4627e-12, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.302902
Average KL loss: 0.002333
Average total loss: 2.305235
tensor(7.1510e-06, device='cuda:0') tensor(5.9269e-07, device='cuda:0') tensor(-1.5588e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.303155
Average KL loss: 0.002347
Average total loss: 2.305502
tensor(5.2883e-06, device='cuda:0') tensor(6.1039e-07, device='cuda:0') tensor(-1.7719e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.302898
Average KL loss: 0.002351
Average total loss: 2.305249
tensor(4.8537e-06, device='cuda:0') tensor(5.9303e-07, device='cuda:0') tensor(2.4821e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.302630
Average KL loss: 0.002361
Average total loss: 2.304991
tensor(7.6529e-06, device='cuda:0') tensor(7.2303e-07, device='cuda:0') tensor(-7.0271e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.302598
Average KL loss: 0.002381
Average total loss: 2.304978
tensor(8.2163e-06, device='cuda:0') tensor(8.4289e-07, device='cuda:0') tensor(1.7615e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.302725
Average KL loss: 0.002392
Average total loss: 2.305117
tensor(9.1444e-06, device='cuda:0') tensor(9.5426e-07, device='cuda:0') tensor(-1.0941e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.302480
Average KL loss: 0.002406
Average total loss: 2.304886
tensor(9.3984e-06, device='cuda:0') tensor(1.0100e-06, device='cuda:0') tensor(2.1252e-11, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.302804
Average KL loss: 0.002415
Average total loss: 2.305219
tensor(1.0144e-05, device='cuda:0') tensor(1.2076e-06, device='cuda:0') tensor(-4.2698e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.302581
Average KL loss: 0.002440
Average total loss: 2.305020
tensor(9.9387e-06, device='cuda:0') tensor(1.2481e-06, device='cuda:0') tensor(-3.3304e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.302411
Average KL loss: 0.002420
Average total loss: 2.304831
tensor(1.1164e-05, device='cuda:0') tensor(1.0115e-06, device='cuda:0') tensor(1.7319e-11, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.302441
Average KL loss: 0.002402
Average total loss: 2.304843
tensor(1.0458e-05, device='cuda:0') tensor(9.5138e-07, device='cuda:0') tensor(2.6798e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.302666
Average KL loss: 0.002397
Average total loss: 2.305062
tensor(1.0508e-05, device='cuda:0') tensor(9.3064e-07, device='cuda:0') tensor(-6.8365e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.302522
Average KL loss: 0.002396
Average total loss: 2.304918
tensor(1.1153e-05, device='cuda:0') tensor(9.3068e-07, device='cuda:0') tensor(4.1745e-11, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.302700
Average KL loss: 0.002394
Average total loss: 2.305095
tensor(1.0751e-05, device='cuda:0') tensor(9.1745e-07, device='cuda:0') tensor(-1.1403e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.302373
Average KL loss: 0.002394
Average total loss: 2.304767
tensor(1.0975e-05, device='cuda:0') tensor(9.2015e-07, device='cuda:0') tensor(1.4711e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.302330
Average KL loss: 0.002394
Average total loss: 2.304724
tensor(1.2140e-05, device='cuda:0') tensor(9.2823e-07, device='cuda:0') tensor(6.1342e-11, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.302549
Average KL loss: 0.002396
Average total loss: 2.304945
tensor(1.1780e-05, device='cuda:0') tensor(9.3498e-07, device='cuda:0') tensor(2.4074e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.302167
Average KL loss: 0.002396
Average total loss: 2.304564
tensor(1.2175e-05, device='cuda:0') tensor(9.4386e-07, device='cuda:0') tensor(-7.2346e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.302636
Average KL loss: 0.002398
Average total loss: 2.305034
tensor(1.1534e-05, device='cuda:0') tensor(9.4156e-07, device='cuda:0') tensor(1.6228e-11, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.302518
Average KL loss: 0.002398
Average total loss: 2.304916
tensor(1.1937e-05, device='cuda:0') tensor(9.4757e-07, device='cuda:0') tensor(-3.2955e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.302741
Average KL loss: 0.002398
Average total loss: 2.305139
tensor(1.1472e-05, device='cuda:0') tensor(9.5102e-07, device='cuda:0') tensor(2.6998e-11, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.302575
Average KL loss: 0.002399
Average total loss: 2.304973
tensor(1.0979e-05, device='cuda:0') tensor(9.4854e-07, device='cuda:0') tensor(-9.1248e-11, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.302285
Average KL loss: 0.002399
Average total loss: 2.304684
tensor(1.1774e-05, device='cuda:0') tensor(9.5989e-07, device='cuda:0') tensor(-4.7025e-11, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.302735
Average KL loss: 0.002400
Average total loss: 2.305135
tensor(1.1229e-05, device='cuda:0') tensor(9.5665e-07, device='cuda:0') tensor(-3.6868e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.302656
Average KL loss: 0.002400
Average total loss: 2.305056
tensor(1.1615e-05, device='cuda:0') tensor(9.6731e-07, device='cuda:0') tensor(3.7486e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.302488
Average KL loss: 0.002402
Average total loss: 2.304890
tensor(1.1710e-05, device='cuda:0') tensor(9.7571e-07, device='cuda:0') tensor(-4.3704e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.302759
Average KL loss: 0.002402
Average total loss: 2.305161
tensor(1.1380e-05, device='cuda:0') tensor(9.7513e-07, device='cuda:0') tensor(6.7585e-11, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.302341
Average KL loss: 0.002403
Average total loss: 2.304744
tensor(1.2238e-05, device='cuda:0') tensor(9.9337e-07, device='cuda:0') tensor(-4.7671e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.302383
Average KL loss: 0.002405
Average total loss: 2.304787
tensor(1.2105e-05, device='cuda:0') tensor(9.9993e-07, device='cuda:0') tensor(-3.9173e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 2.302597
Average KL loss: 0.002405
Average total loss: 2.305002
tensor(1.2229e-05, device='cuda:0') tensor(9.9461e-07, device='cuda:0') tensor(2.0791e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 2.302977
Average KL loss: 0.002404
Average total loss: 2.305381
tensor(1.2208e-05, device='cuda:0') tensor(9.8956e-07, device='cuda:0') tensor(-3.5101e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 2.302677
Average KL loss: 0.002403
Average total loss: 2.305080
tensor(1.2207e-05, device='cuda:0') tensor(9.8585e-07, device='cuda:0') tensor(8.0108e-11, device='cuda:0')
Epoch 36
Average batch original loss after noise: 2.302596
Average KL loss: 0.002403
Average total loss: 2.304999
tensor(1.2156e-05, device='cuda:0') tensor(9.8301e-07, device='cuda:0') tensor(-1.0182e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 2.302462
Average KL loss: 0.002403
Average total loss: 2.304865
tensor(1.2150e-05, device='cuda:0') tensor(9.8114e-07, device='cuda:0') tensor(2.4772e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 2.302357
Average KL loss: 0.002402
Average total loss: 2.304760
tensor(1.2164e-05, device='cuda:0') tensor(9.7993e-07, device='cuda:0') tensor(1.1640e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 2.302401
Average KL loss: 0.002402
Average total loss: 2.304803
tensor(1.2099e-05, device='cuda:0') tensor(9.7843e-07, device='cuda:0') tensor(-2.5303e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 2.302210
Average KL loss: 0.002402
Average total loss: 2.304612
tensor(1.2066e-05, device='cuda:0') tensor(9.7776e-07, device='cuda:0') tensor(1.7733e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 2.302471
Average KL loss: 0.002402
Average total loss: 2.304873
tensor(1.1966e-05, device='cuda:0') tensor(9.7650e-07, device='cuda:0') tensor(9.4351e-11, device='cuda:0')
Epoch 42
Average batch original loss after noise: 2.302736
Average KL loss: 0.002402
Average total loss: 2.305138
tensor(1.1994e-05, device='cuda:0') tensor(9.7629e-07, device='cuda:0') tensor(-1.5415e-10, device='cuda:0')
 Percentile value: -8.241697742050745e-07
Non-zero model percentage: 80.0%, Non-zero mask percentage: 80.0%

--- Pruning Level [1/24]: ---
conv1.weight         | nonzeros =    1453 /    1728             ( 84.09%) | total_pruned =     275 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   32414 /   36864             ( 87.93%) | total_pruned =    4450 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   27916 /   36864             ( 75.73%) | total_pruned =    8948 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   26892 /   36864             ( 72.95%) | total_pruned =    9972 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   27080 /   36864             ( 73.46%) | total_pruned =    9784 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   49146 /   73728             ( 66.66%) | total_pruned =   24582 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   94602 /  147456             ( 64.16%) | total_pruned =   52854 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5513 /    8192             ( 67.30%) | total_pruned =    2679 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  113870 /  147456             ( 77.22%) | total_pruned =   33586 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  117216 /  147456             ( 79.49%) | total_pruned =   30240 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  179844 /  294912             ( 60.98%) | total_pruned =  115068 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  368532 /  589824             ( 62.48%) | total_pruned =  221292 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   21560 /   32768             ( 65.80%) | total_pruned =   11208 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     193 /     256             ( 75.39%) | total_pruned =      63 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  478244 /  589824             ( 81.08%) | total_pruned =  111580 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     148 /     256             ( 57.81%) | total_pruned =     108 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  508288 /  589824             ( 86.18%) | total_pruned =   81536 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     166 /     256             ( 64.84%) | total_pruned =      90 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  815349 / 1179648             ( 69.12%) | total_pruned =  364299 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     409 /     512             ( 79.88%) | total_pruned =     103 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     127 /     512             ( 24.80%) | total_pruned =     385 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1889438 / 2359296             ( 80.08%) | total_pruned =  469858 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     392 /     512             ( 76.56%) | total_pruned =     120 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     142 /     512             ( 27.73%) | total_pruned =     370 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  100546 /  131072             ( 76.71%) | total_pruned =   30526 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     390 /     512             ( 76.17%) | total_pruned =     122 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     137 /     512             ( 26.76%) | total_pruned =     375 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1984319 / 2359296             ( 84.11%) | total_pruned =  374977 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     402 /     512             ( 78.52%) | total_pruned =     110 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     147 /     512             ( 28.71%) | total_pruned =     365 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2088071 / 2359296             ( 88.50%) | total_pruned =  271225 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     222 /     512             ( 43.36%) | total_pruned =     290 | shape = torch.Size([512])
linear.weight        | nonzeros =    2680 /    5120             ( 52.34%) | total_pruned =    2440 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       6 /      10             ( 60.00%) | total_pruned =       4 | shape = torch.Size([10])
alive: 8943010, pruned : 2235752, total: 11178762, Compression rate :       1.25x  ( 20.00% pruned)
Train Epoch: 59/100 Loss: 0.014560 Accuracy: 88.82 100.00 % Best test Accuracy: 88.89%
tensor(1.1924e-05, device='cuda:0') tensor(9.7553e-07, device='cuda:0') tensor(-5.1686e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.293041
Average KL loss: 0.002718
Average total loss: 2.295759
tensor(4.0294e-05, device='cuda:0') tensor(5.4482e-06, device='cuda:0') tensor(-5.9409e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.293620
Average KL loss: 0.003281
Average total loss: 2.296901
tensor(5.3381e-05, device='cuda:0') tensor(8.8479e-06, device='cuda:0') tensor(-3.9204e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.290211
Average KL loss: 0.003682
Average total loss: 2.293893
tensor(6.7702e-05, device='cuda:0') tensor(1.1448e-05, device='cuda:0') tensor(2.5201e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.282181
Average KL loss: 0.004096
Average total loss: 2.286277
tensor(8.3400e-05, device='cuda:0') tensor(1.4920e-05, device='cuda:0') tensor(-4.0172e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.286085
Average KL loss: 0.004508
Average total loss: 2.290592
tensor(8.8520e-05, device='cuda:0') tensor(1.7415e-05, device='cuda:0') tensor(-1.1964e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.281404
Average KL loss: 0.004901
Average total loss: 2.286305
tensor(9.8007e-05, device='cuda:0') tensor(2.0318e-05, device='cuda:0') tensor(-1.0357e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.282279
Average KL loss: 0.005304
Average total loss: 2.287583
tensor(0.0001, device='cuda:0') tensor(2.2858e-05, device='cuda:0') tensor(-6.7288e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.276113
Average KL loss: 0.005701
Average total loss: 2.281814
tensor(0.0001, device='cuda:0') tensor(2.6452e-05, device='cuda:0') tensor(-1.6929e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.278875
Average KL loss: 0.006146
Average total loss: 2.285021
tensor(0.0001, device='cuda:0') tensor(2.9351e-05, device='cuda:0') tensor(-4.2412e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.274253
Average KL loss: 0.006618
Average total loss: 2.280871
tensor(0.0001, device='cuda:0') tensor(3.2634e-05, device='cuda:0') tensor(-1.9517e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.273265
Average KL loss: 0.007056
Average total loss: 2.280321
tensor(0.0001, device='cuda:0') tensor(3.5885e-05, device='cuda:0') tensor(-1.1867e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.267885
Average KL loss: 0.007455
Average total loss: 2.275340
tensor(0.0002, device='cuda:0') tensor(3.8498e-05, device='cuda:0') tensor(-1.6597e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.269026
Average KL loss: 0.007881
Average total loss: 2.276907
tensor(0.0002, device='cuda:0') tensor(4.1624e-05, device='cuda:0') tensor(-1.0995e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.263370
Average KL loss: 0.008326
Average total loss: 2.271696
tensor(0.0002, device='cuda:0') tensor(4.5803e-05, device='cuda:0') tensor(-2.3452e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.264364
Average KL loss: 0.008885
Average total loss: 2.273248
tensor(0.0002, device='cuda:0') tensor(4.9221e-05, device='cuda:0') tensor(-2.2491e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.262858
Average KL loss: 0.009525
Average total loss: 2.272383
tensor(0.0002, device='cuda:0') tensor(5.4385e-05, device='cuda:0') tensor(-2.9574e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.256527
Average KL loss: 0.010149
Average total loss: 2.266676
tensor(0.0002, device='cuda:0') tensor(5.8708e-05, device='cuda:0') tensor(-2.3480e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.245236
Average KL loss: 0.010882
Average total loss: 2.256118
tensor(0.0002, device='cuda:0') tensor(6.4919e-05, device='cuda:0') tensor(-3.1655e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.241136
Average KL loss: 0.011789
Average total loss: 2.252925
tensor(0.0002, device='cuda:0') tensor(7.1938e-05, device='cuda:0') tensor(4.1936e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.241973
Average KL loss: 0.012653
Average total loss: 2.254626
tensor(0.0003, device='cuda:0') tensor(7.7390e-05, device='cuda:0') tensor(-2.0928e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.242908
Average KL loss: 0.013446
Average total loss: 2.256354
tensor(0.0003, device='cuda:0') tensor(8.2926e-05, device='cuda:0') tensor(-5.1446e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.231651
Average KL loss: 0.014210
Average total loss: 2.245861
tensor(0.0003, device='cuda:0') tensor(8.8913e-05, device='cuda:0') tensor(-4.9732e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.223572
Average KL loss: 0.015213
Average total loss: 2.238785
tensor(0.0003, device='cuda:0') tensor(9.7252e-05, device='cuda:0') tensor(-2.5390e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.217600
Average KL loss: 0.016503
Average total loss: 2.234104
tensor(0.0003, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-8.8951e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.213939
Average KL loss: 0.017608
Average total loss: 2.231547
tensor(0.0003, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-2.0900e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.206474
Average KL loss: 0.018712
Average total loss: 2.225187
tensor(0.0004, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-2.9704e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.206387
Average KL loss: 0.019949
Average total loss: 2.226336
tensor(0.0004, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-1.2678e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.192126
Average KL loss: 0.021127
Average total loss: 2.213253
tensor(0.0004, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-2.2496e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.199795
Average KL loss: 0.022343
Average total loss: 2.222138
tensor(0.0004, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-2.0855e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.186078
Average KL loss: 0.023402
Average total loss: 2.209480
tensor(0.0004, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-5.1577e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.169974
Average KL loss: 0.024866
Average total loss: 2.194840
tensor(0.0004, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-3.5031e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.164496
Average KL loss: 0.026369
Average total loss: 2.190865
tensor(0.0004, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-2.4891e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 2.161912
Average KL loss: 0.027606
Average total loss: 2.189518
tensor(0.0005, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-2.0881e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 2.143301
Average KL loss: 0.029181
Average total loss: 2.172482
tensor(0.0005, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-4.3256e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 2.138185
Average KL loss: 0.030781
Average total loss: 2.168966
tensor(0.0005, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-6.1955e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 2.126223
Average KL loss: 0.032409
Average total loss: 2.158632
tensor(0.0005, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-6.2773e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 2.107497
Average KL loss: 0.034346
Average total loss: 2.141843
tensor(0.0005, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-2.2654e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 2.112325
Average KL loss: 0.036199
Average total loss: 2.148524
tensor(0.0006, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-5.0951e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 2.095623
Average KL loss: 0.037915
Average total loss: 2.133537
tensor(0.0006, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-6.9595e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 2.080131
Average KL loss: 0.039771
Average total loss: 2.119902
tensor(0.0006, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-4.2963e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 2.076163
Average KL loss: 0.041545
Average total loss: 2.117708
tensor(0.0006, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-3.2569e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 2.055201
Average KL loss: 0.043294
Average total loss: 2.098494
tensor(0.0007, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-4.1506e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 2.037023
Average KL loss: 0.045182
Average total loss: 2.082205
tensor(0.0007, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-5.4614e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 2.039041
Average KL loss: 0.046940
Average total loss: 2.085981
tensor(0.0007, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-4.0619e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 2.033927
Average KL loss: 0.048490
Average total loss: 2.082417
tensor(0.0007, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-6.7886e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 2.018183
Average KL loss: 0.050337
Average total loss: 2.068520
tensor(0.0007, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.5277e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 2.003573
Average KL loss: 0.052335
Average total loss: 2.055907
tensor(0.0007, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.1616e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.986860
Average KL loss: 0.054139
Average total loss: 2.040998
tensor(0.0008, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-4.1151e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.980992
Average KL loss: 0.055736
Average total loss: 2.036728
tensor(0.0008, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-6.8507e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.949444
Average KL loss: 0.057568
Average total loss: 2.007013
tensor(0.0008, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-7.6007e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.956693
Average KL loss: 0.059677
Average total loss: 2.016370
tensor(0.0008, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-6.0014e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.940495
Average KL loss: 0.061819
Average total loss: 2.002314
tensor(0.0009, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-6.6141e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.940995
Average KL loss: 0.063751
Average total loss: 2.004746
tensor(0.0009, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-7.5379e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.910121
Average KL loss: 0.065283
Average total loss: 1.975404
tensor(0.0009, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-6.1248e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.896946
Average KL loss: 0.066991
Average total loss: 1.963937
tensor(0.0009, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-7.9121e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.892831
Average KL loss: 0.068869
Average total loss: 1.961700
tensor(0.0009, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-7.4339e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.883228
Average KL loss: 0.070684
Average total loss: 1.953912
tensor(0.0009, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-7.3427e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.854062
Average KL loss: 0.072342
Average total loss: 1.926404
tensor(0.0010, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-6.6907e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.855992
Average KL loss: 0.074252
Average total loss: 1.930244
tensor(0.0010, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.6113e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.842513
Average KL loss: 0.075978
Average total loss: 1.918491
tensor(0.0010, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-3.9917e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.810119
Average KL loss: 0.077721
Average total loss: 1.887840
tensor(0.0010, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-5.5388e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.821701
Average KL loss: 0.079833
Average total loss: 1.901534
tensor(0.0010, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-7.1428e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.786377
Average KL loss: 0.081664
Average total loss: 1.868040
tensor(0.0011, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-5.5582e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.798431
Average KL loss: 0.083788
Average total loss: 1.882219
tensor(0.0011, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-6.6236e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.781043
Average KL loss: 0.085691
Average total loss: 1.866734
tensor(0.0011, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-7.0003e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.751333
Average KL loss: 0.087347
Average total loss: 1.838680
tensor(0.0011, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-9.9732e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.749458
Average KL loss: 0.088936
Average total loss: 1.838394
tensor(0.0011, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-6.9320e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.736927
Average KL loss: 0.090753
Average total loss: 1.827681
tensor(0.0011, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-8.0045e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.719282
Average KL loss: 0.092543
Average total loss: 1.811826
tensor(0.0011, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-5.2294e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.689728
Average KL loss: 0.093923
Average total loss: 1.783650
tensor(0.0012, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-7.2935e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.697753
Average KL loss: 0.095352
Average total loss: 1.793105
tensor(0.0012, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-5.4021e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.702234
Average KL loss: 0.096778
Average total loss: 1.799012
tensor(0.0012, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-8.1268e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.679999
Average KL loss: 0.098213
Average total loss: 1.778212
tensor(0.0012, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-8.8180e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.653065
Average KL loss: 0.099845
Average total loss: 1.752910
tensor(0.0012, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-7.6094e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.641330
Average KL loss: 0.101442
Average total loss: 1.742773
tensor(0.0012, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-8.4518e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.638831
Average KL loss: 0.102757
Average total loss: 1.741588
tensor(0.0012, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-8.0238e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.585150
Average KL loss: 0.104208
Average total loss: 1.689358
tensor(0.0013, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-7.3928e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.609316
Average KL loss: 0.105506
Average total loss: 1.714822
tensor(0.0013, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.0501e-07, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.604566
Average KL loss: 0.107074
Average total loss: 1.711639
tensor(0.0013, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-6.7500e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.589453
Average KL loss: 0.108487
Average total loss: 1.697940
tensor(0.0013, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-5.3150e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.563411
Average KL loss: 0.109936
Average total loss: 1.673346
tensor(0.0013, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-6.3946e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.570388
Average KL loss: 0.111493
Average total loss: 1.681881
tensor(0.0013, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.0082e-07, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.542224
Average KL loss: 0.113000
Average total loss: 1.655224
tensor(0.0013, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-7.4398e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.551882
Average KL loss: 0.114053
Average total loss: 1.665934
tensor(0.0013, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-8.5135e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.520270
Average KL loss: 0.115213
Average total loss: 1.635484
tensor(0.0014, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-7.3419e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.514718
Average KL loss: 0.116402
Average total loss: 1.631120
tensor(0.0014, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-5.8000e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.492576
Average KL loss: 0.117620
Average total loss: 1.610196
tensor(0.0014, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-9.6038e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.478431
Average KL loss: 0.118894
Average total loss: 1.597324
tensor(0.0014, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-4.6041e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.491047
Average KL loss: 0.120140
Average total loss: 1.611188
tensor(0.0014, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-9.6844e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.462458
Average KL loss: 0.121399
Average total loss: 1.583857
tensor(0.0014, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-6.0808e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.481161
Average KL loss: 0.122601
Average total loss: 1.603762
tensor(0.0014, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.1431e-07, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.430589
Average KL loss: 0.123734
Average total loss: 1.554322
tensor(0.0014, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-6.2134e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.413704
Average KL loss: 0.124864
Average total loss: 1.538568
tensor(0.0015, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-8.5507e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.428482
Average KL loss: 0.125886
Average total loss: 1.554368
tensor(0.0015, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-6.6351e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.427116
Average KL loss: 0.126872
Average total loss: 1.553988
tensor(0.0015, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-5.5033e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.415146
Average KL loss: 0.128082
Average total loss: 1.543229
tensor(0.0015, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.9510e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.409754
Average KL loss: 0.129211
Average total loss: 1.538965
tensor(0.0015, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-6.7751e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.410894
Average KL loss: 0.130454
Average total loss: 1.541348
tensor(0.0015, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-9.4101e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.390917
Average KL loss: 0.131599
Average total loss: 1.522516
tensor(0.0015, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-6.9848e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.371938
Average KL loss: 0.132748
Average total loss: 1.504686
tensor(0.0015, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-8.5004e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.358336
Average KL loss: 0.133734
Average total loss: 1.492070
tensor(0.0015, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-6.5256e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.363459
Average KL loss: 0.134674
Average total loss: 1.498133
tensor(0.0015, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.0903e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.357342
Average KL loss: 0.135583
Average total loss: 1.492926
tensor(0.0015, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-6.9185e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.343842
Average KL loss: 0.136497
Average total loss: 1.480338
tensor(0.0015, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-6.9001e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.336497
Average KL loss: 0.137603
Average total loss: 1.474100
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.5457e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.313120
Average KL loss: 0.138616
Average total loss: 1.451735
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.9055e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.307493
Average KL loss: 0.139495
Average total loss: 1.446988
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.5890e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.304396
Average KL loss: 0.140359
Average total loss: 1.444755
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.1924e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.274223
Average KL loss: 0.141492
Average total loss: 1.415715
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-9.6897e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.310819
Average KL loss: 0.142607
Average total loss: 1.453426
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.5211e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.277009
Average KL loss: 0.143542
Average total loss: 1.420551
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.4165e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.259448
Average KL loss: 0.144299
Average total loss: 1.403747
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1448e-07, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.246323
Average KL loss: 0.145152
Average total loss: 1.391475
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.5981e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.245319
Average KL loss: 0.146132
Average total loss: 1.391451
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.7396e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.222820
Average KL loss: 0.146926
Average total loss: 1.369747
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.7124e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.242853
Average KL loss: 0.147795
Average total loss: 1.390649
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-8.1924e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.200383
Average KL loss: 0.148705
Average total loss: 1.349088
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-5.1909e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.214574
Average KL loss: 0.149553
Average total loss: 1.364127
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-5.9991e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.227934
Average KL loss: 0.150401
Average total loss: 1.378335
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-6.7632e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.193078
Average KL loss: 0.151414
Average total loss: 1.344492
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-7.8718e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.189418
Average KL loss: 0.152123
Average total loss: 1.341541
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-9.9506e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.191443
Average KL loss: 0.153035
Average total loss: 1.344478
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-5.6662e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.152037
Average KL loss: 0.153758
Average total loss: 1.305796
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-4.1180e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.167165
Average KL loss: 0.154303
Average total loss: 1.321468
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-4.8235e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.167702
Average KL loss: 0.155044
Average total loss: 1.322746
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-6.2702e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.153896
Average KL loss: 0.155824
Average total loss: 1.309720
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.0917e-07, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.144660
Average KL loss: 0.156803
Average total loss: 1.301462
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-5.9928e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.146876
Average KL loss: 0.157494
Average total loss: 1.304370
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-5.9796e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.133296
Average KL loss: 0.158260
Average total loss: 1.291556
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.3971e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.115120
Average KL loss: 0.158980
Average total loss: 1.274100
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.0886e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.101222
Average KL loss: 0.159620
Average total loss: 1.260842
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.1447e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.123670
Average KL loss: 0.160335
Average total loss: 1.284005
tensor(0.0018, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-8.0672e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.099698
Average KL loss: 0.161033
Average total loss: 1.260731
tensor(0.0018, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-8.1378e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.082800
Average KL loss: 0.161699
Average total loss: 1.244499
tensor(0.0018, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.9039e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.081150
Average KL loss: 0.162183
Average total loss: 1.243333
tensor(0.0018, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.0075e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.065592
Average KL loss: 0.162599
Average total loss: 1.228191
tensor(0.0018, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-8.1861e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.083181
Average KL loss: 0.163101
Average total loss: 1.246282
tensor(0.0018, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.2294e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.068244
Average KL loss: 0.163613
Average total loss: 1.231856
tensor(0.0018, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.3930e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.045818
Average KL loss: 0.164202
Average total loss: 1.210020
tensor(0.0018, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.1626e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.053254
Average KL loss: 0.164577
Average total loss: 1.217831
tensor(0.0018, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.6239e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.034892
Average KL loss: 0.165330
Average total loss: 1.200223
tensor(0.0018, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.3171e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.053935
Average KL loss: 0.165980
Average total loss: 1.219915
tensor(0.0018, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.2482e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.040080
Average KL loss: 0.166693
Average total loss: 1.206773
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-5.9188e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.036572
Average KL loss: 0.167242
Average total loss: 1.203814
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.2640e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.028294
Average KL loss: 0.167986
Average total loss: 1.196280
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.4972e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.028835
Average KL loss: 0.168530
Average total loss: 1.197365
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-6.3639e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.003869
Average KL loss: 0.169049
Average total loss: 1.172919
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-9.4721e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.004278
Average KL loss: 0.169686
Average total loss: 1.173964
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-6.1707e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.006395
Average KL loss: 0.170054
Average total loss: 1.176449
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-5.9191e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.979274
Average KL loss: 0.170652
Average total loss: 1.149926
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.7630e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.984291
Average KL loss: 0.171084
Average total loss: 1.155374
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-6.1574e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.977936
Average KL loss: 0.171577
Average total loss: 1.149512
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-6.2247e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.979615
Average KL loss: 0.172048
Average total loss: 1.151664
tensor(0.0019, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.0023e-07, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.972613
Average KL loss: 0.172500
Average total loss: 1.145113
tensor(0.0019, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.5675e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.966355
Average KL loss: 0.173028
Average total loss: 1.139383
tensor(0.0019, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-5.9933e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.949183
Average KL loss: 0.173572
Average total loss: 1.122755
tensor(0.0019, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.4715e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.957643
Average KL loss: 0.174075
Average total loss: 1.131718
tensor(0.0019, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.1485e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.948377
Average KL loss: 0.174311
Average total loss: 1.122688
tensor(0.0019, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-5.5315e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.954647
Average KL loss: 0.174582
Average total loss: 1.129228
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.4131e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.953851
Average KL loss: 0.175204
Average total loss: 1.129055
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.0960e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.930742
Average KL loss: 0.175833
Average total loss: 1.106575
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.6145e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.932471
Average KL loss: 0.176101
Average total loss: 1.108571
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.4886e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.918302
Average KL loss: 0.176549
Average total loss: 1.094852
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.7901e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.922835
Average KL loss: 0.177122
Average total loss: 1.099957
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.3105e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.930762
Average KL loss: 0.177805
Average total loss: 1.108567
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.1689e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.892032
Average KL loss: 0.178101
Average total loss: 1.070134
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.5719e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.896771
Average KL loss: 0.178264
Average total loss: 1.075035
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.3170e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.900230
Average KL loss: 0.178557
Average total loss: 1.078787
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.1845e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.903995
Average KL loss: 0.179093
Average total loss: 1.083088
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.8838e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.879626
Average KL loss: 0.179362
Average total loss: 1.058988
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.9710e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.886193
Average KL loss: 0.179682
Average total loss: 1.065875
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.8757e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.868396
Average KL loss: 0.180021
Average total loss: 1.048416
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.7898e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.844870
Average KL loss: 0.180314
Average total loss: 1.025184
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.9607e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.892774
Average KL loss: 0.180599
Average total loss: 1.073374
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.5572e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.856281
Average KL loss: 0.180988
Average total loss: 1.037269
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.8427e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.851008
Average KL loss: 0.181358
Average total loss: 1.032366
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.0642e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.849104
Average KL loss: 0.181579
Average total loss: 1.030683
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.8970e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.843469
Average KL loss: 0.181881
Average total loss: 1.025350
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.8151e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.833266
Average KL loss: 0.182096
Average total loss: 1.015362
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.5267e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.839759
Average KL loss: 0.182332
Average total loss: 1.022091
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.6431e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.846903
Average KL loss: 0.182620
Average total loss: 1.029523
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.8869e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.835258
Average KL loss: 0.182889
Average total loss: 1.018147
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.1800e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.828364
Average KL loss: 0.183215
Average total loss: 1.011579
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.5970e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.831798
Average KL loss: 0.183328
Average total loss: 1.015127
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-6.6623e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.825822
Average KL loss: 0.183649
Average total loss: 1.009471
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.8737e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.817709
Average KL loss: 0.183780
Average total loss: 1.001489
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.6676e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.804129
Average KL loss: 0.184038
Average total loss: 0.988167
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.5496e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.802797
Average KL loss: 0.184234
Average total loss: 0.987031
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-6.9144e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.812761
Average KL loss: 0.184520
Average total loss: 0.997281
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.4151e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.800076
Average KL loss: 0.184765
Average total loss: 0.984840
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.3200e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.798539
Average KL loss: 0.185095
Average total loss: 0.983635
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.4124e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.789287
Average KL loss: 0.185345
Average total loss: 0.974632
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.1052e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.790501
Average KL loss: 0.185640
Average total loss: 0.976141
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.1864e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.783325
Average KL loss: 0.185752
Average total loss: 0.969077
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.8752e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.800556
Average KL loss: 0.186054
Average total loss: 0.986610
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-6.3353e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.783723
Average KL loss: 0.186370
Average total loss: 0.970093
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.4084e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.778196
Average KL loss: 0.186553
Average total loss: 0.964749
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.9434e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.773730
Average KL loss: 0.186692
Average total loss: 0.960422
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-5.7889e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.755839
Average KL loss: 0.186815
Average total loss: 0.942653
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-5.5519e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.753303
Average KL loss: 0.187008
Average total loss: 0.940311
 Percentile value: -9.98900674176184e-08
Non-zero model percentage: 64.0%, Non-zero mask percentage: 64.0%

--- Pruning Level [2/24]: ---
conv1.weight         | nonzeros =    1383 /    1728             ( 80.03%) | total_pruned =     345 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   30934 /   36864             ( 83.91%) | total_pruned =    5930 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   24050 /   36864             ( 65.24%) | total_pruned =   12814 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   20747 /   36864             ( 56.28%) | total_pruned =   16117 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   20848 /   36864             ( 56.55%) | total_pruned =   16016 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   29793 /   73728             ( 40.41%) | total_pruned =   43935 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   54873 /  147456             ( 37.21%) | total_pruned =   92583 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3662 /    8192             ( 44.70%) | total_pruned =    4530 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   88291 /  147456             ( 59.88%) | total_pruned =   59165 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  101341 /  147456             ( 68.73%) | total_pruned =   46115 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  102418 /  294912             ( 34.73%) | total_pruned =  192494 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  225029 /  589824             ( 38.15%) | total_pruned =  364795 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   14915 /   32768             ( 45.52%) | total_pruned =   17853 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     173 /     256             ( 67.58%) | total_pruned =      83 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  364627 /  589824             ( 61.82%) | total_pruned =  225197 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     109 /     256             ( 42.58%) | total_pruned =     147 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  427412 /  589824             ( 72.46%) | total_pruned =  162412 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  536162 / 1179648             ( 45.45%) | total_pruned =  643486 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     395 /     512             ( 77.15%) | total_pruned =     117 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     117 /     512             ( 22.85%) | total_pruned =     395 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1493423 / 2359296             ( 63.30%) | total_pruned =  865873 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     357 /     512             ( 69.73%) | total_pruned =     155 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     111 /     512             ( 21.68%) | total_pruned =     401 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   77630 /  131072             ( 59.23%) | total_pruned =   53442 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     348 /     512             ( 67.97%) | total_pruned =     164 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     107 /     512             ( 20.90%) | total_pruned =     405 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1647207 / 2359296             ( 69.82%) | total_pruned =  712089 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     390 /     512             ( 76.17%) | total_pruned =     122 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1877657 / 2359296             ( 79.59%) | total_pruned =  481639 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     209 /     512             ( 40.82%) | total_pruned =     303 | shape = torch.Size([512])
linear.weight        | nonzeros =    2398 /    5120             ( 46.84%) | total_pruned =    2722 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       5 /      10             ( 50.00%) | total_pruned =       5 | shape = torch.Size([10])
alive: 7154408, pruned : 4024354, total: 11178762, Compression rate :       1.56x  ( 36.00% pruned)
Train Epoch: 57/100 Loss: 0.013141 Accuracy: 88.91 100.00 % Best test Accuracy: 88.99%
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-6.9121e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.279161
Average KL loss: 0.174042
Average total loss: 1.453203
tensor(0.0027, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.5813e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.214315
Average KL loss: 0.162799
Average total loss: 1.377113
tensor(0.0029, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.7889e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.180045
Average KL loss: 0.158512
Average total loss: 1.338558
tensor(0.0029, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-6.1923e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.148943
Average KL loss: 0.156820
Average total loss: 1.305763
tensor(0.0029, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-6.4014e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.136240
Average KL loss: 0.156437
Average total loss: 1.292677
tensor(0.0029, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.9720e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.101508
Average KL loss: 0.156833
Average total loss: 1.258342
tensor(0.0029, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.7587e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.112397
Average KL loss: 0.157652
Average total loss: 1.270049
tensor(0.0029, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.9971e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.070430
Average KL loss: 0.158547
Average total loss: 1.228977
tensor(0.0029, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.4310e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.068530
Average KL loss: 0.159733
Average total loss: 1.228263
tensor(0.0029, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.7407e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.052216
Average KL loss: 0.161018
Average total loss: 1.213235
tensor(0.0028, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.6969e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.017896
Average KL loss: 0.162327
Average total loss: 1.180222
tensor(0.0028, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-7.0520e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.032555
Average KL loss: 0.163613
Average total loss: 1.196168
tensor(0.0028, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.0054e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.010879
Average KL loss: 0.164916
Average total loss: 1.175795
tensor(0.0028, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.0546e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.001704
Average KL loss: 0.166286
Average total loss: 1.167990
tensor(0.0028, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.7192e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.972480
Average KL loss: 0.167655
Average total loss: 1.140135
tensor(0.0027, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.7252e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.971372
Average KL loss: 0.168745
Average total loss: 1.140118
tensor(0.0027, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.2802e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.947206
Average KL loss: 0.169906
Average total loss: 1.117112
tensor(0.0027, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.1577e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.954459
Average KL loss: 0.170971
Average total loss: 1.125429
tensor(0.0027, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.3315e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.939604
Average KL loss: 0.172297
Average total loss: 1.111901
tensor(0.0027, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.6371e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.939149
Average KL loss: 0.173431
Average total loss: 1.112580
tensor(0.0027, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.0215e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.895298
Average KL loss: 0.174548
Average total loss: 1.069846
tensor(0.0027, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.8787e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.910912
Average KL loss: 0.175448
Average total loss: 1.086360
tensor(0.0026, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.5132e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.911667
Average KL loss: 0.176476
Average total loss: 1.088143
tensor(0.0026, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.9368e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.923085
Average KL loss: 0.177487
Average total loss: 1.100572
tensor(0.0026, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.6164e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.879732
Average KL loss: 0.178284
Average total loss: 1.058016
tensor(0.0026, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.9115e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.875739
Average KL loss: 0.179035
Average total loss: 1.054774
tensor(0.0026, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.7162e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.871880
Average KL loss: 0.179892
Average total loss: 1.051771
tensor(0.0026, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.6925e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.864116
Average KL loss: 0.180839
Average total loss: 1.044955
tensor(0.0026, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.4921e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.870450
Average KL loss: 0.181816
Average total loss: 1.052266
tensor(0.0026, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.7046e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.874634
Average KL loss: 0.182859
Average total loss: 1.057493
tensor(0.0026, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.8374e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.831657
Average KL loss: 0.183640
Average total loss: 1.015297
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.3030e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.840835
Average KL loss: 0.184290
Average total loss: 1.025125
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.7925e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.834659
Average KL loss: 0.184880
Average total loss: 1.019539
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.9645e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.832834
Average KL loss: 0.185561
Average total loss: 1.018395
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.9549e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.818288
Average KL loss: 0.186237
Average total loss: 1.004525
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.3322e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.815427
Average KL loss: 0.186770
Average total loss: 1.002197
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.1232e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.840278
Average KL loss: 0.187340
Average total loss: 1.027618
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.8793e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.808722
Average KL loss: 0.188007
Average total loss: 0.996729
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.3812e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.803345
Average KL loss: 0.188601
Average total loss: 0.991946
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-6.0390e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.801859
Average KL loss: 0.189313
Average total loss: 0.991172
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.3019e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.785235
Average KL loss: 0.189931
Average total loss: 0.975165
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.5890e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.805186
Average KL loss: 0.190424
Average total loss: 0.995610
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-6.9182e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.771773
Average KL loss: 0.190957
Average total loss: 0.962730
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-5.0092e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.784944
Average KL loss: 0.191339
Average total loss: 0.976283
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.2525e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.781265
Average KL loss: 0.191904
Average total loss: 0.973169
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.8394e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.782821
Average KL loss: 0.192505
Average total loss: 0.975326
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.0795e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.772211
Average KL loss: 0.193138
Average total loss: 0.965349
tensor(0.0024, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.2129e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.780425
Average KL loss: 0.193698
Average total loss: 0.974123
tensor(0.0024, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.3755e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.775338
Average KL loss: 0.194304
Average total loss: 0.969642
tensor(0.0024, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.3918e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.770973
Average KL loss: 0.194885
Average total loss: 0.965858
tensor(0.0024, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.0540e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.756857
Average KL loss: 0.195256
Average total loss: 0.952113
tensor(0.0024, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.1696e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.756163
Average KL loss: 0.195601
Average total loss: 0.951763
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.1540e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.756551
Average KL loss: 0.195924
Average total loss: 0.952475
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.5533e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.758645
Average KL loss: 0.196286
Average total loss: 0.954932
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.1780e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.739006
Average KL loss: 0.196617
Average total loss: 0.935623
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.5887e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.731524
Average KL loss: 0.196926
Average total loss: 0.928450
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.4528e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.730736
Average KL loss: 0.197313
Average total loss: 0.928049
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.7214e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.736270
Average KL loss: 0.197668
Average total loss: 0.933938
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.9937e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.726456
Average KL loss: 0.198136
Average total loss: 0.924592
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.6353e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.706565
Average KL loss: 0.198424
Average total loss: 0.904989
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.2386e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.716033
Average KL loss: 0.198780
Average total loss: 0.914813
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.3491e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.696515
Average KL loss: 0.199069
Average total loss: 0.895584
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.8716e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.726732
Average KL loss: 0.199372
Average total loss: 0.926104
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.1827e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.704335
Average KL loss: 0.199692
Average total loss: 0.904027
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.2645e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.708067
Average KL loss: 0.199871
Average total loss: 0.907938
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.8418e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.702750
Average KL loss: 0.200304
Average total loss: 0.903054
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.6501e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.726708
Average KL loss: 0.200663
Average total loss: 0.927370
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.2445e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.695112
Average KL loss: 0.201083
Average total loss: 0.896195
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.3647e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.692661
Average KL loss: 0.201346
Average total loss: 0.894007
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.6724e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.703019
Average KL loss: 0.201599
Average total loss: 0.904618
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.1944e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.684244
Average KL loss: 0.201942
Average total loss: 0.886186
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.4096e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.681180
Average KL loss: 0.202101
Average total loss: 0.883281
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.0483e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.683687
Average KL loss: 0.202269
Average total loss: 0.885956
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.0117e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.678293
Average KL loss: 0.202431
Average total loss: 0.880724
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.3038e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.679057
Average KL loss: 0.202595
Average total loss: 0.881652
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.1691e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.679946
Average KL loss: 0.202865
Average total loss: 0.882811
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.4936e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.680085
Average KL loss: 0.203136
Average total loss: 0.883221
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-5.7620e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.666087
Average KL loss: 0.203287
Average total loss: 0.869374
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.6053e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.690013
Average KL loss: 0.203492
Average total loss: 0.893505
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.9072e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.660401
Average KL loss: 0.203827
Average total loss: 0.864228
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.0425e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.662040
Average KL loss: 0.203977
Average total loss: 0.866016
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.6235e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.642163
Average KL loss: 0.204144
Average total loss: 0.846306
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.8808e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.669058
Average KL loss: 0.204419
Average total loss: 0.873476
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.3963e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.640305
Average KL loss: 0.204723
Average total loss: 0.845028
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.6594e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.646592
Average KL loss: 0.204848
Average total loss: 0.851440
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.8226e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.654174
Average KL loss: 0.205145
Average total loss: 0.859318
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.4083e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.639575
Average KL loss: 0.205297
Average total loss: 0.844872
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.3096e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.647973
Average KL loss: 0.205464
Average total loss: 0.853437
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.9855e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.649279
Average KL loss: 0.205710
Average total loss: 0.854989
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-6.8528e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.646096
Average KL loss: 0.205898
Average total loss: 0.851994
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.1360e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.634847
Average KL loss: 0.206081
Average total loss: 0.840928
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.8710e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.621214
Average KL loss: 0.206266
Average total loss: 0.827480
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.5392e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.636622
Average KL loss: 0.206404
Average total loss: 0.843027
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.8004e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.631880
Average KL loss: 0.206599
Average total loss: 0.838479
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.9303e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.636845
Average KL loss: 0.206719
Average total loss: 0.843564
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-3.0217e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.639792
Average KL loss: 0.206956
Average total loss: 0.846748
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.0834e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.637447
Average KL loss: 0.207255
Average total loss: 0.844701
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.6462e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.629584
Average KL loss: 0.207512
Average total loss: 0.837096
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-5.0179e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.613304
Average KL loss: 0.207791
Average total loss: 0.821094
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-3.3120e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.620878
Average KL loss: 0.207934
Average total loss: 0.828812
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.5751e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.627840
Average KL loss: 0.208009
Average total loss: 0.835849
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.0064e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.611946
Average KL loss: 0.208104
Average total loss: 0.820051
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.8867e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.621434
Average KL loss: 0.208109
Average total loss: 0.829543
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.6788e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.603431
Average KL loss: 0.208240
Average total loss: 0.811670
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.7862e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.600943
Average KL loss: 0.208234
Average total loss: 0.809177
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.1535e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.614154
Average KL loss: 0.208336
Average total loss: 0.822490
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.5395e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.620345
Average KL loss: 0.208470
Average total loss: 0.828815
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.9948e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.593349
Average KL loss: 0.208675
Average total loss: 0.802024
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.3491e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.587510
Average KL loss: 0.208685
Average total loss: 0.796195
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.7263e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.583578
Average KL loss: 0.208649
Average total loss: 0.792227
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-3.9135e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.602664
Average KL loss: 0.208731
Average total loss: 0.811395
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.4029e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.594814
Average KL loss: 0.208835
Average total loss: 0.803649
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.3902e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.606155
Average KL loss: 0.208888
Average total loss: 0.815043
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.7888e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.594591
Average KL loss: 0.209064
Average total loss: 0.803655
tensor(0.0023, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.7116e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.584026
Average KL loss: 0.209255
Average total loss: 0.793280
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.5752e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.595739
Average KL loss: 0.209511
Average total loss: 0.805250
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.2859e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.591682
Average KL loss: 0.209708
Average total loss: 0.801390
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-5.1986e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.586611
Average KL loss: 0.209816
Average total loss: 0.796427
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.1429e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.586745
Average KL loss: 0.210020
Average total loss: 0.796764
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.9445e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.582671
Average KL loss: 0.210260
Average total loss: 0.792931
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.4837e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.576195
Average KL loss: 0.210272
Average total loss: 0.786467
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.6486e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.574216
Average KL loss: 0.210353
Average total loss: 0.784569
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.3894e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.573242
Average KL loss: 0.210426
Average total loss: 0.783668
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-4.3371e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.564284
Average KL loss: 0.210538
Average total loss: 0.774823
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.0426e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.597726
Average KL loss: 0.210692
Average total loss: 0.808419
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.5010e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.571833
Average KL loss: 0.210944
Average total loss: 0.782777
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.8322e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.565351
Average KL loss: 0.211003
Average total loss: 0.776354
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.2516e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.576709
Average KL loss: 0.211036
Average total loss: 0.787745
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.9125e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.563895
Average KL loss: 0.211207
Average total loss: 0.775102
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.4380e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.558112
Average KL loss: 0.211156
Average total loss: 0.769268
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.0783e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.566391
Average KL loss: 0.211150
Average total loss: 0.777541
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.3921e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.571430
Average KL loss: 0.211251
Average total loss: 0.782681
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.4354e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.561031
Average KL loss: 0.211445
Average total loss: 0.772476
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.7979e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.551458
Average KL loss: 0.211401
Average total loss: 0.762859
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.1406e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.551827
Average KL loss: 0.211430
Average total loss: 0.763257
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.9455e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.559131
Average KL loss: 0.211596
Average total loss: 0.770727
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.5052e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.552765
Average KL loss: 0.211781
Average total loss: 0.764547
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.0798e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.548152
Average KL loss: 0.211917
Average total loss: 0.760069
tensor(0.0023, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.4601e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.546301
Average KL loss: 0.212019
Average total loss: 0.758320
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.2257e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.560469
Average KL loss: 0.212087
Average total loss: 0.772556
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-8.8141e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.529366
Average KL loss: 0.212166
Average total loss: 0.741532
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.2187e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.543847
Average KL loss: 0.212162
Average total loss: 0.756008
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.3614e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.547041
Average KL loss: 0.212318
Average total loss: 0.759359
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.8145e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.545720
Average KL loss: 0.212514
Average total loss: 0.758234
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.4792e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.532198
Average KL loss: 0.212671
Average total loss: 0.744869
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.6375e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.533599
Average KL loss: 0.212701
Average total loss: 0.746300
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.7186e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.537230
Average KL loss: 0.212726
Average total loss: 0.749956
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.4968e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.533187
Average KL loss: 0.212689
Average total loss: 0.745876
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.2589e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.547816
Average KL loss: 0.212841
Average total loss: 0.760657
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-5.6450e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.541456
Average KL loss: 0.212995
Average total loss: 0.754451
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.9456e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.528005
Average KL loss: 0.212992
Average total loss: 0.740998
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.9716e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.529671
Average KL loss: 0.213006
Average total loss: 0.742677
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.6532e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.522288
Average KL loss: 0.213025
Average total loss: 0.735312
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.6541e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.535115
Average KL loss: 0.213094
Average total loss: 0.748208
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.2616e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.541604
Average KL loss: 0.213370
Average total loss: 0.754974
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.5645e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.519400
Average KL loss: 0.213410
Average total loss: 0.732810
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.9791e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.524104
Average KL loss: 0.213282
Average total loss: 0.737386
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.4718e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.524896
Average KL loss: 0.213348
Average total loss: 0.738244
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.9608e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.523102
Average KL loss: 0.213426
Average total loss: 0.736528
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-3.3520e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.526530
Average KL loss: 0.213509
Average total loss: 0.740039
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.0501e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.523579
Average KL loss: 0.213525
Average total loss: 0.737104
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.1370e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.518198
Average KL loss: 0.213592
Average total loss: 0.731790
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.9035e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.514504
Average KL loss: 0.213591
Average total loss: 0.728094
tensor(0.0023, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.5568e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.515639
Average KL loss: 0.213664
Average total loss: 0.729303
tensor(0.0023, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.1470e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.523371
Average KL loss: 0.213762
Average total loss: 0.737134
tensor(0.0023, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.5164e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.524052
Average KL loss: 0.213955
Average total loss: 0.738007
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.5301e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.506165
Average KL loss: 0.214003
Average total loss: 0.720168
tensor(0.0023, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.1784e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.514585
Average KL loss: 0.214044
Average total loss: 0.728629
tensor(0.0023, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.0190e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.518918
Average KL loss: 0.214103
Average total loss: 0.733022
tensor(0.0023, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3742e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.510320
Average KL loss: 0.214227
Average total loss: 0.724548
tensor(0.0023, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.7550e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.508432
Average KL loss: 0.214279
Average total loss: 0.722710
tensor(0.0023, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-9.5978e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.506475
Average KL loss: 0.214317
Average total loss: 0.720792
tensor(0.0023, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.7572e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.494036
Average KL loss: 0.214399
Average total loss: 0.708435
tensor(0.0023, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.1362e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.505866
Average KL loss: 0.214351
Average total loss: 0.720217
tensor(0.0023, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.0469e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.504131
Average KL loss: 0.214419
Average total loss: 0.718550
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.4570e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.508152
Average KL loss: 0.214519
Average total loss: 0.722671
tensor(0.0023, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.8966e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.495905
Average KL loss: 0.214578
Average total loss: 0.710483
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.9758e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.496332
Average KL loss: 0.214678
Average total loss: 0.711011
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.2887e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.505789
Average KL loss: 0.214759
Average total loss: 0.720547
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.2719e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.498944
Average KL loss: 0.214841
Average total loss: 0.713784
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.2504e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.501121
Average KL loss: 0.214897
Average total loss: 0.716018
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.3550e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.496373
Average KL loss: 0.214960
Average total loss: 0.711333
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.5758e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.487014
Average KL loss: 0.214990
Average total loss: 0.702003
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.3549e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.487089
Average KL loss: 0.214990
Average total loss: 0.702079
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.7629e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.487847
Average KL loss: 0.215163
Average total loss: 0.703010
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.6100e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.500323
Average KL loss: 0.215324
Average total loss: 0.715647
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.6776e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.493697
Average KL loss: 0.215322
Average total loss: 0.709019
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3530e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.482209
Average KL loss: 0.215308
Average total loss: 0.697517
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.8205e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.484140
Average KL loss: 0.215317
Average total loss: 0.699457
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.9266e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.493643
Average KL loss: 0.215267
Average total loss: 0.708910
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.2832e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.487427
Average KL loss: 0.215307
Average total loss: 0.702734
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.3375e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.482478
Average KL loss: 0.215293
Average total loss: 0.697771
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-8.5408e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.493369
Average KL loss: 0.215328
Average total loss: 0.708696
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.3447e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.473169
Average KL loss: 0.215360
Average total loss: 0.688529
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.0634e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.487590
Average KL loss: 0.215363
Average total loss: 0.702953
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.8532e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.482722
Average KL loss: 0.215476
Average total loss: 0.698198
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.2296e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.482063
Average KL loss: 0.215457
Average total loss: 0.697520
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.5944e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.471958
Average KL loss: 0.215476
Average total loss: 0.687434
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.6480e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.477973
Average KL loss: 0.215492
Average total loss: 0.693465
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.2482e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.475611
Average KL loss: 0.215519
Average total loss: 0.691130
 Percentile value: -7.255880660750335e-08
Non-zero model percentage: 51.200008392333984%, Non-zero mask percentage: 51.200008392333984%

--- Pruning Level [3/24]: ---
conv1.weight         | nonzeros =    1342 /    1728             ( 77.66%) | total_pruned =     386 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.weight           | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
bn1.bias             | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   29994 /   36864             ( 81.36%) | total_pruned =    6870 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   21511 /   36864             ( 58.35%) | total_pruned =   15353 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   17223 /   36864             ( 46.72%) | total_pruned =   19641 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   16959 /   36864             ( 46.00%) | total_pruned =   19905 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   19906 /   73728             ( 27.00%) | total_pruned =   53822 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   35178 /  147456             ( 23.86%) | total_pruned =  112278 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2741 /    8192             ( 33.46%) | total_pruned =    5451 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   71811 /  147456             ( 48.70%) | total_pruned =   75645 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   88194 /  147456             ( 59.81%) | total_pruned =   59262 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   63233 /  294912             ( 21.44%) | total_pruned =  231679 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  149784 /  589824             ( 25.39%) | total_pruned =  440040 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      28 /     256             ( 10.94%) | total_pruned =     228 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   11233 /   32768             ( 34.28%) | total_pruned =   21535 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  292729 /  589824             ( 49.63%) | total_pruned =  297095 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  365646 /  589824             ( 61.99%) | total_pruned =  224178 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  378867 / 1179648             ( 32.12%) | total_pruned =  800781 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     392 /     512             ( 76.56%) | total_pruned =     120 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     113 /     512             ( 22.07%) | total_pruned =     399 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1209799 / 2359296             ( 51.28%) | total_pruned = 1149497 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     332 /     512             ( 64.84%) | total_pruned =     180 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   60716 /  131072             ( 46.32%) | total_pruned =   70356 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     292 /     512             ( 57.03%) | total_pruned =     220 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      91 /     512             ( 17.77%) | total_pruned =     421 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1320164 / 2359296             ( 55.96%) | total_pruned = 1039132 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     365 /     512             ( 71.29%) | total_pruned =     147 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      87 /     512             ( 16.99%) | total_pruned =     425 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1555082 / 2359296             ( 65.91%) | total_pruned =  804214 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     468 /     512             ( 91.41%) | total_pruned =      44 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     184 /     512             ( 35.94%) | total_pruned =     328 | shape = torch.Size([512])
linear.weight        | nonzeros =    2129 /    5120             ( 41.58%) | total_pruned =    2991 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 5723527, pruned : 5455235, total: 11178762, Compression rate :       1.95x  ( 48.80% pruned)
Train Epoch: 80/100 Loss: 0.011781 Accuracy: 88.47 100.00 % Best test Accuracy: 88.70%
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-6.7977e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.869497
Average KL loss: 0.207576
Average total loss: 1.077073
tensor(0.0028, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.6006e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.848095
Average KL loss: 0.200509
Average total loss: 1.048604
tensor(0.0028, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.6870e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.833075
Average KL loss: 0.197594
Average total loss: 1.030669
tensor(0.0029, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-4.4301e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.793789
Average KL loss: 0.196203
Average total loss: 0.989993
tensor(0.0029, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-4.1089e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.791827
Average KL loss: 0.195739
Average total loss: 0.987566
tensor(0.0028, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-3.2241e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.751488
Average KL loss: 0.195609
Average total loss: 0.947096
tensor(0.0028, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-4.5043e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.742137
Average KL loss: 0.195896
Average total loss: 0.938034
tensor(0.0028, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-4.0620e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.742992
Average KL loss: 0.196321
Average total loss: 0.939313
tensor(0.0028, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.6663e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.744327
Average KL loss: 0.196860
Average total loss: 0.941187
tensor(0.0028, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.5928e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.705535
Average KL loss: 0.197450
Average total loss: 0.902985
tensor(0.0028, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.5036e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.707303
Average KL loss: 0.198000
Average total loss: 0.905303
tensor(0.0028, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.8535e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.707770
Average KL loss: 0.198680
Average total loss: 0.906451
tensor(0.0027, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.9020e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.687672
Average KL loss: 0.199357
Average total loss: 0.887030
tensor(0.0027, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.0727e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.699945
Average KL loss: 0.200015
Average total loss: 0.899960
tensor(0.0027, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3134e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.668310
Average KL loss: 0.200684
Average total loss: 0.868994
tensor(0.0027, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.6056e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.679413
Average KL loss: 0.201349
Average total loss: 0.880762
tensor(0.0027, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.7037e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.675353
Average KL loss: 0.202126
Average total loss: 0.877479
tensor(0.0027, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.7649e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.661046
Average KL loss: 0.202820
Average total loss: 0.863867
tensor(0.0027, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.5430e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.663816
Average KL loss: 0.203445
Average total loss: 0.867261
tensor(0.0027, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.5907e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.644259
Average KL loss: 0.204036
Average total loss: 0.848295
tensor(0.0026, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.6851e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.638889
Average KL loss: 0.204599
Average total loss: 0.843488
tensor(0.0026, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.8996e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.640776
Average KL loss: 0.205062
Average total loss: 0.845839
tensor(0.0026, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.7275e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.638126
Average KL loss: 0.205634
Average total loss: 0.843760
tensor(0.0026, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.2367e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.628300
Average KL loss: 0.206128
Average total loss: 0.834428
tensor(0.0026, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.5180e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.623133
Average KL loss: 0.206624
Average total loss: 0.829757
tensor(0.0026, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.3413e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.634214
Average KL loss: 0.207077
Average total loss: 0.841291
tensor(0.0026, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.9110e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.622110
Average KL loss: 0.207562
Average total loss: 0.829672
tensor(0.0026, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.5589e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.625408
Average KL loss: 0.208038
Average total loss: 0.833446
tensor(0.0026, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.8755e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.619814
Average KL loss: 0.208487
Average total loss: 0.828300
tensor(0.0026, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.6044e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.628669
Average KL loss: 0.209024
Average total loss: 0.837693
tensor(0.0026, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.0327e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.610572
Average KL loss: 0.209450
Average total loss: 0.820022
tensor(0.0026, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.1026e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.604594
Average KL loss: 0.209844
Average total loss: 0.814438
tensor(0.0026, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.4972e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.608625
Average KL loss: 0.210168
Average total loss: 0.818793
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.7894e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.609640
Average KL loss: 0.210538
Average total loss: 0.820178
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.2621e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.611975
Average KL loss: 0.210978
Average total loss: 0.822953
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.4656e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.604206
Average KL loss: 0.211351
Average total loss: 0.815557
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.2051e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.575504
Average KL loss: 0.211619
Average total loss: 0.787123
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.7547e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.586381
Average KL loss: 0.211834
Average total loss: 0.798215
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.6846e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.584034
Average KL loss: 0.212289
Average total loss: 0.796323
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.1335e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.584649
Average KL loss: 0.212507
Average total loss: 0.797155
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.8755e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.581300
Average KL loss: 0.212819
Average total loss: 0.794120
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.4288e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.587206
Average KL loss: 0.212997
Average total loss: 0.800203
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.9196e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.584622
Average KL loss: 0.213428
Average total loss: 0.798050
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.4371e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.578326
Average KL loss: 0.213717
Average total loss: 0.792043
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-8.2868e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.580347
Average KL loss: 0.214036
Average total loss: 0.794383
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.9213e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.586240
Average KL loss: 0.214418
Average total loss: 0.800658
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.0392e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.577388
Average KL loss: 0.214717
Average total loss: 0.792104
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.0768e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.572926
Average KL loss: 0.214977
Average total loss: 0.787902
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.8678e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.553528
Average KL loss: 0.215086
Average total loss: 0.768614
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.1143e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.556204
Average KL loss: 0.215073
Average total loss: 0.771277
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.4386e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.572345
Average KL loss: 0.215068
Average total loss: 0.787413
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.0743e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.561639
Average KL loss: 0.215065
Average total loss: 0.776704
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.2539e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.568154
Average KL loss: 0.215069
Average total loss: 0.783223
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.0075e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.560912
Average KL loss: 0.215070
Average total loss: 0.775983
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.5557e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.579325
Average KL loss: 0.215069
Average total loss: 0.794394
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.9033e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.568509
Average KL loss: 0.215073
Average total loss: 0.783582
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.8899e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.567558
Average KL loss: 0.215075
Average total loss: 0.782633
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.2668e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.549491
Average KL loss: 0.215075
Average total loss: 0.764566
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.1242e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.568410
Average KL loss: 0.215072
Average total loss: 0.783482
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.3842e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.568677
Average KL loss: 0.215080
Average total loss: 0.783757
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.2965e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.572088
Average KL loss: 0.215087
Average total loss: 0.787174
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.4599e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.559812
Average KL loss: 0.215100
Average total loss: 0.774912
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.3158e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.560251
Average KL loss: 0.215106
Average total loss: 0.775356
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.0121e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.562058
Average KL loss: 0.215108
Average total loss: 0.777166
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.0681e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.563949
Average KL loss: 0.215111
Average total loss: 0.779060
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.8099e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.566731
Average KL loss: 0.215131
Average total loss: 0.781861
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.0621e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.572037
Average KL loss: 0.215139
Average total loss: 0.787176
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.9110e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.573830
Average KL loss: 0.215154
Average total loss: 0.788984
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.1092e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.556575
Average KL loss: 0.215167
Average total loss: 0.771742
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.3830e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.569554
Average KL loss: 0.215160
Average total loss: 0.784714
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.0901e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.553612
Average KL loss: 0.215160
Average total loss: 0.768772
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.4596e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.558806
Average KL loss: 0.215159
Average total loss: 0.773965
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.1642e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.570741
Average KL loss: 0.215159
Average total loss: 0.785900
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.8675e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.572619
Average KL loss: 0.215161
Average total loss: 0.787780
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.7058e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.566610
Average KL loss: 0.215162
Average total loss: 0.781772
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.8052e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.565479
Average KL loss: 0.215162
Average total loss: 0.780641
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.4958e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.581707
Average KL loss: 0.215162
Average total loss: 0.796869
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.2378e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.566687
Average KL loss: 0.215162
Average total loss: 0.781849
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.1246e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.563226
Average KL loss: 0.215161
Average total loss: 0.778388
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.9365e-08, device='cuda:0')
 Percentile value: 8.01272008743581e-08
Non-zero model percentage: 40.96000671386719%, Non-zero mask percentage: 40.96000671386719%

--- Pruning Level [4/24]: ---
conv1.weight         | nonzeros =    1156 /    1728             ( 66.90%) | total_pruned =     572 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
bn1.weight           | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
bn1.bias             | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   28200 /   36864             ( 76.50%) | total_pruned =    8664 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   18264 /   36864             ( 49.54%) | total_pruned =   18600 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   14635 /   36864             ( 39.70%) | total_pruned =   22229 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   14062 /   36864             ( 38.15%) | total_pruned =   22802 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   14616 /   73728             ( 19.82%) | total_pruned =   59112 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   24126 /  147456             ( 16.36%) | total_pruned =  123330 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2179 /    8192             ( 26.60%) | total_pruned =    6013 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   56804 /  147456             ( 38.52%) | total_pruned =   90652 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   72455 /  147456             ( 49.14%) | total_pruned =   75001 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   41783 /  294912             ( 14.17%) | total_pruned =  253129 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  104236 /  589824             ( 17.67%) | total_pruned =  485588 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    8613 /   32768             ( 26.28%) | total_pruned =   24155 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     155 /     256             ( 60.55%) | total_pruned =     101 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  229608 /  589824             ( 38.93%) | total_pruned =  360216 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      90 /     256             ( 35.16%) | total_pruned =     166 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  295337 /  589824             ( 50.07%) | total_pruned =  294487 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     200 /     256             ( 78.12%) | total_pruned =      56 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  272157 / 1179648             ( 23.07%) | total_pruned =  907491 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     427 /     512             ( 83.40%) | total_pruned =      85 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     390 /     512             ( 76.17%) | total_pruned =     122 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     101 /     512             ( 19.73%) | total_pruned =     411 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  971221 / 2359296             ( 41.17%) | total_pruned = 1388075 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     380 /     512             ( 74.22%) | total_pruned =     132 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     315 /     512             ( 61.52%) | total_pruned =     197 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   48071 /  131072             ( 36.68%) | total_pruned =   83001 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     394 /     512             ( 76.95%) | total_pruned =     118 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     246 /     512             ( 48.05%) | total_pruned =     266 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      85 /     512             ( 16.60%) | total_pruned =     427 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1070436 / 2359296             ( 45.37%) | total_pruned = 1288860 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     346 /     512             ( 67.58%) | total_pruned =     166 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      79 /     512             ( 15.43%) | total_pruned =     433 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1280926 / 2359296             ( 54.29%) | total_pruned = 1078370 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     352 /     512             ( 68.75%) | total_pruned =     160 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     427 /     512             ( 83.40%) | total_pruned =      85 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     164 /     512             ( 32.03%) | total_pruned =     348 | shape = torch.Size([512])
linear.weight        | nonzeros =    1888 /    5120             ( 36.88%) | total_pruned =    3232 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 4578822, pruned : 6599940, total: 11178762, Compression rate :       2.44x  ( 59.04% pruned)
Train Epoch: 55/100 Loss: 0.013817 Accuracy: 88.13 100.00 % Best test Accuracy: 88.30%
tensor(0.0025, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-5.4591e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.925484
Average KL loss: 0.208717
Average total loss: 1.134201
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.5961e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.891852
Average KL loss: 0.202963
Average total loss: 1.094815
tensor(0.0029, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.0232e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.886303
Average KL loss: 0.200724
Average total loss: 1.087027
tensor(0.0029, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.3970e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.877531
Average KL loss: 0.199886
Average total loss: 1.077417
tensor(0.0029, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.1135e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.869586
Average KL loss: 0.199734
Average total loss: 1.069319
tensor(0.0029, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.0925e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.849333
Average KL loss: 0.200065
Average total loss: 1.049398
tensor(0.0029, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.3546e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.829084
Average KL loss: 0.200609
Average total loss: 1.029693
tensor(0.0028, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.1895e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.817165
Average KL loss: 0.201255
Average total loss: 1.018420
tensor(0.0028, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.9185e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.838799
Average KL loss: 0.202032
Average total loss: 1.040831
tensor(0.0028, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.7407e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.806191
Average KL loss: 0.202823
Average total loss: 1.009013
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.6148e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.784101
Average KL loss: 0.203645
Average total loss: 0.987746
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.4676e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.768398
Average KL loss: 0.204502
Average total loss: 0.972900
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.7480e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.777024
Average KL loss: 0.205342
Average total loss: 0.982367
tensor(0.0027, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.7577e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.765132
Average KL loss: 0.206204
Average total loss: 0.971336
tensor(0.0027, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.0296e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.753659
Average KL loss: 0.207071
Average total loss: 0.960730
tensor(0.0027, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.4089e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.750365
Average KL loss: 0.207910
Average total loss: 0.958275
tensor(0.0027, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.5082e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.760702
Average KL loss: 0.208744
Average total loss: 0.969446
tensor(0.0027, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.6326e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.740476
Average KL loss: 0.209622
Average total loss: 0.950098
tensor(0.0027, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.2616e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.712146
Average KL loss: 0.210385
Average total loss: 0.922531
tensor(0.0027, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.8065e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.728379
Average KL loss: 0.211125
Average total loss: 0.939504
tensor(0.0027, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.1483e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.709581
Average KL loss: 0.211996
Average total loss: 0.921576
tensor(0.0027, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.8230e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.697839
Average KL loss: 0.212632
Average total loss: 0.910470
tensor(0.0027, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.9080e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.710149
Average KL loss: 0.213284
Average total loss: 0.923433
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.7544e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.702881
Average KL loss: 0.213929
Average total loss: 0.916811
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-4.1807e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.707364
Average KL loss: 0.214546
Average total loss: 0.921910
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.8884e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.701632
Average KL loss: 0.215230
Average total loss: 0.916862
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.4726e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.691874
Average KL loss: 0.215872
Average total loss: 0.907746
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.2067e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.698924
Average KL loss: 0.216462
Average total loss: 0.915386
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-8.4495e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.688518
Average KL loss: 0.217040
Average total loss: 0.905557
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.0603e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.684094
Average KL loss: 0.217670
Average total loss: 0.901764
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.1861e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.684670
Average KL loss: 0.218258
Average total loss: 0.902928
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.6771e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.660698
Average KL loss: 0.218785
Average total loss: 0.879483
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.2567e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.664739
Average KL loss: 0.219233
Average total loss: 0.883972
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.3294e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.661788
Average KL loss: 0.219748
Average total loss: 0.881536
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.2964e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.671494
Average KL loss: 0.220238
Average total loss: 0.891732
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.7142e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.660330
Average KL loss: 0.220731
Average total loss: 0.881060
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.1532e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.671058
Average KL loss: 0.221157
Average total loss: 0.892215
tensor(0.0025, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.1247e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.646915
Average KL loss: 0.221592
Average total loss: 0.868507
tensor(0.0025, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.1458e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.651796
Average KL loss: 0.222115
Average total loss: 0.873911
tensor(0.0025, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.9661e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.642487
Average KL loss: 0.222657
Average total loss: 0.865144
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.9891e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.646557
Average KL loss: 0.223208
Average total loss: 0.869765
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.2705e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.638387
Average KL loss: 0.223637
Average total loss: 0.862023
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-8.0240e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.643085
Average KL loss: 0.224116
Average total loss: 0.867201
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.2445e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.652368
Average KL loss: 0.224607
Average total loss: 0.876975
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-6.7018e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.631063
Average KL loss: 0.224970
Average total loss: 0.856032
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-7.5004e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.621389
Average KL loss: 0.225364
Average total loss: 0.846753
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.7420e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.627258
Average KL loss: 0.225770
Average total loss: 0.853028
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.6033e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.633355
Average KL loss: 0.226170
Average total loss: 0.859524
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.7840e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.649101
Average KL loss: 0.226583
Average total loss: 0.875685
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.3862e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.620903
Average KL loss: 0.226943
Average total loss: 0.847846
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.5810e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.634956
Average KL loss: 0.227338
Average total loss: 0.862294
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-7.7226e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.617196
Average KL loss: 0.227684
Average total loss: 0.844880
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.5835e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.616957
Average KL loss: 0.228054
Average total loss: 0.845011
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.3479e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.619033
Average KL loss: 0.228435
Average total loss: 0.847468
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-5.7162e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.624562
Average KL loss: 0.228824
Average total loss: 0.853386
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.1953e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.612924
Average KL loss: 0.229224
Average total loss: 0.842149
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.9249e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.611160
Average KL loss: 0.229603
Average total loss: 0.840763
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.7007e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.612489
Average KL loss: 0.229953
Average total loss: 0.842442
tensor(0.0025, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.0389e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.625201
Average KL loss: 0.230279
Average total loss: 0.855480
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.0015e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.618819
Average KL loss: 0.230659
Average total loss: 0.849478
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.8078e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.624618
Average KL loss: 0.230913
Average total loss: 0.855531
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.4542e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.606865
Average KL loss: 0.231266
Average total loss: 0.838131
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.0938e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.605068
Average KL loss: 0.231624
Average total loss: 0.836692
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.8200e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.614376
Average KL loss: 0.231995
Average total loss: 0.846372
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.3706e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.600318
Average KL loss: 0.232379
Average total loss: 0.832697
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-4.0690e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.592198
Average KL loss: 0.232738
Average total loss: 0.824935
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.6954e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.601577
Average KL loss: 0.232949
Average total loss: 0.834525
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.3187e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.604035
Average KL loss: 0.233206
Average total loss: 0.837241
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-6.3530e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.593086
Average KL loss: 0.233483
Average total loss: 0.826569
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.5399e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.598602
Average KL loss: 0.233754
Average total loss: 0.832357
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.3423e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.585084
Average KL loss: 0.234074
Average total loss: 0.819158
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.4105e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.585389
Average KL loss: 0.234363
Average total loss: 0.819752
tensor(0.0024, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.2506e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.592598
Average KL loss: 0.234603
Average total loss: 0.827201
tensor(0.0024, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-6.7175e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.574573
Average KL loss: 0.234800
Average total loss: 0.809373
tensor(0.0024, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.4828e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.582856
Average KL loss: 0.234975
Average total loss: 0.817830
tensor(0.0024, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.5706e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.585582
Average KL loss: 0.235114
Average total loss: 0.820696
tensor(0.0024, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.1771e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.578925
Average KL loss: 0.235302
Average total loss: 0.814227
tensor(0.0024, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.4909e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.575834
Average KL loss: 0.235479
Average total loss: 0.811313
tensor(0.0024, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.3743e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.572712
Average KL loss: 0.235638
Average total loss: 0.808350
tensor(0.0024, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.3233e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.576489
Average KL loss: 0.235842
Average total loss: 0.812331
tensor(0.0024, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.4878e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.577825
Average KL loss: 0.236070
Average total loss: 0.813894
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-7.5635e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.572001
Average KL loss: 0.236307
Average total loss: 0.808307
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-8.7715e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.573115
Average KL loss: 0.236456
Average total loss: 0.809571
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.1268e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.568140
Average KL loss: 0.236611
Average total loss: 0.804751
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.2109e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.583507
Average KL loss: 0.236876
Average total loss: 0.820383
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.0556e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.580654
Average KL loss: 0.237175
Average total loss: 0.817829
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.4031e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.564760
Average KL loss: 0.237372
Average total loss: 0.802131
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-5.1642e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.571600
Average KL loss: 0.237480
Average total loss: 0.809080
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-7.1033e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.559771
Average KL loss: 0.237671
Average total loss: 0.797442
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.3028e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.560434
Average KL loss: 0.237910
Average total loss: 0.798343
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.0414e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.559669
Average KL loss: 0.238080
Average total loss: 0.797748
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-9.4258e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.575146
Average KL loss: 0.238295
Average total loss: 0.813441
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.3138e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.558235
Average KL loss: 0.238567
Average total loss: 0.796802
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.4976e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.558038
Average KL loss: 0.238771
Average total loss: 0.796809
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.8013e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.577641
Average KL loss: 0.238988
Average total loss: 0.816629
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-4.4327e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.561309
Average KL loss: 0.239224
Average total loss: 0.800533
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.9993e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.559217
Average KL loss: 0.239379
Average total loss: 0.798596
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.5917e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.557741
Average KL loss: 0.239559
Average total loss: 0.797300
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.2334e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.565109
Average KL loss: 0.239765
Average total loss: 0.804874
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.6967e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.549189
Average KL loss: 0.240083
Average total loss: 0.789272
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.2314e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.565259
Average KL loss: 0.240283
Average total loss: 0.805541
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.1208e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.563729
Average KL loss: 0.240491
Average total loss: 0.804220
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.5441e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.563069
Average KL loss: 0.240713
Average total loss: 0.803782
tensor(0.0024, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.8839e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.558262
Average KL loss: 0.241000
Average total loss: 0.799262
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.4116e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.547912
Average KL loss: 0.241088
Average total loss: 0.789000
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.7152e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.550107
Average KL loss: 0.241196
Average total loss: 0.791303
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.6324e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.544900
Average KL loss: 0.241399
Average total loss: 0.786299
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-6.9423e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.549240
Average KL loss: 0.241524
Average total loss: 0.790764
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-5.7875e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.543425
Average KL loss: 0.241611
Average total loss: 0.785036
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.0333e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.540037
Average KL loss: 0.241733
Average total loss: 0.781771
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.9919e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.545871
Average KL loss: 0.241849
Average total loss: 0.787721
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.4179e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.550964
Average KL loss: 0.241951
Average total loss: 0.792915
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.0415e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.540002
Average KL loss: 0.242141
Average total loss: 0.782144
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.6366e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.548482
Average KL loss: 0.242258
Average total loss: 0.790740
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.8805e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.537709
Average KL loss: 0.242408
Average total loss: 0.780117
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.5649e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.535937
Average KL loss: 0.242550
Average total loss: 0.778486
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-8.4542e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.543691
Average KL loss: 0.242663
Average total loss: 0.786353
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.6594e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.554701
Average KL loss: 0.242807
Average total loss: 0.797509
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-5.7746e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.553180
Average KL loss: 0.243018
Average total loss: 0.796198
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-7.1114e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.534627
Average KL loss: 0.243167
Average total loss: 0.777793
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.8983e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.548367
Average KL loss: 0.243306
Average total loss: 0.791673
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.1009e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.544274
Average KL loss: 0.243477
Average total loss: 0.787751
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.2469e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.529619
Average KL loss: 0.243625
Average total loss: 0.773244
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.5605e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.536000
Average KL loss: 0.243724
Average total loss: 0.779724
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.6844e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.532225
Average KL loss: 0.243800
Average total loss: 0.776024
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-8.8576e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.533013
Average KL loss: 0.243900
Average total loss: 0.776913
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.7562e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.524725
Average KL loss: 0.244052
Average total loss: 0.768777
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-7.5490e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.532685
Average KL loss: 0.244171
Average total loss: 0.776856
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.0464e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.536569
Average KL loss: 0.244327
Average total loss: 0.780896
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.1251e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.531682
Average KL loss: 0.244501
Average total loss: 0.776183
tensor(0.0024, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.7805e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.535633
Average KL loss: 0.244636
Average total loss: 0.780269
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.0348e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.535036
Average KL loss: 0.244712
Average total loss: 0.779749
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.6716e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.529369
Average KL loss: 0.244783
Average total loss: 0.774152
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.7809e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.526196
Average KL loss: 0.244835
Average total loss: 0.771031
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.3094e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.519292
Average KL loss: 0.244902
Average total loss: 0.764194
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.7858e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.523839
Average KL loss: 0.244981
Average total loss: 0.768820
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2855e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.529243
Average KL loss: 0.245068
Average total loss: 0.774311
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.8598e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.534073
Average KL loss: 0.245221
Average total loss: 0.779294
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.4066e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.512908
Average KL loss: 0.245361
Average total loss: 0.758270
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.6592e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.523998
Average KL loss: 0.245410
Average total loss: 0.769408
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2775e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.512214
Average KL loss: 0.245523
Average total loss: 0.757737
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.0227e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.513424
Average KL loss: 0.245562
Average total loss: 0.758985
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.8590e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.526358
Average KL loss: 0.245648
Average total loss: 0.772006
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.3736e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.526569
Average KL loss: 0.245782
Average total loss: 0.772351
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.3749e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.507361
Average KL loss: 0.245869
Average total loss: 0.753230
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-8.9529e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.526198
Average KL loss: 0.245943
Average total loss: 0.772141
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.0446e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.519863
Average KL loss: 0.246080
Average total loss: 0.765943
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-4.1619e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.512540
Average KL loss: 0.246230
Average total loss: 0.758770
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.6095e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.521441
Average KL loss: 0.246337
Average total loss: 0.767778
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.9200e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.510548
Average KL loss: 0.246440
Average total loss: 0.756988
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-8.0384e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.514313
Average KL loss: 0.246521
Average total loss: 0.760834
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.9976e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.523554
Average KL loss: 0.246634
Average total loss: 0.770188
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2518e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.503394
Average KL loss: 0.246726
Average total loss: 0.750119
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.3283e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.513230
Average KL loss: 0.246813
Average total loss: 0.760044
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.1246e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.519691
Average KL loss: 0.246892
Average total loss: 0.766583
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.1607e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.511468
Average KL loss: 0.247041
Average total loss: 0.758509
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.8472e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.522068
Average KL loss: 0.247178
Average total loss: 0.769245
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.4352e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.515601
Average KL loss: 0.247396
Average total loss: 0.762997
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-4.8895e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.504903
Average KL loss: 0.247568
Average total loss: 0.752471
tensor(0.0024, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.0656e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.506766
Average KL loss: 0.247720
Average total loss: 0.754485
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.0487e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.503517
Average KL loss: 0.247838
Average total loss: 0.751355
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.7140e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.503702
Average KL loss: 0.247842
Average total loss: 0.751544
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.8356e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.513004
Average KL loss: 0.247847
Average total loss: 0.760850
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.9122e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.510781
Average KL loss: 0.247881
Average total loss: 0.758662
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0278e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.501752
Average KL loss: 0.247938
Average total loss: 0.749690
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.3408e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.501313
Average KL loss: 0.247927
Average total loss: 0.749240
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.2830e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.509984
Average KL loss: 0.247917
Average total loss: 0.757901
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.7465e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.496348
Average KL loss: 0.247906
Average total loss: 0.744254
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.1373e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.511692
Average KL loss: 0.247893
Average total loss: 0.759585
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.8792e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.520242
Average KL loss: 0.247886
Average total loss: 0.768128
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.0967e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.505237
Average KL loss: 0.247878
Average total loss: 0.753115
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.2118e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.501850
Average KL loss: 0.247877
Average total loss: 0.749728
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0398e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.494195
Average KL loss: 0.247874
Average total loss: 0.742069
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.3746e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.502352
Average KL loss: 0.247870
Average total loss: 0.750222
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.7400e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.504790
Average KL loss: 0.247858
Average total loss: 0.752647
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0515e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.514720
Average KL loss: 0.247847
Average total loss: 0.762567
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.8338e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.500174
Average KL loss: 0.247838
Average total loss: 0.748013
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.8422e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.503851
Average KL loss: 0.247837
Average total loss: 0.751688
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.5389e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.503370
Average KL loss: 0.247831
Average total loss: 0.751201
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.3044e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.508488
Average KL loss: 0.247817
Average total loss: 0.756305
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4819e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.502188
Average KL loss: 0.247808
Average total loss: 0.749996
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.6594e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.505030
Average KL loss: 0.247804
Average total loss: 0.752834
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4081e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.513256
Average KL loss: 0.247806
Average total loss: 0.761062
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2018e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.512674
Average KL loss: 0.247809
Average total loss: 0.760483
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.4234e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.509355
Average KL loss: 0.247812
Average total loss: 0.757168
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4073e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.503970
Average KL loss: 0.247812
Average total loss: 0.751782
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.2007e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.509643
Average KL loss: 0.247811
Average total loss: 0.757454
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.3422e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.501176
Average KL loss: 0.247810
Average total loss: 0.748986
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0334e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.502216
Average KL loss: 0.247810
Average total loss: 0.750025
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.1614e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.515699
Average KL loss: 0.247809
Average total loss: 0.763508
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.3167e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.496714
Average KL loss: 0.247809
Average total loss: 0.744522
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.6553e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.516301
Average KL loss: 0.247808
Average total loss: 0.764109
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.2974e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.511407
Average KL loss: 0.247808
Average total loss: 0.759214
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.2591e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.506469
Average KL loss: 0.247807
Average total loss: 0.754276
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.3829e-08, device='cuda:0')
 Percentile value: 8.096595394135875e-08
Non-zero model percentage: 32.76801300048828%, Non-zero mask percentage: 32.76801300048828%

--- Pruning Level [5/24]: ---
conv1.weight         | nonzeros =     705 /    1728             ( 40.80%) | total_pruned =    1023 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.weight           | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
bn1.bias             | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5464 /   36864             ( 14.82%) | total_pruned =   31400 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   12363 /   36864             ( 33.54%) | total_pruned =   24501 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    8766 /   36864             ( 23.78%) | total_pruned =   28098 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   11679 /   36864             ( 31.68%) | total_pruned =   25185 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   10967 /   73728             ( 14.87%) | total_pruned =   62761 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   17478 /  147456             ( 11.85%) | total_pruned =  129978 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1734 /    8192             ( 21.17%) | total_pruned =    6458 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   43406 /  147456             ( 29.44%) | total_pruned =  104050 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   57578 /  147456             ( 39.05%) | total_pruned =   89878 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   27725 /  294912             (  9.40%) | total_pruned =  267187 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   73549 /  589824             ( 12.47%) | total_pruned =  516275 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      87 /     256             ( 33.98%) | total_pruned =     169 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     224 /     256             ( 87.50%) | total_pruned =      32 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6751 /   32768             ( 20.60%) | total_pruned =   26017 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      79 /     256             ( 30.86%) | total_pruned =     177 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     144 /     256             ( 56.25%) | total_pruned =     112 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  184459 /  589824             ( 31.27%) | total_pruned =  405365 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      54 /     256             ( 21.09%) | total_pruned =     202 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  242395 /  589824             ( 41.10%) | total_pruned =  347429 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     147 /     256             ( 57.42%) | total_pruned =     109 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  192649 / 1179648             ( 16.33%) | total_pruned =  986999 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     382 /     512             ( 74.61%) | total_pruned =     130 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      77 /     512             ( 15.04%) | total_pruned =     435 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  764687 / 2359296             ( 32.41%) | total_pruned = 1594609 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     205 /     512             ( 40.04%) | total_pruned =     307 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     280 /     512             ( 54.69%) | total_pruned =     232 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      71 /     512             ( 13.87%) | total_pruned =     441 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   39120 /  131072             ( 29.85%) | total_pruned =   91952 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     107 /     512             ( 20.90%) | total_pruned =     405 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     213 /     512             ( 41.60%) | total_pruned =     299 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      70 /     512             ( 13.67%) | total_pruned =     442 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  888551 / 2359296             ( 37.66%) | total_pruned = 1470745 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     123 /     512             ( 24.02%) | total_pruned =     389 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     299 /     512             ( 58.40%) | total_pruned =     213 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1066094 / 2359296             ( 45.19%) | total_pruned = 1293202 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     142 /     512             ( 27.73%) | total_pruned =     370 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     375 /     512             ( 73.24%) | total_pruned =     137 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     142 /     512             ( 27.73%) | total_pruned =     370 | shape = torch.Size([512])
linear.weight        | nonzeros =    1591 /    5120             ( 31.07%) | total_pruned =    3529 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 3663058, pruned : 7515704, total: 11178762, Compression rate :       3.05x  ( 67.23% pruned)
Train Epoch: 61/100 Loss: 0.020561 Accuracy: 87.97 100.00 % Best test Accuracy: 88.19%
tensor(0.0024, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.9035e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.843547
Average KL loss: 0.242222
Average total loss: 1.085769
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.6279e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.851668
Average KL loss: 0.236305
Average total loss: 1.087973
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.6729e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.822872
Average KL loss: 0.233045
Average total loss: 1.055917
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.9124e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.822275
Average KL loss: 0.231081
Average total loss: 1.053356
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.0737e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.808837
Average KL loss: 0.229855
Average total loss: 1.038693
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.1753e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.791936
Average KL loss: 0.229091
Average total loss: 1.021027
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.4370e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.783515
Average KL loss: 0.228695
Average total loss: 1.012210
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.2548e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.771890
Average KL loss: 0.228553
Average total loss: 1.000443
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.2944e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.779229
Average KL loss: 0.228588
Average total loss: 1.007816
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.9142e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.761262
Average KL loss: 0.228767
Average total loss: 0.990028
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.4174e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.741432
Average KL loss: 0.228966
Average total loss: 0.970397
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.1159e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.746329
Average KL loss: 0.229221
Average total loss: 0.975550
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.0823e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.730886
Average KL loss: 0.229558
Average total loss: 0.960444
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.3405e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.721661
Average KL loss: 0.229967
Average total loss: 0.951628
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.2045e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.729710
Average KL loss: 0.230446
Average total loss: 0.960156
tensor(0.0026, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.7533e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.715118
Average KL loss: 0.230930
Average total loss: 0.946047
tensor(0.0026, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.3499e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.719551
Average KL loss: 0.231363
Average total loss: 0.950914
tensor(0.0026, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.7389e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.690323
Average KL loss: 0.231822
Average total loss: 0.922145
tensor(0.0026, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.3107e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.698202
Average KL loss: 0.232252
Average total loss: 0.930454
tensor(0.0026, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.6102e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.687896
Average KL loss: 0.232737
Average total loss: 0.920633
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.3017e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.696853
Average KL loss: 0.233213
Average total loss: 0.930065
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2776e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.698171
Average KL loss: 0.233656
Average total loss: 0.931827
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.2278e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.676584
Average KL loss: 0.234123
Average total loss: 0.910706
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.3130e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.681956
Average KL loss: 0.234547
Average total loss: 0.916503
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.2959e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.663637
Average KL loss: 0.234977
Average total loss: 0.898615
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.1431e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.657765
Average KL loss: 0.235438
Average total loss: 0.893203
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.6983e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.663357
Average KL loss: 0.235867
Average total loss: 0.899225
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.3075e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.665970
Average KL loss: 0.236324
Average total loss: 0.902294
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.0808e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.655442
Average KL loss: 0.236812
Average total loss: 0.892254
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-9.5061e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.643691
Average KL loss: 0.237190
Average total loss: 0.880880
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.3222e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.644203
Average KL loss: 0.237594
Average total loss: 0.881797
tensor(0.0026, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.4140e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.646327
Average KL loss: 0.237961
Average total loss: 0.884288
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.2190e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.640582
Average KL loss: 0.238391
Average total loss: 0.878973
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.1346e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.644798
Average KL loss: 0.238803
Average total loss: 0.883601
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.3876e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.639077
Average KL loss: 0.239190
Average total loss: 0.878267
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.3954e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.635025
Average KL loss: 0.239593
Average total loss: 0.874618
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.5149e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.631165
Average KL loss: 0.239975
Average total loss: 0.871141
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.7657e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.622773
Average KL loss: 0.240316
Average total loss: 0.863089
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.4004e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.639976
Average KL loss: 0.240665
Average total loss: 0.880642
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.4344e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.639874
Average KL loss: 0.241009
Average total loss: 0.880883
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.4216e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.637159
Average KL loss: 0.241367
Average total loss: 0.878525
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.1989e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.624581
Average KL loss: 0.241665
Average total loss: 0.866246
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.5539e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.633673
Average KL loss: 0.242025
Average total loss: 0.875697
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.3279e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.617779
Average KL loss: 0.242449
Average total loss: 0.860228
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.2534e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.626020
Average KL loss: 0.242828
Average total loss: 0.868847
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4353e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.617138
Average KL loss: 0.243183
Average total loss: 0.860321
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.1800e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.604142
Average KL loss: 0.243508
Average total loss: 0.847650
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.1888e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.608219
Average KL loss: 0.243839
Average total loss: 0.852058
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0095e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.613323
Average KL loss: 0.244110
Average total loss: 0.857433
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.7453e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.603859
Average KL loss: 0.244327
Average total loss: 0.848186
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.4011e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.609503
Average KL loss: 0.244666
Average total loss: 0.854169
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0863e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.597593
Average KL loss: 0.245029
Average total loss: 0.842622
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.8549e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.600607
Average KL loss: 0.245340
Average total loss: 0.845948
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.1453e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.600564
Average KL loss: 0.245651
Average total loss: 0.846214
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.3106e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.602182
Average KL loss: 0.246001
Average total loss: 0.848183
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.0453e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.602455
Average KL loss: 0.246332
Average total loss: 0.848786
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.7575e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.592373
Average KL loss: 0.246575
Average total loss: 0.838947
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.6677e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.591153
Average KL loss: 0.246886
Average total loss: 0.838039
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.5360e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.590729
Average KL loss: 0.247143
Average total loss: 0.837872
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.0285e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.598729
Average KL loss: 0.247420
Average total loss: 0.846150
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.4491e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.583993
Average KL loss: 0.247665
Average total loss: 0.831658
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3920e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.574938
Average KL loss: 0.247888
Average total loss: 0.822826
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.5138e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.571321
Average KL loss: 0.248143
Average total loss: 0.819465
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.9269e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.576252
Average KL loss: 0.248388
Average total loss: 0.824640
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4566e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.575024
Average KL loss: 0.248596
Average total loss: 0.823620
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.8175e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.579361
Average KL loss: 0.248800
Average total loss: 0.828161
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.7375e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.591647
Average KL loss: 0.248994
Average total loss: 0.840641
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.4196e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.578709
Average KL loss: 0.249280
Average total loss: 0.827989
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5041e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.577776
Average KL loss: 0.249545
Average total loss: 0.827321
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.9066e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.573461
Average KL loss: 0.249809
Average total loss: 0.823271
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.5079e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.586135
Average KL loss: 0.250052
Average total loss: 0.836187
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.3414e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.579034
Average KL loss: 0.250255
Average total loss: 0.829289
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.7119e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.586602
Average KL loss: 0.250474
Average total loss: 0.837076
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.6643e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.582686
Average KL loss: 0.250691
Average total loss: 0.833377
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1113e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.569493
Average KL loss: 0.250803
Average total loss: 0.820296
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.3639e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.567175
Average KL loss: 0.250815
Average total loss: 0.817989
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.1858e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.572075
Average KL loss: 0.250832
Average total loss: 0.822907
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.3869e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.566820
Average KL loss: 0.250841
Average total loss: 0.817661
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.9171e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.569164
Average KL loss: 0.250839
Average total loss: 0.820003
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.3694e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.567650
Average KL loss: 0.250843
Average total loss: 0.818493
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.9056e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.565334
Average KL loss: 0.250858
Average total loss: 0.816192
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5568e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.565256
Average KL loss: 0.250870
Average total loss: 0.816126
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.0846e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.563849
Average KL loss: 0.250878
Average total loss: 0.814727
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.5239e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.566850
Average KL loss: 0.250891
Average total loss: 0.817741
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1382e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.572930
Average KL loss: 0.250904
Average total loss: 0.823834
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1372e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.579494
Average KL loss: 0.250926
Average total loss: 0.830420
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.0677e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.585319
Average KL loss: 0.250945
Average total loss: 0.836264
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.8251e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.562836
Average KL loss: 0.250957
Average total loss: 0.813793
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1149e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.579474
Average KL loss: 0.250963
Average total loss: 0.830437
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.8736e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.567275
Average KL loss: 0.250979
Average total loss: 0.818254
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4358e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.569214
Average KL loss: 0.250998
Average total loss: 0.820212
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.0390e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.575139
Average KL loss: 0.251012
Average total loss: 0.826152
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.8937e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.574420
Average KL loss: 0.251031
Average total loss: 0.825450
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.8476e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.561306
Average KL loss: 0.251052
Average total loss: 0.812358
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.8020e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.554218
Average KL loss: 0.251063
Average total loss: 0.805281
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.9441e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.570134
Average KL loss: 0.251068
Average total loss: 0.821202
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.3107e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.581528
Average KL loss: 0.251088
Average total loss: 0.832616
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4736e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.574435
Average KL loss: 0.251106
Average total loss: 0.825541
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.6413e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.576914
Average KL loss: 0.251129
Average total loss: 0.828043
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.2684e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.570802
Average KL loss: 0.251148
Average total loss: 0.821950
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.4041e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.567364
Average KL loss: 0.251166
Average total loss: 0.818530
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4134e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.562006
Average KL loss: 0.251183
Average total loss: 0.813189
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.5645e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.576660
Average KL loss: 0.251196
Average total loss: 0.827856
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.8869e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.572792
Average KL loss: 0.251210
Average total loss: 0.824002
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-9.6789e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.566292
Average KL loss: 0.251226
Average total loss: 0.817518
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.6519e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.568087
Average KL loss: 0.251235
Average total loss: 0.819323
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.6846e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.560334
Average KL loss: 0.251240
Average total loss: 0.811574
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.0191e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.562447
Average KL loss: 0.251241
Average total loss: 0.813689
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.2867e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.558120
Average KL loss: 0.251243
Average total loss: 0.809362
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.4705e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.561237
Average KL loss: 0.251244
Average total loss: 0.812481
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.7490e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.568371
Average KL loss: 0.251246
Average total loss: 0.819617
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.5725e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.567169
Average KL loss: 0.251247
Average total loss: 0.818416
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.9280e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.576666
Average KL loss: 0.251248
Average total loss: 0.827914
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4790e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.572946
Average KL loss: 0.251249
Average total loss: 0.824195
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.5175e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.577485
Average KL loss: 0.251250
Average total loss: 0.828735
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1483e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.574704
Average KL loss: 0.251251
Average total loss: 0.825956
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.5787e-08, device='cuda:0')
 Percentile value: 7.980177230137997e-08
Non-zero model percentage: 26.214414596557617%, Non-zero mask percentage: 26.214414596557617%

--- Pruning Level [6/24]: ---
conv1.weight         | nonzeros =     555 /    1728             ( 32.12%) | total_pruned =    1173 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.weight           | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
bn1.bias             | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4328 /   36864             ( 11.74%) | total_pruned =   32536 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    9791 /   36864             ( 26.56%) | total_pruned =   27073 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    6840 /   36864             ( 18.55%) | total_pruned =   30024 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9163 /   36864             ( 24.86%) | total_pruned =   27701 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8301 /   73728             ( 11.26%) | total_pruned =   65427 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   13111 /  147456             (  8.89%) | total_pruned =  134345 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1352 /    8192             ( 16.50%) | total_pruned =    6840 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   34185 /  147456             ( 23.18%) | total_pruned =  113271 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   46056 /  147456             ( 31.23%) | total_pruned =  101400 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   19894 /  294912             (  6.75%) | total_pruned =  275018 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      57 /     256             ( 22.27%) | total_pruned =     199 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   54301 /  589824             (  9.21%) | total_pruned =  535523 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      62 /     256             ( 24.22%) | total_pruned =     194 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5191 /   32768             ( 15.84%) | total_pruned =   27577 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      58 /     256             ( 22.66%) | total_pruned =     198 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     130 /     256             ( 50.78%) | total_pruned =     126 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  144297 /  589824             ( 24.46%) | total_pruned =  445527 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      63 /     256             ( 24.61%) | total_pruned =     193 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  191878 /  589824             ( 32.53%) | total_pruned =  397946 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      65 /     256             ( 25.39%) | total_pruned =     191 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  144155 / 1179648             ( 12.22%) | total_pruned = 1035493 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     150 /     512             ( 29.30%) | total_pruned =     362 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      68 /     512             ( 13.28%) | total_pruned =     444 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  612028 / 2359296             ( 25.94%) | total_pruned = 1747268 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     171 /     512             ( 33.40%) | total_pruned =     341 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     236 /     512             ( 46.09%) | total_pruned =     276 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      58 /     512             ( 11.33%) | total_pruned =     454 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   31250 /  131072             ( 23.84%) | total_pruned =   99822 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      91 /     512             ( 17.77%) | total_pruned =     421 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     174 /     512             ( 33.98%) | total_pruned =     338 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      60 /     512             ( 11.72%) | total_pruned =     452 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  721262 / 2359296             ( 30.57%) | total_pruned = 1638034 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      98 /     512             ( 19.14%) | total_pruned =     414 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     254 /     512             ( 49.61%) | total_pruned =     258 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  866536 / 2359296             ( 36.73%) | total_pruned = 1492760 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     304 /     512             ( 59.38%) | total_pruned =     208 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
linear.weight        | nonzeros =    1352 /    5120             ( 26.41%) | total_pruned =    3768 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 2930447, pruned : 8248315, total: 11178762, Compression rate :       3.81x  ( 73.79% pruned)
Train Epoch: 57/100 Loss: 0.019429 Accuracy: 88.16 100.00 % Best test Accuracy: 88.31%
tensor(0.0024, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.0485e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.921880
Average KL loss: 0.246887
Average total loss: 1.168766
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.8976e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.896780
Average KL loss: 0.242620
Average total loss: 1.139400
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.9223e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.890436
Average KL loss: 0.240449
Average total loss: 1.130885
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.7760e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.874093
Average KL loss: 0.239209
Average total loss: 1.113302
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.7733e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.854239
Average KL loss: 0.238528
Average total loss: 1.092767
tensor(0.0027, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.3651e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.854119
Average KL loss: 0.238241
Average total loss: 1.092360
tensor(0.0027, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.5678e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.852682
Average KL loss: 0.238177
Average total loss: 1.090860
tensor(0.0027, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.3144e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.827540
Average KL loss: 0.238274
Average total loss: 1.065814
tensor(0.0027, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.9249e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.816115
Average KL loss: 0.238510
Average total loss: 1.054625
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.3188e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.809564
Average KL loss: 0.238801
Average total loss: 1.048365
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.8430e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.794617
Average KL loss: 0.239162
Average total loss: 1.033780
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.8295e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.790745
Average KL loss: 0.239565
Average total loss: 1.030310
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.0943e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.789311
Average KL loss: 0.240006
Average total loss: 1.029316
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.5093e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.780663
Average KL loss: 0.240492
Average total loss: 1.021155
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.9642e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.762660
Average KL loss: 0.240996
Average total loss: 1.003656
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2171e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.773157
Average KL loss: 0.241471
Average total loss: 1.014627
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.0318e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.756948
Average KL loss: 0.241992
Average total loss: 0.998941
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.6435e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.759329
Average KL loss: 0.242508
Average total loss: 1.001837
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.4261e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.747734
Average KL loss: 0.243017
Average total loss: 0.990752
tensor(0.0026, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.4491e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.751799
Average KL loss: 0.243505
Average total loss: 0.995304
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.0826e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.714438
Average KL loss: 0.244018
Average total loss: 0.958455
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.4946e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.725747
Average KL loss: 0.244514
Average total loss: 0.970261
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.0739e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.748434
Average KL loss: 0.245024
Average total loss: 0.993459
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.6520e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.716234
Average KL loss: 0.245560
Average total loss: 0.961794
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.2064e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.711472
Average KL loss: 0.246019
Average total loss: 0.957491
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.0077e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.714813
Average KL loss: 0.246490
Average total loss: 0.961303
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5453e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.715198
Average KL loss: 0.246987
Average total loss: 0.962185
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.0096e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.706205
Average KL loss: 0.247490
Average total loss: 0.953695
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.9345e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.708045
Average KL loss: 0.248002
Average total loss: 0.956047
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.2852e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.699895
Average KL loss: 0.248497
Average total loss: 0.948392
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.5596e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.697400
Average KL loss: 0.248959
Average total loss: 0.946359
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.2546e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.693358
Average KL loss: 0.249394
Average total loss: 0.942752
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.5054e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.703729
Average KL loss: 0.249814
Average total loss: 0.953543
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4655e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.702741
Average KL loss: 0.250257
Average total loss: 0.952998
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.0543e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.669113
Average KL loss: 0.250712
Average total loss: 0.919825
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1149e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.677693
Average KL loss: 0.251160
Average total loss: 0.928852
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.4102e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.667923
Average KL loss: 0.251574
Average total loss: 0.919497
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.2631e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.662927
Average KL loss: 0.251938
Average total loss: 0.914865
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.2915e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.677140
Average KL loss: 0.252357
Average total loss: 0.929498
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.4701e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.679724
Average KL loss: 0.252756
Average total loss: 0.932481
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-9.1377e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.671671
Average KL loss: 0.253155
Average total loss: 0.924826
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-9.7547e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.661493
Average KL loss: 0.253556
Average total loss: 0.915049
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.3021e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.660362
Average KL loss: 0.253944
Average total loss: 0.914306
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.6164e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.663810
Average KL loss: 0.254313
Average total loss: 0.918123
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.1966e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.673401
Average KL loss: 0.254651
Average total loss: 0.928053
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.0243e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.659546
Average KL loss: 0.255083
Average total loss: 0.914629
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.4398e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.653669
Average KL loss: 0.255463
Average total loss: 0.909132
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.4858e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.669836
Average KL loss: 0.255864
Average total loss: 0.925700
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.5588e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.649229
Average KL loss: 0.256255
Average total loss: 0.905484
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.7546e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.647319
Average KL loss: 0.256649
Average total loss: 0.903968
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.2660e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.644348
Average KL loss: 0.256997
Average total loss: 0.901346
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-9.2080e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.646343
Average KL loss: 0.257361
Average total loss: 0.903704
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.6010e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.640154
Average KL loss: 0.257687
Average total loss: 0.897841
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.3969e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.646600
Average KL loss: 0.258026
Average total loss: 0.904627
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0974e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.638982
Average KL loss: 0.258390
Average total loss: 0.897372
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.6712e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.645021
Average KL loss: 0.258714
Average total loss: 0.903735
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.5515e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.638881
Average KL loss: 0.259076
Average total loss: 0.897957
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(8.6873e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.632922
Average KL loss: 0.259443
Average total loss: 0.892365
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0503e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.633123
Average KL loss: 0.259769
Average total loss: 0.892892
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0238e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.636785
Average KL loss: 0.260082
Average total loss: 0.896867
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.7139e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.621055
Average KL loss: 0.260398
Average total loss: 0.881453
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.3627e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.634031
Average KL loss: 0.260714
Average total loss: 0.894745
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.1529e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.624907
Average KL loss: 0.261031
Average total loss: 0.885938
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.2379e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.625477
Average KL loss: 0.261346
Average total loss: 0.886823
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.2582e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.628960
Average KL loss: 0.261608
Average total loss: 0.890568
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.0511e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.635260
Average KL loss: 0.261898
Average total loss: 0.897158
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.7289e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.631501
Average KL loss: 0.262229
Average total loss: 0.893731
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-4.8928e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.613792
Average KL loss: 0.262501
Average total loss: 0.876293
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.4904e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.620850
Average KL loss: 0.262749
Average total loss: 0.883599
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.3560e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.618616
Average KL loss: 0.263003
Average total loss: 0.881618
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.3931e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.622065
Average KL loss: 0.263296
Average total loss: 0.885361
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.2335e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.612066
Average KL loss: 0.263519
Average total loss: 0.875585
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.6159e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.609526
Average KL loss: 0.263794
Average total loss: 0.873321
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.3659e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.615916
Average KL loss: 0.264053
Average total loss: 0.879968
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.3836e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.605703
Average KL loss: 0.264279
Average total loss: 0.869982
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.0558e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.608645
Average KL loss: 0.264601
Average total loss: 0.873246
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.7957e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.604206
Average KL loss: 0.264853
Average total loss: 0.869059
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.8834e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.616183
Average KL loss: 0.265110
Average total loss: 0.881293
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-8.9591e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.593605
Average KL loss: 0.265383
Average total loss: 0.858987
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0543e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.603454
Average KL loss: 0.265610
Average total loss: 0.869063
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.4291e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.609876
Average KL loss: 0.265853
Average total loss: 0.875729
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.0500e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.584082
Average KL loss: 0.266115
Average total loss: 0.850197
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.2857e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.601836
Average KL loss: 0.266352
Average total loss: 0.868188
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.8162e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.595675
Average KL loss: 0.266591
Average total loss: 0.862266
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.5500e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.605782
Average KL loss: 0.266855
Average total loss: 0.872636
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.3321e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.606943
Average KL loss: 0.267079
Average total loss: 0.874022
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.4335e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.580750
Average KL loss: 0.267320
Average total loss: 0.848070
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.1738e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.589045
Average KL loss: 0.267559
Average total loss: 0.856604
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.7518e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.609231
Average KL loss: 0.267771
Average total loss: 0.877002
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.1755e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.582071
Average KL loss: 0.268011
Average total loss: 0.850082
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-8.0621e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.588391
Average KL loss: 0.268197
Average total loss: 0.856588
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(3.8461e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.591343
Average KL loss: 0.268343
Average total loss: 0.859686
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.0953e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.582432
Average KL loss: 0.268612
Average total loss: 0.851045
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.3480e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.587629
Average KL loss: 0.268880
Average total loss: 0.856509
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(5.6723e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.569302
Average KL loss: 0.269135
Average total loss: 0.838437
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.7009e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.584741
Average KL loss: 0.269336
Average total loss: 0.854077
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.8226e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.574761
Average KL loss: 0.269556
Average total loss: 0.844316
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.1179e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.581374
Average KL loss: 0.269729
Average total loss: 0.851103
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-9.7038e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.581705
Average KL loss: 0.269901
Average total loss: 0.851606
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.0712e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.596303
Average KL loss: 0.270111
Average total loss: 0.866414
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.8482e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.571506
Average KL loss: 0.270356
Average total loss: 0.841863
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.2749e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.587159
Average KL loss: 0.270574
Average total loss: 0.857733
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.0937e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.572029
Average KL loss: 0.270744
Average total loss: 0.842773
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.9419e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.588600
Average KL loss: 0.270923
Average total loss: 0.859524
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.6734e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.575179
Average KL loss: 0.271132
Average total loss: 0.846311
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.7352e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.572953
Average KL loss: 0.271283
Average total loss: 0.844236
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3429e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.580448
Average KL loss: 0.271409
Average total loss: 0.851857
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-6.9691e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.571692
Average KL loss: 0.271423
Average total loss: 0.843116
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.5379e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.590194
Average KL loss: 0.271431
Average total loss: 0.861625
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3080e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.569790
Average KL loss: 0.271432
Average total loss: 0.841222
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(6.8022e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.572252
Average KL loss: 0.271442
Average total loss: 0.843695
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.6937e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.583518
Average KL loss: 0.271452
Average total loss: 0.854970
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.4092e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.577856
Average KL loss: 0.271463
Average total loss: 0.849319
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.1157e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.570194
Average KL loss: 0.271473
Average total loss: 0.841666
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.6772e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.577527
Average KL loss: 0.271482
Average total loss: 0.849009
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.7008e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.589928
Average KL loss: 0.271499
Average total loss: 0.861426
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-7.6506e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.575887
Average KL loss: 0.271514
Average total loss: 0.847402
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-6.8819e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.578963
Average KL loss: 0.271521
Average total loss: 0.850484
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2054e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.571848
Average KL loss: 0.271522
Average total loss: 0.843371
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.4393e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.577239
Average KL loss: 0.271523
Average total loss: 0.848762
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.8077e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.578588
Average KL loss: 0.271525
Average total loss: 0.850113
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.3009e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.568108
Average KL loss: 0.271526
Average total loss: 0.839634
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.9027e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.574655
Average KL loss: 0.271527
Average total loss: 0.846183
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.2758e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.578556
Average KL loss: 0.271529
Average total loss: 0.850085
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.9782e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.577727
Average KL loss: 0.271530
Average total loss: 0.849257
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.1283e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.581035
Average KL loss: 0.271531
Average total loss: 0.852566
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-6.0676e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.571326
Average KL loss: 0.271533
Average total loss: 0.842859
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.0053e-08, device='cuda:0')
 Percentile value: 8.064287726483599e-08
Non-zero model percentage: 20.971534729003906%, Non-zero mask percentage: 20.971534729003906%

--- Pruning Level [7/24]: ---
conv1.weight         | nonzeros =     422 /    1728             ( 24.42%) | total_pruned =    1306 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.weight           | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
bn1.bias             | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    3397 /   36864             (  9.21%) | total_pruned =   33467 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    7590 /   36864             ( 20.59%) | total_pruned =   29274 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    5301 /   36864             ( 14.38%) | total_pruned =   31563 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    7209 /   36864             ( 19.56%) | total_pruned =   29655 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    6408 /   73728             (  8.69%) | total_pruned =   67320 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   10055 /  147456             (  6.82%) | total_pruned =  137401 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1060 /    8192             ( 12.94%) | total_pruned =    7132 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   27043 /  147456             ( 18.34%) | total_pruned =  120413 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   36857 /  147456             ( 25.00%) | total_pruned =  110599 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   14700 /  294912             (  4.98%) | total_pruned =  280212 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   41264 /  589824             (  7.00%) | total_pruned =  548560 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      41 /     256             ( 16.02%) | total_pruned =     215 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4085 /   32768             ( 12.47%) | total_pruned =   28683 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  113425 /  589824             ( 19.23%) | total_pruned =  476399 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     140 /     256             ( 54.69%) | total_pruned =     116 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      55 /     256             ( 21.48%) | total_pruned =     201 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  152374 /  589824             ( 25.83%) | total_pruned =  437450 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     134 /     256             ( 52.34%) | total_pruned =     122 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  109680 / 1179648             (  9.30%) | total_pruned = 1069968 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     112 /     512             ( 21.88%) | total_pruned =     400 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     362 /     512             ( 70.70%) | total_pruned =     150 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      57 /     512             ( 11.13%) | total_pruned =     455 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  490124 / 2359296             ( 20.77%) | total_pruned = 1869172 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     144 /     512             ( 28.12%) | total_pruned =     368 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     189 /     512             ( 36.91%) | total_pruned =     323 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   24971 /  131072             ( 19.05%) | total_pruned =  106101 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      70 /     512             ( 13.67%) | total_pruned =     442 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     131 /     512             ( 25.59%) | total_pruned =     381 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      44 /     512             (  8.59%) | total_pruned =     468 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  584512 / 2359296             ( 24.77%) | total_pruned = 1774784 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     197 /     512             ( 38.48%) | total_pruned =     315 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  698821 / 2359296             ( 29.62%) | total_pruned = 1660475 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      94 /     512             ( 18.36%) | total_pruned =     418 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     249 /     512             ( 48.63%) | total_pruned =     263 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      88 /     512             ( 17.19%) | total_pruned =     424 | shape = torch.Size([512])
linear.weight        | nonzeros =    1101 /    5120             ( 21.50%) | total_pruned =    4019 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 2344358, pruned : 8834404, total: 11178762, Compression rate :       4.77x  ( 79.03% pruned)
Train Epoch: 70/100 Loss: 0.019410 Accuracy: 87.37 99.99 % Best test Accuracy: 87.61%
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.6631e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.919235
Average KL loss: 0.267575
Average total loss: 1.186810
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.0039e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.910268
Average KL loss: 0.263372
Average total loss: 1.173640
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.6392e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.900664
Average KL loss: 0.260878
Average total loss: 1.161542
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.8557e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.891722
Average KL loss: 0.259211
Average total loss: 1.150933
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.8488e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.885521
Average KL loss: 0.258072
Average total loss: 1.143593
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.9105e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.870385
Average KL loss: 0.257282
Average total loss: 1.127667
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.3271e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.845588
Average KL loss: 0.256734
Average total loss: 1.102322
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.1241e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.867355
Average KL loss: 0.256438
Average total loss: 1.123793
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.9130e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.843115
Average KL loss: 0.256234
Average total loss: 1.099348
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.3702e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.832229
Average KL loss: 0.256169
Average total loss: 1.088398
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.4432e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.822521
Average KL loss: 0.256190
Average total loss: 1.078711
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.4009e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.808328
Average KL loss: 0.256249
Average total loss: 1.064576
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.2279e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.809008
Average KL loss: 0.256401
Average total loss: 1.065409
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.5342e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.800636
Average KL loss: 0.256642
Average total loss: 1.057277
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.0350e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.804976
Average KL loss: 0.256849
Average total loss: 1.061824
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.7967e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.797814
Average KL loss: 0.257110
Average total loss: 1.054924
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.7818e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.791459
Average KL loss: 0.257404
Average total loss: 1.048863
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.0265e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.784700
Average KL loss: 0.257762
Average total loss: 1.042462
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.6294e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.773757
Average KL loss: 0.258085
Average total loss: 1.031843
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-4.3398e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.780596
Average KL loss: 0.258402
Average total loss: 1.038998
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.6530e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.766548
Average KL loss: 0.258774
Average total loss: 1.025322
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.5283e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.771864
Average KL loss: 0.259170
Average total loss: 1.031034
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.4604e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.751345
Average KL loss: 0.259566
Average total loss: 1.010911
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.7765e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.748822
Average KL loss: 0.259924
Average total loss: 1.008746
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.0892e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.749134
Average KL loss: 0.260271
Average total loss: 1.009406
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.7367e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.752979
Average KL loss: 0.260631
Average total loss: 1.013611
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.7839e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.754966
Average KL loss: 0.260998
Average total loss: 1.015963
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.4529e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.729778
Average KL loss: 0.261344
Average total loss: 0.991122
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.8461e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.740717
Average KL loss: 0.261742
Average total loss: 1.002459
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.6873e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.740446
Average KL loss: 0.262111
Average total loss: 1.002556
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.4767e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.738521
Average KL loss: 0.262543
Average total loss: 1.001064
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.8885e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.725407
Average KL loss: 0.262981
Average total loss: 0.988388
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.5038e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.718553
Average KL loss: 0.263392
Average total loss: 0.981945
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.4678e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.708162
Average KL loss: 0.263781
Average total loss: 0.971942
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.9664e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.718871
Average KL loss: 0.264179
Average total loss: 0.983050
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.8517e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.734368
Average KL loss: 0.264577
Average total loss: 0.998945
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.1763e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.728241
Average KL loss: 0.264949
Average total loss: 0.993190
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.3659e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.692697
Average KL loss: 0.265381
Average total loss: 0.958077
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.6762e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.703344
Average KL loss: 0.265722
Average total loss: 0.969066
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.5763e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.705964
Average KL loss: 0.266093
Average total loss: 0.972058
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-9.5002e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.691753
Average KL loss: 0.266439
Average total loss: 0.958191
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.4434e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.694786
Average KL loss: 0.266834
Average total loss: 0.961620
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.9855e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.700544
Average KL loss: 0.267287
Average total loss: 0.967831
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2505e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.699916
Average KL loss: 0.267635
Average total loss: 0.967551
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.6001e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.691820
Average KL loss: 0.267965
Average total loss: 0.959784
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.7840e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.690610
Average KL loss: 0.268381
Average total loss: 0.958991
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.1469e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.681940
Average KL loss: 0.268782
Average total loss: 0.950722
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.3135e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.677847
Average KL loss: 0.269173
Average total loss: 0.947020
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.2484e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.679535
Average KL loss: 0.269555
Average total loss: 0.949089
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.6945e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.687095
Average KL loss: 0.269907
Average total loss: 0.957003
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.0848e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.667823
Average KL loss: 0.270233
Average total loss: 0.938056
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.0380e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.667514
Average KL loss: 0.270569
Average total loss: 0.938083
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.1890e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.667114
Average KL loss: 0.270877
Average total loss: 0.937991
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-7.8976e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.664490
Average KL loss: 0.271251
Average total loss: 0.935741
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.7510e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.676019
Average KL loss: 0.271584
Average total loss: 0.947603
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.5077e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.671623
Average KL loss: 0.271952
Average total loss: 0.943575
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.0575e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.659292
Average KL loss: 0.272307
Average total loss: 0.931600
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.6100e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.667762
Average KL loss: 0.272634
Average total loss: 0.940397
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.5459e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.648699
Average KL loss: 0.272970
Average total loss: 0.921669
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.4161e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.658094
Average KL loss: 0.273269
Average total loss: 0.931363
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.7607e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.657517
Average KL loss: 0.273629
Average total loss: 0.931146
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.2440e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.651325
Average KL loss: 0.273983
Average total loss: 0.925308
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.6841e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.652297
Average KL loss: 0.274322
Average total loss: 0.926619
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.3745e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.656106
Average KL loss: 0.274654
Average total loss: 0.930760
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3742e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.653982
Average KL loss: 0.275008
Average total loss: 0.928990
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.6151e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.649386
Average KL loss: 0.275329
Average total loss: 0.924714
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3005e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.646409
Average KL loss: 0.275673
Average total loss: 0.922082
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.1469e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.656759
Average KL loss: 0.275950
Average total loss: 0.932709
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.5727e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.642728
Average KL loss: 0.276197
Average total loss: 0.918925
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-3.4181e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.636146
Average KL loss: 0.276474
Average total loss: 0.912619
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.4998e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.644695
Average KL loss: 0.276791
Average total loss: 0.921486
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(1.1994e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.644320
Average KL loss: 0.277137
Average total loss: 0.921457
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-8.2999e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.640304
Average KL loss: 0.277434
Average total loss: 0.917738
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-8.9799e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.641681
Average KL loss: 0.277704
Average total loss: 0.919385
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.1810e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.639944
Average KL loss: 0.278000
Average total loss: 0.917943
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-9.9964e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.647249
Average KL loss: 0.278301
Average total loss: 0.925550
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-8.1308e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.625402
Average KL loss: 0.278590
Average total loss: 0.903992
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.0793e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.630599
Average KL loss: 0.278861
Average total loss: 0.909460
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-5.6854e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.642956
Average KL loss: 0.279154
Average total loss: 0.922110
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.4786e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.629625
Average KL loss: 0.279495
Average total loss: 0.909119
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-9.6796e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.628969
Average KL loss: 0.279780
Average total loss: 0.908749
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2634e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.640084
Average KL loss: 0.280064
Average total loss: 0.920148
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.1958e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.619490
Average KL loss: 0.280361
Average total loss: 0.899851
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2046e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.635780
Average KL loss: 0.280643
Average total loss: 0.916423
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.2803e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.628108
Average KL loss: 0.280892
Average total loss: 0.909000
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.1507e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.631013
Average KL loss: 0.281127
Average total loss: 0.912141
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.3713e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.626219
Average KL loss: 0.281359
Average total loss: 0.907578
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.2414e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.617929
Average KL loss: 0.281580
Average total loss: 0.899509
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.9723e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.614150
Average KL loss: 0.281778
Average total loss: 0.895928
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.8803e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.628041
Average KL loss: 0.282023
Average total loss: 0.910064
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.7279e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.617213
Average KL loss: 0.282250
Average total loss: 0.899463
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-8.1489e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.613103
Average KL loss: 0.282453
Average total loss: 0.895556
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-9.2392e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.607804
Average KL loss: 0.282679
Average total loss: 0.890483
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-8.0281e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.615088
Average KL loss: 0.282840
Average total loss: 0.897928
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.7769e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.625423
Average KL loss: 0.283067
Average total loss: 0.908490
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.4410e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.623816
Average KL loss: 0.283328
Average total loss: 0.907144
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2133e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.608503
Average KL loss: 0.283572
Average total loss: 0.892075
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.4036e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.601601
Average KL loss: 0.283786
Average total loss: 0.885388
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.4435e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.614118
Average KL loss: 0.283967
Average total loss: 0.898084
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.3996e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.622481
Average KL loss: 0.284167
Average total loss: 0.906649
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.5697e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.622521
Average KL loss: 0.284405
Average total loss: 0.906927
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2183e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.599875
Average KL loss: 0.284640
Average total loss: 0.884515
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.5944e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.602909
Average KL loss: 0.284868
Average total loss: 0.887777
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.4597e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.594830
Average KL loss: 0.285066
Average total loss: 0.879896
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.3164e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.607991
Average KL loss: 0.285314
Average total loss: 0.893305
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.1070e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.603624
Average KL loss: 0.285518
Average total loss: 0.889141
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.1220e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.594356
Average KL loss: 0.285709
Average total loss: 0.880065
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.1518e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.602445
Average KL loss: 0.285892
Average total loss: 0.888336
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.5223e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.614244
Average KL loss: 0.286146
Average total loss: 0.900389
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.5269e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.595161
Average KL loss: 0.286319
Average total loss: 0.881480
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.3569e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.589205
Average KL loss: 0.286483
Average total loss: 0.875688
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.4903e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.607656
Average KL loss: 0.286667
Average total loss: 0.894324
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.8259e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.597209
Average KL loss: 0.286826
Average total loss: 0.884035
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.3918e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.603053
Average KL loss: 0.287062
Average total loss: 0.890115
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.3320e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.593969
Average KL loss: 0.287278
Average total loss: 0.881248
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.8339e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.597304
Average KL loss: 0.287448
Average total loss: 0.884751
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.1773e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.593017
Average KL loss: 0.287607
Average total loss: 0.880623
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.6543e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.595714
Average KL loss: 0.287753
Average total loss: 0.883467
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0101e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.581001
Average KL loss: 0.287927
Average total loss: 0.868928
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0469e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.583791
Average KL loss: 0.288081
Average total loss: 0.871872
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.1691e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.595301
Average KL loss: 0.288271
Average total loss: 0.883571
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.6502e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.600904
Average KL loss: 0.288497
Average total loss: 0.889401
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.6648e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.589968
Average KL loss: 0.288679
Average total loss: 0.878647
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.1565e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.592656
Average KL loss: 0.288836
Average total loss: 0.881492
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.1520e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.615232
Average KL loss: 0.289006
Average total loss: 0.904238
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.7067e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.587692
Average KL loss: 0.289178
Average total loss: 0.876871
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(1.5444e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.571012
Average KL loss: 0.289354
Average total loss: 0.860365
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.2552e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.582849
Average KL loss: 0.289436
Average total loss: 0.872285
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.4999e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.583784
Average KL loss: 0.289577
Average total loss: 0.873361
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.2047e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.580407
Average KL loss: 0.289773
Average total loss: 0.870180
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2428e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.578887
Average KL loss: 0.289944
Average total loss: 0.868831
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.0666e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.589294
Average KL loss: 0.290100
Average total loss: 0.879394
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.1411e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.577983
Average KL loss: 0.290240
Average total loss: 0.868223
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.3203e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.588395
Average KL loss: 0.290391
Average total loss: 0.878786
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.8031e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.581816
Average KL loss: 0.290538
Average total loss: 0.872353
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.6195e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.585384
Average KL loss: 0.290727
Average total loss: 0.876111
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.6927e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.575612
Average KL loss: 0.290850
Average total loss: 0.866462
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.7094e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.578422
Average KL loss: 0.290982
Average total loss: 0.869404
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.2884e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.580150
Average KL loss: 0.291085
Average total loss: 0.871235
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(5.5327e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.583061
Average KL loss: 0.291089
Average total loss: 0.874150
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.8670e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.571132
Average KL loss: 0.291100
Average total loss: 0.862232
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.7626e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.582041
Average KL loss: 0.291118
Average total loss: 0.873159
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0659e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.571722
Average KL loss: 0.291129
Average total loss: 0.862851
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0352e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.581246
Average KL loss: 0.291140
Average total loss: 0.872385
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2665e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.570143
Average KL loss: 0.291148
Average total loss: 0.861292
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2143e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.574203
Average KL loss: 0.291159
Average total loss: 0.865362
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.4919e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.573386
Average KL loss: 0.291170
Average total loss: 0.864556
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(4.1147e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.580490
Average KL loss: 0.291178
Average total loss: 0.871668
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.3189e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.578835
Average KL loss: 0.291191
Average total loss: 0.870026
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.5919e-11, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.574147
Average KL loss: 0.291199
Average total loss: 0.865347
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.3435e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.576245
Average KL loss: 0.291200
Average total loss: 0.867445
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.5778e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.572660
Average KL loss: 0.291202
Average total loss: 0.863861
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.3457e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.588125
Average KL loss: 0.291203
Average total loss: 0.879327
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.7463e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.594470
Average KL loss: 0.291204
Average total loss: 0.885674
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2448e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.583607
Average KL loss: 0.291204
Average total loss: 0.874812
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.9596e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.588472
Average KL loss: 0.291205
Average total loss: 0.879677
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.3227e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.579711
Average KL loss: 0.291206
Average total loss: 0.870917
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.3012e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.582799
Average KL loss: 0.291208
Average total loss: 0.874006
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.8915e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.574690
Average KL loss: 0.291209
Average total loss: 0.865899
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.1259e-08, device='cuda:0')
 Percentile value: 8.078490765228707e-08
Non-zero model percentage: 16.777233123779297%, Non-zero mask percentage: 16.777233123779297%

--- Pruning Level [8/24]: ---
conv1.weight         | nonzeros =     349 /    1728             ( 20.20%) | total_pruned =    1379 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
bn1.weight           | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
bn1.bias             | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2729 /   36864             (  7.40%) | total_pruned =   34135 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    6097 /   36864             ( 16.54%) | total_pruned =   30767 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4203 /   36864             ( 11.40%) | total_pruned =   32661 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    5632 /   36864             ( 15.28%) | total_pruned =   31232 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    5098 /   73728             (  6.91%) | total_pruned =   68630 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    7939 /  147456             (  5.38%) | total_pruned =  139517 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     828 /    8192             ( 10.11%) | total_pruned =    7364 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   21568 /  147456             ( 14.63%) | total_pruned =  125888 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   29614 /  147456             ( 20.08%) | total_pruned =  117842 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   11200 /  294912             (  3.80%) | total_pruned =  283712 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   31947 /  589824             (  5.42%) | total_pruned =  557877 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3239 /   32768             (  9.88%) | total_pruned =   29529 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     114 /     256             ( 44.53%) | total_pruned =     142 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   90199 /  589824             ( 15.29%) | total_pruned =  499625 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     136 /     256             ( 53.12%) | total_pruned =     120 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  121862 /  589824             ( 20.66%) | total_pruned =  467962 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     130 /     256             ( 50.78%) | total_pruned =     126 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   84931 / 1179648             (  7.20%) | total_pruned = 1094717 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      59 /     512             ( 11.52%) | total_pruned =     453 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     345 /     512             ( 67.38%) | total_pruned =     167 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  392647 / 2359296             ( 16.64%) | total_pruned = 1966649 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     155 /     512             ( 30.27%) | total_pruned =     357 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   19939 /  131072             ( 15.21%) | total_pruned =  111133 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      62 /     512             ( 12.11%) | total_pruned =     450 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      96 /     512             ( 18.75%) | total_pruned =     416 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      36 /     512             (  7.03%) | total_pruned =     476 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  471775 / 2359296             ( 20.00%) | total_pruned = 1887521 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      59 /     512             ( 11.52%) | total_pruned =     453 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     158 /     512             ( 30.86%) | total_pruned =     354 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      34 /     512             (  6.64%) | total_pruned =     478 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  559496 / 2359296             ( 23.71%) | total_pruned = 1799800 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      73 /     512             ( 14.26%) | total_pruned =     439 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     191 /     512             ( 37.30%) | total_pruned =     321 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      67 /     512             ( 13.09%) | total_pruned =     445 | shape = torch.Size([512])
linear.weight        | nonzeros =     855 /    5120             ( 16.70%) | total_pruned =    4265 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1875487, pruned : 9303275, total: 11178762, Compression rate :       5.96x  ( 83.22% pruned)
Train Epoch: 62/100 Loss: 0.034720 Accuracy: 86.70 99.99 % Best test Accuracy: 87.46%
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.2303e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.845753
Average KL loss: 0.287852
Average total loss: 1.133604
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.5034e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.851110
Average KL loss: 0.284235
Average total loss: 1.135345
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.7850e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.827306
Average KL loss: 0.281945
Average total loss: 1.109251
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.7641e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.819238
Average KL loss: 0.280310
Average total loss: 1.099547
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.8625e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.814172
Average KL loss: 0.279103
Average total loss: 1.093274
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.3852e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.825193
Average KL loss: 0.278194
Average total loss: 1.103386
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.3699e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.814451
Average KL loss: 0.277542
Average total loss: 1.091993
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.2992e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.800240
Average KL loss: 0.277094
Average total loss: 1.077334
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.1135e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.788301
Average KL loss: 0.276740
Average total loss: 1.065042
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.8620e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.776097
Average KL loss: 0.276497
Average total loss: 1.052594
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.9616e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.786552
Average KL loss: 0.276327
Average total loss: 1.062879
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.1747e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.787159
Average KL loss: 0.276279
Average total loss: 1.063438
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2559e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.766446
Average KL loss: 0.276256
Average total loss: 1.042702
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.8680e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.762839
Average KL loss: 0.276248
Average total loss: 1.039087
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.7415e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.759178
Average KL loss: 0.276338
Average total loss: 1.035516
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.7645e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.768555
Average KL loss: 0.276462
Average total loss: 1.045016
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.6963e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.742131
Average KL loss: 0.276620
Average total loss: 1.018751
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.1476e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.742273
Average KL loss: 0.276795
Average total loss: 1.019067
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.6762e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.740871
Average KL loss: 0.277005
Average total loss: 1.017876
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0235e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.735813
Average KL loss: 0.277188
Average total loss: 1.013001
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.7410e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.731610
Average KL loss: 0.277398
Average total loss: 1.009008
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.6765e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.749607
Average KL loss: 0.277609
Average total loss: 1.027216
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(3.2630e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.739346
Average KL loss: 0.277847
Average total loss: 1.017193
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2672e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.719287
Average KL loss: 0.278126
Average total loss: 0.997412
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.6599e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.715781
Average KL loss: 0.278405
Average total loss: 0.994185
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.5347e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.724258
Average KL loss: 0.278693
Average total loss: 1.002951
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.4455e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.745040
Average KL loss: 0.278969
Average total loss: 1.024008
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.5034e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.722916
Average KL loss: 0.279280
Average total loss: 1.002196
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.9152e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.711341
Average KL loss: 0.279567
Average total loss: 0.990908
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.4752e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.708917
Average KL loss: 0.279895
Average total loss: 0.988813
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.6992e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.714031
Average KL loss: 0.280194
Average total loss: 0.994225
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.4601e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.700841
Average KL loss: 0.280486
Average total loss: 0.981327
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.6052e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.704603
Average KL loss: 0.280791
Average total loss: 0.985395
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.5444e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.709230
Average KL loss: 0.281121
Average total loss: 0.990351
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.6844e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.699268
Average KL loss: 0.281429
Average total loss: 0.980697
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.8772e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.691294
Average KL loss: 0.281753
Average total loss: 0.973047
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.4150e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.707037
Average KL loss: 0.282075
Average total loss: 0.989112
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2755e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.696241
Average KL loss: 0.282400
Average total loss: 0.978641
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0655e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.703178
Average KL loss: 0.282691
Average total loss: 0.985869
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2864e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.689412
Average KL loss: 0.282958
Average total loss: 0.972369
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0174e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.692308
Average KL loss: 0.283261
Average total loss: 0.975569
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.1143e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.686658
Average KL loss: 0.283595
Average total loss: 0.970253
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.6237e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.682798
Average KL loss: 0.283915
Average total loss: 0.966713
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.6031e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.695830
Average KL loss: 0.284203
Average total loss: 0.980033
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.1650e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.676278
Average KL loss: 0.284507
Average total loss: 0.960785
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.1205e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.671470
Average KL loss: 0.284808
Average total loss: 0.956278
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2615e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.674404
Average KL loss: 0.285140
Average total loss: 0.959544
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.1603e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.668519
Average KL loss: 0.285447
Average total loss: 0.953966
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.5980e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.670511
Average KL loss: 0.285791
Average total loss: 0.956301
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.8033e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.670585
Average KL loss: 0.286087
Average total loss: 0.956672
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.8060e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.674092
Average KL loss: 0.286446
Average total loss: 0.960538
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.2497e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.670147
Average KL loss: 0.286760
Average total loss: 0.956907
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.0652e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.666795
Average KL loss: 0.287063
Average total loss: 0.953859
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.8423e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.673792
Average KL loss: 0.287371
Average total loss: 0.961164
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.2510e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.667284
Average KL loss: 0.287638
Average total loss: 0.954922
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2571e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.661342
Average KL loss: 0.287939
Average total loss: 0.949281
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4961e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.656314
Average KL loss: 0.288177
Average total loss: 0.944491
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.9943e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.672875
Average KL loss: 0.288445
Average total loss: 0.961320
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.6275e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.645607
Average KL loss: 0.288721
Average total loss: 0.934328
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.2483e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.650540
Average KL loss: 0.288968
Average total loss: 0.939508
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.1819e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.655770
Average KL loss: 0.289260
Average total loss: 0.945030
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.6865e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.648971
Average KL loss: 0.289532
Average total loss: 0.938503
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.5124e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.647314
Average KL loss: 0.289828
Average total loss: 0.937142
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.4799e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.648301
Average KL loss: 0.290112
Average total loss: 0.938412
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.2857e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.648665
Average KL loss: 0.290416
Average total loss: 0.939081
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.3183e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.643890
Average KL loss: 0.290731
Average total loss: 0.934620
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(5.8434e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.636575
Average KL loss: 0.290998
Average total loss: 0.927572
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.1192e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.657127
Average KL loss: 0.291260
Average total loss: 0.948387
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0498e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.645051
Average KL loss: 0.291519
Average total loss: 0.936569
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.1821e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.632384
Average KL loss: 0.291746
Average total loss: 0.924130
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.1218e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.640856
Average KL loss: 0.291984
Average total loss: 0.932840
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.4750e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.634485
Average KL loss: 0.292256
Average total loss: 0.926741
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.3690e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.637077
Average KL loss: 0.292540
Average total loss: 0.929617
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.1259e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.645287
Average KL loss: 0.292824
Average total loss: 0.938111
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0466e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.646011
Average KL loss: 0.293091
Average total loss: 0.939102
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0992e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.633132
Average KL loss: 0.293310
Average total loss: 0.926442
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.2163e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.635323
Average KL loss: 0.293515
Average total loss: 0.928838
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.6491e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.628909
Average KL loss: 0.293788
Average total loss: 0.922697
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.2299e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.624262
Average KL loss: 0.294085
Average total loss: 0.918348
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.1141e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.634012
Average KL loss: 0.294321
Average total loss: 0.928333
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.0675e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.636300
Average KL loss: 0.294546
Average total loss: 0.930846
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.7452e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.626838
Average KL loss: 0.294784
Average total loss: 0.921622
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.2817e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.628930
Average KL loss: 0.295067
Average total loss: 0.923997
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.9281e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.618243
Average KL loss: 0.295327
Average total loss: 0.913569
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.7647e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.629639
Average KL loss: 0.295572
Average total loss: 0.925211
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.0365e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.624046
Average KL loss: 0.295798
Average total loss: 0.919844
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.4301e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.630008
Average KL loss: 0.296025
Average total loss: 0.926033
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.3533e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.618514
Average KL loss: 0.296245
Average total loss: 0.914759
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.0760e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.620456
Average KL loss: 0.296460
Average total loss: 0.916916
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.2878e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.612099
Average KL loss: 0.296687
Average total loss: 0.908786
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.0637e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.618535
Average KL loss: 0.296940
Average total loss: 0.915475
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.6233e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.601947
Average KL loss: 0.297143
Average total loss: 0.899090
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.5063e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.612782
Average KL loss: 0.297367
Average total loss: 0.910149
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.4307e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.628932
Average KL loss: 0.297567
Average total loss: 0.926500
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.9505e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.622318
Average KL loss: 0.297765
Average total loss: 0.920082
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.8646e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.624884
Average KL loss: 0.298018
Average total loss: 0.922902
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.5799e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.609347
Average KL loss: 0.298275
Average total loss: 0.907622
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.9172e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.607151
Average KL loss: 0.298510
Average total loss: 0.905661
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.3700e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.605824
Average KL loss: 0.298703
Average total loss: 0.904527
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.2032e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.604945
Average KL loss: 0.298885
Average total loss: 0.903830
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.5140e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.617169
Average KL loss: 0.299077
Average total loss: 0.916246
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.1155e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.594253
Average KL loss: 0.299325
Average total loss: 0.893578
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.2106e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.605042
Average KL loss: 0.299464
Average total loss: 0.904506
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.2119e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.613437
Average KL loss: 0.299610
Average total loss: 0.913047
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-5.5982e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.613333
Average KL loss: 0.299814
Average total loss: 0.913147
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-5.9494e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.614538
Average KL loss: 0.299962
Average total loss: 0.914500
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.0232e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.607618
Average KL loss: 0.300198
Average total loss: 0.907816
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-5.4886e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.607139
Average KL loss: 0.300403
Average total loss: 0.907542
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.6774e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.624731
Average KL loss: 0.300588
Average total loss: 0.925319
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.5139e-11, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.606052
Average KL loss: 0.300765
Average total loss: 0.906817
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.6412e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.600546
Average KL loss: 0.300938
Average total loss: 0.901484
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3686e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.605490
Average KL loss: 0.301139
Average total loss: 0.906629
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.4226e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.610740
Average KL loss: 0.301345
Average total loss: 0.912084
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.2302e-08, device='cuda:0')
