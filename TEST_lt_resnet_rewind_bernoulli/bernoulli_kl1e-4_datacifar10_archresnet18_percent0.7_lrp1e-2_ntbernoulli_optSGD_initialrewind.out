Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/8]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2827e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302672
Average KL loss: 0.002684
Average total loss: 2.305356
tensor(2.6577e-05, device='cuda:0') tensor(4.0590e-06, device='cuda:0') tensor(2.5648e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.302747
Average KL loss: 0.002979
Average total loss: 2.305725
tensor(1.1998e-05, device='cuda:0') tensor(5.8761e-06, device='cuda:0') tensor(-3.2052e-12, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.301992
Average KL loss: 0.003515
Average total loss: 2.305508
tensor(2.8506e-05, device='cuda:0') tensor(1.2379e-05, device='cuda:0') tensor(-3.4651e-11, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.300801
Average KL loss: 0.004661
Average total loss: 2.305462
tensor(6.8023e-05, device='cuda:0') tensor(2.7850e-05, device='cuda:0') tensor(3.0066e-13, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.296340
Average KL loss: 0.008573
Average total loss: 2.304913
tensor(0.0002, device='cuda:0') tensor(7.7966e-05, device='cuda:0') tensor(-5.9129e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.242151
Average KL loss: 0.030764
Average total loss: 2.272915
tensor(0.0009, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.3138e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.904220
Average KL loss: 0.124509
Average total loss: 2.028728
tensor(0.0026, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.4956e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.381591
Average KL loss: 0.250861
Average total loss: 1.632452
tensor(0.0031, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.8293e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.031771
Average KL loss: 0.302618
Average total loss: 1.334389
tensor(0.0030, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.9341e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.881427
Average KL loss: 0.308868
Average total loss: 1.190295
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-5.1496e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.798027
Average KL loss: 0.309036
Average total loss: 1.107063
tensor(0.0029, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.4536e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.754729
Average KL loss: 0.311400
Average total loss: 1.066129
tensor(0.0028, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.2742e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.695266
Average KL loss: 0.309724
Average total loss: 1.004990
tensor(0.0028, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.3761e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.644160
Average KL loss: 0.305798
Average total loss: 0.949959
tensor(0.0028, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-6.8511e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.616043
Average KL loss: 0.304813
Average total loss: 0.920857
tensor(0.0028, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.6214e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.595678
Average KL loss: 0.303582
Average total loss: 0.899260
tensor(0.0028, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.1181e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.571360
Average KL loss: 0.301201
Average total loss: 0.872560
tensor(0.0028, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.7522e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.553082
Average KL loss: 0.300057
Average total loss: 0.853139
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.0667e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.543076
Average KL loss: 0.299864
Average total loss: 0.842941
tensor(0.0028, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2289e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.520515
Average KL loss: 0.298806
Average total loss: 0.819322
tensor(0.0028, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2023e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.515513
Average KL loss: 0.299252
Average total loss: 0.814765
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2000e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.499175
Average KL loss: 0.298311
Average total loss: 0.797486
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2749e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.495127
Average KL loss: 0.301150
Average total loss: 0.796278
tensor(0.0028, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.7852e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.478750
Average KL loss: 0.299744
Average total loss: 0.778495
tensor(0.0028, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5389e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.477695
Average KL loss: 0.299493
Average total loss: 0.777188
tensor(0.0028, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.4146e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.462231
Average KL loss: 0.298533
Average total loss: 0.760764
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.1999e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.455008
Average KL loss: 0.300123
Average total loss: 0.755131
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.1936e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.454331
Average KL loss: 0.299698
Average total loss: 0.754029
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0792e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.430505
Average KL loss: 0.298222
Average total loss: 0.728727
tensor(0.0028, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.7253e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.441425
Average KL loss: 0.299654
Average total loss: 0.741079
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2778e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.429539
Average KL loss: 0.299546
Average total loss: 0.729085
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3964e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.421279
Average KL loss: 0.299815
Average total loss: 0.721094
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.1763e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.418745
Average KL loss: 0.299948
Average total loss: 0.718693
tensor(0.0029, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3651e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.417771
Average KL loss: 0.301744
Average total loss: 0.719515
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.0321e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.408453
Average KL loss: 0.301415
Average total loss: 0.709869
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2605e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.406461
Average KL loss: 0.302058
Average total loss: 0.708519
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2266e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.400730
Average KL loss: 0.301606
Average total loss: 0.702336
tensor(0.0029, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.6823e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.397688
Average KL loss: 0.301894
Average total loss: 0.699583
tensor(0.0029, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.6183e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.390997
Average KL loss: 0.302276
Average total loss: 0.693273
tensor(0.0029, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.5471e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.396720
Average KL loss: 0.303744
Average total loss: 0.700464
tensor(0.0029, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.4151e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.384471
Average KL loss: 0.303673
Average total loss: 0.688143
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.6547e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.383196
Average KL loss: 0.303071
Average total loss: 0.686267
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.3213e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.378353
Average KL loss: 0.302777
Average total loss: 0.681130
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.0410e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.382397
Average KL loss: 0.304443
Average total loss: 0.686840
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.0742e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.372872
Average KL loss: 0.303917
Average total loss: 0.676789
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.8271e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.368683
Average KL loss: 0.303230
Average total loss: 0.671913
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.5151e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.373898
Average KL loss: 0.304088
Average total loss: 0.677987
tensor(0.0030, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3642e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.366455
Average KL loss: 0.306385
Average total loss: 0.672841
tensor(0.0030, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.4247e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.369430
Average KL loss: 0.305466
Average total loss: 0.674896
tensor(0.0030, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.9913e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.355943
Average KL loss: 0.304933
Average total loss: 0.660876
tensor(0.0029, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.2284e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.361495
Average KL loss: 0.305657
Average total loss: 0.667152
tensor(0.0029, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-7.0756e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.359149
Average KL loss: 0.305430
Average total loss: 0.664579
tensor(0.0030, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.2929e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.357564
Average KL loss: 0.306753
Average total loss: 0.664317
tensor(0.0030, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-9.5667e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.352447
Average KL loss: 0.306648
Average total loss: 0.659095
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.9713e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.348188
Average KL loss: 0.305937
Average total loss: 0.654125
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-5.0642e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.350813
Average KL loss: 0.307290
Average total loss: 0.658103
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-7.4972e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.348743
Average KL loss: 0.306650
Average total loss: 0.655393
tensor(0.0030, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.5554e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.344358
Average KL loss: 0.306008
Average total loss: 0.650366
tensor(0.0030, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.8567e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.344477
Average KL loss: 0.307396
Average total loss: 0.651873
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.5832e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.347760
Average KL loss: 0.307994
Average total loss: 0.655754
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6681e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.339191
Average KL loss: 0.308534
Average total loss: 0.647725
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.7072e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.341612
Average KL loss: 0.308409
Average total loss: 0.650021
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-6.2547e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.339154
Average KL loss: 0.309087
Average total loss: 0.648240
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.9382e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.334873
Average KL loss: 0.309406
Average total loss: 0.644279
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.3912e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.334543
Average KL loss: 0.308697
Average total loss: 0.643240
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-6.5834e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.334045
Average KL loss: 0.308845
Average total loss: 0.642890
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(3.2238e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.328669
Average KL loss: 0.307674
Average total loss: 0.636343
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.1677e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.330733
Average KL loss: 0.309187
Average total loss: 0.639920
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.4925e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.330107
Average KL loss: 0.308965
Average total loss: 0.639072
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.3198e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.332467
Average KL loss: 0.310391
Average total loss: 0.642858
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1547e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.332513
Average KL loss: 0.311353
Average total loss: 0.643866
tensor(0.0030, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(4.7039e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.328166
Average KL loss: 0.311207
Average total loss: 0.639373
tensor(0.0030, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.4217e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.331470
Average KL loss: 0.311498
Average total loss: 0.642968
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1813e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.325514
Average KL loss: 0.311096
Average total loss: 0.636609
tensor(0.0030, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.6673e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.322756
Average KL loss: 0.310572
Average total loss: 0.633328
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(9.3856e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.324293
Average KL loss: 0.310967
Average total loss: 0.635261
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.8980e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.322791
Average KL loss: 0.311973
Average total loss: 0.634764
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.0939e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.322608
Average KL loss: 0.311570
Average total loss: 0.634178
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.6271e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.322892
Average KL loss: 0.313285
Average total loss: 0.636178
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(6.9156e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.320143
Average KL loss: 0.313006
Average total loss: 0.633149
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.8358e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.318661
Average KL loss: 0.313077
Average total loss: 0.631738
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.2900e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.321448
Average KL loss: 0.313067
Average total loss: 0.634515
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.8174e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.318586
Average KL loss: 0.313321
Average total loss: 0.631908
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.8857e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.318531
Average KL loss: 0.313399
Average total loss: 0.631930
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.5323e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.315570
Average KL loss: 0.313156
Average total loss: 0.628726
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.2423e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.318805
Average KL loss: 0.313512
Average total loss: 0.632317
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.7784e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.316196
Average KL loss: 0.314286
Average total loss: 0.630482
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.3620e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.314958
Average KL loss: 0.313336
Average total loss: 0.628294
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.9559e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.312144
Average KL loss: 0.313444
Average total loss: 0.625588
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-5.9755e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.315220
Average KL loss: 0.313748
Average total loss: 0.628968
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.7535e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.314807
Average KL loss: 0.314898
Average total loss: 0.629704
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-6.9040e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.311816
Average KL loss: 0.314734
Average total loss: 0.626550
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.5258e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.310645
Average KL loss: 0.314392
Average total loss: 0.625036
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.0594e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.311993
Average KL loss: 0.315058
Average total loss: 0.627051
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.6422e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.311613
Average KL loss: 0.315098
Average total loss: 0.626711
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.9490e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.309061
Average KL loss: 0.314885
Average total loss: 0.623946
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.3461e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.310720
Average KL loss: 0.315092
Average total loss: 0.625812
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(2.1839e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.310587
Average KL loss: 0.315305
Average total loss: 0.625891
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.7079e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.307078
Average KL loss: 0.314877
Average total loss: 0.621956
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.1982e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.310115
Average KL loss: 0.315148
Average total loss: 0.625263
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.0616e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.306154
Average KL loss: 0.314411
Average total loss: 0.620566
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(1.6405e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.308740
Average KL loss: 0.315252
Average total loss: 0.623992
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.1401e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.305619
Average KL loss: 0.315246
Average total loss: 0.620865
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.0127e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.310232
Average KL loss: 0.316691
Average total loss: 0.626922
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.4810e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.301800
Average KL loss: 0.316424
Average total loss: 0.618224
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.3429e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.303254
Average KL loss: 0.315679
Average total loss: 0.618933
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(8.2033e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.303851
Average KL loss: 0.315579
Average total loss: 0.619431
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.8590e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.306397
Average KL loss: 0.316086
Average total loss: 0.622483
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(2.6833e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.304565
Average KL loss: 0.317610
Average total loss: 0.622175
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.0165e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.303958
Average KL loss: 0.317102
Average total loss: 0.621061
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3028e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.302356
Average KL loss: 0.316738
Average total loss: 0.619093
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.0874e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.301272
Average KL loss: 0.317020
Average total loss: 0.618293
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5851e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.302122
Average KL loss: 0.316443
Average total loss: 0.618565
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(5.9515e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.302712
Average KL loss: 0.317099
Average total loss: 0.619811
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(6.5320e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.301318
Average KL loss: 0.317207
Average total loss: 0.618525
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(3.9346e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.303331
Average KL loss: 0.317486
Average total loss: 0.620817
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.2038e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.302171
Average KL loss: 0.311490
Average total loss: 0.613661
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.3115e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.297085
Average KL loss: 0.303492
Average total loss: 0.600577
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.1054e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.296952
Average KL loss: 0.299613
Average total loss: 0.596565
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.3049e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.296429
Average KL loss: 0.297289
Average total loss: 0.593718
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(4.3097e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.303861
Average KL loss: 0.295690
Average total loss: 0.599551
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.7434e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.299297
Average KL loss: 0.294589
Average total loss: 0.593885
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(5.5730e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.299572
Average KL loss: 0.293731
Average total loss: 0.593302
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.6080e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.297962
Average KL loss: 0.293067
Average total loss: 0.591029
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.9358e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.300435
Average KL loss: 0.292598
Average total loss: 0.593033
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-8.4561e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.300297
Average KL loss: 0.292253
Average total loss: 0.592550
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.4206e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.303111
Average KL loss: 0.291910
Average total loss: 0.595021
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.1833e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.300009
Average KL loss: 0.291737
Average total loss: 0.591746
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.0906e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.298371
Average KL loss: 0.291403
Average total loss: 0.589775
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.0561e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.300339
Average KL loss: 0.291098
Average total loss: 0.591437
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(6.0543e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.301461
Average KL loss: 0.290967
Average total loss: 0.592428
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(6.0308e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.301101
Average KL loss: 0.290740
Average total loss: 0.591840
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(8.6308e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.299242
Average KL loss: 0.290556
Average total loss: 0.589798
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.5625e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.299013
Average KL loss: 0.290444
Average total loss: 0.589457
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.0136e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.299418
Average KL loss: 0.290282
Average total loss: 0.589700
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.3191e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.299462
Average KL loss: 0.290224
Average total loss: 0.589685
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.0240e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.300726
Average KL loss: 0.290216
Average total loss: 0.590942
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.9843e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.297846
Average KL loss: 0.290020
Average total loss: 0.587866
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.2266e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.298812
Average KL loss: 0.289880
Average total loss: 0.588692
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(2.3254e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.295722
Average KL loss: 0.289853
Average total loss: 0.585575
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3492e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.300447
Average KL loss: 0.289835
Average total loss: 0.590281
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(5.2945e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.298634
Average KL loss: 0.289771
Average total loss: 0.588405
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.8410e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.299482
Average KL loss: 0.289720
Average total loss: 0.589202
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.5690e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.298981
Average KL loss: 0.289695
Average total loss: 0.588676
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(3.3160e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.298836
Average KL loss: 0.289661
Average total loss: 0.588497
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.4229e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.298603
Average KL loss: 0.289579
Average total loss: 0.588182
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.6243e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.299793
Average KL loss: 0.289523
Average total loss: 0.589316
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6452e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.297734
Average KL loss: 0.289438
Average total loss: 0.587171
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.9939e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.295528
Average KL loss: 0.289406
Average total loss: 0.584934
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.8764e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.297291
Average KL loss: 0.289461
Average total loss: 0.586752
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.3630e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.298736
Average KL loss: 0.289337
Average total loss: 0.588074
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.4711e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.298988
Average KL loss: 0.289242
Average total loss: 0.588230
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.0883e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.298516
Average KL loss: 0.289197
Average total loss: 0.587714
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.1816e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.299162
Average KL loss: 0.289323
Average total loss: 0.588485
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.6868e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.296932
Average KL loss: 0.289342
Average total loss: 0.586274
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.7322e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.294781
Average KL loss: 0.289319
Average total loss: 0.584101
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.0525e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.295517
Average KL loss: 0.289128
Average total loss: 0.584645
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0918e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.298547
Average KL loss: 0.289096
Average total loss: 0.587642
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(4.0567e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.301097
Average KL loss: 0.289173
Average total loss: 0.590269
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.3429e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.297061
Average KL loss: 0.289244
Average total loss: 0.586305
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.3445e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.295213
Average KL loss: 0.289223
Average total loss: 0.584436
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.4253e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.293798
Average KL loss: 0.289093
Average total loss: 0.582891
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.3094e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.295295
Average KL loss: 0.288935
Average total loss: 0.584230
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.0817e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.298816
Average KL loss: 0.288934
Average total loss: 0.587750
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.0890e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.299009
Average KL loss: 0.289056
Average total loss: 0.588065
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.7580e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.299208
Average KL loss: 0.289138
Average total loss: 0.588346
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.7396e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.298439
Average KL loss: 0.289153
Average total loss: 0.587592
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.2199e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.294563
Average KL loss: 0.289111
Average total loss: 0.583674
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.1560e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.302569
Average KL loss: 0.289086
Average total loss: 0.591656
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0593e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.297357
Average KL loss: 0.289210
Average total loss: 0.586567
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.3717e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.296936
Average KL loss: 0.289177
Average total loss: 0.586114
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.8442e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.300125
Average KL loss: 0.289271
Average total loss: 0.589396
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.0999e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.299169
Average KL loss: 0.289313
Average total loss: 0.588482
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.2752e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.292199
Average KL loss: 0.289241
Average total loss: 0.581441
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.8882e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.298745
Average KL loss: 0.288986
Average total loss: 0.587731
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.0302e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.298329
Average KL loss: 0.288815
Average total loss: 0.587143
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.3348e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.295989
Average KL loss: 0.288666
Average total loss: 0.584655
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.4154e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.297100
Average KL loss: 0.288538
Average total loss: 0.585638
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.6435e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.296065
Average KL loss: 0.288427
Average total loss: 0.584491
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.3132e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.300114
Average KL loss: 0.288328
Average total loss: 0.588443
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.3388e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.296444
Average KL loss: 0.288237
Average total loss: 0.584681
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.5738e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.297537
Average KL loss: 0.288149
Average total loss: 0.585686
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5993e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.296707
Average KL loss: 0.288081
Average total loss: 0.584787
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.2960e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.298621
Average KL loss: 0.288018
Average total loss: 0.586639
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.3165e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.298793
Average KL loss: 0.287961
Average total loss: 0.586754
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6959e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.298290
Average KL loss: 0.287925
Average total loss: 0.586215
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.3860e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.298897
Average KL loss: 0.287915
Average total loss: 0.586812
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.3096e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.297919
Average KL loss: 0.287906
Average total loss: 0.585825
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.1511e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.296225
Average KL loss: 0.287897
Average total loss: 0.584122
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.0544e-12, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.298449
Average KL loss: 0.287887
Average total loss: 0.586336
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.2273e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.297753
Average KL loss: 0.287879
Average total loss: 0.585631
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.9166e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.297042
Average KL loss: 0.287870
Average total loss: 0.584912
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5891e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.296852
Average KL loss: 0.287861
Average total loss: 0.584713
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.1500e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.295027
Average KL loss: 0.287853
Average total loss: 0.582880
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5896e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.294179
Average KL loss: 0.287845
Average total loss: 0.582024
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.4734e-09, device='cuda:0')
 Percentile value: 0.007161015179008245
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/8]: ---
conv1.weight         | nonzeros =     475 /    1728             ( 27.49%) | total_pruned =    1253 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
bn1.bias             | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5459 /   36864             ( 14.81%) | total_pruned =   31405 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   12296 /   36864             ( 33.36%) | total_pruned =   24568 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   11418 /   36864             ( 30.97%) | total_pruned =   25446 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   14078 /   36864             ( 38.19%) | total_pruned =   22786 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   35147 /   73728             ( 47.67%) | total_pruned =   38581 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   69560 /  147456             ( 47.17%) | total_pruned =   77896 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4549 /    8192             ( 55.53%) | total_pruned =    3643 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   50044 /  147456             ( 33.94%) | total_pruned =   97412 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   43218 /  147456             ( 29.31%) | total_pruned =  104238 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  141645 /  294912             ( 48.03%) | total_pruned =  153267 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     111 /     256             ( 43.36%) | total_pruned =     145 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  275657 /  589824             ( 46.74%) | total_pruned =  314167 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   16111 /   32768             ( 49.17%) | total_pruned =   16657 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  230556 /  589824             ( 39.09%) | total_pruned =  359268 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  182144 /  589824             ( 30.88%) | total_pruned =  407680 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  451225 / 1179648             ( 38.25%) | total_pruned =  728423 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     106 /     512             ( 20.70%) | total_pruned =     406 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  531173 / 2359296             ( 22.51%) | total_pruned = 1828123 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     481 /     512             ( 93.95%) | total_pruned =      31 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     277 /     512             ( 54.10%) | total_pruned =     235 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   27675 /  131072             ( 21.11%) | total_pruned =  103397 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     494 /     512             ( 96.48%) | total_pruned =      18 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  557150 / 2359296             ( 23.62%) | total_pruned = 1802146 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  682304 / 2359296             ( 28.92%) | total_pruned = 1676992 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5073 /    5120             ( 99.08%) | total_pruned =      47 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 60/100 Loss: 0.021199 Accuracy: 89.51 100.00 % Best test Accuracy: 89.59%
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.2793e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.795309
Average KL loss: 0.307220
Average total loss: 1.102529
tensor(0.0036, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.5868e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.621071
Average KL loss: 0.333687
Average total loss: 0.954758
tensor(0.0037, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.7512e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.578303
Average KL loss: 0.338226
Average total loss: 0.916529
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-9.7606e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.549683
Average KL loss: 0.339974
Average total loss: 0.889657
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.7412e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.522064
Average KL loss: 0.338515
Average total loss: 0.860579
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.1276e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.514115
Average KL loss: 0.334396
Average total loss: 0.848511
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.9116e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.490915
Average KL loss: 0.333537
Average total loss: 0.824452
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.5914e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.485119
Average KL loss: 0.332792
Average total loss: 0.817911
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.4921e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.476809
Average KL loss: 0.333187
Average total loss: 0.809996
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.2048e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.473443
Average KL loss: 0.332994
Average total loss: 0.806437
tensor(0.0036, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-7.2701e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.458036
Average KL loss: 0.333981
Average total loss: 0.792017
tensor(0.0035, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.3844e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.444801
Average KL loss: 0.333119
Average total loss: 0.777920
tensor(0.0035, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.6345e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.445991
Average KL loss: 0.331671
Average total loss: 0.777662
tensor(0.0035, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.1149e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.441154
Average KL loss: 0.331930
Average total loss: 0.773084
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.9238e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.443464
Average KL loss: 0.332759
Average total loss: 0.776223
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.6165e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.435089
Average KL loss: 0.333679
Average total loss: 0.768768
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-4.5465e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.424284
Average KL loss: 0.333339
Average total loss: 0.757623
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-8.3826e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.429069
Average KL loss: 0.333462
Average total loss: 0.762531
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-8.4921e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.422093
Average KL loss: 0.333744
Average total loss: 0.755837
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-9.1620e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.418400
Average KL loss: 0.334078
Average total loss: 0.752479
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-9.1146e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.415138
Average KL loss: 0.333611
Average total loss: 0.748748
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.8327e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.410724
Average KL loss: 0.334346
Average total loss: 0.745070
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.6395e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.404482
Average KL loss: 0.333908
Average total loss: 0.738391
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.2626e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.401105
Average KL loss: 0.333183
Average total loss: 0.734289
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.0852e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.413723
Average KL loss: 0.334560
Average total loss: 0.748284
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.1814e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.400833
Average KL loss: 0.334287
Average total loss: 0.735120
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.2231e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.395557
Average KL loss: 0.333330
Average total loss: 0.728887
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2532e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.394547
Average KL loss: 0.333746
Average total loss: 0.728293
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.7711e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.393705
Average KL loss: 0.334261
Average total loss: 0.727966
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.5109e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.390344
Average KL loss: 0.333711
Average total loss: 0.724055
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.0528e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.386800
Average KL loss: 0.333667
Average total loss: 0.720467
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.9572e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.383800
Average KL loss: 0.333504
Average total loss: 0.717304
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.4703e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.390477
Average KL loss: 0.334185
Average total loss: 0.724663
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.4044e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.389554
Average KL loss: 0.335016
Average total loss: 0.724571
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.4798e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.387927
Average KL loss: 0.334975
Average total loss: 0.722902
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.0673e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.379849
Average KL loss: 0.335052
Average total loss: 0.714901
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.0307e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.382922
Average KL loss: 0.335035
Average total loss: 0.717956
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.9344e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.380180
Average KL loss: 0.334344
Average total loss: 0.714523
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.9888e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.379351
Average KL loss: 0.335221
Average total loss: 0.714571
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.2395e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.376342
Average KL loss: 0.334740
Average total loss: 0.711082
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.1285e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.371690
Average KL loss: 0.335360
Average total loss: 0.707050
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(6.3893e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.381401
Average KL loss: 0.334959
Average total loss: 0.716360
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.1027e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.372799
Average KL loss: 0.335431
Average total loss: 0.708230
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(8.3105e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.373340
Average KL loss: 0.335786
Average total loss: 0.709126
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(6.3484e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.367011
Average KL loss: 0.335107
Average total loss: 0.702117
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.4189e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.369607
Average KL loss: 0.335369
Average total loss: 0.704976
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.9347e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.366770
Average KL loss: 0.335677
Average total loss: 0.702447
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.6839e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.364972
Average KL loss: 0.335566
Average total loss: 0.700538
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.7609e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.369907
Average KL loss: 0.335155
Average total loss: 0.705061
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.8583e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.374500
Average KL loss: 0.336575
Average total loss: 0.711075
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.4846e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.364750
Average KL loss: 0.337149
Average total loss: 0.701899
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.1779e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.363339
Average KL loss: 0.336714
Average total loss: 0.700052
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.2214e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.358437
Average KL loss: 0.336155
Average total loss: 0.694592
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(1.3366e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.358895
Average KL loss: 0.335533
Average total loss: 0.694428
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3770e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.357029
Average KL loss: 0.335879
Average total loss: 0.692909
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.7596e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.358355
Average KL loss: 0.336014
Average total loss: 0.694369
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.3145e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.355912
Average KL loss: 0.336075
Average total loss: 0.691987
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.1501e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.354402
Average KL loss: 0.336370
Average total loss: 0.690771
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.2934e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.360021
Average KL loss: 0.336835
Average total loss: 0.696856
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(7.3439e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.355443
Average KL loss: 0.336449
Average total loss: 0.691892
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.1487e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.350696
Average KL loss: 0.336107
Average total loss: 0.686804
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.7246e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.357366
Average KL loss: 0.336011
Average total loss: 0.693377
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(2.6958e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.357018
Average KL loss: 0.336821
Average total loss: 0.693838
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.1098e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.355516
Average KL loss: 0.337809
Average total loss: 0.693325
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.6916e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.354852
Average KL loss: 0.337768
Average total loss: 0.692620
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.0671e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.349519
Average KL loss: 0.337460
Average total loss: 0.686978
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.5190e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.355402
Average KL loss: 0.338134
Average total loss: 0.693535
tensor(0.0036, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.2396e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.349991
Average KL loss: 0.338255
Average total loss: 0.688246
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.7130e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.347744
Average KL loss: 0.338193
Average total loss: 0.685937
tensor(0.0036, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-9.7617e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.358182
Average KL loss: 0.338020
Average total loss: 0.696202
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(3.4303e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.352187
Average KL loss: 0.339144
Average total loss: 0.691330
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.9780e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.351335
Average KL loss: 0.338816
Average total loss: 0.690151
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(4.8325e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.348254
Average KL loss: 0.338625
Average total loss: 0.686879
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.2270e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.350818
Average KL loss: 0.338580
Average total loss: 0.689397
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.6102e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.346354
Average KL loss: 0.338482
Average total loss: 0.684835
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(4.4483e-11, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.352096
Average KL loss: 0.339118
Average total loss: 0.691214
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.0177e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.347567
Average KL loss: 0.339171
Average total loss: 0.686738
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.7409e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.349691
Average KL loss: 0.339295
Average total loss: 0.688986
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.2671e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.346519
Average KL loss: 0.339409
Average total loss: 0.685928
tensor(0.0036, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.5745e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.345901
Average KL loss: 0.339570
Average total loss: 0.685471
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.0910e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.341152
Average KL loss: 0.338804
Average total loss: 0.679956
tensor(0.0036, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.1765e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.342616
Average KL loss: 0.338153
Average total loss: 0.680769
tensor(0.0036, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.6111e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.343662
Average KL loss: 0.338448
Average total loss: 0.682110
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.5473e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.336288
Average KL loss: 0.338686
Average total loss: 0.674974
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(5.3862e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.342038
Average KL loss: 0.338191
Average total loss: 0.680229
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.3847e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.343145
Average KL loss: 0.338789
Average total loss: 0.681934
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.2099e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.339356
Average KL loss: 0.339044
Average total loss: 0.678400
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(5.6073e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.344153
Average KL loss: 0.339642
Average total loss: 0.683794
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.6874e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.343177
Average KL loss: 0.339832
Average total loss: 0.683008
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4872e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.340163
Average KL loss: 0.339776
Average total loss: 0.679939
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.5525e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.341577
Average KL loss: 0.338624
Average total loss: 0.680200
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-8.3276e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.344258
Average KL loss: 0.340258
Average total loss: 0.684516
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.4704e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.344281
Average KL loss: 0.340377
Average total loss: 0.684658
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0096e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.339540
Average KL loss: 0.341286
Average total loss: 0.680826
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(3.0225e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.340365
Average KL loss: 0.339981
Average total loss: 0.680346
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.2228e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.339272
Average KL loss: 0.337744
Average total loss: 0.677016
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.2062e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.337450
Average KL loss: 0.333166
Average total loss: 0.670616
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.1221e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.333888
Average KL loss: 0.330253
Average total loss: 0.664141
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.8360e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.341626
Average KL loss: 0.328164
Average total loss: 0.669790
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.4214e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.340164
Average KL loss: 0.326646
Average total loss: 0.666810
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.6663e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.339557
Average KL loss: 0.325352
Average total loss: 0.664909
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0330e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.343359
Average KL loss: 0.324306
Average total loss: 0.667665
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.8386e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.334204
Average KL loss: 0.323469
Average total loss: 0.657673
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0778e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.336031
Average KL loss: 0.322531
Average total loss: 0.658561
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.2508e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.333648
Average KL loss: 0.321807
Average total loss: 0.655454
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5320e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.335726
Average KL loss: 0.321042
Average total loss: 0.656768
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.9624e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.336964
Average KL loss: 0.320503
Average total loss: 0.657467
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.1818e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.337677
Average KL loss: 0.320103
Average total loss: 0.657780
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.7722e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.337952
Average KL loss: 0.319656
Average total loss: 0.657608
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.3862e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.334233
Average KL loss: 0.319212
Average total loss: 0.653445
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.0474e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.335804
Average KL loss: 0.318952
Average total loss: 0.654756
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.7602e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.334622
Average KL loss: 0.318594
Average total loss: 0.653216
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.0094e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.339978
Average KL loss: 0.318340
Average total loss: 0.658318
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.8689e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.336434
Average KL loss: 0.318183
Average total loss: 0.654617
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0307e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.335620
Average KL loss: 0.317956
Average total loss: 0.653577
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.0127e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.335994
Average KL loss: 0.317773
Average total loss: 0.653766
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.7071e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.334959
Average KL loss: 0.317435
Average total loss: 0.652394
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0697e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.337632
Average KL loss: 0.317107
Average total loss: 0.654739
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.4337e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.334722
Average KL loss: 0.316944
Average total loss: 0.651666
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.3158e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.338424
Average KL loss: 0.316777
Average total loss: 0.655202
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.3451e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.340979
Average KL loss: 0.316737
Average total loss: 0.657717
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.3168e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.337743
Average KL loss: 0.316753
Average total loss: 0.654496
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.5045e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.337865
Average KL loss: 0.316721
Average total loss: 0.654586
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.0039e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.334532
Average KL loss: 0.316591
Average total loss: 0.651123
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.6567e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.339693
Average KL loss: 0.316389
Average total loss: 0.656081
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.9353e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.335680
Average KL loss: 0.316285
Average total loss: 0.651965
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.0965e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.338123
Average KL loss: 0.316192
Average total loss: 0.654315
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.1398e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.336679
Average KL loss: 0.316081
Average total loss: 0.652759
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.0452e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.333181
Average KL loss: 0.315939
Average total loss: 0.649119
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.1932e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.336572
Average KL loss: 0.315841
Average total loss: 0.652414
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.5998e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.335978
Average KL loss: 0.315720
Average total loss: 0.651698
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.5617e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.334798
Average KL loss: 0.315758
Average total loss: 0.650556
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.8546e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.336175
Average KL loss: 0.315785
Average total loss: 0.651960
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.5442e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.333497
Average KL loss: 0.315697
Average total loss: 0.649194
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.0026e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.335593
Average KL loss: 0.315559
Average total loss: 0.651152
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.7070e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.335119
Average KL loss: 0.315448
Average total loss: 0.650567
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(6.3234e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.340210
Average KL loss: 0.315445
Average total loss: 0.655655
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.1518e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.336237
Average KL loss: 0.315396
Average total loss: 0.651633
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.5246e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.331625
Average KL loss: 0.315206
Average total loss: 0.646831
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.9548e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.333963
Average KL loss: 0.315079
Average total loss: 0.649042
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.0188e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.335216
Average KL loss: 0.315017
Average total loss: 0.650233
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.1205e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.331720
Average KL loss: 0.314974
Average total loss: 0.646695
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.8522e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.337994
Average KL loss: 0.314928
Average total loss: 0.652923
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.1641e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.336602
Average KL loss: 0.314912
Average total loss: 0.651514
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.5087e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.339997
Average KL loss: 0.314959
Average total loss: 0.654957
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6720e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.334520
Average KL loss: 0.314997
Average total loss: 0.649517
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.3731e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.336292
Average KL loss: 0.314890
Average total loss: 0.651182
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.7265e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.335893
Average KL loss: 0.314900
Average total loss: 0.650793
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.1513e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.334132
Average KL loss: 0.314909
Average total loss: 0.649042
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.4513e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.335130
Average KL loss: 0.314904
Average total loss: 0.650034
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.3250e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.333968
Average KL loss: 0.314807
Average total loss: 0.648775
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.2475e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.332820
Average KL loss: 0.314697
Average total loss: 0.647517
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.8416e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.333553
Average KL loss: 0.314638
Average total loss: 0.648191
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(7.0762e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.336286
Average KL loss: 0.314573
Average total loss: 0.650859
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.5467e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.331337
Average KL loss: 0.314480
Average total loss: 0.645818
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.6043e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.340053
Average KL loss: 0.314402
Average total loss: 0.654456
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(6.3418e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.337885
Average KL loss: 0.314342
Average total loss: 0.652227
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.5264e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.334358
Average KL loss: 0.314279
Average total loss: 0.648637
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0146e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.337390
Average KL loss: 0.314213
Average total loss: 0.651602
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.3156e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.337014
Average KL loss: 0.314150
Average total loss: 0.651165
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(6.4420e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.329965
Average KL loss: 0.314094
Average total loss: 0.644059
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.3686e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.335913
Average KL loss: 0.314042
Average total loss: 0.649955
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(9.5885e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.340086
Average KL loss: 0.314002
Average total loss: 0.654088
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.1532e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.336025
Average KL loss: 0.313964
Average total loss: 0.649989
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.2959e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.332034
Average KL loss: 0.313932
Average total loss: 0.645966
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.3314e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.329449
Average KL loss: 0.313884
Average total loss: 0.643333
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.3182e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.335708
Average KL loss: 0.313847
Average total loss: 0.649556
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.1377e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.334997
Average KL loss: 0.313807
Average total loss: 0.648804
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.6221e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.332195
Average KL loss: 0.313764
Average total loss: 0.645959
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.9903e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.336035
Average KL loss: 0.313723
Average total loss: 0.649758
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6807e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.336243
Average KL loss: 0.313696
Average total loss: 0.649940
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.0536e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.337937
Average KL loss: 0.313669
Average total loss: 0.651606
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.2709e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.339522
Average KL loss: 0.313654
Average total loss: 0.653176
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.1933e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.335782
Average KL loss: 0.313634
Average total loss: 0.649417
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.7158e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.336368
Average KL loss: 0.313608
Average total loss: 0.649976
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0852e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.336201
Average KL loss: 0.313581
Average total loss: 0.649783
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0885e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.337679
Average KL loss: 0.313556
Average total loss: 0.651235
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.2110e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.333098
Average KL loss: 0.313544
Average total loss: 0.646642
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(9.2963e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.336364
Average KL loss: 0.313539
Average total loss: 0.649904
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.0321e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.334138
Average KL loss: 0.313536
Average total loss: 0.647674
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7145e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.335642
Average KL loss: 0.313532
Average total loss: 0.649174
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6256e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.337840
Average KL loss: 0.313529
Average total loss: 0.651369
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.0399e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.336468
Average KL loss: 0.313525
Average total loss: 0.649994
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5517e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.333643
Average KL loss: 0.313522
Average total loss: 0.647164
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7143e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.338939
Average KL loss: 0.313517
Average total loss: 0.652456
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.6974e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.333343
Average KL loss: 0.313513
Average total loss: 0.646856
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.4204e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.332310
Average KL loss: 0.313509
Average total loss: 0.645819
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.4580e-09, device='cuda:0')
 Percentile value: 0.02574667371809482
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/8]: ---
conv1.weight         | nonzeros =     215 /    1728             ( 12.44%) | total_pruned =    1513 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
bn1.bias             | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     957 /   36864             (  2.60%) | total_pruned =   35907 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2474 /   36864             (  6.71%) | total_pruned =   34390 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3251 /   36864             (  8.82%) | total_pruned =   33613 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    5136 /   36864             ( 13.93%) | total_pruned =   31728 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13766 /   73728             ( 18.67%) | total_pruned =   59962 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   25341 /  147456             ( 17.19%) | total_pruned =  122115 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2010 /    8192             ( 24.54%) | total_pruned =    6182 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   14747 /  147456             ( 10.00%) | total_pruned =  132709 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   11283 /  147456             (  7.65%) | total_pruned =  136173 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   59504 /  294912             ( 20.18%) | total_pruned =  235408 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  108418 /  589824             ( 18.38%) | total_pruned =  481406 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      44 /     256             ( 17.19%) | total_pruned =     212 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6920 /   32768             ( 21.12%) | total_pruned =   25848 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   71204 /  589824             ( 12.07%) | total_pruned =  518620 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   43922 /  589824             (  7.45%) | total_pruned =  545902 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  160438 / 1179648             ( 13.60%) | total_pruned = 1019210 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  133453 / 2359296             (  5.66%) | total_pruned = 2225843 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     395 /     512             ( 77.15%) | total_pruned =     117 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     190 /     512             ( 37.11%) | total_pruned =     322 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    4875 /  131072             (  3.72%) | total_pruned =  126197 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     299 /     512             ( 58.40%) | total_pruned =     213 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  122212 / 2359296             (  5.18%) | total_pruned = 2237084 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     391 /     512             ( 76.37%) | total_pruned =     121 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  206151 / 2359296             (  8.74%) | total_pruned = 2153145 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     467 /     512             ( 91.21%) | total_pruned =      45 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     463 /     512             ( 90.43%) | total_pruned =      49 | shape = torch.Size([512])
linear.weight        | nonzeros =    4529 /    5120             ( 88.46%) | total_pruned =     591 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 51/100 Loss: 0.019574 Accuracy: 88.26 100.00 % Best test Accuracy: 88.66%
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.2942e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.984401
Average KL loss: 0.307889
Average total loss: 1.292290
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.3073e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.789574
Average KL loss: 0.330313
Average total loss: 1.119887
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.6444e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.713390
Average KL loss: 0.341336
Average total loss: 1.054726
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.8228e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.679119
Average KL loss: 0.345278
Average total loss: 1.024397
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.7209e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.634725
Average KL loss: 0.347514
Average total loss: 0.982238
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.9023e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.607263
Average KL loss: 0.347928
Average total loss: 0.955190
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.0452e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.584091
Average KL loss: 0.347900
Average total loss: 0.931991
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.9520e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.581952
Average KL loss: 0.349404
Average total loss: 0.931356
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-7.7502e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.550510
Average KL loss: 0.350206
Average total loss: 0.900716
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.3501e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.542829
Average KL loss: 0.350698
Average total loss: 0.893527
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-6.9338e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.530240
Average KL loss: 0.351313
Average total loss: 0.881553
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.7959e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.530716
Average KL loss: 0.352163
Average total loss: 0.882879
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.7877e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.512791
Average KL loss: 0.352900
Average total loss: 0.865691
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.4739e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.526621
Average KL loss: 0.353889
Average total loss: 0.880511
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.9128e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.501422
Average KL loss: 0.353551
Average total loss: 0.854972
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.6500e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.502485
Average KL loss: 0.354379
Average total loss: 0.856865
tensor(0.0034, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.5897e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.488449
Average KL loss: 0.354360
Average total loss: 0.842810
tensor(0.0034, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5922e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.499980
Average KL loss: 0.354849
Average total loss: 0.854829
tensor(0.0034, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.8854e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.486430
Average KL loss: 0.356485
Average total loss: 0.842916
tensor(0.0034, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.9424e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.483535
Average KL loss: 0.356637
Average total loss: 0.840172
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.2426e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.480920
Average KL loss: 0.356744
Average total loss: 0.837664
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.2683e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.469282
Average KL loss: 0.356287
Average total loss: 0.825569
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.3796e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.469532
Average KL loss: 0.356888
Average total loss: 0.826420
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.6735e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.474266
Average KL loss: 0.356411
Average total loss: 0.830677
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.8368e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.468339
Average KL loss: 0.356653
Average total loss: 0.824992
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.1150e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.460668
Average KL loss: 0.357180
Average total loss: 0.817848
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.8070e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.457918
Average KL loss: 0.357480
Average total loss: 0.815398
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.3150e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.449408
Average KL loss: 0.357412
Average total loss: 0.806820
tensor(0.0034, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.4200e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.458657
Average KL loss: 0.357642
Average total loss: 0.816299
tensor(0.0034, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.0007e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.449162
Average KL loss: 0.357569
Average total loss: 0.806731
tensor(0.0034, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.3485e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.449856
Average KL loss: 0.357638
Average total loss: 0.807494
tensor(0.0034, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-9.4751e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.450125
Average KL loss: 0.358328
Average total loss: 0.808453
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.7594e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.444683
Average KL loss: 0.358272
Average total loss: 0.802955
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-8.4997e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.445286
Average KL loss: 0.358367
Average total loss: 0.803653
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1278e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.435841
Average KL loss: 0.358449
Average total loss: 0.794290
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.5214e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.437623
Average KL loss: 0.358062
Average total loss: 0.795685
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.7757e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.443146
Average KL loss: 0.358674
Average total loss: 0.801820
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.4623e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.435883
Average KL loss: 0.359018
Average total loss: 0.794901
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1677e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.436067
Average KL loss: 0.359573
Average total loss: 0.795641
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.7942e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.440666
Average KL loss: 0.359367
Average total loss: 0.800033
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.5438e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.431739
Average KL loss: 0.359897
Average total loss: 0.791636
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.1561e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.428904
Average KL loss: 0.360293
Average total loss: 0.789198
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.2777e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.428633
Average KL loss: 0.360029
Average total loss: 0.788662
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.9473e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.426673
Average KL loss: 0.360062
Average total loss: 0.786735
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.0255e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.426939
Average KL loss: 0.360040
Average total loss: 0.786979
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.3498e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.426730
Average KL loss: 0.360111
Average total loss: 0.786841
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.7255e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.422993
Average KL loss: 0.360242
Average total loss: 0.783235
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.0733e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.422646
Average KL loss: 0.359885
Average total loss: 0.782531
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.5878e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.420190
Average KL loss: 0.359728
Average total loss: 0.779918
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.0155e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.416618
Average KL loss: 0.359349
Average total loss: 0.775966
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.4918e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.418421
Average KL loss: 0.359604
Average total loss: 0.778025
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(6.9212e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.415884
Average KL loss: 0.359276
Average total loss: 0.775160
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.7345e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.412332
Average KL loss: 0.358952
Average total loss: 0.771284
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.1970e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.415424
Average KL loss: 0.358996
Average total loss: 0.774420
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.8354e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.415616
Average KL loss: 0.359496
Average total loss: 0.775112
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.4240e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.407685
Average KL loss: 0.360068
Average total loss: 0.767754
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.3830e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.413557
Average KL loss: 0.359809
Average total loss: 0.773367
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.2889e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.411645
Average KL loss: 0.360288
Average total loss: 0.771933
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-8.6789e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.413068
Average KL loss: 0.361053
Average total loss: 0.774121
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(5.2371e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.408546
Average KL loss: 0.360602
Average total loss: 0.769148
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(3.1302e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.416789
Average KL loss: 0.360618
Average total loss: 0.777407
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.6687e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.411162
Average KL loss: 0.362164
Average total loss: 0.773326
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.8544e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.403651
Average KL loss: 0.361833
Average total loss: 0.765484
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4974e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.407655
Average KL loss: 0.361516
Average total loss: 0.769171
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.2869e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.408796
Average KL loss: 0.361579
Average total loss: 0.770375
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.8790e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.407628
Average KL loss: 0.361782
Average total loss: 0.769410
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.0092e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.406334
Average KL loss: 0.361383
Average total loss: 0.767717
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.4150e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.409288
Average KL loss: 0.362022
Average total loss: 0.771310
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.7079e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.397630
Average KL loss: 0.361766
Average total loss: 0.759396
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.9329e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.408460
Average KL loss: 0.361825
Average total loss: 0.770285
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.0861e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.404609
Average KL loss: 0.363092
Average total loss: 0.767701
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1332e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.403705
Average KL loss: 0.362629
Average total loss: 0.766333
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.7684e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.402839
Average KL loss: 0.362121
Average total loss: 0.764960
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.6715e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.402784
Average KL loss: 0.362357
Average total loss: 0.765141
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.1392e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.402165
Average KL loss: 0.362471
Average total loss: 0.764636
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.7416e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.400812
Average KL loss: 0.362313
Average total loss: 0.763125
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.1528e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.398287
Average KL loss: 0.362524
Average total loss: 0.760811
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.7363e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.408268
Average KL loss: 0.362420
Average total loss: 0.770688
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.9145e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.406519
Average KL loss: 0.362389
Average total loss: 0.768908
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-9.7354e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.402794
Average KL loss: 0.362231
Average total loss: 0.765025
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.4272e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.396742
Average KL loss: 0.360981
Average total loss: 0.757723
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.0648e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.400957
Average KL loss: 0.358677
Average total loss: 0.759634
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.6665e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.394042
Average KL loss: 0.356948
Average total loss: 0.750990
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.2716e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.395332
Average KL loss: 0.355576
Average total loss: 0.750908
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.1562e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.399870
Average KL loss: 0.354322
Average total loss: 0.754192
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.5918e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.397416
Average KL loss: 0.353219
Average total loss: 0.750635
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.8616e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.399056
Average KL loss: 0.352214
Average total loss: 0.751270
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.2615e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.400974
Average KL loss: 0.351472
Average total loss: 0.752446
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(7.0966e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.398732
Average KL loss: 0.350731
Average total loss: 0.749464
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.9209e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.394854
Average KL loss: 0.350013
Average total loss: 0.744868
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.3579e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.399475
Average KL loss: 0.349391
Average total loss: 0.748866
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.1638e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.398779
Average KL loss: 0.348911
Average total loss: 0.747689
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.4826e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.394142
Average KL loss: 0.348479
Average total loss: 0.742620
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.7758e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.401197
Average KL loss: 0.348068
Average total loss: 0.749265
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.6846e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.396880
Average KL loss: 0.347699
Average total loss: 0.744579
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.5996e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.396680
Average KL loss: 0.347300
Average total loss: 0.743980
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.3776e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.395971
Average KL loss: 0.346935
Average total loss: 0.742906
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.1286e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.406536
Average KL loss: 0.346618
Average total loss: 0.753154
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.4090e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.395687
Average KL loss: 0.346295
Average total loss: 0.741982
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-8.8580e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.394982
Average KL loss: 0.345915
Average total loss: 0.740896
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.7034e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.399253
Average KL loss: 0.345642
Average total loss: 0.744895
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(7.5618e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.399937
Average KL loss: 0.345348
Average total loss: 0.745285
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0998e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.393249
Average KL loss: 0.345091
Average total loss: 0.738340
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0322e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.397153
Average KL loss: 0.344827
Average total loss: 0.741980
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.2908e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.399447
Average KL loss: 0.344644
Average total loss: 0.744091
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.8481e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.395313
Average KL loss: 0.344455
Average total loss: 0.739768
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.1901e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.396114
Average KL loss: 0.344295
Average total loss: 0.740409
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.9422e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.393334
Average KL loss: 0.344006
Average total loss: 0.737340
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.0273e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.394243
Average KL loss: 0.343749
Average total loss: 0.737992
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.0506e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.396928
Average KL loss: 0.343576
Average total loss: 0.740504
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.8847e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.396878
Average KL loss: 0.343490
Average total loss: 0.740369
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0960e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.394090
Average KL loss: 0.343377
Average total loss: 0.737467
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.1503e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.393272
Average KL loss: 0.343252
Average total loss: 0.736524
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.5996e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.397095
Average KL loss: 0.343114
Average total loss: 0.740209
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.1345e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.389888
Average KL loss: 0.342943
Average total loss: 0.732831
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.3338e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.396705
Average KL loss: 0.342742
Average total loss: 0.739447
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8043e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.393809
Average KL loss: 0.342657
Average total loss: 0.736466
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(7.0681e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.393023
Average KL loss: 0.342403
Average total loss: 0.735427
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.2533e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.394704
Average KL loss: 0.342185
Average total loss: 0.736889
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.6228e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.401562
Average KL loss: 0.342047
Average total loss: 0.743609
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.4260e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.395886
Average KL loss: 0.342084
Average total loss: 0.737971
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7331e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.395180
Average KL loss: 0.341992
Average total loss: 0.737172
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.3771e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.396883
Average KL loss: 0.341891
Average total loss: 0.738773
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.3307e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.399007
Average KL loss: 0.341829
Average total loss: 0.740836
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.3137e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.394590
Average KL loss: 0.341810
Average total loss: 0.736400
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.5737e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.403794
Average KL loss: 0.341814
Average total loss: 0.745607
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.9997e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.396227
Average KL loss: 0.341766
Average total loss: 0.737993
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.8126e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.393868
Average KL loss: 0.341722
Average total loss: 0.735590
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.7539e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.391061
Average KL loss: 0.341672
Average total loss: 0.732733
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0923e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.397339
Average KL loss: 0.341623
Average total loss: 0.738962
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.7952e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.393553
Average KL loss: 0.341577
Average total loss: 0.735130
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.0290e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.397489
Average KL loss: 0.341537
Average total loss: 0.739026
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.4042e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.402745
Average KL loss: 0.341505
Average total loss: 0.744250
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.0907e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.397728
Average KL loss: 0.341476
Average total loss: 0.739204
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.5685e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.398349
Average KL loss: 0.341443
Average total loss: 0.739792
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.0086e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.394460
Average KL loss: 0.341415
Average total loss: 0.735875
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.2449e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.392752
Average KL loss: 0.341376
Average total loss: 0.734128
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.4629e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.397575
Average KL loss: 0.341337
Average total loss: 0.738912
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.1940e-12, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.395019
Average KL loss: 0.341305
Average total loss: 0.736324
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.8513e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.392358
Average KL loss: 0.341269
Average total loss: 0.733627
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.9703e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.393689
Average KL loss: 0.341250
Average total loss: 0.734939
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.8192e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.396658
Average KL loss: 0.341245
Average total loss: 0.737903
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.7036e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.396211
Average KL loss: 0.341241
Average total loss: 0.737452
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.0942e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.398778
Average KL loss: 0.341238
Average total loss: 0.740016
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.0272e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.393883
Average KL loss: 0.341234
Average total loss: 0.735117
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.4013e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.401348
Average KL loss: 0.341231
Average total loss: 0.742580
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.9291e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.392003
Average KL loss: 0.341228
Average total loss: 0.733231
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.0360e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.397761
Average KL loss: 0.341225
Average total loss: 0.738986
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.4694e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.394892
Average KL loss: 0.341221
Average total loss: 0.736112
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.7442e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.396501
Average KL loss: 0.341216
Average total loss: 0.737717
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.9877e-09, device='cuda:0')
 Percentile value: 0.09376627057790754
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/8]: ---
conv1.weight         | nonzeros =     175 /    1728             ( 10.13%) | total_pruned =    1553 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     354 /   36864             (  0.96%) | total_pruned =   36510 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     475 /   36864             (  1.29%) | total_pruned =   36389 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     728 /   36864             (  1.97%) | total_pruned =   36136 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1483 /   36864             (  4.02%) | total_pruned =   35381 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4434 /   73728             (  6.01%) | total_pruned =   69294 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    8617 /  147456             (  5.84%) | total_pruned =  138839 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     836 /    8192             ( 10.21%) | total_pruned =    7356 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4872 /  147456             (  3.30%) | total_pruned =  142584 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3841 /  147456             (  2.60%) | total_pruned =  143615 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   23578 /  294912             (  7.99%) | total_pruned =  271334 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     214 /     256             ( 83.59%) | total_pruned =      42 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      56 /     256             ( 21.88%) | total_pruned =     200 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   40117 /  589824             (  6.80%) | total_pruned =  549707 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2627 /   32768             (  8.02%) | total_pruned =   30141 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     189 /     256             ( 73.83%) | total_pruned =      67 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      41 /     256             ( 16.02%) | total_pruned =     215 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   23663 /  589824             (  4.01%) | total_pruned =  566161 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     194 /     256             ( 75.78%) | total_pruned =      62 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   14390 /  589824             (  2.44%) | total_pruned =  575434 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     166 /     256             ( 64.84%) | total_pruned =      90 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   46078 / 1179648             (  3.91%) | total_pruned = 1133570 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     453 /     512             ( 88.48%) | total_pruned =      59 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      43 /     512             (  8.40%) | total_pruned =     469 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   31342 / 2359296             (  1.33%) | total_pruned = 2327954 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     298 /     512             ( 58.20%) | total_pruned =     214 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     167 /     512             ( 32.62%) | total_pruned =     345 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     935 /  131072             (  0.71%) | total_pruned =  130137 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     158 /     512             ( 30.86%) | total_pruned =     354 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     174 /     512             ( 33.98%) | total_pruned =     338 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   30489 / 2359296             (  1.29%) | total_pruned = 2328807 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     225 /     512             ( 43.95%) | total_pruned =     287 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   54874 / 2359296             (  2.33%) | total_pruned = 2304422 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
linear.weight        | nonzeros =    3680 /    5120             ( 71.88%) | total_pruned =    1440 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 62/100 Loss: 0.019187 Accuracy: 88.22 100.00 % Best test Accuracy: 88.29%
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.3467e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.738931
Average KL loss: 0.319287
Average total loss: 1.058218
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.5537e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.643184
Average KL loss: 0.324557
Average total loss: 0.967741
tensor(0.0033, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6320e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.598296
Average KL loss: 0.330903
Average total loss: 0.929198
tensor(0.0032, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.2880e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.572223
Average KL loss: 0.334983
Average total loss: 0.907206
tensor(0.0032, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2291e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.559052
Average KL loss: 0.337477
Average total loss: 0.896530
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.4955e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.541950
Average KL loss: 0.339480
Average total loss: 0.881429
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.7021e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.532397
Average KL loss: 0.340440
Average total loss: 0.872838
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.5186e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.529092
Average KL loss: 0.342637
Average total loss: 0.871729
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.8232e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.514382
Average KL loss: 0.344380
Average total loss: 0.858762
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.7711e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.511776
Average KL loss: 0.346087
Average total loss: 0.857863
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.6880e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.506133
Average KL loss: 0.347821
Average total loss: 0.853954
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(3.3415e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.499351
Average KL loss: 0.349226
Average total loss: 0.848578
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(8.0733e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.495274
Average KL loss: 0.349843
Average total loss: 0.845117
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.1208e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.493686
Average KL loss: 0.350329
Average total loss: 0.844015
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.7919e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.487194
Average KL loss: 0.351216
Average total loss: 0.838410
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.8795e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.490459
Average KL loss: 0.352252
Average total loss: 0.842710
tensor(0.0030, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.4326e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.483025
Average KL loss: 0.353612
Average total loss: 0.836638
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.6080e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.484253
Average KL loss: 0.354628
Average total loss: 0.838881
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.1874e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.483777
Average KL loss: 0.354889
Average total loss: 0.838666
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.9827e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.478273
Average KL loss: 0.355616
Average total loss: 0.833889
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(8.1166e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.477538
Average KL loss: 0.356287
Average total loss: 0.833824
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.9041e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.475505
Average KL loss: 0.356753
Average total loss: 0.832258
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.2106e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.469226
Average KL loss: 0.356702
Average total loss: 0.825928
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(8.6851e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.469959
Average KL loss: 0.357034
Average total loss: 0.826994
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.7352e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.465886
Average KL loss: 0.357422
Average total loss: 0.823307
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.7273e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.470306
Average KL loss: 0.357490
Average total loss: 0.827796
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.5131e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.463306
Average KL loss: 0.358152
Average total loss: 0.821458
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.5995e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.467746
Average KL loss: 0.357852
Average total loss: 0.825597
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.3486e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.460962
Average KL loss: 0.358312
Average total loss: 0.819274
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.7129e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.460034
Average KL loss: 0.358635
Average total loss: 0.818669
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.6924e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.463513
Average KL loss: 0.358697
Average total loss: 0.822211
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(5.0323e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.465443
Average KL loss: 0.358723
Average total loss: 0.824166
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(7.0612e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.464909
Average KL loss: 0.359784
Average total loss: 0.824693
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.5065e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.461635
Average KL loss: 0.360205
Average total loss: 0.821840
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.5686e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.457788
Average KL loss: 0.360118
Average total loss: 0.817906
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.1173e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.463842
Average KL loss: 0.360859
Average total loss: 0.824701
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(2.9758e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.451196
Average KL loss: 0.361176
Average total loss: 0.812372
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.1206e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.452446
Average KL loss: 0.361197
Average total loss: 0.813644
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-7.6930e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.458378
Average KL loss: 0.361325
Average total loss: 0.819703
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.0093e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.452589
Average KL loss: 0.361475
Average total loss: 0.814063
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(1.6199e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.454738
Average KL loss: 0.361155
Average total loss: 0.815893
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.9633e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.456900
Average KL loss: 0.361880
Average total loss: 0.818781
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(4.2469e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.454463
Average KL loss: 0.362110
Average total loss: 0.816573
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.9985e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.452076
Average KL loss: 0.361994
Average total loss: 0.814070
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.9635e-11, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.450301
Average KL loss: 0.362742
Average total loss: 0.813043
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.7879e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.457847
Average KL loss: 0.363140
Average total loss: 0.820987
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.0955e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.451124
Average KL loss: 0.363374
Average total loss: 0.814498
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0457e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.454904
Average KL loss: 0.363326
Average total loss: 0.818230
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(9.4911e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.453862
Average KL loss: 0.362701
Average total loss: 0.816563
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.0970e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.449231
Average KL loss: 0.361799
Average total loss: 0.811029
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.3999e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.451418
Average KL loss: 0.361000
Average total loss: 0.812418
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(3.1794e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.447200
Average KL loss: 0.360245
Average total loss: 0.807445
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.3027e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.447959
Average KL loss: 0.359560
Average total loss: 0.807519
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.3847e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.447721
Average KL loss: 0.358949
Average total loss: 0.806671
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.9192e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.453966
Average KL loss: 0.358445
Average total loss: 0.812411
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.3749e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.447907
Average KL loss: 0.357968
Average total loss: 0.805875
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.7050e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.450357
Average KL loss: 0.357526
Average total loss: 0.807883
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.6052e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.448975
Average KL loss: 0.357116
Average total loss: 0.806091
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.9278e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.453013
Average KL loss: 0.356686
Average total loss: 0.809699
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.4010e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.455791
Average KL loss: 0.356364
Average total loss: 0.812155
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.5359e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.453424
Average KL loss: 0.355989
Average total loss: 0.809413
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.4821e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.447313
Average KL loss: 0.355596
Average total loss: 0.802909
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(4.0594e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.447961
Average KL loss: 0.355228
Average total loss: 0.803188
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.5746e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.455307
Average KL loss: 0.354910
Average total loss: 0.810218
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(5.8028e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.450354
Average KL loss: 0.354623
Average total loss: 0.804977
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.4034e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.448133
Average KL loss: 0.354355
Average total loss: 0.802487
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.4793e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.449554
Average KL loss: 0.354107
Average total loss: 0.803661
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.2900e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.449362
Average KL loss: 0.353872
Average total loss: 0.803234
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.9089e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.444674
Average KL loss: 0.353659
Average total loss: 0.798333
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.1639e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.455573
Average KL loss: 0.353401
Average total loss: 0.808974
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.2857e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.446919
Average KL loss: 0.353173
Average total loss: 0.800092
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(7.2103e-11, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.449755
Average KL loss: 0.352896
Average total loss: 0.802651
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.7502e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.446654
Average KL loss: 0.352703
Average total loss: 0.799356
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.6673e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.446040
Average KL loss: 0.352467
Average total loss: 0.798508
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.2269e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.448658
Average KL loss: 0.352299
Average total loss: 0.800957
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.6787e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.455723
Average KL loss: 0.352147
Average total loss: 0.807869
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.4278e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.447799
Average KL loss: 0.351988
Average total loss: 0.799787
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.8101e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.449201
Average KL loss: 0.351834
Average total loss: 0.801034
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.1381e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.448662
Average KL loss: 0.351661
Average total loss: 0.800323
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(4.8981e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.452439
Average KL loss: 0.351427
Average total loss: 0.803866
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.6466e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.448748
Average KL loss: 0.351295
Average total loss: 0.800043
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.3673e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.447458
Average KL loss: 0.351269
Average total loss: 0.798727
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(5.1074e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.444924
Average KL loss: 0.351242
Average total loss: 0.796166
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.2595e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.450478
Average KL loss: 0.351209
Average total loss: 0.801687
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.4118e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.449192
Average KL loss: 0.351178
Average total loss: 0.800370
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.0383e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.448222
Average KL loss: 0.351147
Average total loss: 0.799369
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1995e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.445803
Average KL loss: 0.351112
Average total loss: 0.796916
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.3085e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.446983
Average KL loss: 0.351078
Average total loss: 0.798061
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.8411e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.445557
Average KL loss: 0.351051
Average total loss: 0.796609
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.7264e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.447192
Average KL loss: 0.351021
Average total loss: 0.798213
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.7665e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.445054
Average KL loss: 0.350995
Average total loss: 0.796049
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.0592e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.452768
Average KL loss: 0.350973
Average total loss: 0.803741
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.6719e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.447355
Average KL loss: 0.350955
Average total loss: 0.798310
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.3816e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.445834
Average KL loss: 0.350928
Average total loss: 0.796762
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.0213e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.449873
Average KL loss: 0.350903
Average total loss: 0.800776
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.7891e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.451117
Average KL loss: 0.350873
Average total loss: 0.801990
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(5.8668e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.444126
Average KL loss: 0.350849
Average total loss: 0.794975
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.8912e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.452927
Average KL loss: 0.350831
Average total loss: 0.803758
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.7075e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.444949
Average KL loss: 0.350809
Average total loss: 0.795759
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.5732e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.446968
Average KL loss: 0.350783
Average total loss: 0.797751
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.8660e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.453100
Average KL loss: 0.350757
Average total loss: 0.803857
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.6205e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.440941
Average KL loss: 0.350733
Average total loss: 0.791674
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.6643e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.452871
Average KL loss: 0.350710
Average total loss: 0.803581
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1403e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.448559
Average KL loss: 0.350683
Average total loss: 0.799243
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.6428e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.445600
Average KL loss: 0.350659
Average total loss: 0.796259
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.6250e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.449534
Average KL loss: 0.350633
Average total loss: 0.800167
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.9823e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.448746
Average KL loss: 0.350616
Average total loss: 0.799362
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(3.1022e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.446633
Average KL loss: 0.350592
Average total loss: 0.797226
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0153e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.442303
Average KL loss: 0.350569
Average total loss: 0.792872
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(5.9602e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.445152
Average KL loss: 0.350545
Average total loss: 0.795696
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(4.1230e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.442693
Average KL loss: 0.350522
Average total loss: 0.793215
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.2790e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.443579
Average KL loss: 0.350490
Average total loss: 0.794069
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.7668e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.445650
Average KL loss: 0.350458
Average total loss: 0.796107
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.7779e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.444158
Average KL loss: 0.350445
Average total loss: 0.794603
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.5084e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.448382
Average KL loss: 0.350443
Average total loss: 0.798825
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.8298e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.446714
Average KL loss: 0.350441
Average total loss: 0.797155
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.0461e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.445844
Average KL loss: 0.350439
Average total loss: 0.796284
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.8388e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.442224
Average KL loss: 0.350437
Average total loss: 0.792661
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.3111e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.445631
Average KL loss: 0.350434
Average total loss: 0.796066
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.5629e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.444542
Average KL loss: 0.350432
Average total loss: 0.794974
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.3965e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.445510
Average KL loss: 0.350429
Average total loss: 0.795940
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(8.6025e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.446737
Average KL loss: 0.350427
Average total loss: 0.797163
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.9676e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.440856
Average KL loss: 0.350424
Average total loss: 0.791280
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.0905e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.449848
Average KL loss: 0.350421
Average total loss: 0.800269
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.6200e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.443692
Average KL loss: 0.350419
Average total loss: 0.794111
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.6108e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.445362
Average KL loss: 0.350416
Average total loss: 0.795778
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.6563e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.450486
Average KL loss: 0.350414
Average total loss: 0.800900
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.2148e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.445900
Average KL loss: 0.350411
Average total loss: 0.796311
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.0228e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.447213
Average KL loss: 0.350408
Average total loss: 0.797621
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.9029e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.445821
Average KL loss: 0.350406
Average total loss: 0.796226
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0124e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.444726
Average KL loss: 0.350404
Average total loss: 0.795130
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(4.5894e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.449161
Average KL loss: 0.350401
Average total loss: 0.799562
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.2025e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.449655
Average KL loss: 0.350398
Average total loss: 0.800053
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.4404e-09, device='cuda:0')
 Percentile value: 0.3044411182403564
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/8]: ---
conv1.weight         | nonzeros =     126 /    1728             (  7.29%) | total_pruned =    1602 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     128 /   36864             (  0.35%) | total_pruned =   36736 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     199 /   36864             (  0.54%) | total_pruned =   36665 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     346 /   36864             (  0.94%) | total_pruned =   36518 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     794 /   36864             (  2.15%) | total_pruned =   36070 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2037 /   73728             (  2.76%) | total_pruned =   71691 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3992 /  147456             (  2.71%) | total_pruned =  143464 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     435 /    8192             (  5.31%) | total_pruned =    7757 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1976 /  147456             (  1.34%) | total_pruned =  145480 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1784 /  147456             (  1.21%) | total_pruned =  145672 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    9617 /  294912             (  3.26%) | total_pruned =  285295 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   15117 /  589824             (  2.56%) | total_pruned =  574707 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     892 /   32768             (  2.72%) | total_pruned =   31876 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    7691 /  589824             (  1.30%) | total_pruned =  582133 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     170 /     256             ( 66.41%) | total_pruned =      86 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4988 /  589824             (  0.85%) | total_pruned =  584836 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   11221 / 1179648             (  0.95%) | total_pruned = 1168427 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     379 /     512             ( 74.02%) | total_pruned =     133 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    7998 / 2359296             (  0.34%) | total_pruned = 2351298 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     195 /     512             ( 38.09%) | total_pruned =     317 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     124 /     512             ( 24.22%) | total_pruned =     388 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     236 /  131072             (  0.18%) | total_pruned =  130836 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      63 /     512             ( 12.30%) | total_pruned =     449 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     128 /     512             ( 25.00%) | total_pruned =     384 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    6943 / 2359296             (  0.29%) | total_pruned = 2352353 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     152 /     512             ( 29.69%) | total_pruned =     360 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    9083 / 2359296             (  0.38%) | total_pruned = 2350213 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     303 /     512             ( 59.18%) | total_pruned =     209 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     244 /     512             ( 47.66%) | total_pruned =     268 | shape = torch.Size([512])
linear.weight        | nonzeros =    1683 /    5120             ( 32.87%) | total_pruned =    3437 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 64/100 Loss: 0.019513 Accuracy: 87.28 100.00 % Best test Accuracy: 87.74%
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.3968e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.903328
Average KL loss: 0.320832
Average total loss: 1.224160
tensor(0.0029, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.5664e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.810334
Average KL loss: 0.314233
Average total loss: 1.124567
tensor(0.0029, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-7.9847e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.754838
Average KL loss: 0.317862
Average total loss: 1.072700
tensor(0.0028, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.6950e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.710005
Average KL loss: 0.321694
Average total loss: 1.031699
tensor(0.0028, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.8253e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.693213
Average KL loss: 0.324638
Average total loss: 1.017851
tensor(0.0028, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.9105e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.677189
Average KL loss: 0.326985
Average total loss: 1.004174
tensor(0.0027, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.3856e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.657469
Average KL loss: 0.329619
Average total loss: 0.987087
tensor(0.0027, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.4322e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.645186
Average KL loss: 0.332983
Average total loss: 0.978168
tensor(0.0027, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-9.7688e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.618532
Average KL loss: 0.336259
Average total loss: 0.954791
tensor(0.0027, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.0752e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.613907
Average KL loss: 0.339495
Average total loss: 0.953402
tensor(0.0027, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.3628e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.598274
Average KL loss: 0.342232
Average total loss: 0.940506
tensor(0.0027, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.8883e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.599354
Average KL loss: 0.344503
Average total loss: 0.943858
tensor(0.0027, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-7.3275e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.589109
Average KL loss: 0.346548
Average total loss: 0.935657
tensor(0.0027, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.1580e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.580112
Average KL loss: 0.348066
Average total loss: 0.928179
tensor(0.0027, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(7.4370e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.582107
Average KL loss: 0.349391
Average total loss: 0.931498
tensor(0.0027, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.8349e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.567889
Average KL loss: 0.351305
Average total loss: 0.919194
tensor(0.0027, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-8.4035e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.575969
Average KL loss: 0.352287
Average total loss: 0.928256
tensor(0.0027, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.7508e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.571147
Average KL loss: 0.353792
Average total loss: 0.924939
tensor(0.0027, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.9631e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.558238
Average KL loss: 0.354890
Average total loss: 0.913128
tensor(0.0027, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.0855e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.553996
Average KL loss: 0.355721
Average total loss: 0.909717
tensor(0.0027, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.0110e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.553745
Average KL loss: 0.356889
Average total loss: 0.910634
tensor(0.0027, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.4416e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.558063
Average KL loss: 0.358062
Average total loss: 0.916125
tensor(0.0027, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-8.3841e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.551633
Average KL loss: 0.359253
Average total loss: 0.910885
tensor(0.0027, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-5.4984e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.539202
Average KL loss: 0.360155
Average total loss: 0.899357
tensor(0.0027, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(2.0264e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.540648
Average KL loss: 0.360656
Average total loss: 0.901304
tensor(0.0027, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.4058e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.539721
Average KL loss: 0.361503
Average total loss: 0.901224
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.1541e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.540560
Average KL loss: 0.362079
Average total loss: 0.902638
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(3.3199e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.534464
Average KL loss: 0.362669
Average total loss: 0.897133
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2001e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.539893
Average KL loss: 0.363188
Average total loss: 0.903081
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.8761e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.532038
Average KL loss: 0.364022
Average total loss: 0.896060
tensor(0.0027, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.4668e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.530767
Average KL loss: 0.364461
Average total loss: 0.895227
tensor(0.0027, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-6.2148e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.531419
Average KL loss: 0.364866
Average total loss: 0.896284
tensor(0.0027, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.7209e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.532419
Average KL loss: 0.364912
Average total loss: 0.897331
tensor(0.0027, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(1.6725e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.525987
Average KL loss: 0.365520
Average total loss: 0.891507
tensor(0.0027, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.4758e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.520838
Average KL loss: 0.366270
Average total loss: 0.887108
tensor(0.0027, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.2934e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.516339
Average KL loss: 0.366745
Average total loss: 0.883083
tensor(0.0027, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(7.8331e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.523798
Average KL loss: 0.367259
Average total loss: 0.891057
tensor(0.0027, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.8415e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.523751
Average KL loss: 0.367641
Average total loss: 0.891392
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.3580e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.524589
Average KL loss: 0.368521
Average total loss: 0.893111
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.1829e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.516763
Average KL loss: 0.369127
Average total loss: 0.885890
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.2505e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.511690
Average KL loss: 0.369294
Average total loss: 0.880984
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.1705e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.517314
Average KL loss: 0.369625
Average total loss: 0.886940
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.2589e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.521542
Average KL loss: 0.370017
Average total loss: 0.891559
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.3658e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.511111
Average KL loss: 0.370830
Average total loss: 0.881941
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.9460e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.516537
Average KL loss: 0.371046
Average total loss: 0.887583
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.8399e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.515395
Average KL loss: 0.371009
Average total loss: 0.886404
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.3971e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.505526
Average KL loss: 0.371276
Average total loss: 0.876801
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-6.2246e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.512345
Average KL loss: 0.371406
Average total loss: 0.883751
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(4.6904e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.509870
Average KL loss: 0.372441
Average total loss: 0.882311
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.5327e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.510464
Average KL loss: 0.372930
Average total loss: 0.883394
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.4940e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.505464
Average KL loss: 0.373413
Average total loss: 0.878877
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.4733e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.508862
Average KL loss: 0.373849
Average total loss: 0.882711
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.4121e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.499953
Average KL loss: 0.374446
Average total loss: 0.874399
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.9167e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.501785
Average KL loss: 0.374208
Average total loss: 0.875993
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.7511e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.498964
Average KL loss: 0.374544
Average total loss: 0.873508
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.1095e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.503291
Average KL loss: 0.375070
Average total loss: 0.878362
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(3.6293e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.498508
Average KL loss: 0.375231
Average total loss: 0.873739
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3272e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.497211
Average KL loss: 0.375326
Average total loss: 0.872536
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.1884e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.495404
Average KL loss: 0.375565
Average total loss: 0.870969
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.9081e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.496599
Average KL loss: 0.375370
Average total loss: 0.871969
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.9513e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.498334
Average KL loss: 0.375904
Average total loss: 0.874238
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.4075e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.492681
Average KL loss: 0.375959
Average total loss: 0.868640
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.5042e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.500000
Average KL loss: 0.376356
Average total loss: 0.876356
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.1919e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.500350
Average KL loss: 0.376847
Average total loss: 0.877197
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0741e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.501827
Average KL loss: 0.377364
Average total loss: 0.879191
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.5123e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.493310
Average KL loss: 0.377801
Average total loss: 0.871111
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.5457e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.491355
Average KL loss: 0.377978
Average total loss: 0.869332
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.4415e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.493483
Average KL loss: 0.378427
Average total loss: 0.871910
tensor(0.0028, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(2.0632e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.491696
Average KL loss: 0.378906
Average total loss: 0.870603
tensor(0.0028, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.8492e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.484697
Average KL loss: 0.378956
Average total loss: 0.863653
tensor(0.0028, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-9.7839e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.487157
Average KL loss: 0.379030
Average total loss: 0.866187
tensor(0.0028, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.1552e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.490964
Average KL loss: 0.379315
Average total loss: 0.870279
tensor(0.0028, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.6201e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.491634
Average KL loss: 0.379163
Average total loss: 0.870797
tensor(0.0028, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(3.1465e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.490994
Average KL loss: 0.379473
Average total loss: 0.870467
tensor(0.0028, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.1736e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.495443
Average KL loss: 0.379355
Average total loss: 0.874798
tensor(0.0028, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(6.3157e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.490660
Average KL loss: 0.379507
Average total loss: 0.870167
tensor(0.0028, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(4.0565e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.491671
Average KL loss: 0.379501
Average total loss: 0.871172
tensor(0.0028, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.0015e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.490934
Average KL loss: 0.380014
Average total loss: 0.870947
tensor(0.0028, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.2346e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.481847
Average KL loss: 0.380442
Average total loss: 0.862289
tensor(0.0028, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.9723e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.491952
Average KL loss: 0.380363
Average total loss: 0.872315
tensor(0.0028, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.0328e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.480356
Average KL loss: 0.380453
Average total loss: 0.860809
tensor(0.0028, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(4.1293e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.486450
Average KL loss: 0.380681
Average total loss: 0.867131
tensor(0.0028, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.3318e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.485387
Average KL loss: 0.380921
Average total loss: 0.866308
tensor(0.0028, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-7.2431e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.484650
Average KL loss: 0.381083
Average total loss: 0.865733
tensor(0.0028, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.7339e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.486354
Average KL loss: 0.380992
Average total loss: 0.867346
tensor(0.0028, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.3446e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.488657
Average KL loss: 0.381183
Average total loss: 0.869840
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(3.4648e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.484440
Average KL loss: 0.381672
Average total loss: 0.866113
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-8.2922e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.480376
Average KL loss: 0.382056
Average total loss: 0.862432
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(2.3740e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.482703
Average KL loss: 0.382245
Average total loss: 0.864948
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(5.9816e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.483465
Average KL loss: 0.382331
Average total loss: 0.865796
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.9097e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.481440
Average KL loss: 0.382061
Average total loss: 0.863501
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.2516e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.482610
Average KL loss: 0.382069
Average total loss: 0.864679
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.9978e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.485923
Average KL loss: 0.382102
Average total loss: 0.868025
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.5220e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.477555
Average KL loss: 0.381766
Average total loss: 0.859321
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1682e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.476057
Average KL loss: 0.381444
Average total loss: 0.857500
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.3897e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.483471
Average KL loss: 0.381183
Average total loss: 0.864654
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.9301e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.478300
Average KL loss: 0.380910
Average total loss: 0.859210
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.8081e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.487985
Average KL loss: 0.380658
Average total loss: 0.868643
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.0284e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.478777
Average KL loss: 0.380407
Average total loss: 0.859184
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.3623e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.482103
Average KL loss: 0.380171
Average total loss: 0.862273
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.7263e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.480076
Average KL loss: 0.380009
Average total loss: 0.860085
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.3029e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.477737
Average KL loss: 0.379859
Average total loss: 0.857596
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.7615e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.484045
Average KL loss: 0.379742
Average total loss: 0.863787
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.6169e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.486386
Average KL loss: 0.379608
Average total loss: 0.865995
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.6141e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.478462
Average KL loss: 0.379400
Average total loss: 0.857862
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.2405e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.482697
Average KL loss: 0.379223
Average total loss: 0.861920
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1983e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.478582
Average KL loss: 0.379134
Average total loss: 0.857716
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1501e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.482277
Average KL loss: 0.379115
Average total loss: 0.861392
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.4507e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.483140
Average KL loss: 0.379098
Average total loss: 0.862238
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.7085e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.484002
Average KL loss: 0.379077
Average total loss: 0.863078
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.4211e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.478334
Average KL loss: 0.379059
Average total loss: 0.857393
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.2278e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.481474
Average KL loss: 0.379040
Average total loss: 0.860513
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.1559e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.475424
Average KL loss: 0.379025
Average total loss: 0.854449
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.2332e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.483051
Average KL loss: 0.379006
Average total loss: 0.862057
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.2573e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.488750
Average KL loss: 0.378994
Average total loss: 0.867743
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1108e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.470685
Average KL loss: 0.378978
Average total loss: 0.849663
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.1293e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.477984
Average KL loss: 0.378958
Average total loss: 0.856942
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.8572e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.476874
Average KL loss: 0.378932
Average total loss: 0.855807
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.8914e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.484478
Average KL loss: 0.378911
Average total loss: 0.863389
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.5932e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.483979
Average KL loss: 0.378890
Average total loss: 0.862869
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.6128e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.478694
Average KL loss: 0.378873
Average total loss: 0.857567
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.0617e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.481005
Average KL loss: 0.378858
Average total loss: 0.859863
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.1078e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.480429
Average KL loss: 0.378840
Average total loss: 0.859269
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.1586e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.482117
Average KL loss: 0.378825
Average total loss: 0.860942
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(8.7815e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.481815
Average KL loss: 0.378806
Average total loss: 0.860621
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.5214e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.483587
Average KL loss: 0.378784
Average total loss: 0.862371
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5798e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.479116
Average KL loss: 0.378767
Average total loss: 0.857883
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.8238e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.476406
Average KL loss: 0.378757
Average total loss: 0.855163
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.5085e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.478956
Average KL loss: 0.378755
Average total loss: 0.857710
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3539e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.483620
Average KL loss: 0.378753
Average total loss: 0.862373
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.6740e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.482746
Average KL loss: 0.378751
Average total loss: 0.861497
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.3394e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.483216
Average KL loss: 0.378750
Average total loss: 0.861965
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3928e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.475857
Average KL loss: 0.378748
Average total loss: 0.854605
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.4160e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.480102
Average KL loss: 0.378746
Average total loss: 0.858848
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.2516e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.478145
Average KL loss: 0.378744
Average total loss: 0.856889
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.8353e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.476685
Average KL loss: 0.378742
Average total loss: 0.855427
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.5087e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.483425
Average KL loss: 0.378740
Average total loss: 0.862165
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.4038e-10, device='cuda:0')
 Percentile value: 0.9695774912834166
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/8]: ---
conv1.weight         | nonzeros =     113 /    1728             (  6.54%) | total_pruned =    1615 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      71 /   36864             (  0.19%) | total_pruned =   36793 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     106 /   36864             (  0.29%) | total_pruned =   36758 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     211 /   36864             (  0.57%) | total_pruned =   36653 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     457 /   36864             (  1.24%) | total_pruned =   36407 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     955 /   73728             (  1.30%) | total_pruned =   72773 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1686 /  147456             (  1.14%) | total_pruned =  145770 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     220 /    8192             (  2.69%) | total_pruned =    7972 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     782 /  147456             (  0.53%) | total_pruned =  146674 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     707 /  147456             (  0.48%) | total_pruned =  146749 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3291 /  294912             (  1.12%) | total_pruned =  291621 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4515 /  589824             (  0.77%) | total_pruned =  585309 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     269 /   32768             (  0.82%) | total_pruned =   32499 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      89 /     256             ( 34.77%) | total_pruned =     167 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2391 /  589824             (  0.41%) | total_pruned =  587433 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1675 /  589824             (  0.28%) | total_pruned =  588149 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      96 /     256             ( 37.50%) | total_pruned =     160 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2488 / 1179648             (  0.21%) | total_pruned = 1177160 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1852 / 2359296             (  0.08%) | total_pruned = 2357444 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     129 /     512             ( 25.20%) | total_pruned =     383 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      60 /     512             ( 11.72%) | total_pruned =     452 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      57 /  131072             (  0.04%) | total_pruned =  131015 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      62 /     512             ( 12.11%) | total_pruned =     450 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1275 / 2359296             (  0.05%) | total_pruned = 2358021 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      89 /     512             ( 17.38%) | total_pruned =     423 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1264 / 2359296             (  0.05%) | total_pruned = 2358032 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     140 /     512             ( 27.34%) | total_pruned =     372 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      94 /     512             ( 18.36%) | total_pruned =     418 | shape = torch.Size([512])
linear.weight        | nonzeros =     488 /    5120             (  9.53%) | total_pruned =    4632 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 99/100 Loss: 0.089034 Accuracy: 84.03 99.49 % Best test Accuracy: 85.72%
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.0227e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.013645
Average KL loss: 0.347085
Average total loss: 1.360729
tensor(0.0025, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.7234e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.920952
Average KL loss: 0.330709
Average total loss: 1.251661
tensor(0.0024, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.8246e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.879689
Average KL loss: 0.327432
Average total loss: 1.207121
tensor(0.0024, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.3802e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.843594
Average KL loss: 0.327085
Average total loss: 1.170680
tensor(0.0024, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-7.9683e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.825857
Average KL loss: 0.327509
Average total loss: 1.153365
tensor(0.0023, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.4152e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.785659
Average KL loss: 0.327947
Average total loss: 1.113606
tensor(0.0023, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.8670e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.776676
Average KL loss: 0.329007
Average total loss: 1.105682
tensor(0.0023, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.7179e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.742127
Average KL loss: 0.331298
Average total loss: 1.073425
tensor(0.0023, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.0709e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.734688
Average KL loss: 0.334192
Average total loss: 1.068880
tensor(0.0023, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.4951e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.706002
Average KL loss: 0.337119
Average total loss: 1.043121
tensor(0.0023, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-9.3352e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.697400
Average KL loss: 0.339641
Average total loss: 1.037041
tensor(0.0023, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.1077e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.694842
Average KL loss: 0.342071
Average total loss: 1.036913
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-8.2562e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.687205
Average KL loss: 0.344389
Average total loss: 1.031594
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.3458e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.673592
Average KL loss: 0.346532
Average total loss: 1.020124
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.3197e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.670218
Average KL loss: 0.348552
Average total loss: 1.018770
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.0682e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.666003
Average KL loss: 0.350543
Average total loss: 1.016545
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-8.7330e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.651474
Average KL loss: 0.352405
Average total loss: 1.003879
tensor(0.0023, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-7.6751e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.639766
Average KL loss: 0.353839
Average total loss: 0.993606
tensor(0.0023, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(1.1694e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.635301
Average KL loss: 0.355511
Average total loss: 0.990812
tensor(0.0023, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-7.6851e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.619610
Average KL loss: 0.357288
Average total loss: 0.976898
tensor(0.0023, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-8.6725e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.639433
Average KL loss: 0.358722
Average total loss: 0.998155
tensor(0.0023, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.1714e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.611622
Average KL loss: 0.360329
Average total loss: 0.971950
tensor(0.0023, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.3100e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.614663
Average KL loss: 0.361776
Average total loss: 0.976439
tensor(0.0023, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.0444e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.610606
Average KL loss: 0.362883
Average total loss: 0.973490
tensor(0.0024, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6994e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.612031
Average KL loss: 0.364255
Average total loss: 0.976287
tensor(0.0024, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.6457e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.604984
Average KL loss: 0.365763
Average total loss: 0.970746
tensor(0.0024, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.3660e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.596559
Average KL loss: 0.366869
Average total loss: 0.963428
tensor(0.0024, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.4341e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.599116
Average KL loss: 0.367860
Average total loss: 0.966976
tensor(0.0024, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.0421e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.598498
Average KL loss: 0.368960
Average total loss: 0.967458
tensor(0.0024, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.7269e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.590914
Average KL loss: 0.370320
Average total loss: 0.961234
tensor(0.0024, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.9879e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.578644
Average KL loss: 0.371357
Average total loss: 0.950001
tensor(0.0024, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.6687e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.587414
Average KL loss: 0.372245
Average total loss: 0.959659
tensor(0.0024, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.1603e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.581082
Average KL loss: 0.373086
Average total loss: 0.954168
tensor(0.0024, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.1504e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.578621
Average KL loss: 0.374259
Average total loss: 0.952880
tensor(0.0024, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.2225e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.572702
Average KL loss: 0.375349
Average total loss: 0.948050
tensor(0.0024, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.1434e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.569129
Average KL loss: 0.376218
Average total loss: 0.945347
tensor(0.0024, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.4473e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.581512
Average KL loss: 0.377106
Average total loss: 0.958618
tensor(0.0024, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.5316e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.566808
Average KL loss: 0.377825
Average total loss: 0.944632
tensor(0.0024, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.4683e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.569593
Average KL loss: 0.378354
Average total loss: 0.947947
tensor(0.0024, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.6374e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.557837
Average KL loss: 0.379035
Average total loss: 0.936872
tensor(0.0024, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.2691e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.557824
Average KL loss: 0.379977
Average total loss: 0.937801
tensor(0.0024, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.8414e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.553568
Average KL loss: 0.380777
Average total loss: 0.934345
tensor(0.0024, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-6.7500e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.562440
Average KL loss: 0.381359
Average total loss: 0.943799
tensor(0.0024, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.2960e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.556665
Average KL loss: 0.382298
Average total loss: 0.938963
tensor(0.0024, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.7019e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.556336
Average KL loss: 0.383145
Average total loss: 0.939482
tensor(0.0024, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.9429e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.550913
Average KL loss: 0.384074
Average total loss: 0.934988
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.1178e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.546408
Average KL loss: 0.384624
Average total loss: 0.931031
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.9146e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.540396
Average KL loss: 0.385047
Average total loss: 0.925443
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.4598e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.546268
Average KL loss: 0.385295
Average total loss: 0.931563
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.5372e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.541691
Average KL loss: 0.385962
Average total loss: 0.927653
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.0929e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.534672
Average KL loss: 0.386720
Average total loss: 0.921393
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.7053e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.534787
Average KL loss: 0.387268
Average total loss: 0.922055
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.9208e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.540758
Average KL loss: 0.387947
Average total loss: 0.928705
tensor(0.0024, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.8852e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.536310
Average KL loss: 0.388857
Average total loss: 0.925166
tensor(0.0024, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.5796e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.529702
Average KL loss: 0.389686
Average total loss: 0.919388
tensor(0.0025, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-8.8767e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.526753
Average KL loss: 0.390451
Average total loss: 0.917204
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.5330e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.530192
Average KL loss: 0.390939
Average total loss: 0.921131
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.3677e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.524094
Average KL loss: 0.391087
Average total loss: 0.915181
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.9508e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.526189
Average KL loss: 0.391610
Average total loss: 0.917799
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.9682e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.527037
Average KL loss: 0.392314
Average total loss: 0.919352
tensor(0.0025, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.0683e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.522686
Average KL loss: 0.392886
Average total loss: 0.915572
tensor(0.0025, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.6075e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.519567
Average KL loss: 0.393330
Average total loss: 0.912897
tensor(0.0025, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.0944e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.518345
Average KL loss: 0.393800
Average total loss: 0.912146
tensor(0.0025, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.3361e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.520652
Average KL loss: 0.394511
Average total loss: 0.915164
tensor(0.0025, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-8.3580e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.515196
Average KL loss: 0.394958
Average total loss: 0.910154
tensor(0.0025, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.4957e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.514253
Average KL loss: 0.395425
Average total loss: 0.909677
tensor(0.0025, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3908e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.515389
Average KL loss: 0.395822
Average total loss: 0.911211
tensor(0.0025, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.1035e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.518562
Average KL loss: 0.396174
Average total loss: 0.914736
tensor(0.0025, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.2194e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.507844
Average KL loss: 0.396638
Average total loss: 0.904482
tensor(0.0025, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.4955e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.514135
Average KL loss: 0.397149
Average total loss: 0.911284
tensor(0.0025, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.5546e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.520603
Average KL loss: 0.397942
Average total loss: 0.918544
tensor(0.0025, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.4610e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.509814
Average KL loss: 0.398413
Average total loss: 0.908227
tensor(0.0025, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.6852e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.508418
Average KL loss: 0.398863
Average total loss: 0.907281
tensor(0.0025, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.6218e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.504830
Average KL loss: 0.399534
Average total loss: 0.904365
tensor(0.0025, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.7006e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.501881
Average KL loss: 0.400127
Average total loss: 0.902008
tensor(0.0025, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.3627e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.504789
Average KL loss: 0.400574
Average total loss: 0.905363
tensor(0.0025, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.9068e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.499019
Average KL loss: 0.400802
Average total loss: 0.899822
tensor(0.0025, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.3039e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.502028
Average KL loss: 0.401177
Average total loss: 0.903205
tensor(0.0025, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.2033e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.507531
Average KL loss: 0.401606
Average total loss: 0.909136
tensor(0.0025, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.5594e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.499502
Average KL loss: 0.402063
Average total loss: 0.901565
tensor(0.0025, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(8.2729e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.503619
Average KL loss: 0.402634
Average total loss: 0.906253
tensor(0.0025, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.1847e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.497673
Average KL loss: 0.403111
Average total loss: 0.900785
tensor(0.0025, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.1867e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.501229
Average KL loss: 0.403470
Average total loss: 0.904699
tensor(0.0025, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.5102e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.503545
Average KL loss: 0.404000
Average total loss: 0.907545
tensor(0.0026, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.4704e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.493464
Average KL loss: 0.404668
Average total loss: 0.898132
tensor(0.0026, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.4167e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.490711
Average KL loss: 0.405108
Average total loss: 0.895819
tensor(0.0026, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.9856e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.494630
Average KL loss: 0.405518
Average total loss: 0.900149
tensor(0.0026, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.9330e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.487917
Average KL loss: 0.405985
Average total loss: 0.893902
tensor(0.0026, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.6818e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.495265
Average KL loss: 0.406417
Average total loss: 0.901682
tensor(0.0026, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.0535e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.495390
Average KL loss: 0.406836
Average total loss: 0.902226
tensor(0.0026, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.6382e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.492878
Average KL loss: 0.407014
Average total loss: 0.899892
tensor(0.0026, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.5345e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.487799
Average KL loss: 0.407218
Average total loss: 0.895017
tensor(0.0026, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.1438e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.489437
Average KL loss: 0.407641
Average total loss: 0.897078
tensor(0.0026, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.6462e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.489476
Average KL loss: 0.407832
Average total loss: 0.897308
tensor(0.0026, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.7560e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.485538
Average KL loss: 0.408403
Average total loss: 0.893941
tensor(0.0026, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.4908e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.481672
Average KL loss: 0.408674
Average total loss: 0.890345
tensor(0.0026, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.9338e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.485873
Average KL loss: 0.408817
Average total loss: 0.894690
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-4.8195e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.488810
Average KL loss: 0.409454
Average total loss: 0.898264
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.0054e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.483103
Average KL loss: 0.409911
Average total loss: 0.893014
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.9782e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.483677
Average KL loss: 0.410462
Average total loss: 0.894140
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(2.3015e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.481316
Average KL loss: 0.410787
Average total loss: 0.892103
tensor(0.0026, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.4166e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.478001
Average KL loss: 0.410755
Average total loss: 0.888756
tensor(0.0026, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.7527e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.477346
Average KL loss: 0.410921
Average total loss: 0.888268
tensor(0.0026, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-7.9231e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.481052
Average KL loss: 0.411400
Average total loss: 0.892451
tensor(0.0026, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(7.0128e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.481437
Average KL loss: 0.411627
Average total loss: 0.893064
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.4886e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.474594
Average KL loss: 0.411860
Average total loss: 0.886454
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.8709e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.486928
Average KL loss: 0.412084
Average total loss: 0.899013
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-4.2879e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.483475
Average KL loss: 0.412452
Average total loss: 0.895927
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-4.0342e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.472023
Average KL loss: 0.413140
Average total loss: 0.885163
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.7446e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.473671
Average KL loss: 0.413347
Average total loss: 0.887018
tensor(0.0026, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.2284e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.479072
Average KL loss: 0.413665
Average total loss: 0.892737
tensor(0.0026, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(3.3262e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.479637
Average KL loss: 0.413917
Average total loss: 0.893554
tensor(0.0026, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.8465e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.477846
Average KL loss: 0.414126
Average total loss: 0.891973
tensor(0.0026, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-3.4248e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.475718
Average KL loss: 0.414165
Average total loss: 0.889883
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.5987e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.472889
Average KL loss: 0.414526
Average total loss: 0.887416
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-5.3995e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.477491
Average KL loss: 0.414978
Average total loss: 0.892469
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(9.6302e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.470943
Average KL loss: 0.415398
Average total loss: 0.886341
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.2450e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.482867
Average KL loss: 0.415767
Average total loss: 0.898634
tensor(0.0027, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-3.2518e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.464723
Average KL loss: 0.416102
Average total loss: 0.880825
tensor(0.0027, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-3.1083e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.469180
Average KL loss: 0.416447
Average total loss: 0.885627
tensor(0.0027, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-3.3897e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.467250
Average KL loss: 0.416756
Average total loss: 0.884007
tensor(0.0027, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-6.8752e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.476315
Average KL loss: 0.417300
Average total loss: 0.893615
tensor(0.0027, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.0239e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.469447
Average KL loss: 0.417749
Average total loss: 0.887196
tensor(0.0027, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.2787e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.470254
Average KL loss: 0.417968
Average total loss: 0.888222
tensor(0.0027, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.3449e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.476220
Average KL loss: 0.418506
Average total loss: 0.894726
tensor(0.0027, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-3.7443e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.467541
Average KL loss: 0.418711
Average total loss: 0.886252
tensor(0.0027, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.4354e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.470691
Average KL loss: 0.418881
Average total loss: 0.889573
tensor(0.0027, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-6.8087e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.467153
Average KL loss: 0.419229
Average total loss: 0.886382
tensor(0.0027, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-7.5089e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.461541
Average KL loss: 0.419532
Average total loss: 0.881073
tensor(0.0027, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-6.6030e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.467906
Average KL loss: 0.419923
Average total loss: 0.887829
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-9.8943e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.466968
Average KL loss: 0.420033
Average total loss: 0.887001
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.6556e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.473895
Average KL loss: 0.419991
Average total loss: 0.893885
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-9.0821e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.467013
Average KL loss: 0.419964
Average total loss: 0.886977
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.4752e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.460514
Average KL loss: 0.419931
Average total loss: 0.880445
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-7.4363e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.459309
Average KL loss: 0.419901
Average total loss: 0.879211
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.7159e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.466508
Average KL loss: 0.419880
Average total loss: 0.886388
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.3893e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.461304
Average KL loss: 0.419850
Average total loss: 0.881155
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.7470e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.460971
Average KL loss: 0.419802
Average total loss: 0.880773
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.0439e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.472161
Average KL loss: 0.419746
Average total loss: 0.891907
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.3488e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.457892
Average KL loss: 0.419717
Average total loss: 0.877609
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.0621e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.463548
Average KL loss: 0.419680
Average total loss: 0.883228
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.5891e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.467099
Average KL loss: 0.419672
Average total loss: 0.886771
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.4532e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.461218
Average KL loss: 0.419668
Average total loss: 0.880886
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.1538e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.459035
Average KL loss: 0.419654
Average total loss: 0.878689
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.9510e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.464180
Average KL loss: 0.419645
Average total loss: 0.883825
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.9862e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.460973
Average KL loss: 0.419632
Average total loss: 0.880605
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.2341e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.462595
Average KL loss: 0.419579
Average total loss: 0.882175
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.3519e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.462102
Average KL loss: 0.419538
Average total loss: 0.881640
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.4906e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.460361
Average KL loss: 0.419511
Average total loss: 0.879872
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(3.9783e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.463528
Average KL loss: 0.419495
Average total loss: 0.883022
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.2838e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.457682
Average KL loss: 0.419480
Average total loss: 0.877162
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.5262e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.461055
Average KL loss: 0.419456
Average total loss: 0.880511
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.0479e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.464768
Average KL loss: 0.419435
Average total loss: 0.884203
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.4936e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.465083
Average KL loss: 0.419400
Average total loss: 0.884483
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.0935e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.468393
Average KL loss: 0.419378
Average total loss: 0.887771
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.3798e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.464299
Average KL loss: 0.419361
Average total loss: 0.883659
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(7.2704e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.458614
Average KL loss: 0.419345
Average total loss: 0.877959
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-9.1109e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.462870
Average KL loss: 0.419317
Average total loss: 0.882187
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.0703e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.458316
Average KL loss: 0.419306
Average total loss: 0.877622
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.2195e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.458466
Average KL loss: 0.419300
Average total loss: 0.877766
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(3.2914e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.467775
Average KL loss: 0.419277
Average total loss: 0.887052
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.7012e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.466922
Average KL loss: 0.419244
Average total loss: 0.886167
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.2487e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.459538
Average KL loss: 0.419230
Average total loss: 0.878768
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.6295e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.459224
Average KL loss: 0.419230
Average total loss: 0.878454
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.4344e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.467965
Average KL loss: 0.419228
Average total loss: 0.887193
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.8303e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.461798
Average KL loss: 0.419228
Average total loss: 0.881026
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.9956e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.466109
Average KL loss: 0.419225
Average total loss: 0.885334
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.8468e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.456905
Average KL loss: 0.419222
Average total loss: 0.876127
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.6945e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.459614
Average KL loss: 0.419219
Average total loss: 0.878833
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.6981e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.466523
Average KL loss: 0.419215
Average total loss: 0.885737
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.1013e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.464561
Average KL loss: 0.419213
Average total loss: 0.883774
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.8693e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.461343
Average KL loss: 0.419213
Average total loss: 0.880556
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.9234e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.458395
Average KL loss: 0.419209
Average total loss: 0.877604
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(4.7402e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.460200
Average KL loss: 0.419203
Average total loss: 0.879403
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.5573e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.468757
Average KL loss: 0.419199
Average total loss: 0.887955
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.3431e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.460829
Average KL loss: 0.419198
Average total loss: 0.880028
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(6.8670e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.459930
Average KL loss: 0.419196
Average total loss: 0.879127
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.1609e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.462082
Average KL loss: 0.419195
Average total loss: 0.881278
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.4749e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.459976
Average KL loss: 0.419193
Average total loss: 0.879170
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.7698e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.463387
Average KL loss: 0.419192
Average total loss: 0.882579
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.3852e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.462713
Average KL loss: 0.419192
Average total loss: 0.881905
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.0778e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.463462
Average KL loss: 0.419192
Average total loss: 0.882654
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(8.0055e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.460087
Average KL loss: 0.419191
Average total loss: 0.879279
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.9426e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.462674
Average KL loss: 0.419191
Average total loss: 0.881865
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.3555e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.462953
Average KL loss: 0.419191
Average total loss: 0.882144
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.0819e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.457108
Average KL loss: 0.419191
Average total loss: 0.876299
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(4.6480e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.465011
Average KL loss: 0.419190
Average total loss: 0.884202
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.7975e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.468246
Average KL loss: 0.419190
Average total loss: 0.887435
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.7965e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.465266
Average KL loss: 0.419190
Average total loss: 0.884456
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.5392e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.456717
Average KL loss: 0.419190
Average total loss: 0.875907
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.9377e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.459437
Average KL loss: 0.419189
Average total loss: 0.878627
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.1649e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.461232
Average KL loss: 0.419189
Average total loss: 0.880421
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(5.0093e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.458889
Average KL loss: 0.419189
Average total loss: 0.878078
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-9.3889e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.463738
Average KL loss: 0.419189
Average total loss: 0.882927
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.3352e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.458609
Average KL loss: 0.419188
Average total loss: 0.877797
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.4438e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.465966
Average KL loss: 0.419188
Average total loss: 0.885154
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-9.3413e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.460058
Average KL loss: 0.419188
Average total loss: 0.879246
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-9.1005e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.463183
Average KL loss: 0.419188
Average total loss: 0.882371
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.4746e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.463629
Average KL loss: 0.419188
Average total loss: 0.882817
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.1720e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.459264
Average KL loss: 0.419187
Average total loss: 0.878451
 Percentile value: 3.599901604652404
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/8]: ---
conv1.weight         | nonzeros =      94 /    1728             (  5.44%) | total_pruned =    1634 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      41 /   36864             (  0.11%) | total_pruned =   36823 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      64 /   36864             (  0.17%) | total_pruned =   36800 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     123 /   36864             (  0.33%) | total_pruned =   36741 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     249 /   36864             (  0.68%) | total_pruned =   36615 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     393 /   73728             (  0.53%) | total_pruned =   73335 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     566 /  147456             (  0.38%) | total_pruned =  146890 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      79 /    8192             (  0.96%) | total_pruned =    8113 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     278 /  147456             (  0.19%) | total_pruned =  147178 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     282 /  147456             (  0.19%) | total_pruned =  147174 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     894 /  294912             (  0.30%) | total_pruned =  294018 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1095 /  589824             (  0.19%) | total_pruned =  588729 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      50 /   32768             (  0.15%) | total_pruned =   32718 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     705 /  589824             (  0.12%) | total_pruned =  589119 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     520 /  589824             (  0.09%) | total_pruned =  589304 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      63 /     256             ( 24.61%) | total_pruned =     193 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     451 / 1179648             (  0.04%) | total_pruned = 1179197 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     166 /     512             ( 32.42%) | total_pruned =     346 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     353 / 2359296             (  0.01%) | total_pruned = 2358943 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      11 /  131072             (  0.01%) | total_pruned =  131061 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     180 / 2359296             (  0.01%) | total_pruned = 2359116 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      47 /     512             (  9.18%) | total_pruned =     465 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     130 / 2359296             (  0.01%) | total_pruned = 2359166 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
linear.weight        | nonzeros =      97 /    5120             (  1.89%) | total_pruned =    5023 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 99/100 Loss: 0.566656 Accuracy: 75.23 81.32 % Best test Accuracy: 75.75%
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.7079e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.004297
Average KL loss: 0.378780
Average total loss: 1.383076
tensor(0.0023, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0548e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.986363
Average KL loss: 0.330666
Average total loss: 1.317029
tensor(0.0020, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.4088e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.000543
Average KL loss: 0.304774
Average total loss: 1.305317
tensor(0.0018, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.2024e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.976535
Average KL loss: 0.286675
Average total loss: 1.263210
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.9927e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.985195
Average KL loss: 0.272673
Average total loss: 1.257869
tensor(0.0016, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.3888e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.948087
Average KL loss: 0.261932
Average total loss: 1.210019
tensor(0.0016, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.6257e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.935950
Average KL loss: 0.254773
Average total loss: 1.190723
tensor(0.0015, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.1394e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.952707
Average KL loss: 0.251228
Average total loss: 1.203935
tensor(0.0015, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.3035e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.929869
Average KL loss: 0.249920
Average total loss: 1.179790
tensor(0.0015, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.9002e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.920054
Average KL loss: 0.249142
Average total loss: 1.169196
tensor(0.0015, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.4621e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.888226
Average KL loss: 0.248622
Average total loss: 1.136848
tensor(0.0015, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.6372e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.890407
Average KL loss: 0.248149
Average total loss: 1.138555
tensor(0.0015, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.3548e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.890701
Average KL loss: 0.247745
Average total loss: 1.138446
tensor(0.0015, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.2180e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.882689
Average KL loss: 0.247442
Average total loss: 1.130131
tensor(0.0015, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.2746e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.862239
Average KL loss: 0.247165
Average total loss: 1.109404
tensor(0.0015, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.9689e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.847420
Average KL loss: 0.246943
Average total loss: 1.094363
tensor(0.0015, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.7259e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.860470
Average KL loss: 0.246669
Average total loss: 1.107139
tensor(0.0015, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.6027e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.853901
Average KL loss: 0.246478
Average total loss: 1.100379
tensor(0.0015, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.2362e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.841303
Average KL loss: 0.246397
Average total loss: 1.087701
tensor(0.0015, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.2456e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.828464
Average KL loss: 0.246335
Average total loss: 1.074799
tensor(0.0015, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-8.9782e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.836120
Average KL loss: 0.246239
Average total loss: 1.082359
tensor(0.0015, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-3.0697e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.826537
Average KL loss: 0.246274
Average total loss: 1.072811
tensor(0.0015, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-3.9839e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.823333
Average KL loss: 0.246134
Average total loss: 1.069466
tensor(0.0015, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.7666e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.820965
Average KL loss: 0.246064
Average total loss: 1.067029
tensor(0.0015, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.1749e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.829526
Average KL loss: 0.246069
Average total loss: 1.075595
tensor(0.0015, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-9.8690e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.816597
Average KL loss: 0.246115
Average total loss: 1.062713
tensor(0.0015, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.4707e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.810927
Average KL loss: 0.246125
Average total loss: 1.057053
tensor(0.0015, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-7.2923e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.794349
Average KL loss: 0.246118
Average total loss: 1.040467
tensor(0.0015, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.0924e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.792085
Average KL loss: 0.246128
Average total loss: 1.038213
tensor(0.0015, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-7.5236e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.802322
Average KL loss: 0.246165
Average total loss: 1.048487
tensor(0.0015, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.2401e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.781679
Average KL loss: 0.246200
Average total loss: 1.027879
tensor(0.0015, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.4451e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.794842
Average KL loss: 0.246298
Average total loss: 1.041140
tensor(0.0015, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.4051e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.786099
Average KL loss: 0.246469
Average total loss: 1.032568
tensor(0.0015, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-6.5355e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.778895
Average KL loss: 0.246604
Average total loss: 1.025499
tensor(0.0015, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.5083e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.775436
Average KL loss: 0.246706
Average total loss: 1.022142
tensor(0.0015, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.5801e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.766157
Average KL loss: 0.246739
Average total loss: 1.012896
tensor(0.0015, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-5.0066e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.767699
Average KL loss: 0.246816
Average total loss: 1.014515
tensor(0.0015, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.1025e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.766140
Average KL loss: 0.246941
Average total loss: 1.013081
tensor(0.0015, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-9.4443e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.761126
Average KL loss: 0.247088
Average total loss: 1.008214
tensor(0.0015, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.7596e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.767620
Average KL loss: 0.247162
Average total loss: 1.014782
tensor(0.0015, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.2828e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.757340
Average KL loss: 0.247251
Average total loss: 1.004591
tensor(0.0015, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.5393e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.759449
Average KL loss: 0.247347
Average total loss: 1.006797
tensor(0.0016, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-7.9114e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.753074
Average KL loss: 0.247350
Average total loss: 1.000423
tensor(0.0016, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.5357e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.753732
Average KL loss: 0.247355
Average total loss: 1.001087
tensor(0.0016, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.6530e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.762232
Average KL loss: 0.247559
Average total loss: 1.009790
tensor(0.0016, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.5587e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.756558
Average KL loss: 0.247799
Average total loss: 1.004357
tensor(0.0016, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.5565e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.750187
Average KL loss: 0.247965
Average total loss: 0.998152
tensor(0.0016, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.4706e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.738700
Average KL loss: 0.248142
Average total loss: 0.986841
tensor(0.0016, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-6.2997e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.746886
Average KL loss: 0.248323
Average total loss: 0.995209
tensor(0.0016, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.8332e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.751900
Average KL loss: 0.248492
Average total loss: 1.000392
tensor(0.0016, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.4031e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.740265
Average KL loss: 0.248609
Average total loss: 0.988874
tensor(0.0016, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.0930e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.748110
Average KL loss: 0.248720
Average total loss: 0.996829
tensor(0.0016, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.6379e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.744882
Average KL loss: 0.248803
Average total loss: 0.993685
tensor(0.0016, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.0098e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.739135
Average KL loss: 0.248998
Average total loss: 0.988132
tensor(0.0016, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.1824e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.743034
Average KL loss: 0.249243
Average total loss: 0.992278
tensor(0.0016, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.2393e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.743998
Average KL loss: 0.249421
Average total loss: 0.993419
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.8248e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.734760
Average KL loss: 0.249546
Average total loss: 0.984306
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.7814e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.744490
Average KL loss: 0.249729
Average total loss: 0.994219
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.1639e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.726144
Average KL loss: 0.249882
Average total loss: 0.976027
tensor(0.0016, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.2917e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.732461
Average KL loss: 0.250006
Average total loss: 0.982467
tensor(0.0016, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.2806e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.724057
Average KL loss: 0.250060
Average total loss: 0.974117
tensor(0.0016, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.0959e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.730558
Average KL loss: 0.250130
Average total loss: 0.980688
tensor(0.0016, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.3926e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.721593
Average KL loss: 0.250269
Average total loss: 0.971862
tensor(0.0016, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-9.4408e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.732938
Average KL loss: 0.250479
Average total loss: 0.983417
tensor(0.0016, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.8747e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.718223
Average KL loss: 0.250635
Average total loss: 0.968857
tensor(0.0016, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.4169e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.713015
Average KL loss: 0.250723
Average total loss: 0.963738
tensor(0.0016, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.6075e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.722175
Average KL loss: 0.250859
Average total loss: 0.973034
tensor(0.0016, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.7960e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.721112
Average KL loss: 0.250951
Average total loss: 0.972063
tensor(0.0016, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.9317e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.718931
Average KL loss: 0.251088
Average total loss: 0.970019
tensor(0.0016, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.3097e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.708211
Average KL loss: 0.251172
Average total loss: 0.959383
tensor(0.0016, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.3779e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.711589
Average KL loss: 0.251231
Average total loss: 0.962821
tensor(0.0016, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.4115e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.707014
Average KL loss: 0.251317
Average total loss: 0.958331
tensor(0.0016, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.8680e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.707675
Average KL loss: 0.251484
Average total loss: 0.959159
tensor(0.0016, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.7358e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.705580
Average KL loss: 0.251638
Average total loss: 0.957218
tensor(0.0016, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-8.2690e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.712278
Average KL loss: 0.251734
Average total loss: 0.964012
tensor(0.0016, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-8.3753e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.716732
Average KL loss: 0.251789
Average total loss: 0.968521
tensor(0.0017, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.3641e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.708376
Average KL loss: 0.251916
Average total loss: 0.960292
tensor(0.0017, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.3629e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.703549
Average KL loss: 0.252037
Average total loss: 0.955587
tensor(0.0017, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.5290e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.705575
Average KL loss: 0.252153
Average total loss: 0.957728
tensor(0.0017, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.6823e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.712669
Average KL loss: 0.252283
Average total loss: 0.964952
tensor(0.0017, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.9606e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.699385
Average KL loss: 0.252448
Average total loss: 0.951833
tensor(0.0017, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.9238e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.723816
Average KL loss: 0.252574
Average total loss: 0.976390
tensor(0.0017, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-9.7934e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.704300
Average KL loss: 0.252759
Average total loss: 0.957059
tensor(0.0017, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.1793e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.698581
Average KL loss: 0.252838
Average total loss: 0.951418
tensor(0.0017, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.4083e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.696596
Average KL loss: 0.252917
Average total loss: 0.949513
tensor(0.0017, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.2893e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.703560
Average KL loss: 0.253015
Average total loss: 0.956575
tensor(0.0017, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7436e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.699083
Average KL loss: 0.253149
Average total loss: 0.952232
tensor(0.0017, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.3016e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.703215
Average KL loss: 0.253340
Average total loss: 0.956555
tensor(0.0017, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.2467e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.693593
Average KL loss: 0.253440
Average total loss: 0.947033
tensor(0.0017, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.6587e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.697751
Average KL loss: 0.253564
Average total loss: 0.951315
tensor(0.0017, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.5053e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.699749
Average KL loss: 0.253640
Average total loss: 0.953389
tensor(0.0017, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.4428e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.696726
Average KL loss: 0.253786
Average total loss: 0.950512
tensor(0.0017, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.1157e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.684059
Average KL loss: 0.253914
Average total loss: 0.937972
tensor(0.0017, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.8965e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.691698
Average KL loss: 0.254068
Average total loss: 0.945767
tensor(0.0017, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.3076e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.698588
Average KL loss: 0.254187
Average total loss: 0.952775
tensor(0.0017, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.5565e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.701026
Average KL loss: 0.254305
Average total loss: 0.955331
tensor(0.0017, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.1093e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.689853
Average KL loss: 0.254370
Average total loss: 0.944223
tensor(0.0017, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.0190e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.691208
Average KL loss: 0.254479
Average total loss: 0.945687
tensor(0.0017, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2573e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.691926
Average KL loss: 0.254540
Average total loss: 0.946466
tensor(0.0017, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4436e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.700746
Average KL loss: 0.254659
Average total loss: 0.955404
tensor(0.0017, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.2634e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.683562
Average KL loss: 0.254779
Average total loss: 0.938341
tensor(0.0017, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(6.8509e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.686929
Average KL loss: 0.254873
Average total loss: 0.941802
tensor(0.0017, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.0087e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.694444
Average KL loss: 0.255030
Average total loss: 0.949474
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.7100e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.684368
Average KL loss: 0.255190
Average total loss: 0.939558
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.5178e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.685281
Average KL loss: 0.255270
Average total loss: 0.940551
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.7745e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.678606
Average KL loss: 0.255284
Average total loss: 0.933890
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.2416e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.690059
Average KL loss: 0.255288
Average total loss: 0.945347
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.6982e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.685132
Average KL loss: 0.255301
Average total loss: 0.940433
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.0587e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.692560
Average KL loss: 0.255317
Average total loss: 0.947877
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.4225e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.683095
Average KL loss: 0.255328
Average total loss: 0.938423
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.4463e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.695124
Average KL loss: 0.255335
Average total loss: 0.950459
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.4847e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.693370
Average KL loss: 0.255343
Average total loss: 0.948713
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.5208e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.691350
Average KL loss: 0.255353
Average total loss: 0.946703
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.5486e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.696197
Average KL loss: 0.255360
Average total loss: 0.951557
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.4690e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.683927
Average KL loss: 0.255373
Average total loss: 0.939300
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.8559e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.691585
Average KL loss: 0.255380
Average total loss: 0.946965
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.5074e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.684846
Average KL loss: 0.255389
Average total loss: 0.940235
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.9672e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.681907
Average KL loss: 0.255395
Average total loss: 0.937302
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.2206e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.687233
Average KL loss: 0.255396
Average total loss: 0.942629
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.1360e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.685593
Average KL loss: 0.255398
Average total loss: 0.940991
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.3224e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.679417
Average KL loss: 0.255399
Average total loss: 0.934816
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.6034e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.691953
Average KL loss: 0.255401
Average total loss: 0.947354
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.2407e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.688709
Average KL loss: 0.255402
Average total loss: 0.944111
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.6949e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.676996
Average KL loss: 0.255403
Average total loss: 0.932399
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.1136e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.679963
Average KL loss: 0.255403
Average total loss: 0.935366
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.9907e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.687419
Average KL loss: 0.255404
Average total loss: 0.942824
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.0794e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.692127
Average KL loss: 0.255406
Average total loss: 0.947533
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.0248e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.689529
Average KL loss: 0.255408
Average total loss: 0.944937
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.1212e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.692754
Average KL loss: 0.255409
Average total loss: 0.948162
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.6075e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.681425
Average KL loss: 0.255409
Average total loss: 0.936834
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.9787e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.686638
Average KL loss: 0.255410
Average total loss: 0.942048
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.4295e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.693440
Average KL loss: 0.255410
Average total loss: 0.948851
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.9440e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.681519
Average KL loss: 0.255412
Average total loss: 0.936931
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.1612e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.684962
Average KL loss: 0.255414
Average total loss: 0.940377
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-9.4468e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.686788
Average KL loss: 0.255415
Average total loss: 0.942203
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.1510e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.682456
Average KL loss: 0.255415
Average total loss: 0.937871
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.5045e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.683874
Average KL loss: 0.255415
Average total loss: 0.939290
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.1208e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.684056
Average KL loss: 0.255415
Average total loss: 0.939472
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.1580e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.686075
Average KL loss: 0.255415
Average total loss: 0.941490
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.6562e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.689451
Average KL loss: 0.255415
Average total loss: 0.944867
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.7567e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.684964
Average KL loss: 0.255416
Average total loss: 0.940380
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.8072e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.682692
Average KL loss: 0.255416
Average total loss: 0.938108
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.2388e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.682039
Average KL loss: 0.255416
Average total loss: 0.937455
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.7322e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.680321
Average KL loss: 0.255416
Average total loss: 0.935737
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.2872e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.683442
Average KL loss: 0.255416
Average total loss: 0.938857
tensor(0.0017, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.7591e-09, device='cuda:0')
 Percentile value: 6.019296550750733
Non-zero model percentage: 0.02187183126807213%, Non-zero mask percentage: 0.02187183126807213%

--- Pruning Level [7/8]: ---
conv1.weight         | nonzeros =      76 /    1728             (  4.40%) | total_pruned =    1652 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      27 /   36864             (  0.07%) | total_pruned =   36837 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      33 /   36864             (  0.09%) | total_pruned =   36831 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      60 /   36864             (  0.16%) | total_pruned =   36804 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      85 /   36864             (  0.23%) | total_pruned =   36779 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =      98 /   73728             (  0.13%) | total_pruned =   73630 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     147 /  147456             (  0.10%) | total_pruned =  147309 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      23 /    8192             (  0.28%) | total_pruned =    8169 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =      74 /  147456             (  0.05%) | total_pruned =  147382 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =      71 /  147456             (  0.05%) | total_pruned =  147385 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     145 /  294912             (  0.05%) | total_pruned =  294767 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     118 /     256             ( 46.09%) | total_pruned =     138 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     184 /  589824             (  0.03%) | total_pruned =  589640 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       9 /   32768             (  0.03%) | total_pruned =   32759 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     152 /  589824             (  0.03%) | total_pruned =  589672 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     139 /  589824             (  0.02%) | total_pruned =  589685 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =      82 / 1179648             (  0.01%) | total_pruned = 1179566 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      56 /     512             ( 10.94%) | total_pruned =     456 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =      58 / 2359296             (  0.00%) | total_pruned = 2359238 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      36 /     512             (  7.03%) | total_pruned =     476 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       4 /  131072             (  0.00%) | total_pruned =  131068 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      55 / 2359296             (  0.00%) | total_pruned = 2359241 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      45 / 2359296             (  0.00%) | total_pruned = 2359251 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
linear.weight        | nonzeros =      50 /    5120             (  0.98%) | total_pruned =    5070 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 2445, pruned : 11176317, total: 11178762, Compression rate :    4572.09x  ( 99.98% pruned)
Train Epoch: 99/100 Loss: 1.078078 Accuracy: 57.78 59.49 % Best test Accuracy: 57.86%
