Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/200 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2827e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302672
Average KL loss: 0.002684
Average total loss: 2.305356
tensor(2.6577e-05, device='cuda:0') tensor(4.0590e-06, device='cuda:0') tensor(2.5648e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.302747
Average KL loss: 0.002979
Average total loss: 2.305725
tensor(1.1998e-05, device='cuda:0') tensor(5.8761e-06, device='cuda:0') tensor(-3.2052e-12, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.301992
Average KL loss: 0.003515
Average total loss: 2.305508
tensor(2.8506e-05, device='cuda:0') tensor(1.2379e-05, device='cuda:0') tensor(-3.4651e-11, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.300801
Average KL loss: 0.004661
Average total loss: 2.305462
tensor(6.8023e-05, device='cuda:0') tensor(2.7850e-05, device='cuda:0') tensor(3.0066e-13, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.296340
Average KL loss: 0.008573
Average total loss: 2.304913
tensor(0.0002, device='cuda:0') tensor(7.7966e-05, device='cuda:0') tensor(-5.9129e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.242151
Average KL loss: 0.030764
Average total loss: 2.272915
tensor(0.0009, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.3138e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.904220
Average KL loss: 0.124509
Average total loss: 2.028728
tensor(0.0026, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.4956e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.381591
Average KL loss: 0.250861
Average total loss: 1.632452
tensor(0.0031, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.8293e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.031771
Average KL loss: 0.302618
Average total loss: 1.334389
tensor(0.0030, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.9341e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.881427
Average KL loss: 0.308868
Average total loss: 1.190295
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-5.1496e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.798027
Average KL loss: 0.309036
Average total loss: 1.107063
tensor(0.0029, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.4536e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.754729
Average KL loss: 0.311400
Average total loss: 1.066129
tensor(0.0028, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.2742e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.695266
Average KL loss: 0.309724
Average total loss: 1.004990
tensor(0.0028, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.3761e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.644160
Average KL loss: 0.305798
Average total loss: 0.949959
tensor(0.0028, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-6.8511e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.616043
Average KL loss: 0.304813
Average total loss: 0.920857
tensor(0.0028, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.6214e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.595678
Average KL loss: 0.303582
Average total loss: 0.899260
tensor(0.0028, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.1181e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.571360
Average KL loss: 0.301201
Average total loss: 0.872560
tensor(0.0028, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.7522e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.553082
Average KL loss: 0.300057
Average total loss: 0.853139
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.0667e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.543076
Average KL loss: 0.299864
Average total loss: 0.842941
tensor(0.0028, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2289e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.520515
Average KL loss: 0.298806
Average total loss: 0.819322
tensor(0.0028, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2023e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.515513
Average KL loss: 0.299252
Average total loss: 0.814765
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2000e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.499175
Average KL loss: 0.298311
Average total loss: 0.797486
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2749e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.495127
Average KL loss: 0.301150
Average total loss: 0.796278
tensor(0.0028, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.7852e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.478750
Average KL loss: 0.299744
Average total loss: 0.778495
tensor(0.0028, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5389e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.477695
Average KL loss: 0.299493
Average total loss: 0.777188
tensor(0.0028, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.4146e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.462231
Average KL loss: 0.298533
Average total loss: 0.760764
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.1999e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.455008
Average KL loss: 0.300123
Average total loss: 0.755131
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.1936e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.454331
Average KL loss: 0.299698
Average total loss: 0.754029
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0792e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.430505
Average KL loss: 0.298222
Average total loss: 0.728727
tensor(0.0028, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.7253e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.441425
Average KL loss: 0.299654
Average total loss: 0.741079
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2778e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.429539
Average KL loss: 0.299546
Average total loss: 0.729085
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3964e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.421279
Average KL loss: 0.299815
Average total loss: 0.721094
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.1763e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.418745
Average KL loss: 0.299948
Average total loss: 0.718693
tensor(0.0029, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3651e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.417771
Average KL loss: 0.301744
Average total loss: 0.719515
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.0321e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.408453
Average KL loss: 0.301415
Average total loss: 0.709869
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2605e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.406461
Average KL loss: 0.302058
Average total loss: 0.708519
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2266e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.400730
Average KL loss: 0.301606
Average total loss: 0.702336
tensor(0.0029, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.6823e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.397688
Average KL loss: 0.301894
Average total loss: 0.699583
tensor(0.0029, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.6183e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.390997
Average KL loss: 0.302276
Average total loss: 0.693273
tensor(0.0029, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.5471e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.396720
Average KL loss: 0.303744
Average total loss: 0.700464
tensor(0.0029, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.4151e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.384471
Average KL loss: 0.303673
Average total loss: 0.688143
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.6547e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.383196
Average KL loss: 0.303071
Average total loss: 0.686267
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.3213e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.378353
Average KL loss: 0.302777
Average total loss: 0.681130
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.0410e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.382397
Average KL loss: 0.304443
Average total loss: 0.686840
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.0742e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.372872
Average KL loss: 0.303917
Average total loss: 0.676789
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.8271e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.368683
Average KL loss: 0.303230
Average total loss: 0.671913
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.5151e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.373898
Average KL loss: 0.304088
Average total loss: 0.677987
tensor(0.0030, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3642e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.366455
Average KL loss: 0.306385
Average total loss: 0.672841
tensor(0.0030, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.4247e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.369430
Average KL loss: 0.305466
Average total loss: 0.674896
tensor(0.0030, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.9913e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.355943
Average KL loss: 0.304933
Average total loss: 0.660876
tensor(0.0029, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.2284e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.361495
Average KL loss: 0.305657
Average total loss: 0.667152
tensor(0.0029, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-7.0756e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.359149
Average KL loss: 0.305430
Average total loss: 0.664579
tensor(0.0030, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.2929e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.357564
Average KL loss: 0.306753
Average total loss: 0.664317
tensor(0.0030, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-9.5667e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.352447
Average KL loss: 0.306648
Average total loss: 0.659095
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.9713e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.348188
Average KL loss: 0.305937
Average total loss: 0.654125
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-5.0642e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.350813
Average KL loss: 0.307290
Average total loss: 0.658103
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-7.4972e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.348743
Average KL loss: 0.306650
Average total loss: 0.655393
tensor(0.0030, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.5554e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.344358
Average KL loss: 0.306008
Average total loss: 0.650366
tensor(0.0030, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.8567e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.344477
Average KL loss: 0.307396
Average total loss: 0.651873
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.5832e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.347760
Average KL loss: 0.307994
Average total loss: 0.655754
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6681e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.339191
Average KL loss: 0.308534
Average total loss: 0.647725
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.7072e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.341612
Average KL loss: 0.308409
Average total loss: 0.650021
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-6.2547e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.339154
Average KL loss: 0.309087
Average total loss: 0.648240
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.9382e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.334873
Average KL loss: 0.309406
Average total loss: 0.644279
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.3912e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.334543
Average KL loss: 0.308697
Average total loss: 0.643240
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-6.5834e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.334045
Average KL loss: 0.308845
Average total loss: 0.642890
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(3.2238e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.328669
Average KL loss: 0.307674
Average total loss: 0.636343
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.1677e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.330733
Average KL loss: 0.309187
Average total loss: 0.639920
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.4925e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.330107
Average KL loss: 0.308965
Average total loss: 0.639072
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.3198e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.332467
Average KL loss: 0.310391
Average total loss: 0.642858
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1547e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.332513
Average KL loss: 0.311353
Average total loss: 0.643866
tensor(0.0030, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(4.7039e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.328166
Average KL loss: 0.311207
Average total loss: 0.639373
tensor(0.0030, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.4217e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.331470
Average KL loss: 0.311498
Average total loss: 0.642968
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1813e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.325514
Average KL loss: 0.311096
Average total loss: 0.636609
tensor(0.0030, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.6673e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.322756
Average KL loss: 0.310572
Average total loss: 0.633328
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(9.3856e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.324293
Average KL loss: 0.310967
Average total loss: 0.635261
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.8980e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.322791
Average KL loss: 0.311973
Average total loss: 0.634764
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.0939e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.322608
Average KL loss: 0.311570
Average total loss: 0.634178
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.6271e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.322892
Average KL loss: 0.313285
Average total loss: 0.636178
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(6.9156e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.320143
Average KL loss: 0.313006
Average total loss: 0.633149
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.8358e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.318661
Average KL loss: 0.313077
Average total loss: 0.631738
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.2900e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.321448
Average KL loss: 0.313067
Average total loss: 0.634515
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.8174e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.318586
Average KL loss: 0.313321
Average total loss: 0.631908
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.8857e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.318531
Average KL loss: 0.313399
Average total loss: 0.631930
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.5323e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.315570
Average KL loss: 0.313156
Average total loss: 0.628726
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.2423e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.318805
Average KL loss: 0.313512
Average total loss: 0.632317
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.7784e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.316196
Average KL loss: 0.314286
Average total loss: 0.630482
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.3620e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.314958
Average KL loss: 0.313336
Average total loss: 0.628294
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.9559e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.312144
Average KL loss: 0.313444
Average total loss: 0.625588
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-5.9755e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.315220
Average KL loss: 0.313748
Average total loss: 0.628968
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.7535e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.314807
Average KL loss: 0.314898
Average total loss: 0.629704
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-6.9040e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.311816
Average KL loss: 0.314734
Average total loss: 0.626550
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.5258e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.310645
Average KL loss: 0.314392
Average total loss: 0.625036
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.0594e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.311993
Average KL loss: 0.315058
Average total loss: 0.627051
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.6422e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.311613
Average KL loss: 0.315098
Average total loss: 0.626711
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.9490e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.309061
Average KL loss: 0.314885
Average total loss: 0.623946
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.3461e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.310720
Average KL loss: 0.315092
Average total loss: 0.625812
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(2.1839e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.310587
Average KL loss: 0.315305
Average total loss: 0.625891
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.7079e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.307078
Average KL loss: 0.314877
Average total loss: 0.621956
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.1982e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.310115
Average KL loss: 0.315148
Average total loss: 0.625263
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.0616e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.306154
Average KL loss: 0.314411
Average total loss: 0.620566
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(1.6405e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.308740
Average KL loss: 0.315252
Average total loss: 0.623992
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.1401e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.305619
Average KL loss: 0.315246
Average total loss: 0.620865
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.0127e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.310232
Average KL loss: 0.316691
Average total loss: 0.626922
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.4810e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.301800
Average KL loss: 0.316424
Average total loss: 0.618224
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.3429e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.303254
Average KL loss: 0.315679
Average total loss: 0.618933
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(8.2033e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.303851
Average KL loss: 0.315579
Average total loss: 0.619431
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.8590e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.306397
Average KL loss: 0.316086
Average total loss: 0.622483
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(2.6833e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.304565
Average KL loss: 0.317610
Average total loss: 0.622175
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.0165e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.303958
Average KL loss: 0.317102
Average total loss: 0.621061
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3028e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.302356
Average KL loss: 0.316738
Average total loss: 0.619093
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.0874e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.301272
Average KL loss: 0.317020
Average total loss: 0.618293
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5851e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.302122
Average KL loss: 0.316443
Average total loss: 0.618565
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(5.9515e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.302712
Average KL loss: 0.317099
Average total loss: 0.619811
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(6.5320e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.301318
Average KL loss: 0.317207
Average total loss: 0.618525
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(3.9346e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.303331
Average KL loss: 0.317486
Average total loss: 0.620817
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.2038e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.302171
Average KL loss: 0.311490
Average total loss: 0.613661
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.3115e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.297085
Average KL loss: 0.303492
Average total loss: 0.600577
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.1054e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.296952
Average KL loss: 0.299613
Average total loss: 0.596565
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.3049e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.296429
Average KL loss: 0.297289
Average total loss: 0.593718
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(4.3097e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.303861
Average KL loss: 0.295690
Average total loss: 0.599551
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.7434e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.299297
Average KL loss: 0.294589
Average total loss: 0.593885
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(5.5730e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.299572
Average KL loss: 0.293731
Average total loss: 0.593302
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.6080e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.297962
Average KL loss: 0.293067
Average total loss: 0.591029
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.9358e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.300435
Average KL loss: 0.292598
Average total loss: 0.593033
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-8.4561e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.300297
Average KL loss: 0.292253
Average total loss: 0.592550
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.4206e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.303111
Average KL loss: 0.291910
Average total loss: 0.595021
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.1833e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.300009
Average KL loss: 0.291737
Average total loss: 0.591746
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.0906e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.298371
Average KL loss: 0.291403
Average total loss: 0.589775
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.0561e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.300339
Average KL loss: 0.291098
Average total loss: 0.591437
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(6.0543e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.301461
Average KL loss: 0.290967
Average total loss: 0.592428
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(6.0308e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.301101
Average KL loss: 0.290740
Average total loss: 0.591840
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(8.6308e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.299242
Average KL loss: 0.290556
Average total loss: 0.589798
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.5625e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.299013
Average KL loss: 0.290444
Average total loss: 0.589457
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.0136e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.299418
Average KL loss: 0.290282
Average total loss: 0.589700
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.3191e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.299462
Average KL loss: 0.290224
Average total loss: 0.589685
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.0240e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.300726
Average KL loss: 0.290216
Average total loss: 0.590942
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.9843e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.297846
Average KL loss: 0.290020
Average total loss: 0.587866
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.2266e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.298812
Average KL loss: 0.289880
Average total loss: 0.588692
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(2.3254e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.295722
Average KL loss: 0.289853
Average total loss: 0.585575
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3492e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.300447
Average KL loss: 0.289835
Average total loss: 0.590281
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(5.2945e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.298634
Average KL loss: 0.289771
Average total loss: 0.588405
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.8410e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.299482
Average KL loss: 0.289720
Average total loss: 0.589202
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.5690e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.298981
Average KL loss: 0.289695
Average total loss: 0.588676
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(3.3160e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.298836
Average KL loss: 0.289661
Average total loss: 0.588497
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.4229e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.298603
Average KL loss: 0.289579
Average total loss: 0.588182
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.6243e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.299793
Average KL loss: 0.289523
Average total loss: 0.589316
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6452e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.297734
Average KL loss: 0.289438
Average total loss: 0.587171
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.9939e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.295528
Average KL loss: 0.289406
Average total loss: 0.584934
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.8764e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.297291
Average KL loss: 0.289461
Average total loss: 0.586752
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.3630e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.298736
Average KL loss: 0.289337
Average total loss: 0.588074
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.4711e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.298988
Average KL loss: 0.289242
Average total loss: 0.588230
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.0883e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.298516
Average KL loss: 0.289197
Average total loss: 0.587714
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.1816e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.299162
Average KL loss: 0.289323
Average total loss: 0.588485
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.6868e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.296932
Average KL loss: 0.289342
Average total loss: 0.586274
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.7322e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.294781
Average KL loss: 0.289319
Average total loss: 0.584101
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.0525e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.295517
Average KL loss: 0.289128
Average total loss: 0.584645
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0918e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.298547
Average KL loss: 0.289096
Average total loss: 0.587642
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(4.0567e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.301097
Average KL loss: 0.289173
Average total loss: 0.590269
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.3429e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.297061
Average KL loss: 0.289244
Average total loss: 0.586305
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.3445e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.295213
Average KL loss: 0.289223
Average total loss: 0.584436
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.4253e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.293798
Average KL loss: 0.289093
Average total loss: 0.582891
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.3094e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.295295
Average KL loss: 0.288935
Average total loss: 0.584230
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.0817e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.298816
Average KL loss: 0.288934
Average total loss: 0.587750
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.0890e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.299009
Average KL loss: 0.289056
Average total loss: 0.588065
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.7580e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.299208
Average KL loss: 0.289138
Average total loss: 0.588346
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.7396e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.298439
Average KL loss: 0.289153
Average total loss: 0.587592
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.2199e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.294563
Average KL loss: 0.289111
Average total loss: 0.583674
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.1560e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.302569
Average KL loss: 0.289086
Average total loss: 0.591656
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0593e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.297357
Average KL loss: 0.289210
Average total loss: 0.586567
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.3717e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.296936
Average KL loss: 0.289177
Average total loss: 0.586114
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.8442e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.300125
Average KL loss: 0.289271
Average total loss: 0.589396
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.0999e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.299169
Average KL loss: 0.289313
Average total loss: 0.588482
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.2752e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.292199
Average KL loss: 0.289241
Average total loss: 0.581441
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.8882e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.298745
Average KL loss: 0.288986
Average total loss: 0.587731
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.0302e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.298329
Average KL loss: 0.288815
Average total loss: 0.587143
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.3348e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.295989
Average KL loss: 0.288666
Average total loss: 0.584655
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.4154e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.297100
Average KL loss: 0.288538
Average total loss: 0.585638
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.6435e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.296065
Average KL loss: 0.288427
Average total loss: 0.584491
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.3132e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.300114
Average KL loss: 0.288328
Average total loss: 0.588443
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.3388e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.296444
Average KL loss: 0.288237
Average total loss: 0.584681
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.5738e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.297537
Average KL loss: 0.288149
Average total loss: 0.585686
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5993e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.296707
Average KL loss: 0.288081
Average total loss: 0.584787
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.2960e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.298621
Average KL loss: 0.288018
Average total loss: 0.586639
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.3165e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.298793
Average KL loss: 0.287961
Average total loss: 0.586754
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6959e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.298290
Average KL loss: 0.287925
Average total loss: 0.586215
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.3860e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.298897
Average KL loss: 0.287915
Average total loss: 0.586812
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.3096e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.297919
Average KL loss: 0.287906
Average total loss: 0.585825
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.1511e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.296225
Average KL loss: 0.287897
Average total loss: 0.584122
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.0544e-12, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.298449
Average KL loss: 0.287887
Average total loss: 0.586336
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.2273e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.297753
Average KL loss: 0.287879
Average total loss: 0.585631
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.9166e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.297042
Average KL loss: 0.287870
Average total loss: 0.584912
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5891e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.296852
Average KL loss: 0.287861
Average total loss: 0.584713
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.1500e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.295027
Average KL loss: 0.287853
Average total loss: 0.582880
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5896e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.294179
Average KL loss: 0.287845
Average total loss: 0.582024
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.4734e-09, device='cuda:0')
 Percentile value: 0.007161015179008245
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =     475 /    1728             ( 27.49%) | total_pruned =    1253 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
bn1.bias             | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5459 /   36864             ( 14.81%) | total_pruned =   31405 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   12296 /   36864             ( 33.36%) | total_pruned =   24568 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   11418 /   36864             ( 30.97%) | total_pruned =   25446 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   14078 /   36864             ( 38.19%) | total_pruned =   22786 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   35147 /   73728             ( 47.67%) | total_pruned =   38581 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   69560 /  147456             ( 47.17%) | total_pruned =   77896 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4549 /    8192             ( 55.53%) | total_pruned =    3643 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   50044 /  147456             ( 33.94%) | total_pruned =   97412 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   43218 /  147456             ( 29.31%) | total_pruned =  104238 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  141645 /  294912             ( 48.03%) | total_pruned =  153267 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     111 /     256             ( 43.36%) | total_pruned =     145 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  275657 /  589824             ( 46.74%) | total_pruned =  314167 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   16111 /   32768             ( 49.17%) | total_pruned =   16657 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  230556 /  589824             ( 39.09%) | total_pruned =  359268 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  182144 /  589824             ( 30.88%) | total_pruned =  407680 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  451225 / 1179648             ( 38.25%) | total_pruned =  728423 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     106 /     512             ( 20.70%) | total_pruned =     406 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  531173 / 2359296             ( 22.51%) | total_pruned = 1828123 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     481 /     512             ( 93.95%) | total_pruned =      31 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     277 /     512             ( 54.10%) | total_pruned =     235 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   27675 /  131072             ( 21.11%) | total_pruned =  103397 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     494 /     512             ( 96.48%) | total_pruned =      18 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  557150 / 2359296             ( 23.62%) | total_pruned = 1802146 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  682304 / 2359296             ( 28.92%) | total_pruned = 1676992 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5073 /    5120             ( 99.08%) | total_pruned =      47 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 60/200 Loss: 0.021199 Accuracy: 89.51 100.00 % Best test Accuracy: 89.59%
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.2793e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.795309
Average KL loss: 0.307220
Average total loss: 1.102529
tensor(0.0036, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.5868e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.621071
Average KL loss: 0.333687
Average total loss: 0.954758
tensor(0.0037, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.7512e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.578303
Average KL loss: 0.338226
Average total loss: 0.916529
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-9.7606e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.549683
Average KL loss: 0.339974
Average total loss: 0.889657
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.7412e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.522064
Average KL loss: 0.338515
Average total loss: 0.860579
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.1276e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.514115
Average KL loss: 0.334396
Average total loss: 0.848511
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.9116e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.490915
Average KL loss: 0.333537
Average total loss: 0.824452
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.5914e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.485119
Average KL loss: 0.332792
Average total loss: 0.817911
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.4921e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.476809
Average KL loss: 0.333187
Average total loss: 0.809996
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.2048e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.473443
Average KL loss: 0.332994
Average total loss: 0.806437
tensor(0.0036, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-7.2701e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.458036
Average KL loss: 0.333981
Average total loss: 0.792017
tensor(0.0035, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.3844e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.444801
Average KL loss: 0.333119
Average total loss: 0.777920
tensor(0.0035, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.6345e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.445991
Average KL loss: 0.331671
Average total loss: 0.777662
tensor(0.0035, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.1149e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.441154
Average KL loss: 0.331930
Average total loss: 0.773084
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.9238e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.443464
Average KL loss: 0.332759
Average total loss: 0.776223
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.6165e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.435089
Average KL loss: 0.333679
Average total loss: 0.768768
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-4.5465e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.424284
Average KL loss: 0.333339
Average total loss: 0.757623
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-8.3826e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.429069
Average KL loss: 0.333462
Average total loss: 0.762531
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-8.4921e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.422093
Average KL loss: 0.333744
Average total loss: 0.755837
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-9.1620e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.418400
Average KL loss: 0.334078
Average total loss: 0.752479
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-9.1146e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.415138
Average KL loss: 0.333611
Average total loss: 0.748748
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.8327e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.410724
Average KL loss: 0.334346
Average total loss: 0.745070
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.6395e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.404482
Average KL loss: 0.333908
Average total loss: 0.738391
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.2626e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.401105
Average KL loss: 0.333183
Average total loss: 0.734289
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.0852e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.413723
Average KL loss: 0.334560
Average total loss: 0.748284
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.1814e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.400833
Average KL loss: 0.334287
Average total loss: 0.735120
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.2231e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.395557
Average KL loss: 0.333330
Average total loss: 0.728887
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2532e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.394547
Average KL loss: 0.333746
Average total loss: 0.728293
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.7711e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.393705
Average KL loss: 0.334261
Average total loss: 0.727966
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.5109e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.390344
Average KL loss: 0.333711
Average total loss: 0.724055
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.0528e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.386800
Average KL loss: 0.333667
Average total loss: 0.720467
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.9572e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.383800
Average KL loss: 0.333504
Average total loss: 0.717304
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.4703e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.390477
Average KL loss: 0.334185
Average total loss: 0.724663
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.4044e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.389554
Average KL loss: 0.335016
Average total loss: 0.724571
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.4798e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.387927
Average KL loss: 0.334975
Average total loss: 0.722902
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.0673e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.379849
Average KL loss: 0.335052
Average total loss: 0.714901
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.0307e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.382922
Average KL loss: 0.335035
Average total loss: 0.717956
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.9344e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.380180
Average KL loss: 0.334344
Average total loss: 0.714523
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.9888e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.379351
Average KL loss: 0.335221
Average total loss: 0.714571
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.2395e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.376342
Average KL loss: 0.334740
Average total loss: 0.711082
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.1285e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.371690
Average KL loss: 0.335360
Average total loss: 0.707050
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(6.3893e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.381401
Average KL loss: 0.334959
Average total loss: 0.716360
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.1027e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.372799
Average KL loss: 0.335431
Average total loss: 0.708230
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(8.3105e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.373340
Average KL loss: 0.335786
Average total loss: 0.709126
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(6.3484e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.367011
Average KL loss: 0.335107
Average total loss: 0.702117
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.4189e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.369607
Average KL loss: 0.335369
Average total loss: 0.704976
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.9347e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.366770
Average KL loss: 0.335677
Average total loss: 0.702447
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.6839e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.364972
Average KL loss: 0.335566
Average total loss: 0.700538
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.7609e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.369907
Average KL loss: 0.335155
Average total loss: 0.705061
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.8583e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.374500
Average KL loss: 0.336575
Average total loss: 0.711075
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.4846e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.364750
Average KL loss: 0.337149
Average total loss: 0.701899
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.1779e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.363339
Average KL loss: 0.336714
Average total loss: 0.700052
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.2214e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.358437
Average KL loss: 0.336155
Average total loss: 0.694592
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(1.3366e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.358895
Average KL loss: 0.335533
Average total loss: 0.694428
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3770e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.357029
Average KL loss: 0.335879
Average total loss: 0.692909
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.7596e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.358355
Average KL loss: 0.336014
Average total loss: 0.694369
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.3145e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.355912
Average KL loss: 0.336075
Average total loss: 0.691987
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.1501e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.354402
Average KL loss: 0.336370
Average total loss: 0.690771
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.2934e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.360021
Average KL loss: 0.336835
Average total loss: 0.696856
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(7.3439e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.355443
Average KL loss: 0.336449
Average total loss: 0.691892
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.1487e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.350696
Average KL loss: 0.336107
Average total loss: 0.686804
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.7246e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.357366
Average KL loss: 0.336011
Average total loss: 0.693377
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(2.6958e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.357018
Average KL loss: 0.336821
Average total loss: 0.693838
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.1098e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.355516
Average KL loss: 0.337809
Average total loss: 0.693325
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.6916e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.354852
Average KL loss: 0.337768
Average total loss: 0.692620
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.0671e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.349519
Average KL loss: 0.337460
Average total loss: 0.686978
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.5190e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.355402
Average KL loss: 0.338134
Average total loss: 0.693535
tensor(0.0036, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.2396e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.349991
Average KL loss: 0.338255
Average total loss: 0.688246
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.7130e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.347744
Average KL loss: 0.338193
Average total loss: 0.685937
tensor(0.0036, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-9.7617e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.358182
Average KL loss: 0.338020
Average total loss: 0.696202
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(3.4303e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.352187
Average KL loss: 0.339144
Average total loss: 0.691330
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.9780e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.351335
Average KL loss: 0.338816
Average total loss: 0.690151
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(4.8325e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.348254
Average KL loss: 0.338625
Average total loss: 0.686879
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.2270e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.350818
Average KL loss: 0.338580
Average total loss: 0.689397
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.6102e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.346354
Average KL loss: 0.338482
Average total loss: 0.684835
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(4.4483e-11, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.352096
Average KL loss: 0.339118
Average total loss: 0.691214
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.0177e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.347567
Average KL loss: 0.339171
Average total loss: 0.686738
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.7409e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.349691
Average KL loss: 0.339295
Average total loss: 0.688986
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.2671e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.346519
Average KL loss: 0.339409
Average total loss: 0.685928
tensor(0.0036, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.5745e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.345901
Average KL loss: 0.339570
Average total loss: 0.685471
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.0910e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.341152
Average KL loss: 0.338804
Average total loss: 0.679956
tensor(0.0036, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.1765e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.342616
Average KL loss: 0.338153
Average total loss: 0.680769
tensor(0.0036, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.6111e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.343662
Average KL loss: 0.338448
Average total loss: 0.682110
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.5473e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.336288
Average KL loss: 0.338686
Average total loss: 0.674974
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(5.3862e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.342038
Average KL loss: 0.338191
Average total loss: 0.680229
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.3847e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.343145
Average KL loss: 0.338789
Average total loss: 0.681934
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.2099e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.339356
Average KL loss: 0.339044
Average total loss: 0.678400
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(5.6073e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.344153
Average KL loss: 0.339642
Average total loss: 0.683794
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.6874e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.343177
Average KL loss: 0.339832
Average total loss: 0.683008
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4872e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.340163
Average KL loss: 0.339776
Average total loss: 0.679939
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.5525e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.341577
Average KL loss: 0.338624
Average total loss: 0.680200
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-8.3276e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.344258
Average KL loss: 0.340258
Average total loss: 0.684516
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.4704e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.344281
Average KL loss: 0.340377
Average total loss: 0.684658
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0096e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.339540
Average KL loss: 0.341286
Average total loss: 0.680826
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(3.0225e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.340365
Average KL loss: 0.339981
Average total loss: 0.680346
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.2228e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.339272
Average KL loss: 0.337744
Average total loss: 0.677016
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.2062e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.337450
Average KL loss: 0.333166
Average total loss: 0.670616
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.1221e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.333888
Average KL loss: 0.330253
Average total loss: 0.664141
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.8360e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.341626
Average KL loss: 0.328164
Average total loss: 0.669790
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.4214e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.340164
Average KL loss: 0.326646
Average total loss: 0.666810
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.6663e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.339557
Average KL loss: 0.325352
Average total loss: 0.664909
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0330e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.343359
Average KL loss: 0.324306
Average total loss: 0.667665
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.8386e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.334204
Average KL loss: 0.323469
Average total loss: 0.657673
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0778e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.336031
Average KL loss: 0.322531
Average total loss: 0.658561
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.2508e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.333648
Average KL loss: 0.321807
Average total loss: 0.655454
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5320e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.335726
Average KL loss: 0.321042
Average total loss: 0.656768
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.9624e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.336964
Average KL loss: 0.320503
Average total loss: 0.657467
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.1818e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.337677
Average KL loss: 0.320103
Average total loss: 0.657780
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.7722e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.337952
Average KL loss: 0.319656
Average total loss: 0.657608
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.3862e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.334233
Average KL loss: 0.319212
Average total loss: 0.653445
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.0474e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.335804
Average KL loss: 0.318952
Average total loss: 0.654756
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.7602e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.334622
Average KL loss: 0.318594
Average total loss: 0.653216
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.0094e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.339978
Average KL loss: 0.318340
Average total loss: 0.658318
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.8689e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.336434
Average KL loss: 0.318183
Average total loss: 0.654617
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0307e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.335620
Average KL loss: 0.317956
Average total loss: 0.653577
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.0127e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.335994
Average KL loss: 0.317773
Average total loss: 0.653766
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.7071e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.334959
Average KL loss: 0.317435
Average total loss: 0.652394
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0697e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.337632
Average KL loss: 0.317107
Average total loss: 0.654739
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.4337e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.334722
Average KL loss: 0.316944
Average total loss: 0.651666
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.3158e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.338424
Average KL loss: 0.316777
Average total loss: 0.655202
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.3451e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.340979
Average KL loss: 0.316737
Average total loss: 0.657717
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.3168e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.337743
Average KL loss: 0.316753
Average total loss: 0.654496
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.5045e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.337865
Average KL loss: 0.316721
Average total loss: 0.654586
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.0039e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.334532
Average KL loss: 0.316591
Average total loss: 0.651123
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.6567e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.339693
Average KL loss: 0.316389
Average total loss: 0.656081
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.9353e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.335680
Average KL loss: 0.316285
Average total loss: 0.651965
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.0965e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.338123
Average KL loss: 0.316192
Average total loss: 0.654315
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.1398e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.336679
Average KL loss: 0.316081
Average total loss: 0.652759
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.0452e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.333181
Average KL loss: 0.315939
Average total loss: 0.649119
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.1932e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.336572
Average KL loss: 0.315841
Average total loss: 0.652414
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.5998e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.335978
Average KL loss: 0.315720
Average total loss: 0.651698
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.5617e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.334798
Average KL loss: 0.315758
Average total loss: 0.650556
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.8546e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.336175
Average KL loss: 0.315785
Average total loss: 0.651960
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.5442e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.333497
Average KL loss: 0.315697
Average total loss: 0.649194
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.0026e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.335593
Average KL loss: 0.315559
Average total loss: 0.651152
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.7070e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.335119
Average KL loss: 0.315448
Average total loss: 0.650567
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(6.3234e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.340210
Average KL loss: 0.315445
Average total loss: 0.655655
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.1518e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.336237
Average KL loss: 0.315396
Average total loss: 0.651633
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.5246e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.331625
Average KL loss: 0.315206
Average total loss: 0.646831
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.9548e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.333963
Average KL loss: 0.315079
Average total loss: 0.649042
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.0188e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.335216
Average KL loss: 0.315017
Average total loss: 0.650233
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.1205e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.331720
Average KL loss: 0.314974
Average total loss: 0.646695
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.8522e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.337994
Average KL loss: 0.314928
Average total loss: 0.652923
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.1641e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.336602
Average KL loss: 0.314912
Average total loss: 0.651514
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.5087e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.339997
Average KL loss: 0.314959
Average total loss: 0.654957
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6720e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.334520
Average KL loss: 0.314997
Average total loss: 0.649517
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.3731e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.336292
Average KL loss: 0.314890
Average total loss: 0.651182
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.7265e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.335893
Average KL loss: 0.314900
Average total loss: 0.650793
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.1513e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.334132
Average KL loss: 0.314909
Average total loss: 0.649042
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.4513e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.335130
Average KL loss: 0.314904
Average total loss: 0.650034
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.3250e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.333968
Average KL loss: 0.314807
Average total loss: 0.648775
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.2475e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.332820
Average KL loss: 0.314697
Average total loss: 0.647517
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.8416e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.333553
Average KL loss: 0.314638
Average total loss: 0.648191
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(7.0762e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.336286
Average KL loss: 0.314573
Average total loss: 0.650859
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.5467e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.331337
Average KL loss: 0.314480
Average total loss: 0.645818
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.6043e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.340053
Average KL loss: 0.314402
Average total loss: 0.654456
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(6.3418e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.337885
Average KL loss: 0.314342
Average total loss: 0.652227
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.5264e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.334358
Average KL loss: 0.314279
Average total loss: 0.648637
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0146e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.337390
Average KL loss: 0.314213
Average total loss: 0.651602
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.3156e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.337014
Average KL loss: 0.314150
Average total loss: 0.651165
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(6.4420e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.329965
Average KL loss: 0.314094
Average total loss: 0.644059
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.3686e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.335913
Average KL loss: 0.314042
Average total loss: 0.649955
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(9.5885e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.340086
Average KL loss: 0.314002
Average total loss: 0.654088
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.1532e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.336025
Average KL loss: 0.313964
Average total loss: 0.649989
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.2959e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.332034
Average KL loss: 0.313932
Average total loss: 0.645966
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.3314e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.329449
Average KL loss: 0.313884
Average total loss: 0.643333
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.3182e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.335708
Average KL loss: 0.313847
Average total loss: 0.649556
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.1377e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.334997
Average KL loss: 0.313807
Average total loss: 0.648804
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.6221e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.332195
Average KL loss: 0.313764
Average total loss: 0.645959
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.9903e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.336035
Average KL loss: 0.313723
Average total loss: 0.649758
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6807e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.336243
Average KL loss: 0.313696
Average total loss: 0.649940
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.0536e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.337937
Average KL loss: 0.313669
Average total loss: 0.651606
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.2709e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.339522
Average KL loss: 0.313654
Average total loss: 0.653176
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.1933e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.335782
Average KL loss: 0.313634
Average total loss: 0.649417
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.7158e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.336368
Average KL loss: 0.313608
Average total loss: 0.649976
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0852e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.336201
Average KL loss: 0.313581
Average total loss: 0.649783
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0885e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.337679
Average KL loss: 0.313556
Average total loss: 0.651235
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.2110e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.333098
Average KL loss: 0.313544
Average total loss: 0.646642
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(9.2963e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.336364
Average KL loss: 0.313539
Average total loss: 0.649904
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.0321e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.334138
Average KL loss: 0.313536
Average total loss: 0.647674
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7145e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.335642
Average KL loss: 0.313532
Average total loss: 0.649174
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6256e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.337840
Average KL loss: 0.313529
Average total loss: 0.651369
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.0399e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.336468
Average KL loss: 0.313525
Average total loss: 0.649994
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5517e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.333643
Average KL loss: 0.313522
Average total loss: 0.647164
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7143e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.338939
Average KL loss: 0.313517
Average total loss: 0.652456
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.6974e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.333343
Average KL loss: 0.313513
Average total loss: 0.646856
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.4204e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.332310
Average KL loss: 0.313509
Average total loss: 0.645819
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.4580e-09, device='cuda:0')
 Percentile value: 0.02574667371809482
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =     215 /    1728             ( 12.44%) | total_pruned =    1513 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
bn1.bias             | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     957 /   36864             (  2.60%) | total_pruned =   35907 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2474 /   36864             (  6.71%) | total_pruned =   34390 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3251 /   36864             (  8.82%) | total_pruned =   33613 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    5136 /   36864             ( 13.93%) | total_pruned =   31728 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13766 /   73728             ( 18.67%) | total_pruned =   59962 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   25341 /  147456             ( 17.19%) | total_pruned =  122115 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2010 /    8192             ( 24.54%) | total_pruned =    6182 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   14747 /  147456             ( 10.00%) | total_pruned =  132709 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   11283 /  147456             (  7.65%) | total_pruned =  136173 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   59504 /  294912             ( 20.18%) | total_pruned =  235408 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  108418 /  589824             ( 18.38%) | total_pruned =  481406 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      44 /     256             ( 17.19%) | total_pruned =     212 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6920 /   32768             ( 21.12%) | total_pruned =   25848 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   71204 /  589824             ( 12.07%) | total_pruned =  518620 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   43922 /  589824             (  7.45%) | total_pruned =  545902 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  160438 / 1179648             ( 13.60%) | total_pruned = 1019210 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  133453 / 2359296             (  5.66%) | total_pruned = 2225843 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     395 /     512             ( 77.15%) | total_pruned =     117 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     190 /     512             ( 37.11%) | total_pruned =     322 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    4875 /  131072             (  3.72%) | total_pruned =  126197 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     299 /     512             ( 58.40%) | total_pruned =     213 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  122212 / 2359296             (  5.18%) | total_pruned = 2237084 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     391 /     512             ( 76.37%) | total_pruned =     121 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  206151 / 2359296             (  8.74%) | total_pruned = 2153145 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     467 /     512             ( 91.21%) | total_pruned =      45 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     463 /     512             ( 90.43%) | total_pruned =      49 | shape = torch.Size([512])
linear.weight        | nonzeros =    4529 /    5120             ( 88.46%) | total_pruned =     591 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 51/200 Loss: 0.019574 Accuracy: 88.26 100.00 % Best test Accuracy: 88.66%
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.2942e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.984401
Average KL loss: 0.307889
Average total loss: 1.292290
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.3073e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.789574
Average KL loss: 0.330313
Average total loss: 1.119887
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.6444e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.713390
Average KL loss: 0.341336
Average total loss: 1.054726
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.8228e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.679119
Average KL loss: 0.345278
Average total loss: 1.024397
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.7209e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.634725
Average KL loss: 0.347514
Average total loss: 0.982238
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.9023e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.607263
Average KL loss: 0.347928
Average total loss: 0.955190
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.0452e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.584091
Average KL loss: 0.347900
Average total loss: 0.931991
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.9520e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.581952
Average KL loss: 0.349404
Average total loss: 0.931356
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-7.7502e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.550510
Average KL loss: 0.350206
Average total loss: 0.900716
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.3501e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.542829
Average KL loss: 0.350698
Average total loss: 0.893527
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-6.9338e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.530240
Average KL loss: 0.351313
Average total loss: 0.881553
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.7959e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.530716
Average KL loss: 0.352163
Average total loss: 0.882879
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.7877e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.512791
Average KL loss: 0.352900
Average total loss: 0.865691
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.4739e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.526621
Average KL loss: 0.353889
Average total loss: 0.880511
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.9128e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.501422
Average KL loss: 0.353551
Average total loss: 0.854972
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.6500e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.502485
Average KL loss: 0.354379
Average total loss: 0.856865
tensor(0.0034, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.5897e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.488449
Average KL loss: 0.354360
Average total loss: 0.842810
tensor(0.0034, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5922e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.499980
Average KL loss: 0.354849
Average total loss: 0.854829
tensor(0.0034, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.8854e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.486430
Average KL loss: 0.356485
Average total loss: 0.842916
tensor(0.0034, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.9424e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.483535
Average KL loss: 0.356637
Average total loss: 0.840172
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.2426e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.480920
Average KL loss: 0.356744
Average total loss: 0.837664
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.2683e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.469282
Average KL loss: 0.356287
Average total loss: 0.825569
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.3796e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.469532
Average KL loss: 0.356888
Average total loss: 0.826420
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.6735e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.474266
Average KL loss: 0.356411
Average total loss: 0.830677
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.8368e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.468339
Average KL loss: 0.356653
Average total loss: 0.824992
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.1150e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.460668
Average KL loss: 0.357180
Average total loss: 0.817848
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.8070e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.457918
Average KL loss: 0.357480
Average total loss: 0.815398
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.3150e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.449408
Average KL loss: 0.357412
Average total loss: 0.806820
tensor(0.0034, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.4200e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.458657
Average KL loss: 0.357642
Average total loss: 0.816299
tensor(0.0034, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.0007e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.449162
Average KL loss: 0.357569
Average total loss: 0.806731
tensor(0.0034, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.3485e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.449856
Average KL loss: 0.357638
Average total loss: 0.807494
tensor(0.0034, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-9.4751e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.450125
Average KL loss: 0.358328
Average total loss: 0.808453
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.7594e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.444683
Average KL loss: 0.358272
Average total loss: 0.802955
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-8.4997e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.445286
Average KL loss: 0.358367
Average total loss: 0.803653
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1278e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.435841
Average KL loss: 0.358449
Average total loss: 0.794290
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.5214e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.437623
Average KL loss: 0.358062
Average total loss: 0.795685
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.7757e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.443146
Average KL loss: 0.358674
Average total loss: 0.801820
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.4623e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.435883
Average KL loss: 0.359018
Average total loss: 0.794901
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1677e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.436067
Average KL loss: 0.359573
Average total loss: 0.795641
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.7942e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.440666
Average KL loss: 0.359367
Average total loss: 0.800033
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.5438e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.431739
Average KL loss: 0.359897
Average total loss: 0.791636
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.1561e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.428904
Average KL loss: 0.360293
Average total loss: 0.789198
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.2777e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.428633
Average KL loss: 0.360029
Average total loss: 0.788662
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.9473e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.426673
Average KL loss: 0.360062
Average total loss: 0.786735
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.0255e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.426939
Average KL loss: 0.360040
Average total loss: 0.786979
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.3498e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.426730
Average KL loss: 0.360111
Average total loss: 0.786841
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.7255e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.422993
Average KL loss: 0.360242
Average total loss: 0.783235
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.0733e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.422646
Average KL loss: 0.359885
Average total loss: 0.782531
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.5878e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.420190
Average KL loss: 0.359728
Average total loss: 0.779918
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.0155e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.416618
Average KL loss: 0.359349
Average total loss: 0.775966
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.4918e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.418421
Average KL loss: 0.359604
Average total loss: 0.778025
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(6.9212e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.415884
Average KL loss: 0.359276
Average total loss: 0.775160
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.7345e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.412332
Average KL loss: 0.358952
Average total loss: 0.771284
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.1970e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.415424
Average KL loss: 0.358996
Average total loss: 0.774420
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.8354e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.415616
Average KL loss: 0.359496
Average total loss: 0.775112
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.4240e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.407685
Average KL loss: 0.360068
Average total loss: 0.767754
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.3830e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.413557
Average KL loss: 0.359809
Average total loss: 0.773367
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.2889e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.411645
Average KL loss: 0.360288
Average total loss: 0.771933
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-8.6789e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.413068
Average KL loss: 0.361053
Average total loss: 0.774121
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(5.2371e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.408546
Average KL loss: 0.360602
Average total loss: 0.769148
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(3.1302e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.416789
Average KL loss: 0.360618
Average total loss: 0.777407
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.6687e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.411162
Average KL loss: 0.362164
Average total loss: 0.773326
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.8544e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.403651
Average KL loss: 0.361833
Average total loss: 0.765484
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4974e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.407655
Average KL loss: 0.361516
Average total loss: 0.769171
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.2869e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.408796
Average KL loss: 0.361579
Average total loss: 0.770375
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.8790e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.407628
Average KL loss: 0.361782
Average total loss: 0.769410
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.0092e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.406334
Average KL loss: 0.361383
Average total loss: 0.767717
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.4150e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.409288
Average KL loss: 0.362022
Average total loss: 0.771310
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.7079e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.397630
Average KL loss: 0.361766
Average total loss: 0.759396
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.9329e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.408460
Average KL loss: 0.361825
Average total loss: 0.770285
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.0861e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.404609
Average KL loss: 0.363092
Average total loss: 0.767701
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1332e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.403705
Average KL loss: 0.362629
Average total loss: 0.766333
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.7684e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.402839
Average KL loss: 0.362121
Average total loss: 0.764960
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.6715e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.402784
Average KL loss: 0.362357
Average total loss: 0.765141
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.1392e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.402165
Average KL loss: 0.362471
Average total loss: 0.764636
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.7416e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.400812
Average KL loss: 0.362313
Average total loss: 0.763125
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.1528e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.398287
Average KL loss: 0.362524
Average total loss: 0.760811
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.7363e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.408268
Average KL loss: 0.362420
Average total loss: 0.770688
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.9145e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.406519
Average KL loss: 0.362389
Average total loss: 0.768908
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-9.7354e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.402794
Average KL loss: 0.362231
Average total loss: 0.765025
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.4272e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.396742
Average KL loss: 0.360981
Average total loss: 0.757723
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.0648e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.400957
Average KL loss: 0.358677
Average total loss: 0.759634
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.6665e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.394042
Average KL loss: 0.356948
Average total loss: 0.750990
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.2716e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.395332
Average KL loss: 0.355576
Average total loss: 0.750908
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.1562e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.399870
Average KL loss: 0.354322
Average total loss: 0.754192
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.5918e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.397416
Average KL loss: 0.353219
Average total loss: 0.750635
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.8616e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.399056
Average KL loss: 0.352214
Average total loss: 0.751270
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.2615e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.400974
Average KL loss: 0.351472
Average total loss: 0.752446
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(7.0966e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.398732
Average KL loss: 0.350731
Average total loss: 0.749464
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.9209e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.394854
Average KL loss: 0.350013
Average total loss: 0.744868
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.3579e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.399475
Average KL loss: 0.349391
Average total loss: 0.748866
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.1638e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.398779
Average KL loss: 0.348911
Average total loss: 0.747689
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.4826e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.394142
Average KL loss: 0.348479
Average total loss: 0.742620
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.7758e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.401197
Average KL loss: 0.348068
Average total loss: 0.749265
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.6846e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.396880
Average KL loss: 0.347699
Average total loss: 0.744579
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.5996e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.396680
Average KL loss: 0.347300
Average total loss: 0.743980
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.3776e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.395971
Average KL loss: 0.346935
Average total loss: 0.742906
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.1286e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.406536
Average KL loss: 0.346618
Average total loss: 0.753154
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.4090e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.395687
Average KL loss: 0.346295
Average total loss: 0.741982
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-8.8580e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.394982
Average KL loss: 0.345915
Average total loss: 0.740896
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.7034e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.399253
Average KL loss: 0.345642
Average total loss: 0.744895
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(7.5618e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.399937
Average KL loss: 0.345348
Average total loss: 0.745285
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0998e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.393249
Average KL loss: 0.345091
Average total loss: 0.738340
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0322e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.397153
Average KL loss: 0.344827
Average total loss: 0.741980
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.2908e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.399447
Average KL loss: 0.344644
Average total loss: 0.744091
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.8481e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.395313
Average KL loss: 0.344455
Average total loss: 0.739768
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.1901e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.396114
Average KL loss: 0.344295
Average total loss: 0.740409
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.9422e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.393334
Average KL loss: 0.344006
Average total loss: 0.737340
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.0273e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.394243
Average KL loss: 0.343749
Average total loss: 0.737992
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.0506e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.396928
Average KL loss: 0.343576
Average total loss: 0.740504
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.8847e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.396878
Average KL loss: 0.343490
Average total loss: 0.740369
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0960e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.394090
Average KL loss: 0.343377
Average total loss: 0.737467
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.1503e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.393272
Average KL loss: 0.343252
Average total loss: 0.736524
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.5996e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.397095
Average KL loss: 0.343114
Average total loss: 0.740209
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.1345e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.389888
Average KL loss: 0.342943
Average total loss: 0.732831
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.3338e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.396705
Average KL loss: 0.342742
Average total loss: 0.739447
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8043e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.393809
Average KL loss: 0.342657
Average total loss: 0.736466
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(7.0681e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.393023
Average KL loss: 0.342403
Average total loss: 0.735427
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.2533e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.394704
Average KL loss: 0.342185
Average total loss: 0.736889
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.6228e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.401562
Average KL loss: 0.342047
Average total loss: 0.743609
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.4260e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.395886
Average KL loss: 0.342084
Average total loss: 0.737971
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7331e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.395180
Average KL loss: 0.341992
Average total loss: 0.737172
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.3771e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.396883
Average KL loss: 0.341891
Average total loss: 0.738773
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.3307e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.399007
Average KL loss: 0.341829
Average total loss: 0.740836
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.3137e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.394590
Average KL loss: 0.341810
Average total loss: 0.736400
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.5737e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.403794
Average KL loss: 0.341814
Average total loss: 0.745607
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.9997e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.396227
Average KL loss: 0.341766
Average total loss: 0.737993
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.8126e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.393868
Average KL loss: 0.341722
Average total loss: 0.735590
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.7539e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.391061
Average KL loss: 0.341672
Average total loss: 0.732733
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0923e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.397339
Average KL loss: 0.341623
Average total loss: 0.738962
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.7952e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.393553
Average KL loss: 0.341577
Average total loss: 0.735130
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.0290e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.397489
Average KL loss: 0.341537
Average total loss: 0.739026
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.4042e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.402745
Average KL loss: 0.341505
Average total loss: 0.744250
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.0907e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.397728
Average KL loss: 0.341476
Average total loss: 0.739204
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.5685e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.398349
Average KL loss: 0.341443
Average total loss: 0.739792
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.0086e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.394460
Average KL loss: 0.341415
Average total loss: 0.735875
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.2449e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.392752
Average KL loss: 0.341376
Average total loss: 0.734128
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.4629e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.397575
Average KL loss: 0.341337
Average total loss: 0.738912
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.1940e-12, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.395019
Average KL loss: 0.341305
Average total loss: 0.736324
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.8513e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.392358
Average KL loss: 0.341269
Average total loss: 0.733627
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.9703e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.393689
Average KL loss: 0.341250
Average total loss: 0.734939
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.8192e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.396658
Average KL loss: 0.341245
Average total loss: 0.737903
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.7036e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.396211
Average KL loss: 0.341241
Average total loss: 0.737452
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.0942e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.398778
Average KL loss: 0.341238
Average total loss: 0.740016
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.0272e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.393883
Average KL loss: 0.341234
Average total loss: 0.735117
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.4013e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.401348
Average KL loss: 0.341231
Average total loss: 0.742580
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.9291e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.392003
Average KL loss: 0.341228
Average total loss: 0.733231
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.0360e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.397761
Average KL loss: 0.341225
Average total loss: 0.738986
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.4694e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.394892
Average KL loss: 0.341221
Average total loss: 0.736112
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.7442e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.396501
Average KL loss: 0.341216
Average total loss: 0.737717
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.9877e-09, device='cuda:0')
 Percentile value: 0.09376627057790754
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =     175 /    1728             ( 10.13%) | total_pruned =    1553 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     354 /   36864             (  0.96%) | total_pruned =   36510 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     475 /   36864             (  1.29%) | total_pruned =   36389 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     728 /   36864             (  1.97%) | total_pruned =   36136 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1483 /   36864             (  4.02%) | total_pruned =   35381 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4434 /   73728             (  6.01%) | total_pruned =   69294 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    8617 /  147456             (  5.84%) | total_pruned =  138839 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     836 /    8192             ( 10.21%) | total_pruned =    7356 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4872 /  147456             (  3.30%) | total_pruned =  142584 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3841 /  147456             (  2.60%) | total_pruned =  143615 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   23578 /  294912             (  7.99%) | total_pruned =  271334 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     214 /     256             ( 83.59%) | total_pruned =      42 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      56 /     256             ( 21.88%) | total_pruned =     200 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   40117 /  589824             (  6.80%) | total_pruned =  549707 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2627 /   32768             (  8.02%) | total_pruned =   30141 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     189 /     256             ( 73.83%) | total_pruned =      67 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      41 /     256             ( 16.02%) | total_pruned =     215 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   23663 /  589824             (  4.01%) | total_pruned =  566161 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     194 /     256             ( 75.78%) | total_pruned =      62 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   14390 /  589824             (  2.44%) | total_pruned =  575434 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     166 /     256             ( 64.84%) | total_pruned =      90 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   46078 / 1179648             (  3.91%) | total_pruned = 1133570 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     453 /     512             ( 88.48%) | total_pruned =      59 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      43 /     512             (  8.40%) | total_pruned =     469 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   31342 / 2359296             (  1.33%) | total_pruned = 2327954 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     298 /     512             ( 58.20%) | total_pruned =     214 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     167 /     512             ( 32.62%) | total_pruned =     345 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     935 /  131072             (  0.71%) | total_pruned =  130137 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     158 /     512             ( 30.86%) | total_pruned =     354 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     174 /     512             ( 33.98%) | total_pruned =     338 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   30489 / 2359296             (  1.29%) | total_pruned = 2328807 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     225 /     512             ( 43.95%) | total_pruned =     287 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   54874 / 2359296             (  2.33%) | total_pruned = 2304422 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
linear.weight        | nonzeros =    3680 /    5120             ( 71.88%) | total_pruned =    1440 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 62/200 Loss: 0.019187 Accuracy: 88.22 100.00 % Best test Accuracy: 88.29%
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.3467e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.738931
Average KL loss: 0.319287
Average total loss: 1.058218
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.5537e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.643184
Average KL loss: 0.324557
Average total loss: 0.967741
tensor(0.0033, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6320e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.598296
Average KL loss: 0.330903
Average total loss: 0.929198
tensor(0.0032, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.2880e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.572223
Average KL loss: 0.334983
Average total loss: 0.907206
tensor(0.0032, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2291e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.559052
Average KL loss: 0.337477
Average total loss: 0.896530
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.4955e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.541950
Average KL loss: 0.339480
Average total loss: 0.881429
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.7021e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.532397
Average KL loss: 0.340440
Average total loss: 0.872838
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.5186e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.529092
Average KL loss: 0.342637
Average total loss: 0.871729
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.8232e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.514382
Average KL loss: 0.344380
Average total loss: 0.858762
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.7711e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.511776
Average KL loss: 0.346087
Average total loss: 0.857863
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.6880e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.506133
Average KL loss: 0.347821
Average total loss: 0.853954
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(3.3415e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.499351
Average KL loss: 0.349226
Average total loss: 0.848578
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(8.0733e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.495274
Average KL loss: 0.349843
Average total loss: 0.845117
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.1208e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.493686
Average KL loss: 0.350329
Average total loss: 0.844015
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.7919e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.487194
Average KL loss: 0.351216
Average total loss: 0.838410
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.8795e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.490459
Average KL loss: 0.352252
Average total loss: 0.842710
tensor(0.0030, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.4326e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.483025
Average KL loss: 0.353612
Average total loss: 0.836638
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.6080e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.484253
Average KL loss: 0.354628
Average total loss: 0.838881
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.1874e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.483777
Average KL loss: 0.354889
Average total loss: 0.838666
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.9827e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.478273
Average KL loss: 0.355616
Average total loss: 0.833889
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(8.1166e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.477538
Average KL loss: 0.356287
Average total loss: 0.833824
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.9041e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.475505
Average KL loss: 0.356753
Average total loss: 0.832258
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.2106e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.469226
Average KL loss: 0.356702
Average total loss: 0.825928
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(8.6851e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.469959
Average KL loss: 0.357034
Average total loss: 0.826994
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.7352e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.465886
Average KL loss: 0.357422
Average total loss: 0.823307
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.7273e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.470306
Average KL loss: 0.357490
Average total loss: 0.827796
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.5131e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.463306
Average KL loss: 0.358152
Average total loss: 0.821458
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.5995e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.467746
Average KL loss: 0.357852
Average total loss: 0.825597
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.3486e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.460962
Average KL loss: 0.358312
Average total loss: 0.819274
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.7129e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.460034
Average KL loss: 0.358635
Average total loss: 0.818669
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.6924e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.463513
Average KL loss: 0.358697
Average total loss: 0.822211
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(5.0323e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.465443
Average KL loss: 0.358723
Average total loss: 0.824166
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(7.0612e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.464909
Average KL loss: 0.359784
Average total loss: 0.824693
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.5065e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.461635
Average KL loss: 0.360205
Average total loss: 0.821840
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.5686e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.457788
Average KL loss: 0.360118
Average total loss: 0.817906
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.1173e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.463842
Average KL loss: 0.360859
Average total loss: 0.824701
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(2.9758e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.451196
Average KL loss: 0.361176
Average total loss: 0.812372
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.1206e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.452446
Average KL loss: 0.361197
Average total loss: 0.813644
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-7.6930e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.458378
Average KL loss: 0.361325
Average total loss: 0.819703
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.0093e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.452589
Average KL loss: 0.361475
Average total loss: 0.814063
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(1.6199e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.454738
Average KL loss: 0.361155
Average total loss: 0.815893
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.9633e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.456900
Average KL loss: 0.361880
Average total loss: 0.818781
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(4.2469e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.454463
Average KL loss: 0.362110
Average total loss: 0.816573
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.9985e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.452076
Average KL loss: 0.361994
Average total loss: 0.814070
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.9635e-11, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.450301
Average KL loss: 0.362742
Average total loss: 0.813043
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.7879e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.457847
Average KL loss: 0.363140
Average total loss: 0.820987
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.0955e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.451124
Average KL loss: 0.363374
Average total loss: 0.814498
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0457e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.454904
Average KL loss: 0.363326
Average total loss: 0.818230
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(9.4911e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.453862
Average KL loss: 0.362701
Average total loss: 0.816563
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.0970e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.449231
Average KL loss: 0.361799
Average total loss: 0.811029
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.3999e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.451418
Average KL loss: 0.361000
Average total loss: 0.812418
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(3.1794e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.447200
Average KL loss: 0.360245
Average total loss: 0.807445
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.3027e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.447959
Average KL loss: 0.359560
Average total loss: 0.807519
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.3847e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.447721
Average KL loss: 0.358949
Average total loss: 0.806671
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.9192e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.453966
Average KL loss: 0.358445
Average total loss: 0.812411
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.3749e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.447907
Average KL loss: 0.357968
Average total loss: 0.805875
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.7050e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.450357
Average KL loss: 0.357526
Average total loss: 0.807883
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.6052e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.448975
Average KL loss: 0.357116
Average total loss: 0.806091
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.9278e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.453013
Average KL loss: 0.356686
Average total loss: 0.809699
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.4010e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.455791
Average KL loss: 0.356364
Average total loss: 0.812155
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.5359e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.453424
Average KL loss: 0.355989
Average total loss: 0.809413
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.4821e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.447313
Average KL loss: 0.355596
Average total loss: 0.802909
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(4.0594e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.447961
Average KL loss: 0.355228
Average total loss: 0.803188
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.5746e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.455307
Average KL loss: 0.354910
Average total loss: 0.810218
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(5.8028e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.450354
Average KL loss: 0.354623
Average total loss: 0.804977
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.4034e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.448133
Average KL loss: 0.354355
Average total loss: 0.802487
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.4793e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.449554
Average KL loss: 0.354107
Average total loss: 0.803661
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.2900e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.449362
Average KL loss: 0.353872
Average total loss: 0.803234
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.9089e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.444674
Average KL loss: 0.353659
Average total loss: 0.798333
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.1639e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.455573
Average KL loss: 0.353401
Average total loss: 0.808974
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.2857e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.446919
Average KL loss: 0.353173
Average total loss: 0.800092
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(7.2103e-11, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.449755
Average KL loss: 0.352896
Average total loss: 0.802651
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.7502e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.446654
Average KL loss: 0.352703
Average total loss: 0.799356
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.6673e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.446040
Average KL loss: 0.352467
Average total loss: 0.798508
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.2269e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.448658
Average KL loss: 0.352299
Average total loss: 0.800957
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.6787e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.455723
Average KL loss: 0.352147
Average total loss: 0.807869
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.4278e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.447799
Average KL loss: 0.351988
Average total loss: 0.799787
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.8101e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.449201
Average KL loss: 0.351834
Average total loss: 0.801034
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.1381e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.448662
Average KL loss: 0.351661
Average total loss: 0.800323
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(4.8981e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.452439
Average KL loss: 0.351427
Average total loss: 0.803866
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.6466e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.448748
Average KL loss: 0.351295
Average total loss: 0.800043
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.3673e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.447458
Average KL loss: 0.351269
Average total loss: 0.798727
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(5.1074e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.444924
Average KL loss: 0.351242
Average total loss: 0.796166
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.2595e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.450478
Average KL loss: 0.351209
Average total loss: 0.801687
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.4118e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.449192
Average KL loss: 0.351178
Average total loss: 0.800370
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.0383e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.448222
Average KL loss: 0.351147
Average total loss: 0.799369
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1995e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.445803
Average KL loss: 0.351112
Average total loss: 0.796916
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.3085e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.446983
Average KL loss: 0.351078
Average total loss: 0.798061
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.8411e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.445557
Average KL loss: 0.351051
Average total loss: 0.796609
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.7264e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.447192
Average KL loss: 0.351021
Average total loss: 0.798213
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.7665e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.445054
Average KL loss: 0.350995
Average total loss: 0.796049
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.0592e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.452768
Average KL loss: 0.350973
Average total loss: 0.803741
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.6719e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.447355
Average KL loss: 0.350955
Average total loss: 0.798310
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.3816e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.445834
Average KL loss: 0.350928
Average total loss: 0.796762
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.0213e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.449873
Average KL loss: 0.350903
Average total loss: 0.800776
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.7891e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.451117
Average KL loss: 0.350873
Average total loss: 0.801990
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(5.8668e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.444126
Average KL loss: 0.350849
Average total loss: 0.794975
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.8912e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.452927
Average KL loss: 0.350831
Average total loss: 0.803758
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.7075e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.444949
Average KL loss: 0.350809
Average total loss: 0.795759
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.5732e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.446968
Average KL loss: 0.350783
Average total loss: 0.797751
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.8660e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.453100
Average KL loss: 0.350757
Average total loss: 0.803857
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.6205e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.440941
Average KL loss: 0.350733
Average total loss: 0.791674
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.6643e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.452871
Average KL loss: 0.350710
Average total loss: 0.803581
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1403e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.448559
Average KL loss: 0.350683
Average total loss: 0.799243
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.6428e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.445600
Average KL loss: 0.350659
Average total loss: 0.796259
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.6250e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.449534
Average KL loss: 0.350633
Average total loss: 0.800167
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.9823e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.448746
Average KL loss: 0.350616
Average total loss: 0.799362
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(3.1022e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.446633
Average KL loss: 0.350592
Average total loss: 0.797226
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0153e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.442303
Average KL loss: 0.350569
Average total loss: 0.792872
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(5.9602e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.445152
Average KL loss: 0.350545
Average total loss: 0.795696
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(4.1230e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.442693
Average KL loss: 0.350522
Average total loss: 0.793215
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.2790e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.443579
Average KL loss: 0.350490
Average total loss: 0.794069
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.7668e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.445650
Average KL loss: 0.350458
Average total loss: 0.796107
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.7779e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.444158
Average KL loss: 0.350445
Average total loss: 0.794603
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.5084e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.448382
Average KL loss: 0.350443
Average total loss: 0.798825
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.8298e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.446714
Average KL loss: 0.350441
Average total loss: 0.797155
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.0461e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.445844
Average KL loss: 0.350439
Average total loss: 0.796284
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.8388e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.442224
Average KL loss: 0.350437
Average total loss: 0.792661
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.3111e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.445631
Average KL loss: 0.350434
Average total loss: 0.796066
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.5629e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.444542
Average KL loss: 0.350432
Average total loss: 0.794974
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.3965e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.445510
Average KL loss: 0.350429
Average total loss: 0.795940
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(8.6025e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.446737
Average KL loss: 0.350427
Average total loss: 0.797163
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.9676e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.440856
Average KL loss: 0.350424
Average total loss: 0.791280
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.0905e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.449848
Average KL loss: 0.350421
Average total loss: 0.800269
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.6200e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.443692
Average KL loss: 0.350419
Average total loss: 0.794111
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.6108e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.445362
Average KL loss: 0.350416
Average total loss: 0.795778
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.6563e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.450486
Average KL loss: 0.350414
Average total loss: 0.800900
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.2148e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.445900
Average KL loss: 0.350411
Average total loss: 0.796311
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.0228e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.447213
Average KL loss: 0.350408
Average total loss: 0.797621
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.9029e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.445821
Average KL loss: 0.350406
Average total loss: 0.796226
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0124e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.444726
Average KL loss: 0.350404
Average total loss: 0.795130
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(4.5894e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.449161
Average KL loss: 0.350401
Average total loss: 0.799562
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.2025e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.449655
Average KL loss: 0.350398
Average total loss: 0.800053
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.4404e-09, device='cuda:0')
 Percentile value: 0.3044411182403564
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =     126 /    1728             (  7.29%) | total_pruned =    1602 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     128 /   36864             (  0.35%) | total_pruned =   36736 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     199 /   36864             (  0.54%) | total_pruned =   36665 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     346 /   36864             (  0.94%) | total_pruned =   36518 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     794 /   36864             (  2.15%) | total_pruned =   36070 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2037 /   73728             (  2.76%) | total_pruned =   71691 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3992 /  147456             (  2.71%) | total_pruned =  143464 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     435 /    8192             (  5.31%) | total_pruned =    7757 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1976 /  147456             (  1.34%) | total_pruned =  145480 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1784 /  147456             (  1.21%) | total_pruned =  145672 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    9617 /  294912             (  3.26%) | total_pruned =  285295 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   15117 /  589824             (  2.56%) | total_pruned =  574707 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     892 /   32768             (  2.72%) | total_pruned =   31876 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    7691 /  589824             (  1.30%) | total_pruned =  582133 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     170 /     256             ( 66.41%) | total_pruned =      86 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4988 /  589824             (  0.85%) | total_pruned =  584836 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   11221 / 1179648             (  0.95%) | total_pruned = 1168427 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     379 /     512             ( 74.02%) | total_pruned =     133 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    7998 / 2359296             (  0.34%) | total_pruned = 2351298 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     195 /     512             ( 38.09%) | total_pruned =     317 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     124 /     512             ( 24.22%) | total_pruned =     388 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     236 /  131072             (  0.18%) | total_pruned =  130836 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      63 /     512             ( 12.30%) | total_pruned =     449 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     128 /     512             ( 25.00%) | total_pruned =     384 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    6943 / 2359296             (  0.29%) | total_pruned = 2352353 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     152 /     512             ( 29.69%) | total_pruned =     360 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    9083 / 2359296             (  0.38%) | total_pruned = 2350213 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     303 /     512             ( 59.18%) | total_pruned =     209 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     244 /     512             ( 47.66%) | total_pruned =     268 | shape = torch.Size([512])
linear.weight        | nonzeros =    1683 /    5120             ( 32.87%) | total_pruned =    3437 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 64/200 Loss: 0.019513 Accuracy: 87.28 100.00 % Best test Accuracy: 87.74%
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.3968e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.903328
Average KL loss: 0.320832
Average total loss: 1.224160
tensor(0.0029, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.5664e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.810334
Average KL loss: 0.314233
Average total loss: 1.124567
tensor(0.0029, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-7.9847e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.754838
Average KL loss: 0.317862
Average total loss: 1.072700
tensor(0.0028, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.6950e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.710005
Average KL loss: 0.321694
Average total loss: 1.031699
tensor(0.0028, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.8253e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.693213
Average KL loss: 0.324638
Average total loss: 1.017851
tensor(0.0028, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.9105e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.677189
Average KL loss: 0.326985
Average total loss: 1.004174
tensor(0.0027, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.3856e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.657469
Average KL loss: 0.329619
Average total loss: 0.987087
tensor(0.0027, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.4322e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.645186
Average KL loss: 0.332983
Average total loss: 0.978168
tensor(0.0027, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-9.7688e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.618532
Average KL loss: 0.336259
Average total loss: 0.954791
tensor(0.0027, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.0752e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.613907
Average KL loss: 0.339495
Average total loss: 0.953402
tensor(0.0027, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.3628e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.598274
Average KL loss: 0.342232
Average total loss: 0.940506
tensor(0.0027, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.8883e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.599354
Average KL loss: 0.344503
Average total loss: 0.943858
tensor(0.0027, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-7.3275e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.589109
Average KL loss: 0.346548
Average total loss: 0.935657
tensor(0.0027, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.1580e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.580112
Average KL loss: 0.348066
Average total loss: 0.928179
tensor(0.0027, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(7.4370e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.582107
Average KL loss: 0.349391
Average total loss: 0.931498
tensor(0.0027, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.8349e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.567889
Average KL loss: 0.351305
Average total loss: 0.919194
tensor(0.0027, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-8.4035e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.575969
Average KL loss: 0.352287
Average total loss: 0.928256
tensor(0.0027, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.7508e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.571147
Average KL loss: 0.353792
Average total loss: 0.924939
tensor(0.0027, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.9631e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.558238
Average KL loss: 0.354890
Average total loss: 0.913128
tensor(0.0027, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.0855e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.553996
Average KL loss: 0.355721
Average total loss: 0.909717
tensor(0.0027, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.0110e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.553745
Average KL loss: 0.356889
Average total loss: 0.910634
tensor(0.0027, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.4416e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.558063
Average KL loss: 0.358062
Average total loss: 0.916125
tensor(0.0027, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-8.3841e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.551633
Average KL loss: 0.359253
Average total loss: 0.910885
tensor(0.0027, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-5.4984e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.539202
Average KL loss: 0.360155
Average total loss: 0.899357
tensor(0.0027, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(2.0264e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.540648
Average KL loss: 0.360656
Average total loss: 0.901304
tensor(0.0027, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.4058e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.539721
Average KL loss: 0.361503
Average total loss: 0.901224
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.1541e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.540560
Average KL loss: 0.362079
Average total loss: 0.902638
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(3.3199e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.534464
Average KL loss: 0.362669
Average total loss: 0.897133
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2001e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.539893
Average KL loss: 0.363188
Average total loss: 0.903081
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.8761e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.532038
Average KL loss: 0.364022
Average total loss: 0.896060
tensor(0.0027, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.4668e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.530767
Average KL loss: 0.364461
Average total loss: 0.895227
tensor(0.0027, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-6.2148e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.531419
Average KL loss: 0.364866
Average total loss: 0.896284
tensor(0.0027, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.7209e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.532419
Average KL loss: 0.364912
Average total loss: 0.897331
tensor(0.0027, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(1.6725e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.525987
Average KL loss: 0.365520
Average total loss: 0.891507
tensor(0.0027, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.4758e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.520838
Average KL loss: 0.366270
Average total loss: 0.887108
tensor(0.0027, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.2934e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.516339
Average KL loss: 0.366745
Average total loss: 0.883083
tensor(0.0027, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(7.8331e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.523798
Average KL loss: 0.367259
Average total loss: 0.891057
tensor(0.0027, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.8415e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.523751
Average KL loss: 0.367641
Average total loss: 0.891392
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.3580e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.524589
Average KL loss: 0.368521
Average total loss: 0.893111
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.1829e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.516763
Average KL loss: 0.369127
Average total loss: 0.885890
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.2505e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.511690
Average KL loss: 0.369294
Average total loss: 0.880984
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.1705e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.517314
Average KL loss: 0.369625
Average total loss: 0.886940
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.2589e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.521542
Average KL loss: 0.370017
Average total loss: 0.891559
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.3658e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.511111
Average KL loss: 0.370830
Average total loss: 0.881941
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.9460e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.516537
Average KL loss: 0.371046
Average total loss: 0.887583
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.8399e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.515395
Average KL loss: 0.371009
Average total loss: 0.886404
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.3971e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.505526
Average KL loss: 0.371276
Average total loss: 0.876801
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-6.2246e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.512345
Average KL loss: 0.371406
Average total loss: 0.883751
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(4.6904e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.509870
Average KL loss: 0.372441
Average total loss: 0.882311
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.5327e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.510464
Average KL loss: 0.372930
Average total loss: 0.883394
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.4940e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.505464
Average KL loss: 0.373413
Average total loss: 0.878877
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.4733e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.508862
Average KL loss: 0.373849
Average total loss: 0.882711
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.4121e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.499953
Average KL loss: 0.374446
Average total loss: 0.874399
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.9167e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.501785
Average KL loss: 0.374208
Average total loss: 0.875993
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.7511e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.498964
Average KL loss: 0.374544
Average total loss: 0.873508
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.1095e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.503291
Average KL loss: 0.375070
Average total loss: 0.878362
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(3.6293e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.498508
Average KL loss: 0.375231
Average total loss: 0.873739
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3272e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.497211
Average KL loss: 0.375326
Average total loss: 0.872536
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.1884e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.495404
Average KL loss: 0.375565
Average total loss: 0.870969
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.9081e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.496599
Average KL loss: 0.375370
Average total loss: 0.871969
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.9513e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.498334
Average KL loss: 0.375904
Average total loss: 0.874238
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.4075e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.492681
Average KL loss: 0.375959
Average total loss: 0.868640
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.5042e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.500000
Average KL loss: 0.376356
Average total loss: 0.876356
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.1919e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.500350
Average KL loss: 0.376847
Average total loss: 0.877197
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0741e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.501827
Average KL loss: 0.377364
Average total loss: 0.879191
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.5123e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.493310
Average KL loss: 0.377801
Average total loss: 0.871111
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.5457e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.491355
Average KL loss: 0.377978
Average total loss: 0.869332
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.4415e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.493483
Average KL loss: 0.378427
Average total loss: 0.871910
tensor(0.0028, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(2.0632e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.491696
Average KL loss: 0.378906
Average total loss: 0.870603
tensor(0.0028, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.8492e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.484697
Average KL loss: 0.378956
Average total loss: 0.863653
tensor(0.0028, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-9.7839e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.487157
Average KL loss: 0.379030
Average total loss: 0.866187
tensor(0.0028, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.1552e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.490964
Average KL loss: 0.379315
Average total loss: 0.870279
tensor(0.0028, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.6201e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.491634
Average KL loss: 0.379163
Average total loss: 0.870797
tensor(0.0028, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(3.1465e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.490994
Average KL loss: 0.379473
Average total loss: 0.870467
tensor(0.0028, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.1736e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.495443
Average KL loss: 0.379355
Average total loss: 0.874798
tensor(0.0028, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(6.3157e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.490660
Average KL loss: 0.379507
Average total loss: 0.870167
tensor(0.0028, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(4.0565e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.491671
Average KL loss: 0.379501
Average total loss: 0.871172
tensor(0.0028, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.0015e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.490934
Average KL loss: 0.380014
Average total loss: 0.870947
tensor(0.0028, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.2346e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.481847
Average KL loss: 0.380442
Average total loss: 0.862289
tensor(0.0028, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.9723e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.491952
Average KL loss: 0.380363
Average total loss: 0.872315
tensor(0.0028, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.0328e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.480356
Average KL loss: 0.380453
Average total loss: 0.860809
tensor(0.0028, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(4.1293e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.486450
Average KL loss: 0.380681
Average total loss: 0.867131
tensor(0.0028, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.3318e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.485387
Average KL loss: 0.380921
Average total loss: 0.866308
tensor(0.0028, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-7.2431e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.484650
Average KL loss: 0.381083
Average total loss: 0.865733
tensor(0.0028, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.7339e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.486354
Average KL loss: 0.380992
Average total loss: 0.867346
tensor(0.0028, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.3446e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.488657
Average KL loss: 0.381183
Average total loss: 0.869840
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(3.4648e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.484440
Average KL loss: 0.381672
Average total loss: 0.866113
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-8.2922e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.480376
Average KL loss: 0.382056
Average total loss: 0.862432
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(2.3740e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.482703
Average KL loss: 0.382245
Average total loss: 0.864948
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(5.9816e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.483465
Average KL loss: 0.382331
Average total loss: 0.865796
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.9097e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.481440
Average KL loss: 0.382061
Average total loss: 0.863501
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.2516e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.482610
Average KL loss: 0.382069
Average total loss: 0.864679
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.9978e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.485923
Average KL loss: 0.382102
Average total loss: 0.868025
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.5220e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.477555
Average KL loss: 0.381766
Average total loss: 0.859321
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1682e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.476057
Average KL loss: 0.381444
Average total loss: 0.857500
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.3897e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.483471
Average KL loss: 0.381183
Average total loss: 0.864654
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.9301e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.478300
Average KL loss: 0.380910
Average total loss: 0.859210
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.8081e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.487985
Average KL loss: 0.380658
Average total loss: 0.868643
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.0284e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.478777
Average KL loss: 0.380407
Average total loss: 0.859184
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.3623e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.482103
Average KL loss: 0.380171
Average total loss: 0.862273
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.7263e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.480076
Average KL loss: 0.380009
Average total loss: 0.860085
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.3029e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.477737
Average KL loss: 0.379859
Average total loss: 0.857596
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.7615e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.484045
Average KL loss: 0.379742
Average total loss: 0.863787
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.6169e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.486386
Average KL loss: 0.379608
Average total loss: 0.865995
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.6141e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.478462
Average KL loss: 0.379400
Average total loss: 0.857862
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.2405e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.482697
Average KL loss: 0.379223
Average total loss: 0.861920
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1983e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.478582
Average KL loss: 0.379134
Average total loss: 0.857716
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1501e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.482277
Average KL loss: 0.379115
Average total loss: 0.861392
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.4507e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.483140
Average KL loss: 0.379098
Average total loss: 0.862238
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.7085e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.484002
Average KL loss: 0.379077
Average total loss: 0.863078
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.4211e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.478334
Average KL loss: 0.379059
Average total loss: 0.857393
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.2278e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.481474
Average KL loss: 0.379040
Average total loss: 0.860513
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.1559e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.475424
Average KL loss: 0.379025
Average total loss: 0.854449
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.2332e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.483051
Average KL loss: 0.379006
Average total loss: 0.862057
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.2573e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.488750
Average KL loss: 0.378994
Average total loss: 0.867743
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1108e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.470685
Average KL loss: 0.378978
Average total loss: 0.849663
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.1293e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.477984
Average KL loss: 0.378958
Average total loss: 0.856942
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.8572e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.476874
Average KL loss: 0.378932
Average total loss: 0.855807
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.8914e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.484478
Average KL loss: 0.378911
Average total loss: 0.863389
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.5932e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.483979
Average KL loss: 0.378890
Average total loss: 0.862869
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.6128e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.478694
Average KL loss: 0.378873
Average total loss: 0.857567
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.0617e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.481005
Average KL loss: 0.378858
Average total loss: 0.859863
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.1078e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.480429
Average KL loss: 0.378840
Average total loss: 0.859269
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.1586e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.482117
Average KL loss: 0.378825
Average total loss: 0.860942
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(8.7815e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.481815
Average KL loss: 0.378806
Average total loss: 0.860621
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.5214e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.483587
Average KL loss: 0.378784
Average total loss: 0.862371
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5798e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.479116
Average KL loss: 0.378767
Average total loss: 0.857883
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.8238e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.476406
Average KL loss: 0.378757
Average total loss: 0.855163
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.5085e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.478956
Average KL loss: 0.378755
Average total loss: 0.857710
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3539e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.483620
Average KL loss: 0.378753
Average total loss: 0.862373
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.6740e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.482746
Average KL loss: 0.378751
Average total loss: 0.861497
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.3394e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.483216
Average KL loss: 0.378750
Average total loss: 0.861965
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3928e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.475857
Average KL loss: 0.378748
Average total loss: 0.854605
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.4160e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.480102
Average KL loss: 0.378746
Average total loss: 0.858848
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.2516e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.478145
Average KL loss: 0.378744
Average total loss: 0.856889
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.8353e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.476685
Average KL loss: 0.378742
Average total loss: 0.855427
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.5087e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.483425
Average KL loss: 0.378740
Average total loss: 0.862165
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.4038e-10, device='cuda:0')
 Percentile value: 0.9695774912834166
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     113 /    1728             (  6.54%) | total_pruned =    1615 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      71 /   36864             (  0.19%) | total_pruned =   36793 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     106 /   36864             (  0.29%) | total_pruned =   36758 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     211 /   36864             (  0.57%) | total_pruned =   36653 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     457 /   36864             (  1.24%) | total_pruned =   36407 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     955 /   73728             (  1.30%) | total_pruned =   72773 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1686 /  147456             (  1.14%) | total_pruned =  145770 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     220 /    8192             (  2.69%) | total_pruned =    7972 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     782 /  147456             (  0.53%) | total_pruned =  146674 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     707 /  147456             (  0.48%) | total_pruned =  146749 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3291 /  294912             (  1.12%) | total_pruned =  291621 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4515 /  589824             (  0.77%) | total_pruned =  585309 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     269 /   32768             (  0.82%) | total_pruned =   32499 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      89 /     256             ( 34.77%) | total_pruned =     167 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2391 /  589824             (  0.41%) | total_pruned =  587433 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1675 /  589824             (  0.28%) | total_pruned =  588149 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      96 /     256             ( 37.50%) | total_pruned =     160 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2488 / 1179648             (  0.21%) | total_pruned = 1177160 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1852 / 2359296             (  0.08%) | total_pruned = 2357444 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     129 /     512             ( 25.20%) | total_pruned =     383 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      60 /     512             ( 11.72%) | total_pruned =     452 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      57 /  131072             (  0.04%) | total_pruned =  131015 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      62 /     512             ( 12.11%) | total_pruned =     450 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1275 / 2359296             (  0.05%) | total_pruned = 2358021 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      89 /     512             ( 17.38%) | total_pruned =     423 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1264 / 2359296             (  0.05%) | total_pruned = 2358032 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     140 /     512             ( 27.34%) | total_pruned =     372 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      94 /     512             ( 18.36%) | total_pruned =     418 | shape = torch.Size([512])
linear.weight        | nonzeros =     488 /    5120             (  9.53%) | total_pruned =    4632 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 174/200 Loss: 0.049420 Accuracy: 83.51 99.82 % Best test Accuracy: 85.72%
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.4874e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.073071
Average KL loss: 0.347487
Average total loss: 1.420558
tensor(0.0025, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.1598e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.979475
Average KL loss: 0.331490
Average total loss: 1.310965
tensor(0.0024, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-3.9899e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.927516
Average KL loss: 0.328687
Average total loss: 1.256203
tensor(0.0024, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.0831e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.874422
Average KL loss: 0.328675
Average total loss: 1.203098
tensor(0.0024, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.9623e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.862516
Average KL loss: 0.329486
Average total loss: 1.192002
tensor(0.0024, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.2994e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.811583
Average KL loss: 0.330331
Average total loss: 1.141914
tensor(0.0023, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.6520e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.794917
Average KL loss: 0.331552
Average total loss: 1.126469
tensor(0.0023, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.2980e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.775605
Average KL loss: 0.334244
Average total loss: 1.109849
tensor(0.0023, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-6.6419e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.758637
Average KL loss: 0.336966
Average total loss: 1.095603
tensor(0.0023, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.1029e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.733138
Average KL loss: 0.339733
Average total loss: 1.072871
tensor(0.0023, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-8.7104e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.725337
Average KL loss: 0.342393
Average total loss: 1.067729
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.3541e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.709668
Average KL loss: 0.344936
Average total loss: 1.054604
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.8194e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.702856
Average KL loss: 0.347312
Average total loss: 1.050168
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.0471e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.695936
Average KL loss: 0.349516
Average total loss: 1.045452
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.5763e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.687487
Average KL loss: 0.351681
Average total loss: 1.039169
tensor(0.0023, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.2492e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.673450
Average KL loss: 0.353629
Average total loss: 1.027079
tensor(0.0023, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.6810e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.668303
Average KL loss: 0.355658
Average total loss: 1.023961
tensor(0.0023, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.8303e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.657778
Average KL loss: 0.357387
Average total loss: 1.015165
tensor(0.0023, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.0662e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.657916
Average KL loss: 0.359137
Average total loss: 1.017053
tensor(0.0023, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.1657e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.639782
Average KL loss: 0.360595
Average total loss: 1.000377
tensor(0.0023, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.0333e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.655720
Average KL loss: 0.362303
Average total loss: 1.018023
tensor(0.0023, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.6459e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.631033
Average KL loss: 0.364194
Average total loss: 0.995227
tensor(0.0024, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.7526e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.633058
Average KL loss: 0.365593
Average total loss: 0.998650
tensor(0.0024, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-8.1038e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.625176
Average KL loss: 0.366762
Average total loss: 0.991937
tensor(0.0024, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.9169e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.626726
Average KL loss: 0.367923
Average total loss: 0.994649
tensor(0.0024, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.2112e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.612097
Average KL loss: 0.369130
Average total loss: 0.981227
tensor(0.0024, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.4100e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.612306
Average KL loss: 0.370325
Average total loss: 0.982631
tensor(0.0024, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.7360e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.611061
Average KL loss: 0.371618
Average total loss: 0.982679
tensor(0.0024, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.3835e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.616805
Average KL loss: 0.372806
Average total loss: 0.989611
tensor(0.0024, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.4519e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.601226
Average KL loss: 0.373892
Average total loss: 0.975119
tensor(0.0024, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.2045e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.597351
Average KL loss: 0.375002
Average total loss: 0.972354
tensor(0.0024, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.7886e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.601913
Average KL loss: 0.376275
Average total loss: 0.978188
tensor(0.0024, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.9986e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.599273
Average KL loss: 0.377504
Average total loss: 0.976777
tensor(0.0024, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-8.2903e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.593223
Average KL loss: 0.378507
Average total loss: 0.971730
tensor(0.0024, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.6354e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.590405
Average KL loss: 0.379669
Average total loss: 0.970074
tensor(0.0024, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.1148e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.581372
Average KL loss: 0.380770
Average total loss: 0.962142
tensor(0.0024, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.0651e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.591474
Average KL loss: 0.381759
Average total loss: 0.973233
tensor(0.0024, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.4651e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.581719
Average KL loss: 0.382707
Average total loss: 0.964426
tensor(0.0024, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.2871e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.583872
Average KL loss: 0.383409
Average total loss: 0.967282
tensor(0.0024, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.1167e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.573835
Average KL loss: 0.384268
Average total loss: 0.958103
tensor(0.0024, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.2908e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.566966
Average KL loss: 0.385485
Average total loss: 0.952450
tensor(0.0024, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.0447e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.562794
Average KL loss: 0.386169
Average total loss: 0.948963
tensor(0.0024, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.8132e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.572888
Average KL loss: 0.386704
Average total loss: 0.959592
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.0779e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.561020
Average KL loss: 0.387539
Average total loss: 0.948559
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-9.4535e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.562196
Average KL loss: 0.388550
Average total loss: 0.950746
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.5149e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.559175
Average KL loss: 0.389347
Average total loss: 0.948522
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.0408e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.558623
Average KL loss: 0.389977
Average total loss: 0.948600
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.1100e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.553500
Average KL loss: 0.390563
Average total loss: 0.944063
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.5679e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.558286
Average KL loss: 0.390973
Average total loss: 0.949259
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.2631e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.547208
Average KL loss: 0.391652
Average total loss: 0.938859
tensor(0.0024, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.6211e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.545173
Average KL loss: 0.392307
Average total loss: 0.937480
tensor(0.0024, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.3543e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.544194
Average KL loss: 0.393128
Average total loss: 0.937322
tensor(0.0025, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.6729e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.551315
Average KL loss: 0.393886
Average total loss: 0.945201
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.5253e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.548857
Average KL loss: 0.394669
Average total loss: 0.943526
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.2758e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.540595
Average KL loss: 0.395490
Average total loss: 0.936085
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(4.7723e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.529943
Average KL loss: 0.395904
Average total loss: 0.925847
tensor(0.0025, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.7473e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.543432
Average KL loss: 0.396356
Average total loss: 0.939788
tensor(0.0025, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(9.6998e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.537947
Average KL loss: 0.396817
Average total loss: 0.934764
tensor(0.0025, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.5122e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.536260
Average KL loss: 0.397261
Average total loss: 0.933521
tensor(0.0025, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.0021e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.537275
Average KL loss: 0.397843
Average total loss: 0.935118
tensor(0.0025, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.5096e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.530781
Average KL loss: 0.398547
Average total loss: 0.929328
tensor(0.0025, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.2314e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.529807
Average KL loss: 0.399079
Average total loss: 0.928886
tensor(0.0025, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.9016e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.527327
Average KL loss: 0.399517
Average total loss: 0.926844
tensor(0.0025, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.2104e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.527231
Average KL loss: 0.400192
Average total loss: 0.927424
tensor(0.0025, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.1447e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.532284
Average KL loss: 0.400589
Average total loss: 0.932873
tensor(0.0025, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.3319e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.527046
Average KL loss: 0.401021
Average total loss: 0.928067
tensor(0.0025, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0764e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.523329
Average KL loss: 0.401544
Average total loss: 0.924873
tensor(0.0025, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.7838e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.513455
Average KL loss: 0.401880
Average total loss: 0.915335
tensor(0.0025, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.0634e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.520595
Average KL loss: 0.402269
Average total loss: 0.922865
tensor(0.0025, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.0663e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.523975
Average KL loss: 0.402855
Average total loss: 0.926830
tensor(0.0025, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.4802e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.532024
Average KL loss: 0.403621
Average total loss: 0.935645
tensor(0.0025, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.4029e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.529810
Average KL loss: 0.404279
Average total loss: 0.934089
tensor(0.0025, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.9179e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.509822
Average KL loss: 0.404786
Average total loss: 0.914609
tensor(0.0025, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.5266e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.510261
Average KL loss: 0.405215
Average total loss: 0.915475
tensor(0.0025, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.0426e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.514543
Average KL loss: 0.405791
Average total loss: 0.920334
tensor(0.0025, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.6149e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.522753
Average KL loss: 0.406069
Average total loss: 0.928822
tensor(0.0025, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.1211e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.507543
Average KL loss: 0.406513
Average total loss: 0.914056
tensor(0.0025, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.7528e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.505123
Average KL loss: 0.406805
Average total loss: 0.911928
tensor(0.0025, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.1226e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.517160
Average KL loss: 0.406846
Average total loss: 0.924006
tensor(0.0025, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.8855e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.510473
Average KL loss: 0.407006
Average total loss: 0.917480
tensor(0.0025, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.7201e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.514228
Average KL loss: 0.407510
Average total loss: 0.921738
tensor(0.0025, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.6400e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.505497
Average KL loss: 0.408083
Average total loss: 0.913580
tensor(0.0025, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.4468e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.505124
Average KL loss: 0.408530
Average total loss: 0.913654
tensor(0.0026, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.6456e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.507823
Average KL loss: 0.409129
Average total loss: 0.916952
tensor(0.0026, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.6537e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.503501
Average KL loss: 0.409918
Average total loss: 0.913419
tensor(0.0026, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.6738e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.499290
Average KL loss: 0.410512
Average total loss: 0.909802
tensor(0.0026, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-7.9659e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.494602
Average KL loss: 0.410754
Average total loss: 0.905356
tensor(0.0026, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.9623e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.501640
Average KL loss: 0.410945
Average total loss: 0.912586
tensor(0.0026, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.2254e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.503944
Average KL loss: 0.411508
Average total loss: 0.915453
tensor(0.0026, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.0334e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.505897
Average KL loss: 0.411793
Average total loss: 0.917690
tensor(0.0026, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.2692e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.501231
Average KL loss: 0.412094
Average total loss: 0.913325
tensor(0.0026, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.8036e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.499473
Average KL loss: 0.412458
Average total loss: 0.911931
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(2.0720e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.500813
Average KL loss: 0.412997
Average total loss: 0.913810
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.4334e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.497021
Average KL loss: 0.413476
Average total loss: 0.910498
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.5071e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.494733
Average KL loss: 0.413987
Average total loss: 0.908720
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-7.5878e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.490910
Average KL loss: 0.414322
Average total loss: 0.905232
tensor(0.0026, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.8620e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.498633
Average KL loss: 0.414731
Average total loss: 0.913364
tensor(0.0026, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.1238e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.491138
Average KL loss: 0.415153
Average total loss: 0.906290
tensor(0.0026, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.6473e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.493559
Average KL loss: 0.415549
Average total loss: 0.909108
tensor(0.0026, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.2544e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.489376
Average KL loss: 0.416056
Average total loss: 0.905432
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.1906e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.489296
Average KL loss: 0.416401
Average total loss: 0.905697
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.6601e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.494952
Average KL loss: 0.416699
Average total loss: 0.911651
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.0017e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.481281
Average KL loss: 0.417131
Average total loss: 0.898412
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.5366e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.483380
Average KL loss: 0.417493
Average total loss: 0.900873
tensor(0.0026, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-9.9849e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.485939
Average KL loss: 0.417995
Average total loss: 0.903934
tensor(0.0026, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.7009e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.478964
Average KL loss: 0.418507
Average total loss: 0.897471
tensor(0.0026, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(2.8505e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.486225
Average KL loss: 0.419034
Average total loss: 0.905259
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-9.1912e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.489932
Average KL loss: 0.419444
Average total loss: 0.909376
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.1386e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.481558
Average KL loss: 0.419692
Average total loss: 0.901250
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.0727e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.486113
Average KL loss: 0.419955
Average total loss: 0.906068
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-6.6163e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.486260
Average KL loss: 0.420320
Average total loss: 0.906581
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-6.0112e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.487369
Average KL loss: 0.420957
Average total loss: 0.908327
tensor(0.0027, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.1420e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.475895
Average KL loss: 0.421298
Average total loss: 0.897193
tensor(0.0027, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-9.4705e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.478775
Average KL loss: 0.421835
Average total loss: 0.900610
tensor(0.0027, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-5.8437e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.481314
Average KL loss: 0.421943
Average total loss: 0.903257
tensor(0.0027, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(1.7043e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.481081
Average KL loss: 0.421975
Average total loss: 0.903055
tensor(0.0027, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-9.2420e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.473992
Average KL loss: 0.422243
Average total loss: 0.896235
tensor(0.0027, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-4.5124e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.485117
Average KL loss: 0.422630
Average total loss: 0.907746
tensor(0.0027, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-5.0152e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.468410
Average KL loss: 0.423030
Average total loss: 0.891439
tensor(0.0027, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-4.7383e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.471081
Average KL loss: 0.423356
Average total loss: 0.894437
tensor(0.0027, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-8.9895e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.465840
Average KL loss: 0.423581
Average total loss: 0.889421
tensor(0.0027, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-5.4431e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.487474
Average KL loss: 0.423913
Average total loss: 0.911387
tensor(0.0027, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-7.5171e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.475924
Average KL loss: 0.424162
Average total loss: 0.900086
tensor(0.0027, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-3.2739e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.474632
Average KL loss: 0.424264
Average total loss: 0.898896
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.2042e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.480172
Average KL loss: 0.424332
Average total loss: 0.904504
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.8272e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.476647
Average KL loss: 0.424638
Average total loss: 0.901284
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.2444e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.479871
Average KL loss: 0.425005
Average total loss: 0.904876
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.0455e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.473856
Average KL loss: 0.425372
Average total loss: 0.899228
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.7404e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.471179
Average KL loss: 0.425587
Average total loss: 0.896766
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.8278e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.465294
Average KL loss: 0.425700
Average total loss: 0.890993
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.7937e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.473767
Average KL loss: 0.425794
Average total loss: 0.899561
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-3.5760e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.477766
Average KL loss: 0.425997
Average total loss: 0.903763
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-6.6432e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.471768
Average KL loss: 0.426084
Average total loss: 0.897852
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-5.3548e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.468334
Average KL loss: 0.426067
Average total loss: 0.894401
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-6.8469e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.466903
Average KL loss: 0.426054
Average total loss: 0.892957
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-6.0967e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.472415
Average KL loss: 0.426058
Average total loss: 0.898473
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.6013e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.469795
Average KL loss: 0.426002
Average total loss: 0.895798
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-6.2285e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.469000
Average KL loss: 0.425962
Average total loss: 0.894961
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.3492e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.477111
Average KL loss: 0.425930
Average total loss: 0.903042
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-7.6023e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.467555
Average KL loss: 0.425914
Average total loss: 0.893469
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.8796e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.470103
Average KL loss: 0.425864
Average total loss: 0.895967
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.8110e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.469110
Average KL loss: 0.425820
Average total loss: 0.894930
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-4.4881e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.471673
Average KL loss: 0.425801
Average total loss: 0.897474
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(7.1661e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.466290
Average KL loss: 0.425786
Average total loss: 0.892076
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-4.9153e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.468690
Average KL loss: 0.425785
Average total loss: 0.894475
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-7.5726e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.468280
Average KL loss: 0.425784
Average total loss: 0.894064
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.4766e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.469254
Average KL loss: 0.425778
Average total loss: 0.895033
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.9492e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.466904
Average KL loss: 0.425774
Average total loss: 0.892678
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-5.3880e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.468857
Average KL loss: 0.425771
Average total loss: 0.894627
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.4830e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.470635
Average KL loss: 0.425767
Average total loss: 0.896402
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-6.8551e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.466352
Average KL loss: 0.425763
Average total loss: 0.892115
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-7.7018e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.472512
Average KL loss: 0.425758
Average total loss: 0.898271
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-5.0926e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.467035
Average KL loss: 0.425754
Average total loss: 0.892788
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.4802e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.467715
Average KL loss: 0.425751
Average total loss: 0.893466
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(5.8052e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.470988
Average KL loss: 0.425749
Average total loss: 0.896737
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-4.5364e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.471571
Average KL loss: 0.425749
Average total loss: 0.897320
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(3.3301e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.463821
Average KL loss: 0.425749
Average total loss: 0.889570
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-4.3813e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.469075
Average KL loss: 0.425748
Average total loss: 0.894823
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-9.9298e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.469035
Average KL loss: 0.425748
Average total loss: 0.894783
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.2952e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.470697
Average KL loss: 0.425748
Average total loss: 0.896445
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-7.8597e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.472103
Average KL loss: 0.425748
Average total loss: 0.897850
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(5.4020e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.476999
Average KL loss: 0.425748
Average total loss: 0.902746
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-4.2085e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.462894
Average KL loss: 0.425748
Average total loss: 0.888641
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(9.9689e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.464300
Average KL loss: 0.425747
Average total loss: 0.890048
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.6270e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.471750
Average KL loss: 0.425747
Average total loss: 0.897497
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.5609e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.463279
Average KL loss: 0.425747
Average total loss: 0.889026
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.0747e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.470613
Average KL loss: 0.425747
Average total loss: 0.896359
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(4.9646e-11, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.467769
Average KL loss: 0.425746
Average total loss: 0.893515
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-9.0184e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.471349
Average KL loss: 0.425746
Average total loss: 0.897095
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.3297e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.478168
Average KL loss: 0.425746
Average total loss: 0.903913
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(4.4522e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.464926
Average KL loss: 0.425745
Average total loss: 0.890671
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.8323e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.471093
Average KL loss: 0.425745
Average total loss: 0.896837
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.9120e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.468183
Average KL loss: 0.425744
Average total loss: 0.893927
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.3597e-09, device='cuda:0')
 Percentile value: 3.6376869201660145
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =      96 /    1728             (  5.56%) | total_pruned =    1632 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      38 /   36864             (  0.10%) | total_pruned =   36826 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      66 /   36864             (  0.18%) | total_pruned =   36798 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     127 /   36864             (  0.34%) | total_pruned =   36737 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     244 /   36864             (  0.66%) | total_pruned =   36620 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     386 /   73728             (  0.52%) | total_pruned =   73342 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     569 /  147456             (  0.39%) | total_pruned =  146887 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      89 /    8192             (  1.09%) | total_pruned =    8103 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     279 /  147456             (  0.19%) | total_pruned =  147177 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     285 /  147456             (  0.19%) | total_pruned =  147171 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     890 /  294912             (  0.30%) | total_pruned =  294022 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1109 /  589824             (  0.19%) | total_pruned =  588715 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     178 /     256             ( 69.53%) | total_pruned =      78 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      50 /   32768             (  0.15%) | total_pruned =   32718 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     705 /  589824             (  0.12%) | total_pruned =  589119 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     524 /  589824             (  0.09%) | total_pruned =  589300 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      66 /     256             ( 25.78%) | total_pruned =     190 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     459 / 1179648             (  0.04%) | total_pruned = 1179189 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     158 /     512             ( 30.86%) | total_pruned =     354 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     338 / 2359296             (  0.01%) | total_pruned = 2358958 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      71 /     512             ( 13.87%) | total_pruned =     441 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       9 /  131072             (  0.01%) | total_pruned =  131063 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      25 /     512             (  4.88%) | total_pruned =     487 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     178 / 2359296             (  0.01%) | total_pruned = 2359118 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      47 /     512             (  9.18%) | total_pruned =     465 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     123 / 2359296             (  0.01%) | total_pruned = 2359173 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
linear.weight        | nonzeros =      96 /    5120             (  1.88%) | total_pruned =    5024 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 152/200 Loss: 0.764544 Accuracy: 70.62 76.77 % Best test Accuracy: 70.98%
