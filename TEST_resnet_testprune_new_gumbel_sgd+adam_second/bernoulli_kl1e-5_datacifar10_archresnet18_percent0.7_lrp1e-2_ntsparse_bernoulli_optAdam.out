Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(2.2858e-06, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.842214
Average KL loss: 51.205980
Average total loss: 53.048193
tensor(-0.3263, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(2.3036e-06, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.539445
Average KL loss: 43.283579
Average total loss: 44.823023
tensor(-0.6075, device='cuda:0') tensor(0.0950, device='cuda:0') tensor(2.0862e-06, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.328707
Average KL loss: 36.797161
Average total loss: 38.125868
tensor(-0.8654, device='cuda:0') tensor(0.1945, device='cuda:0') tensor(1.8518e-06, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.195685
Average KL loss: 31.636416
Average total loss: 32.832100
tensor(-1.0985, device='cuda:0') tensor(0.3052, device='cuda:0') tensor(1.6975e-06, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.113441
Average KL loss: 27.604928
Average total loss: 28.718368
tensor(-1.3075, device='cuda:0') tensor(0.4152, device='cuda:0') tensor(1.5482e-06, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.041288
Average KL loss: 24.434859
Average total loss: 25.476146
tensor(-1.4953, device='cuda:0') tensor(0.5183, device='cuda:0') tensor(1.3772e-06, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.983985
Average KL loss: 21.899403
Average total loss: 22.883387
tensor(-1.6647, device='cuda:0') tensor(0.6125, device='cuda:0') tensor(1.2520e-06, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.935748
Average KL loss: 19.833767
Average total loss: 20.769514
tensor(-1.8184, device='cuda:0') tensor(0.6975, device='cuda:0') tensor(1.1509e-06, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.874812
Average KL loss: 18.122524
Average total loss: 18.997336
tensor(-1.9588, device='cuda:0') tensor(0.7737, device='cuda:0') tensor(1.0574e-06, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.853488
Average KL loss: 16.678564
Average total loss: 17.532052
tensor(-2.0880, device='cuda:0') tensor(0.8419, device='cuda:0') tensor(1.0042e-06, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.826411
Average KL loss: 15.443607
Average total loss: 16.270018
tensor(-2.2074, device='cuda:0') tensor(0.9032, device='cuda:0') tensor(9.2353e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.795674
Average KL loss: 14.375667
Average total loss: 15.171340
tensor(-2.3183, device='cuda:0') tensor(0.9585, device='cuda:0') tensor(8.4631e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.756798
Average KL loss: 13.443233
Average total loss: 14.200031
tensor(-2.4218, device='cuda:0') tensor(1.0085, device='cuda:0') tensor(8.0595e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.757134
Average KL loss: 12.620784
Average total loss: 13.377918
tensor(-2.5188, device='cuda:0') tensor(1.0540, device='cuda:0') tensor(7.5902e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.732274
Average KL loss: 11.889878
Average total loss: 12.622151
tensor(-2.6100, device='cuda:0') tensor(1.0955, device='cuda:0') tensor(7.3302e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.706229
Average KL loss: 11.236757
Average total loss: 11.942986
tensor(-2.6961, device='cuda:0') tensor(1.1337, device='cuda:0') tensor(6.8779e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.678526
Average KL loss: 10.648519
Average total loss: 11.327044
tensor(-2.7776, device='cuda:0') tensor(1.1687, device='cuda:0') tensor(6.4534e-07, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.682383
Average KL loss: 10.116205
Average total loss: 10.798589
tensor(-2.8549, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(6.1790e-07, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.667043
Average KL loss: 9.633089
Average total loss: 10.300132
tensor(-2.9285, device='cuda:0') tensor(1.2319, device='cuda:0') tensor(5.7920e-07, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.656584
Average KL loss: 9.192422
Average total loss: 9.849005
tensor(-2.9987, device='cuda:0') tensor(1.2604, device='cuda:0') tensor(5.6006e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.645927
Average KL loss: 8.788566
Average total loss: 9.434493
tensor(-3.0657, device='cuda:0') tensor(1.2872, device='cuda:0') tensor(5.2622e-07, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.628530
Average KL loss: 8.417790
Average total loss: 9.046320
tensor(-3.1298, device='cuda:0') tensor(1.3126, device='cuda:0') tensor(4.9079e-07, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.619190
Average KL loss: 8.076343
Average total loss: 8.695533
tensor(-3.1913, device='cuda:0') tensor(1.3366, device='cuda:0') tensor(5.0753e-07, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.616374
Average KL loss: 7.760306
Average total loss: 8.376679
tensor(-3.2504, device='cuda:0') tensor(1.3594, device='cuda:0') tensor(4.8043e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.604985
Average KL loss: 7.467135
Average total loss: 8.072120
tensor(-3.3072, device='cuda:0') tensor(1.3813, device='cuda:0') tensor(4.6585e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.593856
Average KL loss: 7.194880
Average total loss: 7.788736
tensor(-3.3620, device='cuda:0') tensor(1.4022, device='cuda:0') tensor(4.4420e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.589742
Average KL loss: 6.940971
Average total loss: 7.530713
tensor(-3.4149, device='cuda:0') tensor(1.4224, device='cuda:0') tensor(4.2884e-07, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.585291
Average KL loss: 6.703803
Average total loss: 7.289094
tensor(-3.4659, device='cuda:0') tensor(1.4419, device='cuda:0') tensor(4.0310e-07, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.581726
Average KL loss: 6.482873
Average total loss: 7.064598
tensor(-3.5152, device='cuda:0') tensor(1.4610, device='cuda:0') tensor(4.1135e-07, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.572865
Average KL loss: 6.275629
Average total loss: 6.848494
tensor(-3.5630, device='cuda:0') tensor(1.4794, device='cuda:0') tensor(3.8294e-07, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.576111
Average KL loss: 6.080650
Average total loss: 6.656761
tensor(-3.6093, device='cuda:0') tensor(1.4972, device='cuda:0') tensor(3.7036e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.559167
Average KL loss: 5.897320
Average total loss: 6.456487
tensor(-3.6543, device='cuda:0') tensor(1.5146, device='cuda:0') tensor(3.5365e-07, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.556533
Average KL loss: 5.724549
Average total loss: 6.281082
tensor(-3.6979, device='cuda:0') tensor(1.5316, device='cuda:0') tensor(3.5672e-07, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.552031
Average KL loss: 5.561272
Average total loss: 6.113302
tensor(-3.7404, device='cuda:0') tensor(1.5481, device='cuda:0') tensor(3.4287e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.555476
Average KL loss: 5.406817
Average total loss: 5.962293
tensor(-3.7817, device='cuda:0') tensor(1.5643, device='cuda:0') tensor(3.3613e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.550190
Average KL loss: 5.260993
Average total loss: 5.811182
tensor(-3.8219, device='cuda:0') tensor(1.5805, device='cuda:0') tensor(3.1190e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.549583
Average KL loss: 5.122980
Average total loss: 5.672563
tensor(-3.8611, device='cuda:0') tensor(1.5963, device='cuda:0') tensor(3.0091e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.545864
Average KL loss: 4.992138
Average total loss: 5.538002
tensor(-3.8993, device='cuda:0') tensor(1.6120, device='cuda:0') tensor(3.0265e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.544505
Average KL loss: 4.867985
Average total loss: 5.412490
tensor(-3.9365, device='cuda:0') tensor(1.6275, device='cuda:0') tensor(2.9679e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.531598
Average KL loss: 4.749891
Average total loss: 5.281488
tensor(-3.9729, device='cuda:0') tensor(1.6426, device='cuda:0') tensor(3.0232e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.524677
Average KL loss: 4.636990
Average total loss: 5.161666
tensor(-4.0085, device='cuda:0') tensor(1.6575, device='cuda:0') tensor(2.8441e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.522023
Average KL loss: 4.529288
Average total loss: 5.051311
tensor(-4.0433, device='cuda:0') tensor(1.6722, device='cuda:0') tensor(2.8483e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.521305
Average KL loss: 4.426519
Average total loss: 4.947824
tensor(-4.0773, device='cuda:0') tensor(1.6870, device='cuda:0') tensor(2.7090e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.536584
Average KL loss: 4.329073
Average total loss: 4.865657
tensor(-4.1106, device='cuda:0') tensor(1.7017, device='cuda:0') tensor(2.6280e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.521662
Average KL loss: 4.236020
Average total loss: 4.757682
tensor(-4.1433, device='cuda:0') tensor(1.7163, device='cuda:0') tensor(2.6730e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.519539
Average KL loss: 4.146740
Average total loss: 4.666279
tensor(-4.1752, device='cuda:0') tensor(1.7307, device='cuda:0') tensor(2.4931e-07, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.534664
Average KL loss: 4.061456
Average total loss: 4.596120
tensor(-4.2065, device='cuda:0') tensor(1.7452, device='cuda:0') tensor(2.4164e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.521344
Average KL loss: 3.979865
Average total loss: 4.501209
tensor(-4.2372, device='cuda:0') tensor(1.7597, device='cuda:0') tensor(2.5577e-07, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.510377
Average KL loss: 3.901862
Average total loss: 4.412239
tensor(-4.2673, device='cuda:0') tensor(1.7740, device='cuda:0') tensor(2.2066e-07, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.513646
Average KL loss: 3.826668
Average total loss: 4.340314
tensor(-4.2970, device='cuda:0') tensor(1.7881, device='cuda:0') tensor(2.2143e-07, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.514702
Average KL loss: 3.754366
Average total loss: 4.269069
tensor(-4.3260, device='cuda:0') tensor(1.8023, device='cuda:0') tensor(2.1656e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.507663
Average KL loss: 3.685278
Average total loss: 4.192941
tensor(-4.3546, device='cuda:0') tensor(1.8164, device='cuda:0') tensor(2.1863e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.514687
Average KL loss: 3.618614
Average total loss: 4.133301
tensor(-4.3826, device='cuda:0') tensor(1.8305, device='cuda:0') tensor(2.1488e-07, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.511667
Average KL loss: 3.554920
Average total loss: 4.066587
tensor(-4.4101, device='cuda:0') tensor(1.8448, device='cuda:0') tensor(2.1300e-07, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.498976
Average KL loss: 3.493183
Average total loss: 3.992159
tensor(-4.4373, device='cuda:0') tensor(1.8586, device='cuda:0') tensor(2.0968e-07, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.505660
Average KL loss: 3.433297
Average total loss: 3.938957
tensor(-4.4640, device='cuda:0') tensor(1.8724, device='cuda:0') tensor(1.9194e-07, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.507553
Average KL loss: 3.375632
Average total loss: 3.883184
tensor(-4.4903, device='cuda:0') tensor(1.8862, device='cuda:0') tensor(1.9000e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.504094
Average KL loss: 3.320220
Average total loss: 3.824314
tensor(-4.5163, device='cuda:0') tensor(1.9001, device='cuda:0') tensor(1.9408e-07, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.502175
Average KL loss: 3.266663
Average total loss: 3.768838
tensor(-4.5418, device='cuda:0') tensor(1.9139, device='cuda:0') tensor(2.0107e-07, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.500447
Average KL loss: 3.214900
Average total loss: 3.715346
tensor(-4.5670, device='cuda:0') tensor(1.9277, device='cuda:0') tensor(1.8367e-07, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.487795
Average KL loss: 3.165048
Average total loss: 3.652843
tensor(-4.5918, device='cuda:0') tensor(1.9416, device='cuda:0') tensor(1.8234e-07, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.490343
Average KL loss: 3.116778
Average total loss: 3.607121
tensor(-4.6162, device='cuda:0') tensor(1.9553, device='cuda:0') tensor(1.8423e-07, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.498563
Average KL loss: 3.070068
Average total loss: 3.568632
tensor(-4.6403, device='cuda:0') tensor(1.9693, device='cuda:0') tensor(1.7992e-07, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.493252
Average KL loss: 3.024785
Average total loss: 3.518036
tensor(-4.6642, device='cuda:0') tensor(1.9829, device='cuda:0') tensor(1.8341e-07, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.487083
Average KL loss: 2.980680
Average total loss: 3.467763
tensor(-4.6877, device='cuda:0') tensor(1.9965, device='cuda:0') tensor(1.6692e-07, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.492769
Average KL loss: 2.938040
Average total loss: 3.430809
tensor(-4.7109, device='cuda:0') tensor(2.0102, device='cuda:0') tensor(1.6593e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.490921
Average KL loss: 2.896723
Average total loss: 3.387644
tensor(-4.7338, device='cuda:0') tensor(2.0239, device='cuda:0') tensor(1.5149e-07, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.494679
Average KL loss: 2.856781
Average total loss: 3.351460
tensor(-4.7565, device='cuda:0') tensor(2.0377, device='cuda:0') tensor(1.6813e-07, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.492806
Average KL loss: 2.817994
Average total loss: 3.310800
tensor(-4.7789, device='cuda:0') tensor(2.0514, device='cuda:0') tensor(1.5543e-07, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.491064
Average KL loss: 2.780354
Average total loss: 3.271418
tensor(-4.8010, device='cuda:0') tensor(2.0652, device='cuda:0') tensor(1.6071e-07, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.491181
Average KL loss: 2.744007
Average total loss: 3.235188
tensor(-4.8228, device='cuda:0') tensor(2.0790, device='cuda:0') tensor(1.4201e-07, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.488938
Average KL loss: 2.708530
Average total loss: 3.197467
tensor(-4.8444, device='cuda:0') tensor(2.0928, device='cuda:0') tensor(1.3768e-07, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.491107
Average KL loss: 2.674094
Average total loss: 3.165202
tensor(-4.8658, device='cuda:0') tensor(2.1066, device='cuda:0') tensor(1.6251e-07, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.486348
Average KL loss: 2.640636
Average total loss: 3.126984
tensor(-4.8869, device='cuda:0') tensor(2.1204, device='cuda:0') tensor(1.4952e-07, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.482604
Average KL loss: 2.608030
Average total loss: 3.090634
tensor(-4.9078, device='cuda:0') tensor(2.1342, device='cuda:0') tensor(1.4731e-07, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.482443
Average KL loss: 2.576319
Average total loss: 3.058762
tensor(-4.9284, device='cuda:0') tensor(2.1480, device='cuda:0') tensor(1.3978e-07, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.483632
Average KL loss: 2.545459
Average total loss: 3.029091
tensor(-4.9489, device='cuda:0') tensor(2.1617, device='cuda:0') tensor(1.2753e-07, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.484485
Average KL loss: 2.515388
Average total loss: 2.999873
tensor(-4.9691, device='cuda:0') tensor(2.1755, device='cuda:0') tensor(1.4583e-07, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.485255
Average KL loss: 2.486402
Average total loss: 2.971657
tensor(-4.9891, device='cuda:0') tensor(2.1895, device='cuda:0') tensor(1.3792e-07, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.471576
Average KL loss: 2.458076
Average total loss: 2.929653
tensor(-5.0089, device='cuda:0') tensor(2.2033, device='cuda:0') tensor(1.3015e-07, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.475109
Average KL loss: 2.430230
Average total loss: 2.905339
tensor(-5.0286, device='cuda:0') tensor(2.2172, device='cuda:0') tensor(1.4438e-07, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.476049
Average KL loss: 2.403008
Average total loss: 2.879056
tensor(-5.0480, device='cuda:0') tensor(2.2309, device='cuda:0') tensor(1.3079e-07, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.475509
Average KL loss: 2.376513
Average total loss: 2.852022
tensor(-5.0673, device='cuda:0') tensor(2.2447, device='cuda:0') tensor(1.3166e-07, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.479487
Average KL loss: 2.350591
Average total loss: 2.830078
tensor(-5.0865, device='cuda:0') tensor(2.2585, device='cuda:0') tensor(1.2825e-07, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.481842
Average KL loss: 2.325544
Average total loss: 2.807386
tensor(-5.1054, device='cuda:0') tensor(2.2726, device='cuda:0') tensor(1.4395e-07, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.474544
Average KL loss: 2.301071
Average total loss: 2.775615
tensor(-5.1242, device='cuda:0') tensor(2.2865, device='cuda:0') tensor(1.2670e-07, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.475302
Average KL loss: 2.277022
Average total loss: 2.752324
tensor(-5.1428, device='cuda:0') tensor(2.3003, device='cuda:0') tensor(1.2291e-07, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.478173
Average KL loss: 2.253570
Average total loss: 2.731742
tensor(-5.1612, device='cuda:0') tensor(2.3142, device='cuda:0') tensor(1.2534e-07, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.474599
Average KL loss: 2.230634
Average total loss: 2.705233
tensor(-5.1795, device='cuda:0') tensor(2.3281, device='cuda:0') tensor(1.3062e-07, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.472311
Average KL loss: 2.208195
Average total loss: 2.680506
tensor(-5.1976, device='cuda:0') tensor(2.3421, device='cuda:0') tensor(1.1532e-07, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.474693
Average KL loss: 2.186444
Average total loss: 2.661137
tensor(-5.2156, device='cuda:0') tensor(2.3562, device='cuda:0') tensor(1.1428e-07, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.470633
Average KL loss: 2.165189
Average total loss: 2.635823
tensor(-5.2335, device='cuda:0') tensor(2.3702, device='cuda:0') tensor(1.1286e-07, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.468099
Average KL loss: 2.144102
Average total loss: 2.612201
tensor(-5.2512, device='cuda:0') tensor(2.3841, device='cuda:0') tensor(1.0846e-07, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.468303
Average KL loss: 2.123573
Average total loss: 2.591877
tensor(-5.2687, device='cuda:0') tensor(2.3981, device='cuda:0') tensor(1.1339e-07, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.471813
Average KL loss: 2.103516
Average total loss: 2.575329
tensor(-5.2862, device='cuda:0') tensor(2.4122, device='cuda:0') tensor(1.1694e-07, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.472561
Average KL loss: 2.084057
Average total loss: 2.556618
tensor(-5.3035, device='cuda:0') tensor(2.4263, device='cuda:0') tensor(1.1651e-07, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.471955
Average KL loss: 2.064852
Average total loss: 2.536807
tensor(-5.3207, device='cuda:0') tensor(2.4404, device='cuda:0') tensor(1.1378e-07, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.469138
Average KL loss: 2.046223
Average total loss: 2.515361
tensor(-5.3378, device='cuda:0') tensor(2.4546, device='cuda:0') tensor(1.1637e-07, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.465387
Average KL loss: 2.027854
Average total loss: 2.493241
tensor(-5.3547, device='cuda:0') tensor(2.4688, device='cuda:0') tensor(1.1477e-07, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.465038
Average KL loss: 2.009871
Average total loss: 2.474910
tensor(-5.3715, device='cuda:0') tensor(2.4829, device='cuda:0') tensor(1.0636e-07, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.465685
Average KL loss: 1.992220
Average total loss: 2.457905
tensor(-5.3882, device='cuda:0') tensor(2.4971, device='cuda:0') tensor(1.0462e-07, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.468923
Average KL loss: 1.974948
Average total loss: 2.443871
tensor(-5.4048, device='cuda:0') tensor(2.5114, device='cuda:0') tensor(1.0224e-07, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.463956
Average KL loss: 1.958164
Average total loss: 2.422121
tensor(-5.4213, device='cuda:0') tensor(2.5257, device='cuda:0') tensor(1.0493e-07, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.463122
Average KL loss: 1.941444
Average total loss: 2.404566
tensor(-5.4377, device='cuda:0') tensor(2.5398, device='cuda:0') tensor(1.0277e-07, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.459215
Average KL loss: 1.925087
Average total loss: 2.384302
tensor(-5.4540, device='cuda:0') tensor(2.5541, device='cuda:0') tensor(1.0298e-07, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.442619
Average KL loss: 1.908870
Average total loss: 2.351489
tensor(-5.4702, device='cuda:0') tensor(2.5680, device='cuda:0') tensor(9.6574e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.465471
Average KL loss: 1.892843
Average total loss: 2.358313
tensor(-5.4863, device='cuda:0') tensor(2.5823, device='cuda:0') tensor(9.5756e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.458515
Average KL loss: 1.877469
Average total loss: 2.335984
tensor(-5.5022, device='cuda:0') tensor(2.5967, device='cuda:0') tensor(9.4216e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.446775
Average KL loss: 1.862239
Average total loss: 2.309014
tensor(-5.5182, device='cuda:0') tensor(2.6109, device='cuda:0') tensor(9.4383e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.458059
Average KL loss: 1.847184
Average total loss: 2.305243
tensor(-5.5340, device='cuda:0') tensor(2.6251, device='cuda:0') tensor(9.5232e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.466265
Average KL loss: 1.832542
Average total loss: 2.298808
tensor(-5.5497, device='cuda:0') tensor(2.6395, device='cuda:0') tensor(9.9198e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.444903
Average KL loss: 1.818084
Average total loss: 2.262987
tensor(-5.5654, device='cuda:0') tensor(2.6538, device='cuda:0') tensor(8.9611e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.450223
Average KL loss: 1.803718
Average total loss: 2.253940
tensor(-5.5809, device='cuda:0') tensor(2.6681, device='cuda:0') tensor(9.6014e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.454013
Average KL loss: 1.789800
Average total loss: 2.243813
tensor(-5.5964, device='cuda:0') tensor(2.6825, device='cuda:0') tensor(9.7146e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.456398
Average KL loss: 1.776120
Average total loss: 2.232517
tensor(-5.6118, device='cuda:0') tensor(2.6969, device='cuda:0') tensor(9.2893e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.454218
Average KL loss: 1.762788
Average total loss: 2.217006
tensor(-5.6271, device='cuda:0') tensor(2.7114, device='cuda:0') tensor(8.8015e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.462865
Average KL loss: 1.749761
Average total loss: 2.212626
tensor(-5.6424, device='cuda:0') tensor(2.7260, device='cuda:0') tensor(9.4739e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.451861
Average KL loss: 1.736863
Average total loss: 2.188724
tensor(-5.6575, device='cuda:0') tensor(2.7405, device='cuda:0') tensor(8.8386e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.449553
Average KL loss: 1.723978
Average total loss: 2.173531
tensor(-5.6726, device='cuda:0') tensor(2.7549, device='cuda:0') tensor(9.2654e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.447552
Average KL loss: 1.711339
Average total loss: 2.158891
tensor(-5.6876, device='cuda:0') tensor(2.7693, device='cuda:0') tensor(8.8543e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.452308
Average KL loss: 1.698924
Average total loss: 2.151231
tensor(-5.7025, device='cuda:0') tensor(2.7838, device='cuda:0') tensor(8.8323e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.446000
Average KL loss: 1.686673
Average total loss: 2.132673
tensor(-5.7174, device='cuda:0') tensor(2.7983, device='cuda:0') tensor(7.0316e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.448399
Average KL loss: 1.674671
Average total loss: 2.123070
tensor(-5.7322, device='cuda:0') tensor(2.8129, device='cuda:0') tensor(8.2577e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.444125
Average KL loss: 1.662855
Average total loss: 2.106980
tensor(-5.7469, device='cuda:0') tensor(2.8274, device='cuda:0') tensor(8.5501e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.439580
Average KL loss: 1.651109
Average total loss: 2.090689
tensor(-5.7615, device='cuda:0') tensor(2.8419, device='cuda:0') tensor(8.7612e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.450935
Average KL loss: 1.639508
Average total loss: 2.090443
tensor(-5.7761, device='cuda:0') tensor(2.8566, device='cuda:0') tensor(9.2686e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.444557
Average KL loss: 1.628356
Average total loss: 2.072913
tensor(-5.7906, device='cuda:0') tensor(2.8713, device='cuda:0') tensor(7.9586e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.447671
Average KL loss: 1.617285
Average total loss: 2.064956
tensor(-5.8051, device='cuda:0') tensor(2.8860, device='cuda:0') tensor(9.1277e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.439084
Average KL loss: 1.606427
Average total loss: 2.045511
tensor(-5.8195, device='cuda:0') tensor(2.9006, device='cuda:0') tensor(8.6817e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.438613
Average KL loss: 1.595452
Average total loss: 2.034064
tensor(-5.8338, device='cuda:0') tensor(2.9151, device='cuda:0') tensor(7.5140e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.444171
Average KL loss: 1.584826
Average total loss: 2.028997
tensor(-5.8481, device='cuda:0') tensor(2.9300, device='cuda:0') tensor(6.4193e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.438284
Average KL loss: 1.574346
Average total loss: 2.012630
tensor(-5.8623, device='cuda:0') tensor(2.9446, device='cuda:0') tensor(7.8627e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.438658
Average KL loss: 1.564104
Average total loss: 2.002762
tensor(-5.8764, device='cuda:0') tensor(2.9594, device='cuda:0') tensor(7.0150e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.438160
Average KL loss: 1.554040
Average total loss: 1.992200
tensor(-5.8905, device='cuda:0') tensor(2.9742, device='cuda:0') tensor(7.9039e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.441449
Average KL loss: 1.543979
Average total loss: 1.985428
tensor(-5.9046, device='cuda:0') tensor(2.9890, device='cuda:0') tensor(7.8630e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.441399
Average KL loss: 1.534135
Average total loss: 1.975534
tensor(-5.9186, device='cuda:0') tensor(3.0039, device='cuda:0') tensor(8.3640e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.427006
Average KL loss: 1.524415
Average total loss: 1.951421
tensor(-5.9325, device='cuda:0') tensor(3.0185, device='cuda:0') tensor(7.4105e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.437143
Average KL loss: 1.514679
Average total loss: 1.951821
tensor(-5.9464, device='cuda:0') tensor(3.0334, device='cuda:0') tensor(7.6033e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.431741
Average KL loss: 1.505414
Average total loss: 1.937155
tensor(-5.9602, device='cuda:0') tensor(3.0484, device='cuda:0') tensor(7.8190e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.437519
Average KL loss: 1.496163
Average total loss: 1.933682
tensor(-5.9740, device='cuda:0') tensor(3.0634, device='cuda:0') tensor(7.7272e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.437155
Average KL loss: 1.487114
Average total loss: 1.924269
tensor(-5.9877, device='cuda:0') tensor(3.0785, device='cuda:0') tensor(6.7683e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.433321
Average KL loss: 1.478233
Average total loss: 1.911554
tensor(-6.0013, device='cuda:0') tensor(3.0935, device='cuda:0') tensor(7.4660e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.431575
Average KL loss: 1.469277
Average total loss: 1.900853
tensor(-6.0150, device='cuda:0') tensor(3.1084, device='cuda:0') tensor(7.1062e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.433957
Average KL loss: 1.460463
Average total loss: 1.894421
tensor(-6.0285, device='cuda:0') tensor(3.1235, device='cuda:0') tensor(7.4544e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.436878
Average KL loss: 1.451790
Average total loss: 1.888668
tensor(-6.0420, device='cuda:0') tensor(3.1386, device='cuda:0') tensor(7.2201e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.432951
Average KL loss: 1.443429
Average total loss: 1.876381
tensor(-6.0555, device='cuda:0') tensor(3.1538, device='cuda:0') tensor(7.3998e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.434673
Average KL loss: 1.435009
Average total loss: 1.869682
tensor(-6.0689, device='cuda:0') tensor(3.1689, device='cuda:0') tensor(7.1224e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.429562
Average KL loss: 1.426744
Average total loss: 1.856305
tensor(-6.0823, device='cuda:0') tensor(3.1840, device='cuda:0') tensor(7.4976e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.429825
Average KL loss: 1.418622
Average total loss: 1.848447
tensor(-6.0956, device='cuda:0') tensor(3.1992, device='cuda:0') tensor(6.6171e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.428428
Average KL loss: 1.410479
Average total loss: 1.838907
tensor(-6.1089, device='cuda:0') tensor(3.2143, device='cuda:0') tensor(6.6892e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.431636
Average KL loss: 1.402513
Average total loss: 1.834149
tensor(-6.1221, device='cuda:0') tensor(3.2295, device='cuda:0') tensor(6.7829e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.428615
Average KL loss: 1.394653
Average total loss: 1.823268
tensor(-6.1353, device='cuda:0') tensor(3.2446, device='cuda:0') tensor(6.5519e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.429541
Average KL loss: 1.386973
Average total loss: 1.816514
tensor(-6.1484, device='cuda:0') tensor(3.2600, device='cuda:0') tensor(6.0865e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.434732
Average KL loss: 1.379475
Average total loss: 1.814207
tensor(-6.1615, device='cuda:0') tensor(3.2753, device='cuda:0') tensor(6.1608e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.421468
Average KL loss: 1.372003
Average total loss: 1.793472
tensor(-6.1745, device='cuda:0') tensor(3.2906, device='cuda:0') tensor(6.0175e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.424112
Average KL loss: 1.364456
Average total loss: 1.788568
tensor(-6.1875, device='cuda:0') tensor(3.3058, device='cuda:0') tensor(6.8825e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.429464
Average KL loss: 1.357107
Average total loss: 1.786571
tensor(-6.2005, device='cuda:0') tensor(3.3211, device='cuda:0') tensor(5.8403e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.422614
Average KL loss: 1.349824
Average total loss: 1.772438
tensor(-6.2134, device='cuda:0') tensor(3.3364, device='cuda:0') tensor(6.5213e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.423723
Average KL loss: 1.342688
Average total loss: 1.766410
tensor(-6.2263, device='cuda:0') tensor(3.3517, device='cuda:0') tensor(7.0336e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.423852
Average KL loss: 1.335656
Average total loss: 1.759508
tensor(-6.2391, device='cuda:0') tensor(3.3670, device='cuda:0') tensor(6.6554e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.423059
Average KL loss: 1.328625
Average total loss: 1.751684
tensor(-6.2519, device='cuda:0') tensor(3.3824, device='cuda:0') tensor(6.5692e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.419431
Average KL loss: 1.321625
Average total loss: 1.741056
tensor(-6.2647, device='cuda:0') tensor(3.3977, device='cuda:0') tensor(6.1913e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.421778
Average KL loss: 1.314806
Average total loss: 1.736584
tensor(-6.2774, device='cuda:0') tensor(3.4131, device='cuda:0') tensor(5.5575e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.421768
Average KL loss: 1.308051
Average total loss: 1.729819
tensor(-6.2901, device='cuda:0') tensor(3.4284, device='cuda:0') tensor(6.4232e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.423576
Average KL loss: 1.301317
Average total loss: 1.724892
tensor(-6.3027, device='cuda:0') tensor(3.4438, device='cuda:0') tensor(5.3302e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.418693
Average KL loss: 1.294683
Average total loss: 1.713376
tensor(-6.3153, device='cuda:0') tensor(3.4591, device='cuda:0') tensor(6.8156e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.415929
Average KL loss: 1.288071
Average total loss: 1.704000
tensor(-6.3279, device='cuda:0') tensor(3.4744, device='cuda:0') tensor(6.1179e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.417302
Average KL loss: 1.281555
Average total loss: 1.698857
tensor(-6.3404, device='cuda:0') tensor(3.4897, device='cuda:0') tensor(7.2587e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.418535
Average KL loss: 1.275069
Average total loss: 1.693605
tensor(-6.3529, device='cuda:0') tensor(3.5051, device='cuda:0') tensor(6.0368e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.410300
Average KL loss: 1.268721
Average total loss: 1.679021
tensor(-6.3654, device='cuda:0') tensor(3.5203, device='cuda:0') tensor(6.2437e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.424532
Average KL loss: 1.262372
Average total loss: 1.686904
tensor(-6.3779, device='cuda:0') tensor(3.5358, device='cuda:0') tensor(6.1727e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.412060
Average KL loss: 1.256291
Average total loss: 1.668352
tensor(-6.3903, device='cuda:0') tensor(3.5512, device='cuda:0') tensor(6.2370e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.417192
Average KL loss: 1.250202
Average total loss: 1.667394
tensor(-6.4026, device='cuda:0') tensor(3.5666, device='cuda:0') tensor(5.8171e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.413626
Average KL loss: 1.244288
Average total loss: 1.657915
tensor(-6.4150, device='cuda:0') tensor(3.5821, device='cuda:0') tensor(5.7366e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.417897
Average KL loss: 1.238357
Average total loss: 1.656253
tensor(-6.4272, device='cuda:0') tensor(3.5975, device='cuda:0') tensor(5.6383e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.415333
Average KL loss: 1.232405
Average total loss: 1.647738
tensor(-6.4395, device='cuda:0') tensor(3.6130, device='cuda:0') tensor(4.6799e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.408220
Average KL loss: 1.226627
Average total loss: 1.634846
tensor(-6.4517, device='cuda:0') tensor(3.6285, device='cuda:0') tensor(6.1062e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.410511
Average KL loss: 1.220827
Average total loss: 1.631338
tensor(-6.4639, device='cuda:0') tensor(3.6438, device='cuda:0') tensor(6.4015e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.408300
Average KL loss: 1.215074
Average total loss: 1.623374
tensor(-6.4761, device='cuda:0') tensor(3.6592, device='cuda:0') tensor(4.9350e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.410301
Average KL loss: 1.209339
Average total loss: 1.619640
tensor(-6.4882, device='cuda:0') tensor(3.6744, device='cuda:0') tensor(5.7480e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.402803
Average KL loss: 1.203742
Average total loss: 1.606545
tensor(-6.5003, device='cuda:0') tensor(3.6899, device='cuda:0') tensor(5.5435e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.414716
Average KL loss: 1.198352
Average total loss: 1.613068
tensor(-6.5124, device='cuda:0') tensor(3.7054, device='cuda:0') tensor(5.3487e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.402951
Average KL loss: 1.192902
Average total loss: 1.595853
tensor(-6.5244, device='cuda:0') tensor(3.7207, device='cuda:0') tensor(5.8015e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.405851
Average KL loss: 1.187428
Average total loss: 1.593279
tensor(-6.5364, device='cuda:0') tensor(3.7360, device='cuda:0') tensor(5.0210e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.412808
Average KL loss: 1.182042
Average total loss: 1.594850
tensor(-6.5484, device='cuda:0') tensor(3.7514, device='cuda:0') tensor(4.1565e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.411997
Average KL loss: 1.176697
Average total loss: 1.588694
tensor(-6.5604, device='cuda:0') tensor(3.7667, device='cuda:0') tensor(4.9017e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.399024
Average KL loss: 1.171468
Average total loss: 1.570492
tensor(-6.5723, device='cuda:0') tensor(3.7820, device='cuda:0') tensor(6.0434e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.404094
Average KL loss: 1.166225
Average total loss: 1.570319
tensor(-6.5842, device='cuda:0') tensor(3.7973, device='cuda:0') tensor(6.0415e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.403723
Average KL loss: 1.161062
Average total loss: 1.564785
tensor(-6.5960, device='cuda:0') tensor(3.8125, device='cuda:0') tensor(4.9899e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.407377
Average KL loss: 1.155941
Average total loss: 1.563317
tensor(-6.6079, device='cuda:0') tensor(3.8279, device='cuda:0') tensor(4.7984e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.397062
Average KL loss: 1.150946
Average total loss: 1.548008
tensor(-6.6196, device='cuda:0') tensor(3.8431, device='cuda:0') tensor(5.0047e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.407399
Average KL loss: 1.145871
Average total loss: 1.553270
tensor(-6.6314, device='cuda:0') tensor(3.8584, device='cuda:0') tensor(5.2612e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.399513
Average KL loss: 1.140891
Average total loss: 1.540404
tensor(-6.6431, device='cuda:0') tensor(3.8736, device='cuda:0') tensor(3.9395e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.395851
Average KL loss: 1.136023
Average total loss: 1.531874
tensor(-6.6548, device='cuda:0') tensor(3.8890, device='cuda:0') tensor(3.9196e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.394635
Average KL loss: 1.131256
Average total loss: 1.525891
tensor(-6.6665, device='cuda:0') tensor(3.9042, device='cuda:0') tensor(4.2344e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.398895
Average KL loss: 1.126391
Average total loss: 1.525286
tensor(-6.6782, device='cuda:0') tensor(3.9195, device='cuda:0') tensor(5.4317e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.397468
Average KL loss: 1.121593
Average total loss: 1.519060
tensor(-6.6898, device='cuda:0') tensor(3.9346, device='cuda:0') tensor(5.0857e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.400240
Average KL loss: 1.116772
Average total loss: 1.517012
tensor(-6.7014, device='cuda:0') tensor(3.9497, device='cuda:0') tensor(5.0760e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.393764
Average KL loss: 1.112041
Average total loss: 1.505805
tensor(-6.7130, device='cuda:0') tensor(3.9647, device='cuda:0') tensor(4.9230e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.397167
Average KL loss: 1.107373
Average total loss: 1.504540
 Percentile value: -4.030775451660157
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1704 /    1728             ( 98.61%) | total_pruned =      24 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   29128 /   36864             ( 79.01%) | total_pruned =    7736 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   29407 /   36864             ( 79.77%) | total_pruned =    7457 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   28522 /   36864             ( 77.37%) | total_pruned =    8342 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   27734 /   36864             ( 75.23%) | total_pruned =    9130 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   54300 /   73728             ( 73.65%) | total_pruned =   19428 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   99719 /  147456             ( 67.63%) | total_pruned =   47737 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7496 /    8192             ( 91.50%) | total_pruned =     696 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   89756 /  147456             ( 60.87%) | total_pruned =   57700 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   89718 /  147456             ( 60.84%) | total_pruned =   57738 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  181625 /  294912             ( 61.59%) | total_pruned =  113287 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  321861 /  589824             ( 54.57%) | total_pruned =  267963 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   26922 /   32768             ( 82.16%) | total_pruned =    5846 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  233883 /  589824             ( 39.65%) | total_pruned =  355941 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  232753 /  589824             ( 39.46%) | total_pruned =  357071 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  500566 / 1179648             ( 42.43%) | total_pruned =  679082 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  626542 / 2359296             ( 26.56%) | total_pruned = 1732754 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   81414 /  131072             ( 62.11%) | total_pruned =   49658 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  354977 / 2359296             ( 15.05%) | total_pruned = 2004319 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  321070 / 2359296             ( 13.61%) | total_pruned = 2038226 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
linear.weight        | nonzeros =    5034 /    5120             ( 98.32%) | total_pruned =      86 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 35/200 Loss: 0.000093 Accuracy: 86.66 100.00 % Best test Accuracy: 86.81%
tensor(-6.7245, device='cuda:0') tensor(3.9798, device='cuda:0') tensor(5.0485e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.467837
Average KL loss: 1.041205
Average total loss: 1.509042
tensor(-6.9080, device='cuda:0') tensor(3.7577, device='cuda:0') tensor(3.6298e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.468281
Average KL loss: 0.987680
Average total loss: 1.455960
tensor(-7.0390, device='cuda:0') tensor(3.7177, device='cuda:0') tensor(2.9125e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.460895
Average KL loss: 0.964070
Average total loss: 1.424966
tensor(-7.1457, device='cuda:0') tensor(3.7295, device='cuda:0') tensor(2.6019e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.456952
Average KL loss: 0.949207
Average total loss: 1.406159
tensor(-7.2371, device='cuda:0') tensor(3.7644, device='cuda:0') tensor(3.2159e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.453743
Average KL loss: 0.938594
Average total loss: 1.392337
tensor(-7.3177, device='cuda:0') tensor(3.8112, device='cuda:0') tensor(3.2463e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.456037
Average KL loss: 0.930432
Average total loss: 1.386469
tensor(-7.3902, device='cuda:0') tensor(3.8646, device='cuda:0') tensor(3.6735e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.451937
Average KL loss: 0.923714
Average total loss: 1.375651
tensor(-7.4561, device='cuda:0') tensor(3.9214, device='cuda:0') tensor(3.4041e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.442616
Average KL loss: 0.917962
Average total loss: 1.360578
tensor(-7.5167, device='cuda:0') tensor(3.9798, device='cuda:0') tensor(3.7170e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.443713
Average KL loss: 0.912837
Average total loss: 1.356549
tensor(-7.5728, device='cuda:0') tensor(4.0388, device='cuda:0') tensor(3.2822e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.441052
Average KL loss: 0.908285
Average total loss: 1.349337
tensor(-7.6252, device='cuda:0') tensor(4.0980, device='cuda:0') tensor(3.0638e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.440279
Average KL loss: 0.904197
Average total loss: 1.344477
tensor(-7.6743, device='cuda:0') tensor(4.1566, device='cuda:0') tensor(3.3653e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.443638
Average KL loss: 0.900455
Average total loss: 1.344093
tensor(-7.7206, device='cuda:0') tensor(4.2144, device='cuda:0') tensor(3.0268e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.426831
Average KL loss: 0.896853
Average total loss: 1.323684
tensor(-7.7645, device='cuda:0') tensor(4.2711, device='cuda:0') tensor(3.3629e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.432193
Average KL loss: 0.893440
Average total loss: 1.325632
tensor(-7.8060, device='cuda:0') tensor(4.3267, device='cuda:0') tensor(3.2029e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.429169
Average KL loss: 0.890206
Average total loss: 1.319374
tensor(-7.8456, device='cuda:0') tensor(4.3813, device='cuda:0') tensor(3.1350e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.432785
Average KL loss: 0.887181
Average total loss: 1.319965
tensor(-7.8834, device='cuda:0') tensor(4.4347, device='cuda:0') tensor(1.5226e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.430492
Average KL loss: 0.884346
Average total loss: 1.314838
tensor(-7.9196, device='cuda:0') tensor(4.4869, device='cuda:0') tensor(3.6050e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.418272
Average KL loss: 0.881444
Average total loss: 1.299715
tensor(-7.9543, device='cuda:0') tensor(4.5376, device='cuda:0') tensor(2.9631e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.420365
Average KL loss: 0.878592
Average total loss: 1.298956
tensor(-7.9877, device='cuda:0') tensor(4.5871, device='cuda:0') tensor(3.5494e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.420804
Average KL loss: 0.875842
Average total loss: 1.296645
tensor(-8.0198, device='cuda:0') tensor(4.6357, device='cuda:0') tensor(2.4817e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.413413
Average KL loss: 0.873311
Average total loss: 1.286724
tensor(-8.0508, device='cuda:0') tensor(4.6832, device='cuda:0') tensor(2.5163e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.416899
Average KL loss: 0.870731
Average total loss: 1.287630
tensor(-8.0807, device='cuda:0') tensor(4.7294, device='cuda:0') tensor(1.8079e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.417316
Average KL loss: 0.868263
Average total loss: 1.285579
tensor(-8.1096, device='cuda:0') tensor(4.7745, device='cuda:0') tensor(3.2938e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.412190
Average KL loss: 0.865777
Average total loss: 1.277967
tensor(-8.1376, device='cuda:0') tensor(4.8187, device='cuda:0') tensor(3.5452e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.420070
Average KL loss: 0.863377
Average total loss: 1.283447
tensor(-8.1648, device='cuda:0') tensor(4.8618, device='cuda:0') tensor(3.3967e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.411599
Average KL loss: 0.861055
Average total loss: 1.272654
tensor(-8.1911, device='cuda:0') tensor(4.9040, device='cuda:0') tensor(2.4816e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.403148
Average KL loss: 0.858670
Average total loss: 1.261818
tensor(-8.2168, device='cuda:0') tensor(4.9449, device='cuda:0') tensor(2.9388e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.412522
Average KL loss: 0.856279
Average total loss: 1.268802
tensor(-8.2417, device='cuda:0') tensor(4.9849, device='cuda:0') tensor(3.0003e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.405799
Average KL loss: 0.853897
Average total loss: 1.259696
tensor(-8.2659, device='cuda:0') tensor(5.0241, device='cuda:0') tensor(2.7314e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.411922
Average KL loss: 0.851653
Average total loss: 1.263576
tensor(-8.2895, device='cuda:0') tensor(5.0625, device='cuda:0') tensor(2.7701e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.404562
Average KL loss: 0.849416
Average total loss: 1.253978
tensor(-8.3126, device='cuda:0') tensor(5.1000, device='cuda:0') tensor(2.8599e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.406936
Average KL loss: 0.847159
Average total loss: 1.254096
tensor(-8.3350, device='cuda:0') tensor(5.1367, device='cuda:0') tensor(3.1826e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.409639
Average KL loss: 0.845025
Average total loss: 1.254664
tensor(-8.3569, device='cuda:0') tensor(5.1727, device='cuda:0') tensor(2.5008e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.405473
Average KL loss: 0.842895
Average total loss: 1.248368
tensor(-8.3784, device='cuda:0') tensor(5.2076, device='cuda:0') tensor(2.8479e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.407015
Average KL loss: 0.840653
Average total loss: 1.247668
tensor(-8.3993, device='cuda:0') tensor(5.2419, device='cuda:0') tensor(1.4023e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.403037
Average KL loss: 0.838500
Average total loss: 1.241537
tensor(-8.4199, device='cuda:0') tensor(5.2754, device='cuda:0') tensor(2.7188e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.409069
Average KL loss: 0.836450
Average total loss: 1.245519
tensor(-8.4399, device='cuda:0') tensor(5.3084, device='cuda:0') tensor(2.8343e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.406105
Average KL loss: 0.834478
Average total loss: 1.240582
tensor(-8.4596, device='cuda:0') tensor(5.3405, device='cuda:0') tensor(1.9967e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.394239
Average KL loss: 0.832399
Average total loss: 1.226639
tensor(-8.4788, device='cuda:0') tensor(5.3720, device='cuda:0') tensor(2.4776e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.403484
Average KL loss: 0.830366
Average total loss: 1.233850
tensor(-8.4977, device='cuda:0') tensor(5.4030, device='cuda:0') tensor(2.4554e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.395255
Average KL loss: 0.828431
Average total loss: 1.223686
tensor(-8.5162, device='cuda:0') tensor(5.4333, device='cuda:0') tensor(2.5034e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.392545
Average KL loss: 0.826341
Average total loss: 1.218886
tensor(-8.5343, device='cuda:0') tensor(5.4628, device='cuda:0') tensor(2.7572e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.397265
Average KL loss: 0.824361
Average total loss: 1.221626
tensor(-8.5521, device='cuda:0') tensor(5.4919, device='cuda:0') tensor(3.1339e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.390469
Average KL loss: 0.822414
Average total loss: 1.212883
tensor(-8.5696, device='cuda:0') tensor(5.5203, device='cuda:0') tensor(2.9109e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.395853
Average KL loss: 0.820441
Average total loss: 1.216294
tensor(-8.5868, device='cuda:0') tensor(5.5482, device='cuda:0') tensor(2.5942e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.394794
Average KL loss: 0.818508
Average total loss: 1.213302
tensor(-8.6037, device='cuda:0') tensor(5.5756, device='cuda:0') tensor(1.5277e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.386768
Average KL loss: 0.816573
Average total loss: 1.203341
tensor(-8.6203, device='cuda:0') tensor(5.6024, device='cuda:0') tensor(2.5207e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.400552
Average KL loss: 0.814651
Average total loss: 1.215202
tensor(-8.6367, device='cuda:0') tensor(5.6288, device='cuda:0') tensor(3.2152e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.390331
Average KL loss: 0.812815
Average total loss: 1.203146
tensor(-8.6528, device='cuda:0') tensor(5.6545, device='cuda:0') tensor(2.8439e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.394104
Average KL loss: 0.810897
Average total loss: 1.205001
tensor(-8.6686, device='cuda:0') tensor(5.6798, device='cuda:0') tensor(2.5454e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.394397
Average KL loss: 0.809098
Average total loss: 1.203495
tensor(-8.6841, device='cuda:0') tensor(5.7048, device='cuda:0') tensor(1.7292e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.383599
Average KL loss: 0.807319
Average total loss: 1.190918
tensor(-8.6995, device='cuda:0') tensor(5.7292, device='cuda:0') tensor(2.8022e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.386980
Average KL loss: 0.805487
Average total loss: 1.192467
tensor(-8.7146, device='cuda:0') tensor(5.7530, device='cuda:0') tensor(2.4247e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.385923
Average KL loss: 0.803698
Average total loss: 1.189620
tensor(-8.7294, device='cuda:0') tensor(5.7764, device='cuda:0') tensor(3.2115e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.384103
Average KL loss: 0.801774
Average total loss: 1.185877
tensor(-8.7441, device='cuda:0') tensor(5.7993, device='cuda:0') tensor(2.8773e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.383439
Average KL loss: 0.799921
Average total loss: 1.183360
tensor(-8.7586, device='cuda:0') tensor(5.8219, device='cuda:0') tensor(3.3003e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.381386
Average KL loss: 0.798139
Average total loss: 1.179525
tensor(-8.7728, device='cuda:0') tensor(5.8440, device='cuda:0') tensor(3.1514e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.381705
Average KL loss: 0.796302
Average total loss: 1.178006
tensor(-8.7869, device='cuda:0') tensor(5.8657, device='cuda:0') tensor(2.1591e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.381915
Average KL loss: 0.794454
Average total loss: 1.176369
tensor(-8.8007, device='cuda:0') tensor(5.8870, device='cuda:0') tensor(2.8066e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.377682
Average KL loss: 0.792653
Average total loss: 1.170335
tensor(-8.8144, device='cuda:0') tensor(5.9081, device='cuda:0') tensor(2.3737e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.375710
Average KL loss: 0.790874
Average total loss: 1.166583
tensor(-8.8279, device='cuda:0') tensor(5.9287, device='cuda:0') tensor(2.6211e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.375740
Average KL loss: 0.789102
Average total loss: 1.164842
tensor(-8.8412, device='cuda:0') tensor(5.9489, device='cuda:0') tensor(2.4932e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.379328
Average KL loss: 0.787315
Average total loss: 1.166642
tensor(-8.8544, device='cuda:0') tensor(5.9688, device='cuda:0') tensor(2.0582e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.375553
Average KL loss: 0.785595
Average total loss: 1.161148
tensor(-8.8674, device='cuda:0') tensor(5.9882, device='cuda:0') tensor(2.4039e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.377259
Average KL loss: 0.783834
Average total loss: 1.161092
tensor(-8.8802, device='cuda:0') tensor(6.0075, device='cuda:0') tensor(2.9535e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.370403
Average KL loss: 0.782017
Average total loss: 1.152419
tensor(-8.8929, device='cuda:0') tensor(6.0262, device='cuda:0') tensor(2.7425e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.374846
Average KL loss: 0.780292
Average total loss: 1.155139
tensor(-8.9054, device='cuda:0') tensor(6.0447, device='cuda:0') tensor(2.1865e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.373182
Average KL loss: 0.778571
Average total loss: 1.151752
tensor(-8.9178, device='cuda:0') tensor(6.0628, device='cuda:0') tensor(2.4191e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.377522
Average KL loss: 0.776824
Average total loss: 1.154346
tensor(-8.9300, device='cuda:0') tensor(6.0806, device='cuda:0') tensor(3.1944e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.367191
Average KL loss: 0.775135
Average total loss: 1.142326
tensor(-8.9421, device='cuda:0') tensor(6.0981, device='cuda:0') tensor(2.5957e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.377118
Average KL loss: 0.773410
Average total loss: 1.150527
tensor(-8.9541, device='cuda:0') tensor(6.1153, device='cuda:0') tensor(2.4589e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.369039
Average KL loss: 0.771733
Average total loss: 1.140772
tensor(-8.9659, device='cuda:0') tensor(6.1322, device='cuda:0') tensor(2.3047e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.367345
Average KL loss: 0.770005
Average total loss: 1.137351
tensor(-8.9776, device='cuda:0') tensor(6.1487, device='cuda:0') tensor(2.9938e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.369490
Average KL loss: 0.768297
Average total loss: 1.137787
tensor(-8.9892, device='cuda:0') tensor(6.1650, device='cuda:0') tensor(2.6787e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.365534
Average KL loss: 0.766674
Average total loss: 1.132208
tensor(-9.0006, device='cuda:0') tensor(6.1811, device='cuda:0') tensor(3.0004e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.368088
Average KL loss: 0.765024
Average total loss: 1.133113
tensor(-9.0119, device='cuda:0') tensor(6.1968, device='cuda:0') tensor(2.2317e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.364658
Average KL loss: 0.763384
Average total loss: 1.128042
tensor(-9.0231, device='cuda:0') tensor(6.2123, device='cuda:0') tensor(2.3111e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.362622
Average KL loss: 0.761709
Average total loss: 1.124331
tensor(-9.0342, device='cuda:0') tensor(6.2275, device='cuda:0') tensor(2.1173e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.368388
Average KL loss: 0.760101
Average total loss: 1.128489
tensor(-9.0452, device='cuda:0') tensor(6.2424, device='cuda:0') tensor(1.9914e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.360862
Average KL loss: 0.758442
Average total loss: 1.119305
tensor(-9.0561, device='cuda:0') tensor(6.2571, device='cuda:0') tensor(2.7461e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.363674
Average KL loss: 0.756809
Average total loss: 1.120483
tensor(-9.0669, device='cuda:0') tensor(6.2715, device='cuda:0') tensor(2.3216e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.363365
Average KL loss: 0.755186
Average total loss: 1.118551
tensor(-9.0775, device='cuda:0') tensor(6.2856, device='cuda:0') tensor(2.7148e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.359872
Average KL loss: 0.753538
Average total loss: 1.113410
tensor(-9.0881, device='cuda:0') tensor(6.2996, device='cuda:0') tensor(2.0113e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.359409
Average KL loss: 0.751949
Average total loss: 1.111358
tensor(-9.0986, device='cuda:0') tensor(6.3133, device='cuda:0') tensor(2.3501e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.362450
Average KL loss: 0.750321
Average total loss: 1.112771
tensor(-9.1089, device='cuda:0') tensor(6.3266, device='cuda:0') tensor(1.7701e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.360995
Average KL loss: 0.748758
Average total loss: 1.109753
tensor(-9.1192, device='cuda:0') tensor(6.3399, device='cuda:0') tensor(2.7925e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.355896
Average KL loss: 0.747193
Average total loss: 1.103090
tensor(-9.1294, device='cuda:0') tensor(6.3529, device='cuda:0') tensor(1.9052e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.356294
Average KL loss: 0.745679
Average total loss: 1.101974
tensor(-9.1394, device='cuda:0') tensor(6.3658, device='cuda:0') tensor(2.3854e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.357743
Average KL loss: 0.744092
Average total loss: 1.101834
tensor(-9.1494, device='cuda:0') tensor(6.3784, device='cuda:0') tensor(2.0253e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.354519
Average KL loss: 0.742533
Average total loss: 1.097052
tensor(-9.1594, device='cuda:0') tensor(6.3906, device='cuda:0') tensor(2.9820e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.354764
Average KL loss: 0.740955
Average total loss: 1.095720
tensor(-9.1692, device='cuda:0') tensor(6.4027, device='cuda:0') tensor(1.6483e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.359511
Average KL loss: 0.739341
Average total loss: 1.098852
tensor(-9.1789, device='cuda:0') tensor(6.4145, device='cuda:0') tensor(3.5003e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.356355
Average KL loss: 0.737776
Average total loss: 1.094131
tensor(-9.1886, device='cuda:0') tensor(6.4261, device='cuda:0') tensor(2.5061e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.348634
Average KL loss: 0.736178
Average total loss: 1.084811
tensor(-9.1981, device='cuda:0') tensor(6.4376, device='cuda:0') tensor(2.6155e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.350933
Average KL loss: 0.734665
Average total loss: 1.085598
tensor(-9.2076, device='cuda:0') tensor(6.4489, device='cuda:0') tensor(2.6230e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.353864
Average KL loss: 0.733206
Average total loss: 1.087069
tensor(-9.2170, device='cuda:0') tensor(6.4601, device='cuda:0') tensor(2.0903e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.348361
Average KL loss: 0.731754
Average total loss: 1.080115
tensor(-9.2264, device='cuda:0') tensor(6.4711, device='cuda:0') tensor(1.9112e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.346855
Average KL loss: 0.730237
Average total loss: 1.077091
tensor(-9.2356, device='cuda:0') tensor(6.4817, device='cuda:0') tensor(2.0511e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.354393
Average KL loss: 0.728699
Average total loss: 1.083092
tensor(-9.2448, device='cuda:0') tensor(6.4923, device='cuda:0') tensor(2.4449e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.344288
Average KL loss: 0.727230
Average total loss: 1.071518
tensor(-9.2539, device='cuda:0') tensor(6.5026, device='cuda:0') tensor(2.0090e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.348124
Average KL loss: 0.725769
Average total loss: 1.073894
tensor(-9.2630, device='cuda:0') tensor(6.5128, device='cuda:0') tensor(1.5098e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.345526
Average KL loss: 0.724274
Average total loss: 1.069800
tensor(-9.2720, device='cuda:0') tensor(6.5227, device='cuda:0') tensor(1.8973e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.356115
Average KL loss: 0.722777
Average total loss: 1.078892
tensor(-9.2809, device='cuda:0') tensor(6.5326, device='cuda:0') tensor(2.0813e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.342535
Average KL loss: 0.721419
Average total loss: 1.063954
tensor(-9.2897, device='cuda:0') tensor(6.5423, device='cuda:0') tensor(2.7397e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.351484
Average KL loss: 0.720020
Average total loss: 1.071504
tensor(-9.2985, device='cuda:0') tensor(6.5519, device='cuda:0') tensor(1.9129e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.341277
Average KL loss: 0.718629
Average total loss: 1.059906
tensor(-9.3072, device='cuda:0') tensor(6.5613, device='cuda:0') tensor(2.1493e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.339263
Average KL loss: 0.717140
Average total loss: 1.056403
tensor(-9.3158, device='cuda:0') tensor(6.5702, device='cuda:0') tensor(2.3554e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.342361
Average KL loss: 0.715690
Average total loss: 1.058051
tensor(-9.3244, device='cuda:0') tensor(6.5792, device='cuda:0') tensor(2.3487e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.339166
Average KL loss: 0.714281
Average total loss: 1.053447
tensor(-9.3329, device='cuda:0') tensor(6.5880, device='cuda:0') tensor(2.6296e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.342749
Average KL loss: 0.712865
Average total loss: 1.055613
tensor(-9.3414, device='cuda:0') tensor(6.5967, device='cuda:0') tensor(2.6392e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.341563
Average KL loss: 0.711484
Average total loss: 1.053048
tensor(-9.3498, device='cuda:0') tensor(6.6052, device='cuda:0') tensor(2.6519e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.340163
Average KL loss: 0.710151
Average total loss: 1.050314
tensor(-9.3581, device='cuda:0') tensor(6.6136, device='cuda:0') tensor(2.3146e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.341942
Average KL loss: 0.708791
Average total loss: 1.050733
tensor(-9.3664, device='cuda:0') tensor(6.6219, device='cuda:0') tensor(2.4481e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.341516
Average KL loss: 0.707461
Average total loss: 1.048977
tensor(-9.3746, device='cuda:0') tensor(6.6301, device='cuda:0') tensor(2.2609e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.339670
Average KL loss: 0.706138
Average total loss: 1.045808
tensor(-9.3828, device='cuda:0') tensor(6.6381, device='cuda:0') tensor(2.1548e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.336190
Average KL loss: 0.704712
Average total loss: 1.040902
tensor(-9.3909, device='cuda:0') tensor(6.6456, device='cuda:0') tensor(1.7739e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.336890
Average KL loss: 0.703322
Average total loss: 1.040212
tensor(-9.3990, device='cuda:0') tensor(6.6534, device='cuda:0') tensor(2.1415e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.338332
Average KL loss: 0.702060
Average total loss: 1.040392
tensor(-9.4070, device='cuda:0') tensor(6.6610, device='cuda:0') tensor(2.8784e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.335847
Average KL loss: 0.700747
Average total loss: 1.036594
tensor(-9.4149, device='cuda:0') tensor(6.6685, device='cuda:0') tensor(2.1731e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.331769
Average KL loss: 0.699443
Average total loss: 1.031212
tensor(-9.4228, device='cuda:0') tensor(6.6755, device='cuda:0') tensor(2.0904e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.335434
Average KL loss: 0.698068
Average total loss: 1.033502
tensor(-9.4307, device='cuda:0') tensor(6.6826, device='cuda:0') tensor(2.3986e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.333842
Average KL loss: 0.696729
Average total loss: 1.030571
tensor(-9.4385, device='cuda:0') tensor(6.6894, device='cuda:0') tensor(1.4918e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.337906
Average KL loss: 0.695427
Average total loss: 1.033334
tensor(-9.4463, device='cuda:0') tensor(6.6964, device='cuda:0') tensor(2.1710e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.328830
Average KL loss: 0.694120
Average total loss: 1.022950
tensor(-9.4540, device='cuda:0') tensor(6.7030, device='cuda:0') tensor(2.2000e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.331647
Average KL loss: 0.692813
Average total loss: 1.024460
tensor(-9.4617, device='cuda:0') tensor(6.7095, device='cuda:0') tensor(2.0447e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.327103
Average KL loss: 0.691508
Average total loss: 1.018611
tensor(-9.4693, device='cuda:0') tensor(6.7160, device='cuda:0') tensor(1.8623e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.327500
Average KL loss: 0.690164
Average total loss: 1.017665
tensor(-9.4768, device='cuda:0') tensor(6.7221, device='cuda:0') tensor(1.8888e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.329695
Average KL loss: 0.688780
Average total loss: 1.018475
tensor(-9.4844, device='cuda:0') tensor(6.7281, device='cuda:0') tensor(2.0167e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.331332
Average KL loss: 0.687459
Average total loss: 1.018791
tensor(-9.4919, device='cuda:0') tensor(6.7342, device='cuda:0') tensor(1.9684e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.330345
Average KL loss: 0.686156
Average total loss: 1.016501
tensor(-9.4993, device='cuda:0') tensor(6.7401, device='cuda:0') tensor(2.3537e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.328925
Average KL loss: 0.684848
Average total loss: 1.013773
tensor(-9.5067, device='cuda:0') tensor(6.7459, device='cuda:0') tensor(1.6370e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.324737
Average KL loss: 0.683533
Average total loss: 1.008269
tensor(-9.5141, device='cuda:0') tensor(6.7516, device='cuda:0') tensor(2.2062e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.331238
Average KL loss: 0.682286
Average total loss: 1.013524
tensor(-9.5214, device='cuda:0') tensor(6.7571, device='cuda:0') tensor(1.9902e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.324575
Average KL loss: 0.680995
Average total loss: 1.005571
tensor(-9.5286, device='cuda:0') tensor(6.7627, device='cuda:0') tensor(1.5745e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.326627
Average KL loss: 0.679733
Average total loss: 1.006360
tensor(-9.5359, device='cuda:0') tensor(6.7681, device='cuda:0') tensor(2.0637e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.327170
Average KL loss: 0.678487
Average total loss: 1.005657
tensor(-9.5431, device='cuda:0') tensor(6.7733, device='cuda:0') tensor(1.8346e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.321501
Average KL loss: 0.677250
Average total loss: 0.998751
tensor(-9.5502, device='cuda:0') tensor(6.7784, device='cuda:0') tensor(1.8875e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.322564
Average KL loss: 0.675983
Average total loss: 0.998547
tensor(-9.5573, device='cuda:0') tensor(6.7833, device='cuda:0') tensor(2.4985e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.323029
Average KL loss: 0.674686
Average total loss: 0.997715
tensor(-9.5644, device='cuda:0') tensor(6.7881, device='cuda:0') tensor(2.4089e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.326046
Average KL loss: 0.673440
Average total loss: 0.999486
tensor(-9.5715, device='cuda:0') tensor(6.7929, device='cuda:0') tensor(1.8451e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.316923
Average KL loss: 0.672299
Average total loss: 0.989222
tensor(-9.5784, device='cuda:0') tensor(6.7978, device='cuda:0') tensor(1.7286e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.317696
Average KL loss: 0.671078
Average total loss: 0.988774
tensor(-9.5854, device='cuda:0') tensor(6.8023, device='cuda:0') tensor(2.3949e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.324387
Average KL loss: 0.669838
Average total loss: 0.994225
tensor(-9.5923, device='cuda:0') tensor(6.8067, device='cuda:0') tensor(2.5784e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.322592
Average KL loss: 0.668657
Average total loss: 0.991249
tensor(-9.5992, device='cuda:0') tensor(6.8112, device='cuda:0') tensor(2.3973e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.320461
Average KL loss: 0.667454
Average total loss: 0.987915
tensor(-9.6061, device='cuda:0') tensor(6.8155, device='cuda:0') tensor(1.2381e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.317547
Average KL loss: 0.666241
Average total loss: 0.983789
tensor(-9.6129, device='cuda:0') tensor(6.8196, device='cuda:0') tensor(2.1570e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.317968
Average KL loss: 0.664985
Average total loss: 0.982952
tensor(-9.6197, device='cuda:0') tensor(6.8236, device='cuda:0') tensor(2.0407e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.319973
Average KL loss: 0.663806
Average total loss: 0.983779
tensor(-9.6264, device='cuda:0') tensor(6.8276, device='cuda:0') tensor(1.6941e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.316119
Average KL loss: 0.662660
Average total loss: 0.978779
tensor(-9.6332, device='cuda:0') tensor(6.8315, device='cuda:0') tensor(2.1208e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.315032
Average KL loss: 0.661463
Average total loss: 0.976495
tensor(-9.6398, device='cuda:0') tensor(6.8352, device='cuda:0') tensor(1.8212e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.313227
Average KL loss: 0.660240
Average total loss: 0.973467
tensor(-9.6465, device='cuda:0') tensor(6.8389, device='cuda:0') tensor(2.0390e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.316501
Average KL loss: 0.659082
Average total loss: 0.975583
tensor(-9.6531, device='cuda:0') tensor(6.8426, device='cuda:0') tensor(1.9587e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.312350
Average KL loss: 0.657897
Average total loss: 0.970247
tensor(-9.6597, device='cuda:0') tensor(6.8460, device='cuda:0') tensor(1.9522e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.313873
Average KL loss: 0.656701
Average total loss: 0.970574
tensor(-9.6663, device='cuda:0') tensor(6.8494, device='cuda:0') tensor(1.6274e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.313124
Average KL loss: 0.655564
Average total loss: 0.968689
tensor(-9.6728, device='cuda:0') tensor(6.8529, device='cuda:0') tensor(1.6041e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.310955
Average KL loss: 0.654438
Average total loss: 0.965393
tensor(-9.6793, device='cuda:0') tensor(6.8563, device='cuda:0') tensor(2.0829e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.311060
Average KL loss: 0.653318
Average total loss: 0.964378
tensor(-9.6857, device='cuda:0') tensor(6.8595, device='cuda:0') tensor(2.0273e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.310029
Average KL loss: 0.652115
Average total loss: 0.962144
tensor(-9.6922, device='cuda:0') tensor(6.8625, device='cuda:0') tensor(2.0378e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.308641
Average KL loss: 0.650912
Average total loss: 0.959553
tensor(-9.6986, device='cuda:0') tensor(6.8653, device='cuda:0') tensor(1.5091e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.310367
Average KL loss: 0.649797
Average total loss: 0.960164
tensor(-9.7050, device='cuda:0') tensor(6.8682, device='cuda:0') tensor(1.5537e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.301968
Average KL loss: 0.648645
Average total loss: 0.950613
tensor(-9.7113, device='cuda:0') tensor(6.8709, device='cuda:0') tensor(2.3329e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.309530
Average KL loss: 0.647428
Average total loss: 0.956957
tensor(-9.7176, device='cuda:0') tensor(6.8735, device='cuda:0') tensor(1.2174e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.306539
Average KL loss: 0.646311
Average total loss: 0.952850
tensor(-9.7239, device='cuda:0') tensor(6.8762, device='cuda:0') tensor(2.0351e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.307705
Average KL loss: 0.645191
Average total loss: 0.952896
tensor(-9.7302, device='cuda:0') tensor(6.8787, device='cuda:0') tensor(1.5807e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.306169
Average KL loss: 0.644072
Average total loss: 0.950241
tensor(-9.7365, device='cuda:0') tensor(6.8812, device='cuda:0') tensor(2.1789e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.305574
Average KL loss: 0.642949
Average total loss: 0.948524
tensor(-9.7427, device='cuda:0') tensor(6.8837, device='cuda:0') tensor(2.0576e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.305514
Average KL loss: 0.641821
Average total loss: 0.947335
tensor(-9.7488, device='cuda:0') tensor(6.8860, device='cuda:0') tensor(1.4666e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.305809
Average KL loss: 0.640726
Average total loss: 0.946535
tensor(-9.7550, device='cuda:0') tensor(6.8883, device='cuda:0') tensor(1.4288e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.301676
Average KL loss: 0.639679
Average total loss: 0.941355
tensor(-9.7611, device='cuda:0') tensor(6.8905, device='cuda:0') tensor(1.4352e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.303649
Average KL loss: 0.638591
Average total loss: 0.942240
tensor(-9.7672, device='cuda:0') tensor(6.8927, device='cuda:0') tensor(2.0124e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.294298
Average KL loss: 0.637530
Average total loss: 0.931828
tensor(-9.7733, device='cuda:0') tensor(6.8947, device='cuda:0') tensor(1.8268e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.302063
Average KL loss: 0.636400
Average total loss: 0.938462
tensor(-9.7794, device='cuda:0') tensor(6.8967, device='cuda:0') tensor(1.9412e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.304971
Average KL loss: 0.635344
Average total loss: 0.940314
tensor(-9.7854, device='cuda:0') tensor(6.8986, device='cuda:0') tensor(2.0611e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.299886
Average KL loss: 0.634313
Average total loss: 0.934199
tensor(-9.7914, device='cuda:0') tensor(6.9005, device='cuda:0') tensor(1.8945e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.302240
Average KL loss: 0.633300
Average total loss: 0.935540
tensor(-9.7974, device='cuda:0') tensor(6.9023, device='cuda:0') tensor(1.7927e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.303484
Average KL loss: 0.632276
Average total loss: 0.935759
tensor(-9.8034, device='cuda:0') tensor(6.9040, device='cuda:0') tensor(1.9075e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.296329
Average KL loss: 0.631228
Average total loss: 0.927557
tensor(-9.8093, device='cuda:0') tensor(6.9056, device='cuda:0') tensor(1.4831e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.293394
Average KL loss: 0.630174
Average total loss: 0.923567
tensor(-9.8152, device='cuda:0') tensor(6.9071, device='cuda:0') tensor(2.1083e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.300902
Average KL loss: 0.629113
Average total loss: 0.930014
tensor(-9.8211, device='cuda:0') tensor(6.9085, device='cuda:0') tensor(2.0784e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.297764
Average KL loss: 0.628089
Average total loss: 0.925852
tensor(-9.8270, device='cuda:0') tensor(6.9098, device='cuda:0') tensor(2.1027e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.293770
Average KL loss: 0.627072
Average total loss: 0.920842
tensor(-9.8328, device='cuda:0') tensor(6.9112, device='cuda:0') tensor(1.5114e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.294587
Average KL loss: 0.626030
Average total loss: 0.920616
tensor(-9.8386, device='cuda:0') tensor(6.9126, device='cuda:0') tensor(1.7209e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.295172
Average KL loss: 0.625070
Average total loss: 0.920242
tensor(-9.8444, device='cuda:0') tensor(6.9138, device='cuda:0') tensor(1.8669e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.289032
Average KL loss: 0.624056
Average total loss: 0.913089
tensor(-9.8502, device='cuda:0') tensor(6.9150, device='cuda:0') tensor(1.6492e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.296554
Average KL loss: 0.623010
Average total loss: 0.919564
tensor(-9.8560, device='cuda:0') tensor(6.9160, device='cuda:0') tensor(1.8799e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.297094
Average KL loss: 0.622028
Average total loss: 0.919122
tensor(-9.8617, device='cuda:0') tensor(6.9171, device='cuda:0') tensor(1.7394e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.290675
Average KL loss: 0.621048
Average total loss: 0.911723
tensor(-9.8674, device='cuda:0') tensor(6.9181, device='cuda:0') tensor(7.5584e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.294537
Average KL loss: 0.620023
Average total loss: 0.914560
tensor(-9.8731, device='cuda:0') tensor(6.9189, device='cuda:0') tensor(1.7214e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.294043
Average KL loss: 0.618969
Average total loss: 0.913012
tensor(-9.8788, device='cuda:0') tensor(6.9196, device='cuda:0') tensor(1.7654e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.292164
Average KL loss: 0.617957
Average total loss: 0.910121
tensor(-9.8845, device='cuda:0') tensor(6.9205, device='cuda:0') tensor(1.2119e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.293059
Average KL loss: 0.616944
Average total loss: 0.910004
tensor(-9.8901, device='cuda:0') tensor(6.9213, device='cuda:0') tensor(1.8708e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.293736
Average KL loss: 0.615989
Average total loss: 0.909725
tensor(-9.8957, device='cuda:0') tensor(6.9219, device='cuda:0') tensor(1.5595e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.288262
Average KL loss: 0.615006
Average total loss: 0.903267
tensor(-9.9013, device='cuda:0') tensor(6.9224, device='cuda:0') tensor(1.7394e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.288824
Average KL loss: 0.613959
Average total loss: 0.902782
tensor(-9.9069, device='cuda:0') tensor(6.9229, device='cuda:0') tensor(1.8170e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.291228
Average KL loss: 0.612974
Average total loss: 0.904202
tensor(-9.9124, device='cuda:0') tensor(6.9234, device='cuda:0') tensor(1.3395e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.290269
Average KL loss: 0.612041
Average total loss: 0.902310
tensor(-9.9180, device='cuda:0') tensor(6.9239, device='cuda:0') tensor(1.9360e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.291041
Average KL loss: 0.611058
Average total loss: 0.902099
tensor(-9.9235, device='cuda:0') tensor(6.9243, device='cuda:0') tensor(1.6960e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.291473
Average KL loss: 0.610094
Average total loss: 0.901567
tensor(-9.9290, device='cuda:0') tensor(6.9246, device='cuda:0') tensor(1.1429e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.290135
Average KL loss: 0.609136
Average total loss: 0.899272
tensor(-9.9345, device='cuda:0') tensor(6.9249, device='cuda:0') tensor(1.6789e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.283833
Average KL loss: 0.608184
Average total loss: 0.892017
 Percentile value: -3.8880393981933596
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =    1562 /    1728             ( 90.39%) | total_pruned =     166 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   15272 /   36864             ( 41.43%) | total_pruned =   21592 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   15456 /   36864             ( 41.93%) | total_pruned =   21408 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   14685 /   36864             ( 39.84%) | total_pruned =   22179 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   13622 /   36864             ( 36.95%) | total_pruned =   23242 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   27126 /   73728             ( 36.79%) | total_pruned =   46602 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   44100 /  147456             ( 29.91%) | total_pruned =  103356 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5316 /    8192             ( 64.89%) | total_pruned =    2876 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   36856 /  147456             ( 24.99%) | total_pruned =  110600 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   36032 /  147456             ( 24.44%) | total_pruned =  111424 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   72874 /  294912             ( 24.71%) | total_pruned =  222038 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  112043 /  589824             ( 19.00%) | total_pruned =  477781 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   15394 /   32768             ( 46.98%) | total_pruned =   17374 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   64923 /  589824             ( 11.01%) | total_pruned =  524901 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     204 /     256             ( 79.69%) | total_pruned =      52 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   67085 /  589824             ( 11.37%) | total_pruned =  522739 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  133037 / 1179648             ( 11.28%) | total_pruned = 1046611 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     445 /     512             ( 86.91%) | total_pruned =      67 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  134877 / 2359296             (  5.72%) | total_pruned = 2224419 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   29623 /  131072             ( 22.60%) | total_pruned =  101449 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   73950 / 2359296             (  3.13%) | total_pruned = 2285346 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     363 /     512             ( 70.90%) | total_pruned =     149 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     171 /     512             ( 33.40%) | total_pruned =     341 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   78765 / 2359296             (  3.34%) | total_pruned = 2280531 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
linear.weight        | nonzeros =    4728 /    5120             ( 92.34%) | total_pruned =     392 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       6 /      10             ( 60.00%) | total_pruned =       4 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 22/200 Loss: 0.000003 Accuracy: 87.36 100.00 % Best test Accuracy: 87.36%
tensor(-9.9399, device='cuda:0') tensor(6.9250, device='cuda:0') tensor(1.0866e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.357693
Average KL loss: 0.586556
Average total loss: 0.944249
tensor(-10.0052, device='cuda:0') tensor(6.4509, device='cuda:0') tensor(1.1193e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.342226
Average KL loss: 0.569244
Average total loss: 0.911470
tensor(-10.0530, device='cuda:0') tensor(6.1612, device='cuda:0') tensor(9.8674e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.334413
Average KL loss: 0.561549
Average total loss: 0.895962
tensor(-10.0924, device='cuda:0') tensor(5.9472, device='cuda:0') tensor(1.1154e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.340178
Average KL loss: 0.556859
Average total loss: 0.897037
tensor(-10.1266, device='cuda:0') tensor(5.7780, device='cuda:0') tensor(1.3431e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.335478
Average KL loss: 0.553611
Average total loss: 0.889089
tensor(-10.1569, device='cuda:0') tensor(5.6390, device='cuda:0') tensor(1.0438e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.335150
Average KL loss: 0.551184
Average total loss: 0.886334
tensor(-10.1844, device='cuda:0') tensor(5.5222, device='cuda:0') tensor(7.0468e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.330389
Average KL loss: 0.549292
Average total loss: 0.879681
tensor(-10.2095, device='cuda:0') tensor(5.4220, device='cuda:0') tensor(7.5688e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.330162
Average KL loss: 0.547712
Average total loss: 0.877874
tensor(-10.2328, device='cuda:0') tensor(5.3350, device='cuda:0') tensor(6.8875e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.325046
Average KL loss: 0.546375
Average total loss: 0.871421
tensor(-10.2545, device='cuda:0') tensor(5.2584, device='cuda:0') tensor(1.0119e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.323749
Average KL loss: 0.545204
Average total loss: 0.868953
tensor(-10.2749, device='cuda:0') tensor(5.1906, device='cuda:0') tensor(6.5180e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.322547
Average KL loss: 0.544227
Average total loss: 0.866774
tensor(-10.2941, device='cuda:0') tensor(5.1299, device='cuda:0') tensor(4.6888e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.318468
Average KL loss: 0.543342
Average total loss: 0.861809
tensor(-10.3123, device='cuda:0') tensor(5.0754, device='cuda:0') tensor(1.2795e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.320890
Average KL loss: 0.542481
Average total loss: 0.863372
tensor(-10.3297, device='cuda:0') tensor(5.0260, device='cuda:0') tensor(1.2134e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.316127
Average KL loss: 0.541739
Average total loss: 0.857866
tensor(-10.3462, device='cuda:0') tensor(4.9811, device='cuda:0') tensor(1.0030e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.316432
Average KL loss: 0.541001
Average total loss: 0.857433
tensor(-10.3621, device='cuda:0') tensor(4.9401, device='cuda:0') tensor(7.4210e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.309370
Average KL loss: 0.540346
Average total loss: 0.849715
tensor(-10.3774, device='cuda:0') tensor(4.9024, device='cuda:0') tensor(8.7496e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.308130
Average KL loss: 0.539675
Average total loss: 0.847805
tensor(-10.3921, device='cuda:0') tensor(4.8677, device='cuda:0') tensor(8.8165e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.312226
Average KL loss: 0.539070
Average total loss: 0.851296
tensor(-10.4062, device='cuda:0') tensor(4.8358, device='cuda:0') tensor(8.0135e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.303779
Average KL loss: 0.538500
Average total loss: 0.842278
tensor(-10.4199, device='cuda:0') tensor(4.8062, device='cuda:0') tensor(1.8156e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.303963
Average KL loss: 0.537931
Average total loss: 0.841894
tensor(-10.4332, device='cuda:0') tensor(4.7788, device='cuda:0') tensor(4.9587e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.308814
Average KL loss: 0.537443
Average total loss: 0.846257
tensor(-10.4460, device='cuda:0') tensor(4.7533, device='cuda:0') tensor(7.4431e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.303842
Average KL loss: 0.536903
Average total loss: 0.840745
tensor(-10.4585, device='cuda:0') tensor(4.7294, device='cuda:0') tensor(5.9640e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.304432
Average KL loss: 0.536366
Average total loss: 0.840798
tensor(-10.4707, device='cuda:0') tensor(4.7071, device='cuda:0') tensor(1.0342e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.295787
Average KL loss: 0.535853
Average total loss: 0.831640
tensor(-10.4825, device='cuda:0') tensor(4.6862, device='cuda:0') tensor(9.2564e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.301839
Average KL loss: 0.535370
Average total loss: 0.837209
tensor(-10.4941, device='cuda:0') tensor(4.6666, device='cuda:0') tensor(6.9792e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.304526
Average KL loss: 0.534871
Average total loss: 0.839396
tensor(-10.5054, device='cuda:0') tensor(4.6481, device='cuda:0') tensor(1.0219e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.298895
Average KL loss: 0.534394
Average total loss: 0.833289
tensor(-10.5164, device='cuda:0') tensor(4.6308, device='cuda:0') tensor(1.2761e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.304630
Average KL loss: 0.533921
Average total loss: 0.838551
tensor(-10.5271, device='cuda:0') tensor(4.6145, device='cuda:0') tensor(1.5388e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.298952
Average KL loss: 0.533450
Average total loss: 0.832402
tensor(-10.5377, device='cuda:0') tensor(4.5990, device='cuda:0') tensor(6.7409e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.298016
Average KL loss: 0.532982
Average total loss: 0.830998
tensor(-10.5480, device='cuda:0') tensor(4.5846, device='cuda:0') tensor(9.0246e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.297710
Average KL loss: 0.532560
Average total loss: 0.830270
tensor(-10.5581, device='cuda:0') tensor(4.5710, device='cuda:0') tensor(8.9376e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.294625
Average KL loss: 0.532132
Average total loss: 0.826757
tensor(-10.5680, device='cuda:0') tensor(4.5580, device='cuda:0') tensor(1.2658e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.292836
Average KL loss: 0.531652
Average total loss: 0.824488
tensor(-10.5777, device='cuda:0') tensor(4.5455, device='cuda:0') tensor(1.4891e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.289977
Average KL loss: 0.531163
Average total loss: 0.821140
tensor(-10.5873, device='cuda:0') tensor(4.5337, device='cuda:0') tensor(1.3957e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.287087
Average KL loss: 0.530703
Average total loss: 0.817789
tensor(-10.5967, device='cuda:0') tensor(4.5225, device='cuda:0') tensor(1.2716e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.290419
Average KL loss: 0.530222
Average total loss: 0.820641
tensor(-10.6059, device='cuda:0') tensor(4.5118, device='cuda:0') tensor(1.0960e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.292838
Average KL loss: 0.529764
Average total loss: 0.822602
tensor(-10.6150, device='cuda:0') tensor(4.5017, device='cuda:0') tensor(8.7593e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.290424
Average KL loss: 0.529349
Average total loss: 0.819773
tensor(-10.6239, device='cuda:0') tensor(4.4921, device='cuda:0') tensor(1.0884e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.288731
Average KL loss: 0.528865
Average total loss: 0.817596
tensor(-10.6327, device='cuda:0') tensor(4.4827, device='cuda:0') tensor(7.3125e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.288703
Average KL loss: 0.528427
Average total loss: 0.817130
tensor(-10.6413, device='cuda:0') tensor(4.4740, device='cuda:0') tensor(8.7820e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.281218
Average KL loss: 0.528000
Average total loss: 0.809218
tensor(-10.6499, device='cuda:0') tensor(4.4656, device='cuda:0') tensor(9.0127e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.286288
Average KL loss: 0.527522
Average total loss: 0.813810
tensor(-10.6583, device='cuda:0') tensor(4.4576, device='cuda:0') tensor(1.1386e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.289491
Average KL loss: 0.527061
Average total loss: 0.816552
tensor(-10.6665, device='cuda:0') tensor(4.4500, device='cuda:0') tensor(8.8659e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.280161
Average KL loss: 0.526621
Average total loss: 0.806782
tensor(-10.6747, device='cuda:0') tensor(4.4427, device='cuda:0') tensor(1.5776e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.284706
Average KL loss: 0.526184
Average total loss: 0.810889
tensor(-10.6828, device='cuda:0') tensor(4.4357, device='cuda:0') tensor(8.7790e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.279820
Average KL loss: 0.525762
Average total loss: 0.805582
tensor(-10.6907, device='cuda:0') tensor(4.4290, device='cuda:0') tensor(7.1488e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.283337
Average KL loss: 0.525302
Average total loss: 0.808638
tensor(-10.6986, device='cuda:0') tensor(4.4225, device='cuda:0') tensor(6.6576e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.280412
Average KL loss: 0.524868
Average total loss: 0.805280
tensor(-10.7063, device='cuda:0') tensor(4.4163, device='cuda:0') tensor(9.8783e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.279767
Average KL loss: 0.524408
Average total loss: 0.804175
tensor(-10.7140, device='cuda:0') tensor(4.4103, device='cuda:0') tensor(1.0958e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.281953
Average KL loss: 0.523960
Average total loss: 0.805913
tensor(-10.7215, device='cuda:0') tensor(4.4046, device='cuda:0') tensor(6.9706e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.285261
Average KL loss: 0.523553
Average total loss: 0.808814
tensor(-10.7290, device='cuda:0') tensor(4.3992, device='cuda:0') tensor(3.6392e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.282255
Average KL loss: 0.523138
Average total loss: 0.805393
tensor(-10.7364, device='cuda:0') tensor(4.3939, device='cuda:0') tensor(9.5449e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.272643
Average KL loss: 0.522719
Average total loss: 0.795362
tensor(-10.7437, device='cuda:0') tensor(4.3887, device='cuda:0') tensor(1.1939e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.276794
Average KL loss: 0.522292
Average total loss: 0.799086
tensor(-10.7509, device='cuda:0') tensor(4.3838, device='cuda:0') tensor(9.9407e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.275074
Average KL loss: 0.521858
Average total loss: 0.796932
tensor(-10.7581, device='cuda:0') tensor(4.3790, device='cuda:0') tensor(1.3448e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.274579
Average KL loss: 0.521444
Average total loss: 0.796023
tensor(-10.7651, device='cuda:0') tensor(4.3745, device='cuda:0') tensor(1.0476e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.275748
Average KL loss: 0.520977
Average total loss: 0.796724
tensor(-10.7721, device='cuda:0') tensor(4.3700, device='cuda:0') tensor(7.9758e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.274169
Average KL loss: 0.520506
Average total loss: 0.794675
tensor(-10.7791, device='cuda:0') tensor(4.3657, device='cuda:0') tensor(1.3078e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.276023
Average KL loss: 0.520044
Average total loss: 0.796067
tensor(-10.7859, device='cuda:0') tensor(4.3615, device='cuda:0') tensor(1.0914e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.269850
Average KL loss: 0.519564
Average total loss: 0.789414
tensor(-10.7927, device='cuda:0') tensor(4.3576, device='cuda:0') tensor(1.6681e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.272228
Average KL loss: 0.519120
Average total loss: 0.791348
tensor(-10.7994, device='cuda:0') tensor(4.3539, device='cuda:0') tensor(4.4545e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.273544
Average KL loss: 0.518687
Average total loss: 0.792231
tensor(-10.8061, device='cuda:0') tensor(4.3501, device='cuda:0') tensor(9.2105e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.272140
Average KL loss: 0.518233
Average total loss: 0.790373
tensor(-10.8127, device='cuda:0') tensor(4.3465, device='cuda:0') tensor(7.3527e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.268556
Average KL loss: 0.517802
Average total loss: 0.786358
tensor(-10.8192, device='cuda:0') tensor(4.3429, device='cuda:0') tensor(1.1954e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.268432
Average KL loss: 0.517341
Average total loss: 0.785773
tensor(-10.8257, device='cuda:0') tensor(4.3396, device='cuda:0') tensor(1.1430e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.270788
Average KL loss: 0.516887
Average total loss: 0.787675
tensor(-10.8321, device='cuda:0') tensor(4.3364, device='cuda:0') tensor(9.7592e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.267558
Average KL loss: 0.516440
Average total loss: 0.783998
tensor(-10.8384, device='cuda:0') tensor(4.3332, device='cuda:0') tensor(7.7028e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.267309
Average KL loss: 0.515938
Average total loss: 0.783247
tensor(-10.8447, device='cuda:0') tensor(4.3301, device='cuda:0') tensor(9.5220e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.268439
Average KL loss: 0.515480
Average total loss: 0.783919
tensor(-10.8510, device='cuda:0') tensor(4.3271, device='cuda:0') tensor(1.1241e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.264742
Average KL loss: 0.515035
Average total loss: 0.779777
tensor(-10.8571, device='cuda:0') tensor(4.3242, device='cuda:0') tensor(8.5710e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.264009
Average KL loss: 0.514564
Average total loss: 0.778573
tensor(-10.8633, device='cuda:0') tensor(4.3215, device='cuda:0') tensor(9.5463e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.267539
Average KL loss: 0.514165
Average total loss: 0.781704
tensor(-10.8694, device='cuda:0') tensor(4.3188, device='cuda:0') tensor(1.1296e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.266617
Average KL loss: 0.513763
Average total loss: 0.780380
tensor(-10.8754, device='cuda:0') tensor(4.3162, device='cuda:0') tensor(1.0422e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.262999
Average KL loss: 0.513354
Average total loss: 0.776352
tensor(-10.8814, device='cuda:0') tensor(4.3137, device='cuda:0') tensor(6.6325e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.263161
Average KL loss: 0.512905
Average total loss: 0.776066
tensor(-10.8873, device='cuda:0') tensor(4.3112, device='cuda:0') tensor(8.3618e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.261205
Average KL loss: 0.512519
Average total loss: 0.773725
tensor(-10.8932, device='cuda:0') tensor(4.3089, device='cuda:0') tensor(1.0055e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.262431
Average KL loss: 0.512101
Average total loss: 0.774532
tensor(-10.8990, device='cuda:0') tensor(4.3066, device='cuda:0') tensor(5.1326e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.260263
Average KL loss: 0.511686
Average total loss: 0.771949
tensor(-10.9048, device='cuda:0') tensor(4.3043, device='cuda:0') tensor(1.2879e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.261835
Average KL loss: 0.511249
Average total loss: 0.773084
tensor(-10.9106, device='cuda:0') tensor(4.3019, device='cuda:0') tensor(6.0522e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.260708
Average KL loss: 0.510779
Average total loss: 0.771487
tensor(-10.9163, device='cuda:0') tensor(4.2996, device='cuda:0') tensor(1.1334e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.259643
Average KL loss: 0.510338
Average total loss: 0.769981
tensor(-10.9220, device='cuda:0') tensor(4.2974, device='cuda:0') tensor(3.8372e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.263541
Average KL loss: 0.509929
Average total loss: 0.773470
tensor(-10.9276, device='cuda:0') tensor(4.2955, device='cuda:0') tensor(9.5207e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.260809
Average KL loss: 0.509513
Average total loss: 0.770322
tensor(-10.9332, device='cuda:0') tensor(4.2934, device='cuda:0') tensor(5.9818e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.261484
Average KL loss: 0.509041
Average total loss: 0.770526
tensor(-10.9388, device='cuda:0') tensor(4.2913, device='cuda:0') tensor(7.9575e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.259182
Average KL loss: 0.508628
Average total loss: 0.767811
tensor(-10.9443, device='cuda:0') tensor(4.2894, device='cuda:0') tensor(9.3884e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.255781
Average KL loss: 0.508208
Average total loss: 0.763989
tensor(-10.9497, device='cuda:0') tensor(4.2875, device='cuda:0') tensor(1.1713e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.253643
Average KL loss: 0.507743
Average total loss: 0.761386
tensor(-10.9552, device='cuda:0') tensor(4.2856, device='cuda:0') tensor(9.5797e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.251935
Average KL loss: 0.507287
Average total loss: 0.759221
tensor(-10.9606, device='cuda:0') tensor(4.2838, device='cuda:0') tensor(6.2277e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.251603
Average KL loss: 0.506831
Average total loss: 0.758435
tensor(-10.9659, device='cuda:0') tensor(4.2820, device='cuda:0') tensor(9.0759e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.253249
Average KL loss: 0.506392
Average total loss: 0.759640
tensor(-10.9713, device='cuda:0') tensor(4.2803, device='cuda:0') tensor(1.3005e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.251099
Average KL loss: 0.505945
Average total loss: 0.757043
tensor(-10.9766, device='cuda:0') tensor(4.2785, device='cuda:0') tensor(1.1882e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.256924
Average KL loss: 0.505494
Average total loss: 0.762418
tensor(-10.9818, device='cuda:0') tensor(4.2768, device='cuda:0') tensor(4.3896e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.257706
Average KL loss: 0.505112
Average total loss: 0.762817
tensor(-10.9870, device='cuda:0') tensor(4.2752, device='cuda:0') tensor(9.4555e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.255285
Average KL loss: 0.504707
Average total loss: 0.759992
tensor(-10.9922, device='cuda:0') tensor(4.2736, device='cuda:0') tensor(7.4770e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.253130
Average KL loss: 0.504281
Average total loss: 0.757411
tensor(-10.9974, device='cuda:0') tensor(4.2720, device='cuda:0') tensor(1.0409e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.252892
Average KL loss: 0.503887
Average total loss: 0.756780
tensor(-11.0025, device='cuda:0') tensor(4.2705, device='cuda:0') tensor(6.3639e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.251338
Average KL loss: 0.503494
Average total loss: 0.754833
tensor(-11.0076, device='cuda:0') tensor(4.2690, device='cuda:0') tensor(9.3474e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.253214
Average KL loss: 0.503070
Average total loss: 0.756283
tensor(-11.0126, device='cuda:0') tensor(4.2676, device='cuda:0') tensor(7.8084e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.251691
Average KL loss: 0.502677
Average total loss: 0.754368
tensor(-11.0177, device='cuda:0') tensor(4.2660, device='cuda:0') tensor(1.1648e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.250320
Average KL loss: 0.502217
Average total loss: 0.752537
tensor(-11.0227, device='cuda:0') tensor(4.2646, device='cuda:0') tensor(5.6997e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.246088
Average KL loss: 0.501817
Average total loss: 0.747906
tensor(-11.0276, device='cuda:0') tensor(4.2633, device='cuda:0') tensor(8.3625e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.246474
Average KL loss: 0.501384
Average total loss: 0.747858
tensor(-11.0326, device='cuda:0') tensor(4.2618, device='cuda:0') tensor(9.5536e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.247014
Average KL loss: 0.500940
Average total loss: 0.747953
tensor(-11.0375, device='cuda:0') tensor(4.2603, device='cuda:0') tensor(6.7644e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.243866
Average KL loss: 0.500474
Average total loss: 0.744339
tensor(-11.0424, device='cuda:0') tensor(4.2589, device='cuda:0') tensor(7.5565e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.243993
Average KL loss: 0.500001
Average total loss: 0.743994
tensor(-11.0472, device='cuda:0') tensor(4.2574, device='cuda:0') tensor(5.0317e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.246317
Average KL loss: 0.499579
Average total loss: 0.745896
tensor(-11.0521, device='cuda:0') tensor(4.2560, device='cuda:0') tensor(6.8562e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.245731
Average KL loss: 0.499136
Average total loss: 0.744867
tensor(-11.0569, device='cuda:0') tensor(4.2546, device='cuda:0') tensor(6.5803e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.240865
Average KL loss: 0.498684
Average total loss: 0.739549
tensor(-11.0616, device='cuda:0') tensor(4.2532, device='cuda:0') tensor(6.9103e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.242404
Average KL loss: 0.498289
Average total loss: 0.740693
tensor(-11.0664, device='cuda:0') tensor(4.2519, device='cuda:0') tensor(1.0776e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.244538
Average KL loss: 0.497849
Average total loss: 0.742388
tensor(-11.0711, device='cuda:0') tensor(4.2506, device='cuda:0') tensor(6.3104e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.247558
Average KL loss: 0.497419
Average total loss: 0.744977
tensor(-11.0758, device='cuda:0') tensor(4.2492, device='cuda:0') tensor(6.7824e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.239282
Average KL loss: 0.496997
Average total loss: 0.736279
tensor(-11.0805, device='cuda:0') tensor(4.2479, device='cuda:0') tensor(8.2784e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.243922
Average KL loss: 0.496566
Average total loss: 0.740488
tensor(-11.0851, device='cuda:0') tensor(4.2467, device='cuda:0') tensor(6.0875e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.240882
Average KL loss: 0.496195
Average total loss: 0.737076
tensor(-11.0898, device='cuda:0') tensor(4.2455, device='cuda:0') tensor(7.5007e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.242949
Average KL loss: 0.495798
Average total loss: 0.738747
tensor(-11.0944, device='cuda:0') tensor(4.2442, device='cuda:0') tensor(8.1527e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.239602
Average KL loss: 0.495368
Average total loss: 0.734970
tensor(-11.0989, device='cuda:0') tensor(4.2430, device='cuda:0') tensor(8.4314e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.241019
Average KL loss: 0.494964
Average total loss: 0.735983
tensor(-11.1035, device='cuda:0') tensor(4.2419, device='cuda:0') tensor(1.0473e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.239526
Average KL loss: 0.494567
Average total loss: 0.734093
tensor(-11.1080, device='cuda:0') tensor(4.2407, device='cuda:0') tensor(1.1637e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.238836
Average KL loss: 0.494156
Average total loss: 0.732991
tensor(-11.1125, device='cuda:0') tensor(4.2395, device='cuda:0') tensor(8.9718e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.236486
Average KL loss: 0.493751
Average total loss: 0.730237
tensor(-11.1170, device='cuda:0') tensor(4.2382, device='cuda:0') tensor(4.7285e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.236151
Average KL loss: 0.493327
Average total loss: 0.729477
tensor(-11.1214, device='cuda:0') tensor(4.2370, device='cuda:0') tensor(5.5771e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.239184
Average KL loss: 0.492992
Average total loss: 0.732176
tensor(-11.1259, device='cuda:0') tensor(4.2359, device='cuda:0') tensor(1.1903e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.238650
Average KL loss: 0.492627
Average total loss: 0.731277
tensor(-11.1303, device='cuda:0') tensor(4.2347, device='cuda:0') tensor(9.6634e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.235020
Average KL loss: 0.492207
Average total loss: 0.727227
tensor(-11.1347, device='cuda:0') tensor(4.2335, device='cuda:0') tensor(1.2552e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.236293
Average KL loss: 0.491781
Average total loss: 0.728074
tensor(-11.1391, device='cuda:0') tensor(4.2323, device='cuda:0') tensor(8.5467e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.235008
Average KL loss: 0.491392
Average total loss: 0.726400
tensor(-11.1434, device='cuda:0') tensor(4.2312, device='cuda:0') tensor(1.0916e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.235548
Average KL loss: 0.490992
Average total loss: 0.726540
tensor(-11.1477, device='cuda:0') tensor(4.2300, device='cuda:0') tensor(6.3732e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.231638
Average KL loss: 0.490564
Average total loss: 0.722202
tensor(-11.1520, device='cuda:0') tensor(4.2288, device='cuda:0') tensor(9.3817e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.237705
Average KL loss: 0.490139
Average total loss: 0.727844
tensor(-11.1563, device='cuda:0') tensor(4.2277, device='cuda:0') tensor(1.2142e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.235100
Average KL loss: 0.489715
Average total loss: 0.724814
tensor(-11.1606, device='cuda:0') tensor(4.2265, device='cuda:0') tensor(1.1520e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.234655
Average KL loss: 0.489295
Average total loss: 0.723950
tensor(-11.1649, device='cuda:0') tensor(4.2254, device='cuda:0') tensor(4.7114e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.233852
Average KL loss: 0.488934
Average total loss: 0.722785
tensor(-11.1691, device='cuda:0') tensor(4.2243, device='cuda:0') tensor(6.7708e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.236423
Average KL loss: 0.488534
Average total loss: 0.724957
tensor(-11.1733, device='cuda:0') tensor(4.2232, device='cuda:0') tensor(5.7712e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.233030
Average KL loss: 0.488137
Average total loss: 0.721167
tensor(-11.1775, device='cuda:0') tensor(4.2221, device='cuda:0') tensor(1.1126e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.230317
Average KL loss: 0.487754
Average total loss: 0.718071
tensor(-11.1816, device='cuda:0') tensor(4.2210, device='cuda:0') tensor(8.7210e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.230816
Average KL loss: 0.487371
Average total loss: 0.718187
tensor(-11.1858, device='cuda:0') tensor(4.2199, device='cuda:0') tensor(6.9081e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.229441
Average KL loss: 0.486977
Average total loss: 0.716418
tensor(-11.1899, device='cuda:0') tensor(4.2187, device='cuda:0') tensor(9.4719e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.229628
Average KL loss: 0.486544
Average total loss: 0.716172
tensor(-11.1941, device='cuda:0') tensor(4.2175, device='cuda:0') tensor(5.7256e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.229123
Average KL loss: 0.486170
Average total loss: 0.715292
tensor(-11.1982, device='cuda:0') tensor(4.2164, device='cuda:0') tensor(7.8209e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.225923
Average KL loss: 0.485794
Average total loss: 0.711717
tensor(-11.2022, device='cuda:0') tensor(4.2152, device='cuda:0') tensor(7.2434e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.224391
Average KL loss: 0.485390
Average total loss: 0.709781
tensor(-11.2063, device='cuda:0') tensor(4.2140, device='cuda:0') tensor(1.1174e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.227409
Average KL loss: 0.484956
Average total loss: 0.712365
tensor(-11.2104, device='cuda:0') tensor(4.2128, device='cuda:0') tensor(7.9689e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.225420
Average KL loss: 0.484572
Average total loss: 0.709991
tensor(-11.2144, device='cuda:0') tensor(4.2117, device='cuda:0') tensor(6.3809e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.226191
Average KL loss: 0.484171
Average total loss: 0.710362
tensor(-11.2184, device='cuda:0') tensor(4.2105, device='cuda:0') tensor(8.1989e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.225872
Average KL loss: 0.483805
Average total loss: 0.709677
tensor(-11.2224, device='cuda:0') tensor(4.2094, device='cuda:0') tensor(6.8287e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.220872
Average KL loss: 0.483365
Average total loss: 0.704237
tensor(-11.2264, device='cuda:0') tensor(4.2083, device='cuda:0') tensor(8.1873e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.223310
Average KL loss: 0.482957
Average total loss: 0.706268
tensor(-11.2303, device='cuda:0') tensor(4.2072, device='cuda:0') tensor(8.6152e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.226037
Average KL loss: 0.482584
Average total loss: 0.708620
tensor(-11.2343, device='cuda:0') tensor(4.2061, device='cuda:0') tensor(1.0455e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.222856
Average KL loss: 0.482193
Average total loss: 0.705050
tensor(-11.2382, device='cuda:0') tensor(4.2050, device='cuda:0') tensor(1.0961e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.221231
Average KL loss: 0.481786
Average total loss: 0.703018
tensor(-11.2421, device='cuda:0') tensor(4.2038, device='cuda:0') tensor(1.0666e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.222217
Average KL loss: 0.481385
Average total loss: 0.703601
tensor(-11.2460, device='cuda:0') tensor(4.2026, device='cuda:0') tensor(7.0263e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.221695
Average KL loss: 0.481012
Average total loss: 0.702706
tensor(-11.2499, device='cuda:0') tensor(4.2015, device='cuda:0') tensor(4.9482e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.222393
Average KL loss: 0.480640
Average total loss: 0.703033
tensor(-11.2538, device='cuda:0') tensor(4.2003, device='cuda:0') tensor(6.8312e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.220601
Average KL loss: 0.480276
Average total loss: 0.700877
tensor(-11.2576, device='cuda:0') tensor(4.1992, device='cuda:0') tensor(5.6206e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.219241
Average KL loss: 0.479885
Average total loss: 0.699126
tensor(-11.2615, device='cuda:0') tensor(4.1981, device='cuda:0') tensor(4.9883e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.220939
Average KL loss: 0.479495
Average total loss: 0.700434
tensor(-11.2653, device='cuda:0') tensor(4.1969, device='cuda:0') tensor(3.2882e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.221944
Average KL loss: 0.479172
Average total loss: 0.701116
tensor(-11.2691, device='cuda:0') tensor(4.1957, device='cuda:0') tensor(7.9017e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.222083
Average KL loss: 0.478814
Average total loss: 0.700897
tensor(-11.2729, device='cuda:0') tensor(4.1946, device='cuda:0') tensor(8.2735e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.219521
Average KL loss: 0.478462
Average total loss: 0.697983
tensor(-11.2767, device='cuda:0') tensor(4.1935, device='cuda:0') tensor(7.4220e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.222583
Average KL loss: 0.478087
Average total loss: 0.700670
tensor(-11.2804, device='cuda:0') tensor(4.1924, device='cuda:0') tensor(4.2108e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.219737
Average KL loss: 0.477733
Average total loss: 0.697470
tensor(-11.2842, device='cuda:0') tensor(4.1914, device='cuda:0') tensor(5.8982e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.217135
Average KL loss: 0.477392
Average total loss: 0.694527
tensor(-11.2879, device='cuda:0') tensor(4.1901, device='cuda:0') tensor(9.0910e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.216543
Average KL loss: 0.477018
Average total loss: 0.693561
tensor(-11.2916, device='cuda:0') tensor(4.1889, device='cuda:0') tensor(6.0360e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.215895
Average KL loss: 0.476601
Average total loss: 0.692496
tensor(-11.2953, device='cuda:0') tensor(4.1878, device='cuda:0') tensor(6.5507e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.215694
Average KL loss: 0.476233
Average total loss: 0.691927
tensor(-11.2990, device='cuda:0') tensor(4.1865, device='cuda:0') tensor(8.9778e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.215380
Average KL loss: 0.475883
Average total loss: 0.691263
tensor(-11.3027, device='cuda:0') tensor(4.1854, device='cuda:0') tensor(1.0232e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.217336
Average KL loss: 0.475527
Average total loss: 0.692863
tensor(-11.3064, device='cuda:0') tensor(4.1842, device='cuda:0') tensor(6.4953e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.218576
Average KL loss: 0.475188
Average total loss: 0.693764
tensor(-11.3100, device='cuda:0') tensor(4.1830, device='cuda:0') tensor(8.5508e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.217514
Average KL loss: 0.474844
Average total loss: 0.692359
tensor(-11.3137, device='cuda:0') tensor(4.1819, device='cuda:0') tensor(6.7511e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.211725
Average KL loss: 0.474521
Average total loss: 0.686246
tensor(-11.3173, device='cuda:0') tensor(4.1808, device='cuda:0') tensor(7.7043e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.212233
Average KL loss: 0.474179
Average total loss: 0.686412
tensor(-11.3209, device='cuda:0') tensor(4.1795, device='cuda:0') tensor(8.3320e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.215735
Average KL loss: 0.473790
Average total loss: 0.689525
tensor(-11.3245, device='cuda:0') tensor(4.1782, device='cuda:0') tensor(1.1068e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.211040
Average KL loss: 0.473388
Average total loss: 0.684428
tensor(-11.3281, device='cuda:0') tensor(4.1769, device='cuda:0') tensor(7.7075e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.214493
Average KL loss: 0.473034
Average total loss: 0.687527
tensor(-11.3317, device='cuda:0') tensor(4.1758, device='cuda:0') tensor(7.5136e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.213414
Average KL loss: 0.472702
Average total loss: 0.686116
tensor(-11.3353, device='cuda:0') tensor(4.1745, device='cuda:0') tensor(7.5972e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.213900
Average KL loss: 0.472344
Average total loss: 0.686244
tensor(-11.3388, device='cuda:0') tensor(4.1732, device='cuda:0') tensor(7.8565e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.212792
Average KL loss: 0.472023
Average total loss: 0.684816
tensor(-11.3424, device='cuda:0') tensor(4.1721, device='cuda:0') tensor(5.0779e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.211255
Average KL loss: 0.471704
Average total loss: 0.682959
tensor(-11.3459, device='cuda:0') tensor(4.1709, device='cuda:0') tensor(9.8910e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.212115
Average KL loss: 0.471341
Average total loss: 0.683456
tensor(-11.3494, device='cuda:0') tensor(4.1696, device='cuda:0') tensor(8.8276e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.207610
Average KL loss: 0.470999
Average total loss: 0.678608
tensor(-11.3529, device='cuda:0') tensor(4.1684, device='cuda:0') tensor(6.8646e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.211288
Average KL loss: 0.470635
Average total loss: 0.681923
tensor(-11.3564, device='cuda:0') tensor(4.1671, device='cuda:0') tensor(7.7637e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.208950
Average KL loss: 0.470297
Average total loss: 0.679247
tensor(-11.3599, device='cuda:0') tensor(4.1658, device='cuda:0') tensor(7.4519e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.205657
Average KL loss: 0.469927
Average total loss: 0.675584
tensor(-11.3634, device='cuda:0') tensor(4.1645, device='cuda:0') tensor(6.4694e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.207788
Average KL loss: 0.469577
Average total loss: 0.677366
tensor(-11.3668, device='cuda:0') tensor(4.1632, device='cuda:0') tensor(9.5388e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.207412
Average KL loss: 0.469250
Average total loss: 0.676662
tensor(-11.3703, device='cuda:0') tensor(4.1619, device='cuda:0') tensor(8.7061e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.206451
Average KL loss: 0.468895
Average total loss: 0.675346
tensor(-11.3737, device='cuda:0') tensor(4.1605, device='cuda:0') tensor(9.2041e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.204389
Average KL loss: 0.468572
Average total loss: 0.672960
tensor(-11.3771, device='cuda:0') tensor(4.1592, device='cuda:0') tensor(7.3309e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.207531
Average KL loss: 0.468235
Average total loss: 0.675767
tensor(-11.3805, device='cuda:0') tensor(4.1580, device='cuda:0') tensor(5.1415e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.207329
Average KL loss: 0.467858
Average total loss: 0.675188
tensor(-11.3839, device='cuda:0') tensor(4.1567, device='cuda:0') tensor(8.6168e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.205043
Average KL loss: 0.467529
Average total loss: 0.672572
tensor(-11.3873, device='cuda:0') tensor(4.1554, device='cuda:0') tensor(7.0633e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.204348
Average KL loss: 0.467185
Average total loss: 0.671533
tensor(-11.3907, device='cuda:0') tensor(4.1541, device='cuda:0') tensor(5.3021e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.204778
Average KL loss: 0.466830
Average total loss: 0.671608
tensor(-11.3941, device='cuda:0') tensor(4.1527, device='cuda:0') tensor(7.8370e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.203223
Average KL loss: 0.466494
Average total loss: 0.669717
tensor(-11.3975, device='cuda:0') tensor(4.1514, device='cuda:0') tensor(5.3776e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.205472
Average KL loss: 0.466159
Average total loss: 0.671631
tensor(-11.4008, device='cuda:0') tensor(4.1500, device='cuda:0') tensor(9.2650e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.200390
Average KL loss: 0.465796
Average total loss: 0.666186
tensor(-11.4042, device='cuda:0') tensor(4.1487, device='cuda:0') tensor(8.0931e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.199467
Average KL loss: 0.465431
Average total loss: 0.664898
tensor(-11.4075, device='cuda:0') tensor(4.1473, device='cuda:0') tensor(1.9461e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.197686
Average KL loss: 0.465077
Average total loss: 0.662763
tensor(-11.4108, device='cuda:0') tensor(4.1460, device='cuda:0') tensor(7.0656e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.201995
Average KL loss: 0.464731
Average total loss: 0.666726
tensor(-11.4141, device='cuda:0') tensor(4.1447, device='cuda:0') tensor(5.5225e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.199752
Average KL loss: 0.464402
Average total loss: 0.664154
tensor(-11.4174, device='cuda:0') tensor(4.1433, device='cuda:0') tensor(5.1426e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.202246
Average KL loss: 0.464056
Average total loss: 0.666302
 Percentile value: -3.1113459110260018
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =    1208 /    1728             ( 69.91%) | total_pruned =     520 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6361 /   36864             ( 17.26%) | total_pruned =   30503 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    6511 /   36864             ( 17.66%) | total_pruned =   30353 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    5879 /   36864             ( 15.95%) | total_pruned =   30985 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    5539 /   36864             ( 15.03%) | total_pruned =   31325 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   10946 /   73728             ( 14.85%) | total_pruned =   62782 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   16390 /  147456             ( 11.12%) | total_pruned =  131066 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2996 /    8192             ( 36.57%) | total_pruned =    5196 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   12583 /  147456             (  8.53%) | total_pruned =  134873 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   11862 /  147456             (  8.04%) | total_pruned =  135594 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   25090 /  294912             (  8.51%) | total_pruned =  269822 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   34448 /  589824             (  5.84%) | total_pruned =  555376 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     176 /     256             ( 68.75%) | total_pruned =      80 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6888 /   32768             ( 21.02%) | total_pruned =   25880 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     184 /     256             ( 71.88%) | total_pruned =      72 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   16877 /  589824             (  2.86%) | total_pruned =  572947 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     191 /     256             ( 74.61%) | total_pruned =      65 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     122 /     256             ( 47.66%) | total_pruned =     134 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   17864 /  589824             (  3.03%) | total_pruned =  571960 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   32603 / 1179648             (  2.76%) | total_pruned = 1147045 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     404 /     512             ( 78.91%) | total_pruned =     108 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     259 /     512             ( 50.59%) | total_pruned =     253 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   30231 / 2359296             (  1.28%) | total_pruned = 2329065 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     487 /     512             ( 95.12%) | total_pruned =      25 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     442 /     512             ( 86.33%) | total_pruned =      70 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    8547 /  131072             (  6.52%) | total_pruned =  122525 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     431 /     512             ( 84.18%) | total_pruned =      81 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     431 /     512             ( 84.18%) | total_pruned =      81 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   17170 / 2359296             (  0.73%) | total_pruned = 2342126 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     267 /     512             ( 52.15%) | total_pruned =     245 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      68 /     512             ( 13.28%) | total_pruned =     444 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   20700 / 2359296             (  0.88%) | total_pruned = 2338596 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     347 /     512             ( 67.77%) | total_pruned =     165 | shape = torch.Size([512])
linear.weight        | nonzeros =    3990 /    5120             ( 77.93%) | total_pruned =    1130 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 25/200 Loss: 0.005422 Accuracy: 86.99 100.00 % Best test Accuracy: 87.08%
tensor(-11.4207, device='cuda:0') tensor(4.1420, device='cuda:0') tensor(2.0377e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.308638
Average KL loss: 0.455120
Average total loss: 0.763758
tensor(-11.4450, device='cuda:0') tensor(3.8960, device='cuda:0') tensor(-5.2343e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.293330
Average KL loss: 0.448074
Average total loss: 0.741404
tensor(-11.4635, device='cuda:0') tensor(3.7370, device='cuda:0') tensor(2.8167e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.279042
Average KL loss: 0.444924
Average total loss: 0.723965
tensor(-11.4791, device='cuda:0') tensor(3.6155, device='cuda:0') tensor(3.4142e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.275466
Average KL loss: 0.443032
Average total loss: 0.718498
tensor(-11.4928, device='cuda:0') tensor(3.5171, device='cuda:0') tensor(-3.3728e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.268886
Average KL loss: 0.441754
Average total loss: 0.710640
tensor(-11.5051, device='cuda:0') tensor(3.4351, device='cuda:0') tensor(-1.2064e-11, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.267948
Average KL loss: 0.440856
Average total loss: 0.708804
tensor(-11.5164, device='cuda:0') tensor(3.3650, device='cuda:0') tensor(3.1606e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.258850
Average KL loss: 0.440162
Average total loss: 0.699012
tensor(-11.5268, device='cuda:0') tensor(3.3041, device='cuda:0') tensor(6.4548e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.258147
Average KL loss: 0.439615
Average total loss: 0.697762
tensor(-11.5366, device='cuda:0') tensor(3.2505, device='cuda:0') tensor(6.1873e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.258904
Average KL loss: 0.439213
Average total loss: 0.698117
tensor(-11.5457, device='cuda:0') tensor(3.2029, device='cuda:0') tensor(-2.2008e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.253798
Average KL loss: 0.438889
Average total loss: 0.692687
tensor(-11.5544, device='cuda:0') tensor(3.1602, device='cuda:0') tensor(1.0736e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.253627
Average KL loss: 0.438657
Average total loss: 0.692284
tensor(-11.5627, device='cuda:0') tensor(3.1216, device='cuda:0') tensor(2.7874e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.247343
Average KL loss: 0.438442
Average total loss: 0.685785
tensor(-11.5706, device='cuda:0') tensor(3.0864, device='cuda:0') tensor(1.2155e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.245256
Average KL loss: 0.438231
Average total loss: 0.683487
tensor(-11.5781, device='cuda:0') tensor(3.0542, device='cuda:0') tensor(2.7914e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.239546
Average KL loss: 0.438030
Average total loss: 0.677576
tensor(-11.5854, device='cuda:0') tensor(3.0246, device='cuda:0') tensor(9.3481e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.239469
Average KL loss: 0.437840
Average total loss: 0.677308
tensor(-11.5924, device='cuda:0') tensor(2.9974, device='cuda:0') tensor(6.3323e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.243621
Average KL loss: 0.437692
Average total loss: 0.681313
tensor(-11.5992, device='cuda:0') tensor(2.9720, device='cuda:0') tensor(2.8928e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.235545
Average KL loss: 0.437555
Average total loss: 0.673099
tensor(-11.6058, device='cuda:0') tensor(2.9484, device='cuda:0') tensor(3.9857e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.233260
Average KL loss: 0.437428
Average total loss: 0.670688
tensor(-11.6123, device='cuda:0') tensor(2.9264, device='cuda:0') tensor(6.6238e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.233181
Average KL loss: 0.437282
Average total loss: 0.670463
tensor(-11.6185, device='cuda:0') tensor(2.9058, device='cuda:0') tensor(7.9922e-11, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.238542
Average KL loss: 0.437205
Average total loss: 0.675747
tensor(-11.6246, device='cuda:0') tensor(2.8865, device='cuda:0') tensor(4.4858e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.234285
Average KL loss: 0.437135
Average total loss: 0.671420
tensor(-11.6305, device='cuda:0') tensor(2.8683, device='cuda:0') tensor(-3.7042e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.228541
Average KL loss: 0.437041
Average total loss: 0.665581
tensor(-11.6363, device='cuda:0') tensor(2.8511, device='cuda:0') tensor(-4.3729e-11, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.228680
Average KL loss: 0.436952
Average total loss: 0.665633
tensor(-11.6420, device='cuda:0') tensor(2.8349, device='cuda:0') tensor(7.7047e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.228471
Average KL loss: 0.436862
Average total loss: 0.665333
tensor(-11.6475, device='cuda:0') tensor(2.8196, device='cuda:0') tensor(-8.3396e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.226354
Average KL loss: 0.436782
Average total loss: 0.663135
tensor(-11.6530, device='cuda:0') tensor(2.8051, device='cuda:0') tensor(1.8184e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.224489
Average KL loss: 0.436666
Average total loss: 0.661154
tensor(-11.6584, device='cuda:0') tensor(2.7911, device='cuda:0') tensor(3.0590e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.219832
Average KL loss: 0.436585
Average total loss: 0.656416
tensor(-11.6636, device='cuda:0') tensor(2.7780, device='cuda:0') tensor(1.6662e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.223689
Average KL loss: 0.436508
Average total loss: 0.660197
tensor(-11.6688, device='cuda:0') tensor(2.7655, device='cuda:0') tensor(4.3904e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.224088
Average KL loss: 0.436427
Average total loss: 0.660514
tensor(-11.6739, device='cuda:0') tensor(2.7536, device='cuda:0') tensor(6.3274e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.220845
Average KL loss: 0.436330
Average total loss: 0.657175
tensor(-11.6789, device='cuda:0') tensor(2.7421, device='cuda:0') tensor(1.5848e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.219047
Average KL loss: 0.436229
Average total loss: 0.655276
tensor(-11.6838, device='cuda:0') tensor(2.7311, device='cuda:0') tensor(-1.1144e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.217084
Average KL loss: 0.436143
Average total loss: 0.653226
tensor(-11.6887, device='cuda:0') tensor(2.7206, device='cuda:0') tensor(2.1522e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.216722
Average KL loss: 0.436062
Average total loss: 0.652784
tensor(-11.6934, device='cuda:0') tensor(2.7105, device='cuda:0') tensor(3.0578e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.216104
Average KL loss: 0.435974
Average total loss: 0.652079
tensor(-11.6982, device='cuda:0') tensor(2.7009, device='cuda:0') tensor(1.0588e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.217983
Average KL loss: 0.435852
Average total loss: 0.653835
tensor(-11.7028, device='cuda:0') tensor(2.6915, device='cuda:0') tensor(1.6019e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.213203
Average KL loss: 0.435751
Average total loss: 0.648954
tensor(-11.7074, device='cuda:0') tensor(2.6825, device='cuda:0') tensor(-1.5972e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.218738
Average KL loss: 0.435649
Average total loss: 0.654387
tensor(-11.7120, device='cuda:0') tensor(2.6739, device='cuda:0') tensor(5.5201e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.214224
Average KL loss: 0.435563
Average total loss: 0.649787
tensor(-11.7165, device='cuda:0') tensor(2.6656, device='cuda:0') tensor(2.2805e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.214619
Average KL loss: 0.435480
Average total loss: 0.650099
tensor(-11.7209, device='cuda:0') tensor(2.6577, device='cuda:0') tensor(8.2718e-11, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.210327
Average KL loss: 0.435396
Average total loss: 0.645722
tensor(-11.7253, device='cuda:0') tensor(2.6500, device='cuda:0') tensor(2.4318e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.211717
Average KL loss: 0.435304
Average total loss: 0.647021
tensor(-11.7297, device='cuda:0') tensor(2.6425, device='cuda:0') tensor(6.1381e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.210364
Average KL loss: 0.435212
Average total loss: 0.645576
tensor(-11.7340, device='cuda:0') tensor(2.6353, device='cuda:0') tensor(9.3951e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.209607
Average KL loss: 0.435097
Average total loss: 0.644704
tensor(-11.7382, device='cuda:0') tensor(2.6283, device='cuda:0') tensor(1.5590e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.209098
Average KL loss: 0.434997
Average total loss: 0.644095
tensor(-11.7425, device='cuda:0') tensor(2.6216, device='cuda:0') tensor(6.2544e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.210392
Average KL loss: 0.434902
Average total loss: 0.645294
tensor(-11.7466, device='cuda:0') tensor(2.6151, device='cuda:0') tensor(2.5781e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.209657
Average KL loss: 0.434807
Average total loss: 0.644464
tensor(-11.7508, device='cuda:0') tensor(2.6088, device='cuda:0') tensor(3.9723e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.210621
Average KL loss: 0.434687
Average total loss: 0.645307
tensor(-11.7549, device='cuda:0') tensor(2.6027, device='cuda:0') tensor(3.4142e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.205900
Average KL loss: 0.434612
Average total loss: 0.640511
tensor(-11.7589, device='cuda:0') tensor(2.5968, device='cuda:0') tensor(1.1503e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.204077
Average KL loss: 0.434488
Average total loss: 0.638565
tensor(-11.7629, device='cuda:0') tensor(2.5910, device='cuda:0') tensor(2.5499e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.200134
Average KL loss: 0.434361
Average total loss: 0.634495
tensor(-11.7669, device='cuda:0') tensor(2.5853, device='cuda:0') tensor(-7.3880e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.206993
Average KL loss: 0.434242
Average total loss: 0.641234
tensor(-11.7709, device='cuda:0') tensor(2.5799, device='cuda:0') tensor(4.0837e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.199968
Average KL loss: 0.434117
Average total loss: 0.634085
tensor(-11.7748, device='cuda:0') tensor(2.5746, device='cuda:0') tensor(5.7582e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.199478
Average KL loss: 0.434002
Average total loss: 0.633480
tensor(-11.7787, device='cuda:0') tensor(2.5695, device='cuda:0') tensor(3.5353e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.198441
Average KL loss: 0.433912
Average total loss: 0.632352
tensor(-11.7825, device='cuda:0') tensor(2.5646, device='cuda:0') tensor(2.2560e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.199818
Average KL loss: 0.433770
Average total loss: 0.633587
tensor(-11.7864, device='cuda:0') tensor(2.5597, device='cuda:0') tensor(4.6880e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.198987
Average KL loss: 0.433650
Average total loss: 0.632638
tensor(-11.7902, device='cuda:0') tensor(2.5550, device='cuda:0') tensor(3.5524e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.199945
Average KL loss: 0.433509
Average total loss: 0.633454
tensor(-11.7939, device='cuda:0') tensor(2.5504, device='cuda:0') tensor(7.8609e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.196278
Average KL loss: 0.433379
Average total loss: 0.629657
tensor(-11.7977, device='cuda:0') tensor(2.5459, device='cuda:0') tensor(4.3932e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.192933
Average KL loss: 0.433246
Average total loss: 0.626179
tensor(-11.8014, device='cuda:0') tensor(2.5415, device='cuda:0') tensor(8.6514e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.196600
Average KL loss: 0.433131
Average total loss: 0.629731
tensor(-11.8051, device='cuda:0') tensor(2.5374, device='cuda:0') tensor(4.7816e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.198620
Average KL loss: 0.433016
Average total loss: 0.631636
tensor(-11.8087, device='cuda:0') tensor(2.5332, device='cuda:0') tensor(-2.4757e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.191134
Average KL loss: 0.432880
Average total loss: 0.624014
tensor(-11.8124, device='cuda:0') tensor(2.5291, device='cuda:0') tensor(-1.5051e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.195191
Average KL loss: 0.432754
Average total loss: 0.627945
tensor(-11.8160, device='cuda:0') tensor(2.5252, device='cuda:0') tensor(-2.1292e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.195467
Average KL loss: 0.432647
Average total loss: 0.628114
tensor(-11.8196, device='cuda:0') tensor(2.5213, device='cuda:0') tensor(3.0347e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.195194
Average KL loss: 0.432530
Average total loss: 0.627725
tensor(-11.8231, device='cuda:0') tensor(2.5176, device='cuda:0') tensor(-2.2065e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.190821
Average KL loss: 0.432403
Average total loss: 0.623225
tensor(-11.8267, device='cuda:0') tensor(2.5140, device='cuda:0') tensor(6.6844e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.195695
Average KL loss: 0.432262
Average total loss: 0.627957
tensor(-11.8302, device='cuda:0') tensor(2.5104, device='cuda:0') tensor(1.3888e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.189417
Average KL loss: 0.432153
Average total loss: 0.621571
tensor(-11.8337, device='cuda:0') tensor(2.5069, device='cuda:0') tensor(4.1591e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.192065
Average KL loss: 0.432024
Average total loss: 0.624089
tensor(-11.8372, device='cuda:0') tensor(2.5033, device='cuda:0') tensor(2.1568e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.190587
Average KL loss: 0.431888
Average total loss: 0.622476
tensor(-11.8406, device='cuda:0') tensor(2.5000, device='cuda:0') tensor(-1.7331e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.191667
Average KL loss: 0.431737
Average total loss: 0.623404
tensor(-11.8441, device='cuda:0') tensor(2.4967, device='cuda:0') tensor(8.7194e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.189502
Average KL loss: 0.431581
Average total loss: 0.621083
tensor(-11.8475, device='cuda:0') tensor(2.4936, device='cuda:0') tensor(2.3060e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.188421
Average KL loss: 0.431464
Average total loss: 0.619886
tensor(-11.8509, device='cuda:0') tensor(2.4905, device='cuda:0') tensor(4.2390e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.189733
Average KL loss: 0.431316
Average total loss: 0.621048
tensor(-11.8542, device='cuda:0') tensor(2.4875, device='cuda:0') tensor(1.4149e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.189940
Average KL loss: 0.431211
Average total loss: 0.621151
tensor(-11.8576, device='cuda:0') tensor(2.4845, device='cuda:0') tensor(2.1341e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.188152
Average KL loss: 0.431106
Average total loss: 0.619257
tensor(-11.8609, device='cuda:0') tensor(2.4816, device='cuda:0') tensor(1.5429e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.184553
Average KL loss: 0.431013
Average total loss: 0.615566
tensor(-11.8642, device='cuda:0') tensor(2.4788, device='cuda:0') tensor(-1.3215e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.188039
Average KL loss: 0.430907
Average total loss: 0.618946
tensor(-11.8675, device='cuda:0') tensor(2.4760, device='cuda:0') tensor(3.7690e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.186897
Average KL loss: 0.430774
Average total loss: 0.617671
tensor(-11.8708, device='cuda:0') tensor(2.4732, device='cuda:0') tensor(3.8539e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.184586
Average KL loss: 0.430617
Average total loss: 0.615203
tensor(-11.8741, device='cuda:0') tensor(2.4705, device='cuda:0') tensor(-3.2510e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.185862
Average KL loss: 0.430476
Average total loss: 0.616338
tensor(-11.8773, device='cuda:0') tensor(2.4678, device='cuda:0') tensor(3.1531e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.180959
Average KL loss: 0.430337
Average total loss: 0.611296
tensor(-11.8806, device='cuda:0') tensor(2.4652, device='cuda:0') tensor(5.7868e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.186733
Average KL loss: 0.430191
Average total loss: 0.616923
tensor(-11.8838, device='cuda:0') tensor(2.4626, device='cuda:0') tensor(-1.0419e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.183672
Average KL loss: 0.430026
Average total loss: 0.613698
tensor(-11.8870, device='cuda:0') tensor(2.4600, device='cuda:0') tensor(4.8856e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.178744
Average KL loss: 0.429868
Average total loss: 0.608612
tensor(-11.8902, device='cuda:0') tensor(2.4574, device='cuda:0') tensor(5.4528e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.182724
Average KL loss: 0.429692
Average total loss: 0.612416
tensor(-11.8933, device='cuda:0') tensor(2.4549, device='cuda:0') tensor(4.2880e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.180162
Average KL loss: 0.429540
Average total loss: 0.609702
tensor(-11.8965, device='cuda:0') tensor(2.4525, device='cuda:0') tensor(2.1431e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.179701
Average KL loss: 0.429417
Average total loss: 0.609117
tensor(-11.8996, device='cuda:0') tensor(2.4502, device='cuda:0') tensor(3.3277e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.178384
Average KL loss: 0.429287
Average total loss: 0.607671
tensor(-11.9027, device='cuda:0') tensor(2.4478, device='cuda:0') tensor(1.6729e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.182190
Average KL loss: 0.429141
Average total loss: 0.611331
tensor(-11.9058, device='cuda:0') tensor(2.4456, device='cuda:0') tensor(1.9061e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.179237
Average KL loss: 0.429016
Average total loss: 0.608253
tensor(-11.9089, device='cuda:0') tensor(2.4435, device='cuda:0') tensor(1.5455e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.178495
Average KL loss: 0.428900
Average total loss: 0.607396
tensor(-11.9120, device='cuda:0') tensor(2.4413, device='cuda:0') tensor(-3.5691e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.180847
Average KL loss: 0.428744
Average total loss: 0.609591
tensor(-11.9151, device='cuda:0') tensor(2.4391, device='cuda:0') tensor(3.5664e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.182697
Average KL loss: 0.428593
Average total loss: 0.611290
tensor(-11.9181, device='cuda:0') tensor(2.4369, device='cuda:0') tensor(2.1743e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.177752
Average KL loss: 0.428428
Average total loss: 0.606180
tensor(-11.9212, device='cuda:0') tensor(2.4348, device='cuda:0') tensor(5.1193e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.175035
Average KL loss: 0.428270
Average total loss: 0.603305
tensor(-11.9242, device='cuda:0') tensor(2.4327, device='cuda:0') tensor(4.2725e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.173245
Average KL loss: 0.428159
Average total loss: 0.601404
tensor(-11.9272, device='cuda:0') tensor(2.4307, device='cuda:0') tensor(2.0361e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.177295
Average KL loss: 0.428038
Average total loss: 0.605332
tensor(-11.9302, device='cuda:0') tensor(2.4287, device='cuda:0') tensor(5.6116e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.178751
Average KL loss: 0.427900
Average total loss: 0.606651
tensor(-11.9331, device='cuda:0') tensor(2.4268, device='cuda:0') tensor(1.4338e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.175825
Average KL loss: 0.427772
Average total loss: 0.603597
tensor(-11.9361, device='cuda:0') tensor(2.4249, device='cuda:0') tensor(2.0431e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.175052
Average KL loss: 0.427625
Average total loss: 0.602677
tensor(-11.9391, device='cuda:0') tensor(2.4229, device='cuda:0') tensor(1.3492e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.173895
Average KL loss: 0.427493
Average total loss: 0.601388
tensor(-11.9420, device='cuda:0') tensor(2.4211, device='cuda:0') tensor(4.0815e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.168919
Average KL loss: 0.427366
Average total loss: 0.596285
tensor(-11.9449, device='cuda:0') tensor(2.4192, device='cuda:0') tensor(1.0464e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.173428
Average KL loss: 0.427216
Average total loss: 0.600644
tensor(-11.9479, device='cuda:0') tensor(2.4174, device='cuda:0') tensor(8.0135e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.171671
Average KL loss: 0.427073
Average total loss: 0.598745
tensor(-11.9508, device='cuda:0') tensor(2.4157, device='cuda:0') tensor(3.4690e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.167704
Average KL loss: 0.426904
Average total loss: 0.594607
tensor(-11.9537, device='cuda:0') tensor(2.4138, device='cuda:0') tensor(4.9514e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.170701
Average KL loss: 0.426741
Average total loss: 0.597441
tensor(-11.9565, device='cuda:0') tensor(2.4121, device='cuda:0') tensor(1.1866e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.168280
Average KL loss: 0.426622
Average total loss: 0.594902
tensor(-11.9594, device='cuda:0') tensor(2.4104, device='cuda:0') tensor(1.6394e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.171491
Average KL loss: 0.426459
Average total loss: 0.597951
tensor(-11.9623, device='cuda:0') tensor(2.4087, device='cuda:0') tensor(1.3408e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.169993
Average KL loss: 0.426311
Average total loss: 0.596304
tensor(-11.9651, device='cuda:0') tensor(2.4071, device='cuda:0') tensor(2.5259e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.170083
Average KL loss: 0.426172
Average total loss: 0.596255
tensor(-11.9679, device='cuda:0') tensor(2.4055, device='cuda:0') tensor(4.6488e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.166897
Average KL loss: 0.426043
Average total loss: 0.592941
tensor(-11.9708, device='cuda:0') tensor(2.4039, device='cuda:0') tensor(2.2696e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.169528
Average KL loss: 0.425902
Average total loss: 0.595431
tensor(-11.9736, device='cuda:0') tensor(2.4022, device='cuda:0') tensor(2.4008e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.167127
Average KL loss: 0.425758
Average total loss: 0.592884
tensor(-11.9764, device='cuda:0') tensor(2.4006, device='cuda:0') tensor(2.8902e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.167074
Average KL loss: 0.425594
Average total loss: 0.592668
tensor(-11.9792, device='cuda:0') tensor(2.3990, device='cuda:0') tensor(3.3912e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.166628
Average KL loss: 0.425463
Average total loss: 0.592091
tensor(-11.9820, device='cuda:0') tensor(2.3975, device='cuda:0') tensor(-2.6647e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.164391
Average KL loss: 0.425318
Average total loss: 0.589709
tensor(-11.9847, device='cuda:0') tensor(2.3960, device='cuda:0') tensor(3.0869e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.163049
Average KL loss: 0.425165
Average total loss: 0.588214
tensor(-11.9875, device='cuda:0') tensor(2.3944, device='cuda:0') tensor(3.7155e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.167572
Average KL loss: 0.425009
Average total loss: 0.592582
tensor(-11.9902, device='cuda:0') tensor(2.3930, device='cuda:0') tensor(2.0630e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.163372
Average KL loss: 0.424864
Average total loss: 0.588236
tensor(-11.9930, device='cuda:0') tensor(2.3915, device='cuda:0') tensor(4.6066e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.165335
Average KL loss: 0.424697
Average total loss: 0.590032
tensor(-11.9957, device='cuda:0') tensor(2.3900, device='cuda:0') tensor(3.3777e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.167426
Average KL loss: 0.424524
Average total loss: 0.591950
tensor(-11.9984, device='cuda:0') tensor(2.3886, device='cuda:0') tensor(2.8735e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.166709
Average KL loss: 0.424380
Average total loss: 0.591089
tensor(-12.0012, device='cuda:0') tensor(2.3872, device='cuda:0') tensor(1.2890e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.163419
Average KL loss: 0.424246
Average total loss: 0.587665
tensor(-12.0039, device='cuda:0') tensor(2.3858, device='cuda:0') tensor(5.0207e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.163271
Average KL loss: 0.424077
Average total loss: 0.587348
tensor(-12.0065, device='cuda:0') tensor(2.3844, device='cuda:0') tensor(3.0456e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.162795
Average KL loss: 0.423932
Average total loss: 0.586727
tensor(-12.0092, device='cuda:0') tensor(2.3829, device='cuda:0') tensor(2.8700e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.160599
Average KL loss: 0.423771
Average total loss: 0.584370
tensor(-12.0119, device='cuda:0') tensor(2.3815, device='cuda:0') tensor(2.9231e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.161646
Average KL loss: 0.423604
Average total loss: 0.585250
tensor(-12.0146, device='cuda:0') tensor(2.3802, device='cuda:0') tensor(2.3176e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.162735
Average KL loss: 0.423479
Average total loss: 0.586214
tensor(-12.0172, device='cuda:0') tensor(2.3789, device='cuda:0') tensor(3.0608e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.160327
Average KL loss: 0.423336
Average total loss: 0.583662
tensor(-12.0199, device='cuda:0') tensor(2.3776, device='cuda:0') tensor(1.3145e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.158571
Average KL loss: 0.423196
Average total loss: 0.581767
tensor(-12.0225, device='cuda:0') tensor(2.3763, device='cuda:0') tensor(1.5646e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.161141
Average KL loss: 0.423054
Average total loss: 0.584195
tensor(-12.0251, device='cuda:0') tensor(2.3750, device='cuda:0') tensor(2.1522e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.159687
Average KL loss: 0.422927
Average total loss: 0.582614
tensor(-12.0278, device='cuda:0') tensor(2.3738, device='cuda:0') tensor(2.8394e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.158755
Average KL loss: 0.422774
Average total loss: 0.581528
tensor(-12.0304, device='cuda:0') tensor(2.3725, device='cuda:0') tensor(2.8081e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.159412
Average KL loss: 0.422631
Average total loss: 0.582042
tensor(-12.0330, device='cuda:0') tensor(2.3713, device='cuda:0') tensor(3.6992e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.157218
Average KL loss: 0.422481
Average total loss: 0.579698
tensor(-12.0356, device='cuda:0') tensor(2.3701, device='cuda:0') tensor(1.0425e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.158732
Average KL loss: 0.422363
Average total loss: 0.581094
tensor(-12.0381, device='cuda:0') tensor(2.3690, device='cuda:0') tensor(3.2416e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.155968
Average KL loss: 0.422234
Average total loss: 0.578202
tensor(-12.0407, device='cuda:0') tensor(2.3677, device='cuda:0') tensor(4.3927e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.156345
Average KL loss: 0.422076
Average total loss: 0.578421
tensor(-12.0433, device='cuda:0') tensor(2.3665, device='cuda:0') tensor(3.6011e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.158637
Average KL loss: 0.421907
Average total loss: 0.580544
tensor(-12.0458, device='cuda:0') tensor(2.3653, device='cuda:0') tensor(4.4029e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.155232
Average KL loss: 0.421750
Average total loss: 0.576982
tensor(-12.0484, device='cuda:0') tensor(2.3641, device='cuda:0') tensor(2.5038e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.156736
Average KL loss: 0.421626
Average total loss: 0.578362
tensor(-12.0509, device='cuda:0') tensor(2.3631, device='cuda:0') tensor(5.8284e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.153273
Average KL loss: 0.421513
Average total loss: 0.574786
tensor(-12.0535, device='cuda:0') tensor(2.3620, device='cuda:0') tensor(3.4964e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.155469
Average KL loss: 0.421384
Average total loss: 0.576853
tensor(-12.0560, device='cuda:0') tensor(2.3608, device='cuda:0') tensor(5.1858e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.156360
Average KL loss: 0.421224
Average total loss: 0.577584
tensor(-12.0585, device='cuda:0') tensor(2.3597, device='cuda:0') tensor(3.6939e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.153204
Average KL loss: 0.421075
Average total loss: 0.574279
tensor(-12.0610, device='cuda:0') tensor(2.3586, device='cuda:0') tensor(9.7893e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.152773
Average KL loss: 0.420933
Average total loss: 0.573706
tensor(-12.0635, device='cuda:0') tensor(2.3574, device='cuda:0') tensor(3.0587e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.151524
Average KL loss: 0.420775
Average total loss: 0.572299
tensor(-12.0660, device='cuda:0') tensor(2.3563, device='cuda:0') tensor(4.1625e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.152148
Average KL loss: 0.420597
Average total loss: 0.572745
tensor(-12.0685, device='cuda:0') tensor(2.3551, device='cuda:0') tensor(3.7268e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.152258
Average KL loss: 0.420443
Average total loss: 0.572701
tensor(-12.0710, device='cuda:0') tensor(2.3541, device='cuda:0') tensor(1.7633e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.155270
Average KL loss: 0.420288
Average total loss: 0.575558
tensor(-12.0735, device='cuda:0') tensor(2.3530, device='cuda:0') tensor(1.9779e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.151487
Average KL loss: 0.420110
Average total loss: 0.571596
tensor(-12.0759, device='cuda:0') tensor(2.3518, device='cuda:0') tensor(8.1714e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.150126
Average KL loss: 0.419952
Average total loss: 0.570077
tensor(-12.0784, device='cuda:0') tensor(2.3507, device='cuda:0') tensor(3.0932e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.154255
Average KL loss: 0.419792
Average total loss: 0.574047
tensor(-12.0808, device='cuda:0') tensor(2.3496, device='cuda:0') tensor(2.4135e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.148632
Average KL loss: 0.419653
Average total loss: 0.568285
tensor(-12.0833, device='cuda:0') tensor(2.3485, device='cuda:0') tensor(7.9595e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.149254
Average KL loss: 0.419488
Average total loss: 0.568742
tensor(-12.0857, device='cuda:0') tensor(2.3473, device='cuda:0') tensor(2.4870e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.152919
Average KL loss: 0.419328
Average total loss: 0.572247
tensor(-12.0882, device='cuda:0') tensor(2.3463, device='cuda:0') tensor(1.0477e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.152757
Average KL loss: 0.419180
Average total loss: 0.571936
tensor(-12.0906, device='cuda:0') tensor(2.3453, device='cuda:0') tensor(2.0168e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.148843
Average KL loss: 0.419026
Average total loss: 0.567869
tensor(-12.0930, device='cuda:0') tensor(2.3443, device='cuda:0') tensor(2.3380e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.150914
Average KL loss: 0.418876
Average total loss: 0.569790
tensor(-12.0954, device='cuda:0') tensor(2.3432, device='cuda:0') tensor(2.6962e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.146637
Average KL loss: 0.418707
Average total loss: 0.565344
tensor(-12.0978, device='cuda:0') tensor(2.3422, device='cuda:0') tensor(4.5019e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.148994
Average KL loss: 0.418538
Average total loss: 0.567532
tensor(-12.1002, device='cuda:0') tensor(2.3413, device='cuda:0') tensor(7.7675e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.149516
Average KL loss: 0.418399
Average total loss: 0.567914
tensor(-12.1026, device='cuda:0') tensor(2.3403, device='cuda:0') tensor(2.3475e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.150006
Average KL loss: 0.418254
Average total loss: 0.568260
tensor(-12.1050, device='cuda:0') tensor(2.3394, device='cuda:0') tensor(2.5952e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.145615
Average KL loss: 0.418121
Average total loss: 0.563737
tensor(-12.1073, device='cuda:0') tensor(2.3384, device='cuda:0') tensor(3.3706e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.148411
Average KL loss: 0.417991
Average total loss: 0.566401
tensor(-12.1097, device='cuda:0') tensor(2.3374, device='cuda:0') tensor(2.0026e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.145766
Average KL loss: 0.417849
Average total loss: 0.563615
tensor(-12.1121, device='cuda:0') tensor(2.3364, device='cuda:0') tensor(3.1392e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.145173
Average KL loss: 0.417704
Average total loss: 0.562876
tensor(-12.1144, device='cuda:0') tensor(2.3354, device='cuda:0') tensor(4.4219e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.148902
Average KL loss: 0.417549
Average total loss: 0.566451
tensor(-12.1168, device='cuda:0') tensor(2.3345, device='cuda:0') tensor(3.4029e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.146878
Average KL loss: 0.417417
Average total loss: 0.564295
tensor(-12.1191, device='cuda:0') tensor(2.3335, device='cuda:0') tensor(4.5311e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.146719
Average KL loss: 0.417277
Average total loss: 0.563996
tensor(-12.1214, device='cuda:0') tensor(2.3325, device='cuda:0') tensor(5.0368e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.146916
Average KL loss: 0.417100
Average total loss: 0.564016
tensor(-12.1238, device='cuda:0') tensor(2.3316, device='cuda:0') tensor(3.7411e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.144897
Average KL loss: 0.416911
Average total loss: 0.561808
tensor(-12.1261, device='cuda:0') tensor(2.3305, device='cuda:0') tensor(2.5950e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.145701
Average KL loss: 0.416748
Average total loss: 0.562449
tensor(-12.1284, device='cuda:0') tensor(2.3296, device='cuda:0') tensor(2.1628e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.146032
Average KL loss: 0.416591
Average total loss: 0.562623
tensor(-12.1307, device='cuda:0') tensor(2.3287, device='cuda:0') tensor(2.7685e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.143613
Average KL loss: 0.416417
Average total loss: 0.560030
tensor(-12.1330, device='cuda:0') tensor(2.3277, device='cuda:0') tensor(6.5722e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.142909
Average KL loss: 0.416244
Average total loss: 0.559153
tensor(-12.1353, device='cuda:0') tensor(2.3268, device='cuda:0') tensor(3.9746e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.140493
Average KL loss: 0.416071
Average total loss: 0.556563
tensor(-12.1376, device='cuda:0') tensor(2.3258, device='cuda:0') tensor(1.5488e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.142599
Average KL loss: 0.415924
Average total loss: 0.558522
tensor(-12.1399, device='cuda:0') tensor(2.3249, device='cuda:0') tensor(2.5897e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.144514
Average KL loss: 0.415807
Average total loss: 0.560321
tensor(-12.1422, device='cuda:0') tensor(2.3240, device='cuda:0') tensor(4.4358e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.142312
Average KL loss: 0.415716
Average total loss: 0.558028
tensor(-12.1445, device='cuda:0') tensor(2.3231, device='cuda:0') tensor(2.1133e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.142022
Average KL loss: 0.415581
Average total loss: 0.557603
tensor(-12.1467, device='cuda:0') tensor(2.3222, device='cuda:0') tensor(2.6864e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.140955
Average KL loss: 0.415453
Average total loss: 0.556407
tensor(-12.1490, device='cuda:0') tensor(2.3214, device='cuda:0') tensor(3.6770e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.142415
Average KL loss: 0.415328
Average total loss: 0.557743
tensor(-12.1512, device='cuda:0') tensor(2.3206, device='cuda:0') tensor(2.6699e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.140229
Average KL loss: 0.415184
Average total loss: 0.555414
tensor(-12.1535, device='cuda:0') tensor(2.3197, device='cuda:0') tensor(3.7804e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.140879
Average KL loss: 0.415034
Average total loss: 0.555914
tensor(-12.1557, device='cuda:0') tensor(2.3188, device='cuda:0') tensor(1.7230e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.141212
Average KL loss: 0.414897
Average total loss: 0.556109
tensor(-12.1580, device='cuda:0') tensor(2.3180, device='cuda:0') tensor(3.6798e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.139496
Average KL loss: 0.414730
Average total loss: 0.554225
tensor(-12.1602, device='cuda:0') tensor(2.3171, device='cuda:0') tensor(2.6893e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.139497
Average KL loss: 0.414598
Average total loss: 0.554095
tensor(-12.1624, device='cuda:0') tensor(2.3163, device='cuda:0') tensor(3.7852e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.140012
Average KL loss: 0.414472
Average total loss: 0.554484
tensor(-12.1647, device='cuda:0') tensor(2.3155, device='cuda:0') tensor(1.5407e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.137547
Average KL loss: 0.414338
Average total loss: 0.551884
tensor(-12.1669, device='cuda:0') tensor(2.3147, device='cuda:0') tensor(4.4030e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.138379
Average KL loss: 0.414191
Average total loss: 0.552570
tensor(-12.1691, device='cuda:0') tensor(2.3139, device='cuda:0') tensor(4.1002e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.136708
Average KL loss: 0.414054
Average total loss: 0.550762
tensor(-12.1713, device='cuda:0') tensor(2.3130, device='cuda:0') tensor(1.2261e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.139314
Average KL loss: 0.413912
Average total loss: 0.553227
tensor(-12.1735, device='cuda:0') tensor(2.3121, device='cuda:0') tensor(2.0600e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.138160
Average KL loss: 0.413771
Average total loss: 0.551932
tensor(-12.1757, device='cuda:0') tensor(2.3114, device='cuda:0') tensor(2.5887e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.138772
Average KL loss: 0.413634
Average total loss: 0.552406
tensor(-12.1779, device='cuda:0') tensor(2.3105, device='cuda:0') tensor(3.1808e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.136762
Average KL loss: 0.413487
Average total loss: 0.550249
tensor(-12.1801, device='cuda:0') tensor(2.3097, device='cuda:0') tensor(3.0329e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.136374
Average KL loss: 0.413345
Average total loss: 0.549719
tensor(-12.1822, device='cuda:0') tensor(2.3089, device='cuda:0') tensor(2.8024e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.136310
Average KL loss: 0.413204
Average total loss: 0.549514
tensor(-12.1844, device='cuda:0') tensor(2.3081, device='cuda:0') tensor(5.8221e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.133606
Average KL loss: 0.413055
Average total loss: 0.546662
 Percentile value: 3.068020105361938
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =     972 /    1728             ( 56.25%) | total_pruned =     756 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2234 /   36864             (  6.06%) | total_pruned =   34630 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2433 /   36864             (  6.60%) | total_pruned =   34431 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2160 /   36864             (  5.86%) | total_pruned =   34704 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2100 /   36864             (  5.70%) | total_pruned =   34764 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3886 /   73728             (  5.27%) | total_pruned =   69842 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5392 /  147456             (  3.66%) | total_pruned =  142064 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1624 /    8192             ( 19.82%) | total_pruned =    6568 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3722 /  147456             (  2.52%) | total_pruned =  143734 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3526 /  147456             (  2.39%) | total_pruned =  143930 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7873 /  294912             (  2.67%) | total_pruned =  287039 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     113 /     256             ( 44.14%) | total_pruned =     143 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    9792 /  589824             (  1.66%) | total_pruned =  580032 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     101 /     256             ( 39.45%) | total_pruned =     155 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2796 /   32768             (  8.53%) | total_pruned =   29972 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     102 /     256             ( 39.84%) | total_pruned =     154 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    4111 /  589824             (  0.70%) | total_pruned =  585713 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     145 /     256             ( 56.64%) | total_pruned =     111 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      66 /     256             ( 25.78%) | total_pruned =     190 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4351 /  589824             (  0.74%) | total_pruned =  585473 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    8347 / 1179648             (  0.71%) | total_pruned = 1171301 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     314 /     512             ( 61.33%) | total_pruned =     198 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     120 /     512             ( 23.44%) | total_pruned =     392 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    6921 / 2359296             (  0.29%) | total_pruned = 2352375 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     382 /     512             ( 74.61%) | total_pruned =     130 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     265 /     512             ( 51.76%) | total_pruned =     247 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2417 /  131072             (  1.84%) | total_pruned =  128655 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     302 /     512             ( 58.98%) | total_pruned =     210 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     247 /     512             ( 48.24%) | total_pruned =     265 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3740 / 2359296             (  0.16%) | total_pruned = 2355556 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    4679 / 2359296             (  0.20%) | total_pruned = 2354617 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      76 /     512             ( 14.84%) | total_pruned =     436 | shape = torch.Size([512])
linear.weight        | nonzeros =    2339 /    5120             ( 45.68%) | total_pruned =    2781 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 26/200 Loss: 0.000225 Accuracy: 86.37 100.00 % Best test Accuracy: 86.78%
tensor(-12.1866, device='cuda:0') tensor(2.3072, device='cuda:0') tensor(-1.1802e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.335268
Average KL loss: 0.409038
Average total loss: 0.744306
tensor(-12.1959, device='cuda:0') tensor(2.1984, device='cuda:0') tensor(-6.6484e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.312069
Average KL loss: 0.405499
Average total loss: 0.717568
tensor(-12.2035, device='cuda:0') tensor(2.1253, device='cuda:0') tensor(-9.2738e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.287647
Average KL loss: 0.403826
Average total loss: 0.691473
tensor(-12.2100, device='cuda:0') tensor(2.0693, device='cuda:0') tensor(-2.9442e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.278366
Average KL loss: 0.402861
Average total loss: 0.681228
tensor(-12.2158, device='cuda:0') tensor(2.0242, device='cuda:0') tensor(-4.6826e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.269195
Average KL loss: 0.402292
Average total loss: 0.671487
tensor(-12.2212, device='cuda:0') tensor(1.9867, device='cuda:0') tensor(-3.6850e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.265306
Average KL loss: 0.401923
Average total loss: 0.667229
tensor(-12.2261, device='cuda:0') tensor(1.9549, device='cuda:0') tensor(-6.0426e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.248333
Average KL loss: 0.401696
Average total loss: 0.650029
tensor(-12.2308, device='cuda:0') tensor(1.9273, device='cuda:0') tensor(-2.7627e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.243203
Average KL loss: 0.401575
Average total loss: 0.644778
tensor(-12.2352, device='cuda:0') tensor(1.9031, device='cuda:0') tensor(3.4166e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.239126
Average KL loss: 0.401512
Average total loss: 0.640638
tensor(-12.2394, device='cuda:0') tensor(1.8815, device='cuda:0') tensor(1.5894e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.238307
Average KL loss: 0.401493
Average total loss: 0.639799
tensor(-12.2434, device='cuda:0') tensor(1.8622, device='cuda:0') tensor(-5.2811e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.226612
Average KL loss: 0.401529
Average total loss: 0.628141
tensor(-12.2473, device='cuda:0') tensor(1.8448, device='cuda:0') tensor(-6.5460e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.222337
Average KL loss: 0.401589
Average total loss: 0.623926
tensor(-12.2510, device='cuda:0') tensor(1.8290, device='cuda:0') tensor(-6.7675e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.216608
Average KL loss: 0.401635
Average total loss: 0.618243
tensor(-12.2546, device='cuda:0') tensor(1.8144, device='cuda:0') tensor(-5.4914e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.214232
Average KL loss: 0.401711
Average total loss: 0.615943
tensor(-12.2581, device='cuda:0') tensor(1.8010, device='cuda:0') tensor(6.8309e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.208542
Average KL loss: 0.401774
Average total loss: 0.610316
tensor(-12.2616, device='cuda:0') tensor(1.7886, device='cuda:0') tensor(-6.1019e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.209034
Average KL loss: 0.401843
Average total loss: 0.610877
tensor(-12.2649, device='cuda:0') tensor(1.7772, device='cuda:0') tensor(-2.9436e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.200757
Average KL loss: 0.401940
Average total loss: 0.602698
tensor(-12.2682, device='cuda:0') tensor(1.7664, device='cuda:0') tensor(-2.7412e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.201170
Average KL loss: 0.402033
Average total loss: 0.603203
tensor(-12.2714, device='cuda:0') tensor(1.7564, device='cuda:0') tensor(-1.8794e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.199328
Average KL loss: 0.402132
Average total loss: 0.601460
tensor(-12.2745, device='cuda:0') tensor(1.7471, device='cuda:0') tensor(-7.4871e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.194944
Average KL loss: 0.402232
Average total loss: 0.597176
tensor(-12.2776, device='cuda:0') tensor(1.7382, device='cuda:0') tensor(-2.7561e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.194330
Average KL loss: 0.402335
Average total loss: 0.596666
tensor(-12.2807, device='cuda:0') tensor(1.7300, device='cuda:0') tensor(1.4185e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.189083
Average KL loss: 0.402438
Average total loss: 0.591522
tensor(-12.2837, device='cuda:0') tensor(1.7222, device='cuda:0') tensor(-5.5331e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.187805
Average KL loss: 0.402554
Average total loss: 0.590359
tensor(-12.2866, device='cuda:0') tensor(1.7149, device='cuda:0') tensor(-2.0956e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.188119
Average KL loss: 0.402660
Average total loss: 0.590779
tensor(-12.2895, device='cuda:0') tensor(1.7079, device='cuda:0') tensor(1.1855e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.184036
Average KL loss: 0.402762
Average total loss: 0.586798
tensor(-12.2924, device='cuda:0') tensor(1.7012, device='cuda:0') tensor(-5.0001e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.184341
Average KL loss: 0.402860
Average total loss: 0.587201
tensor(-12.2952, device='cuda:0') tensor(1.6949, device='cuda:0') tensor(-7.8412e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.183490
Average KL loss: 0.402967
Average total loss: 0.586457
tensor(-12.2980, device='cuda:0') tensor(1.6889, device='cuda:0') tensor(-3.2531e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.181714
Average KL loss: 0.403050
Average total loss: 0.584764
tensor(-12.3008, device='cuda:0') tensor(1.6831, device='cuda:0') tensor(-2.2674e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.179465
Average KL loss: 0.403123
Average total loss: 0.582588
tensor(-12.3035, device='cuda:0') tensor(1.6776, device='cuda:0') tensor(-3.1887e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.176959
Average KL loss: 0.403186
Average total loss: 0.580145
tensor(-12.3062, device='cuda:0') tensor(1.6723, device='cuda:0') tensor(-2.2838e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.175123
Average KL loss: 0.403264
Average total loss: 0.578387
tensor(-12.3089, device='cuda:0') tensor(1.6673, device='cuda:0') tensor(1.9784e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.173386
Average KL loss: 0.403349
Average total loss: 0.576735
tensor(-12.3116, device='cuda:0') tensor(1.6625, device='cuda:0') tensor(-2.6087e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.174251
Average KL loss: 0.403423
Average total loss: 0.577674
tensor(-12.3142, device='cuda:0') tensor(1.6579, device='cuda:0') tensor(6.9031e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.172792
Average KL loss: 0.403524
Average total loss: 0.576316
tensor(-12.3168, device='cuda:0') tensor(1.6535, device='cuda:0') tensor(-2.8007e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.169553
Average KL loss: 0.403605
Average total loss: 0.573158
tensor(-12.3194, device='cuda:0') tensor(1.6492, device='cuda:0') tensor(-4.6773e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.170403
Average KL loss: 0.403704
Average total loss: 0.574107
tensor(-12.3219, device='cuda:0') tensor(1.6452, device='cuda:0') tensor(1.4116e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.169765
Average KL loss: 0.403768
Average total loss: 0.573533
tensor(-12.3245, device='cuda:0') tensor(1.6412, device='cuda:0') tensor(1.0320e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.163993
Average KL loss: 0.403827
Average total loss: 0.567820
tensor(-12.3270, device='cuda:0') tensor(1.6374, device='cuda:0') tensor(4.0263e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.166077
Average KL loss: 0.403896
Average total loss: 0.569973
tensor(-12.3295, device='cuda:0') tensor(1.6337, device='cuda:0') tensor(-2.1064e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.161131
Average KL loss: 0.403965
Average total loss: 0.565096
tensor(-12.3320, device='cuda:0') tensor(1.6302, device='cuda:0') tensor(-5.5338e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.161662
Average KL loss: 0.404043
Average total loss: 0.565705
tensor(-12.3345, device='cuda:0') tensor(1.6268, device='cuda:0') tensor(-4.2476e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.164365
Average KL loss: 0.404112
Average total loss: 0.568477
tensor(-12.3369, device='cuda:0') tensor(1.6235, device='cuda:0') tensor(-3.3797e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.159324
Average KL loss: 0.404179
Average total loss: 0.563503
tensor(-12.3393, device='cuda:0') tensor(1.6203, device='cuda:0') tensor(-1.7985e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.158285
Average KL loss: 0.404222
Average total loss: 0.562507
tensor(-12.3418, device='cuda:0') tensor(1.6172, device='cuda:0') tensor(-1.1883e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.158733
Average KL loss: 0.404306
Average total loss: 0.563039
tensor(-12.3442, device='cuda:0') tensor(1.6143, device='cuda:0') tensor(-6.8288e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.154173
Average KL loss: 0.404368
Average total loss: 0.558541
tensor(-12.3465, device='cuda:0') tensor(1.6113, device='cuda:0') tensor(-9.9263e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.154692
Average KL loss: 0.404416
Average total loss: 0.559107
tensor(-12.3489, device='cuda:0') tensor(1.6085, device='cuda:0') tensor(-4.7113e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.151700
Average KL loss: 0.404485
Average total loss: 0.556185
tensor(-12.3513, device='cuda:0') tensor(1.6058, device='cuda:0') tensor(6.4262e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.151919
Average KL loss: 0.404525
Average total loss: 0.556444
tensor(-12.3536, device='cuda:0') tensor(1.6032, device='cuda:0') tensor(1.8132e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.152204
Average KL loss: 0.404586
Average total loss: 0.556790
tensor(-12.3560, device='cuda:0') tensor(1.6006, device='cuda:0') tensor(-9.8319e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.153105
Average KL loss: 0.404620
Average total loss: 0.557725
tensor(-12.3583, device='cuda:0') tensor(1.5981, device='cuda:0') tensor(-2.5234e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.154028
Average KL loss: 0.404658
Average total loss: 0.558686
tensor(-12.3606, device='cuda:0') tensor(1.5958, device='cuda:0') tensor(-4.1256e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.148624
Average KL loss: 0.404698
Average total loss: 0.553321
tensor(-12.3629, device='cuda:0') tensor(1.5935, device='cuda:0') tensor(-3.1707e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.150325
Average KL loss: 0.404720
Average total loss: 0.555044
tensor(-12.3652, device='cuda:0') tensor(1.5912, device='cuda:0') tensor(-4.1286e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.148263
Average KL loss: 0.404730
Average total loss: 0.552993
tensor(-12.3674, device='cuda:0') tensor(1.5889, device='cuda:0') tensor(-2.9155e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.145472
Average KL loss: 0.404737
Average total loss: 0.550210
tensor(-12.3697, device='cuda:0') tensor(1.5866, device='cuda:0') tensor(-1.3971e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.149449
Average KL loss: 0.404734
Average total loss: 0.554183
tensor(-12.3720, device='cuda:0') tensor(1.5845, device='cuda:0') tensor(2.9411e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.146371
Average KL loss: 0.404758
Average total loss: 0.551129
tensor(-12.3742, device='cuda:0') tensor(1.5825, device='cuda:0') tensor(-5.0502e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.142102
Average KL loss: 0.404813
Average total loss: 0.546915
tensor(-12.3764, device='cuda:0') tensor(1.5805, device='cuda:0') tensor(-1.7058e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.140583
Average KL loss: 0.404842
Average total loss: 0.545425
tensor(-12.3786, device='cuda:0') tensor(1.5786, device='cuda:0') tensor(-3.6042e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.142572
Average KL loss: 0.404864
Average total loss: 0.547436
tensor(-12.3809, device='cuda:0') tensor(1.5767, device='cuda:0') tensor(-3.1361e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.140340
Average KL loss: 0.404889
Average total loss: 0.545229
tensor(-12.3830, device='cuda:0') tensor(1.5750, device='cuda:0') tensor(-3.1162e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.142939
Average KL loss: 0.404931
Average total loss: 0.547869
tensor(-12.3852, device='cuda:0') tensor(1.5733, device='cuda:0') tensor(-3.4508e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.143032
Average KL loss: 0.404972
Average total loss: 0.548004
tensor(-12.3874, device='cuda:0') tensor(1.5715, device='cuda:0') tensor(-1.8147e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.136489
Average KL loss: 0.404991
Average total loss: 0.541480
tensor(-12.3896, device='cuda:0') tensor(1.5698, device='cuda:0') tensor(-1.6062e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.141940
Average KL loss: 0.405004
Average total loss: 0.546944
tensor(-12.3917, device='cuda:0') tensor(1.5681, device='cuda:0') tensor(-2.4573e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.135813
Average KL loss: 0.405007
Average total loss: 0.540821
tensor(-12.3939, device='cuda:0') tensor(1.5665, device='cuda:0') tensor(-2.1413e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.137570
Average KL loss: 0.405015
Average total loss: 0.542586
tensor(-12.3960, device='cuda:0') tensor(1.5649, device='cuda:0') tensor(-2.4163e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.134609
Average KL loss: 0.405012
Average total loss: 0.539621
tensor(-12.3982, device='cuda:0') tensor(1.5633, device='cuda:0') tensor(-1.4845e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.137950
Average KL loss: 0.405017
Average total loss: 0.542967
tensor(-12.4003, device='cuda:0') tensor(1.5618, device='cuda:0') tensor(-2.7346e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.138044
Average KL loss: 0.405034
Average total loss: 0.543077
tensor(-12.4024, device='cuda:0') tensor(1.5603, device='cuda:0') tensor(9.3017e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.135556
Average KL loss: 0.405049
Average total loss: 0.540605
tensor(-12.4045, device='cuda:0') tensor(1.5588, device='cuda:0') tensor(-1.4353e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.137337
Average KL loss: 0.405054
Average total loss: 0.542391
tensor(-12.4066, device='cuda:0') tensor(1.5574, device='cuda:0') tensor(1.2123e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.131431
Average KL loss: 0.405072
Average total loss: 0.536503
tensor(-12.4087, device='cuda:0') tensor(1.5560, device='cuda:0') tensor(-2.2462e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.134967
Average KL loss: 0.405080
Average total loss: 0.540047
tensor(-12.4108, device='cuda:0') tensor(1.5547, device='cuda:0') tensor(-2.3778e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.130980
Average KL loss: 0.405092
Average total loss: 0.536072
tensor(-12.4129, device='cuda:0') tensor(1.5535, device='cuda:0') tensor(2.6234e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.128238
Average KL loss: 0.405088
Average total loss: 0.533326
tensor(-12.4150, device='cuda:0') tensor(1.5522, device='cuda:0') tensor(-1.8966e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.128061
Average KL loss: 0.405086
Average total loss: 0.533147
tensor(-12.4170, device='cuda:0') tensor(1.5510, device='cuda:0') tensor(-1.8500e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.131707
Average KL loss: 0.405050
Average total loss: 0.536757
tensor(-12.4191, device='cuda:0') tensor(1.5497, device='cuda:0') tensor(-7.2823e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.128349
Average KL loss: 0.405033
Average total loss: 0.533381
tensor(-12.4211, device='cuda:0') tensor(1.5485, device='cuda:0') tensor(-1.5261e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.129541
Average KL loss: 0.405019
Average total loss: 0.534559
tensor(-12.4232, device='cuda:0') tensor(1.5473, device='cuda:0') tensor(-3.6672e-11, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.128339
Average KL loss: 0.404988
Average total loss: 0.533326
tensor(-12.4252, device='cuda:0') tensor(1.5461, device='cuda:0') tensor(2.3852e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.130333
Average KL loss: 0.404953
Average total loss: 0.535287
tensor(-12.4272, device='cuda:0') tensor(1.5449, device='cuda:0') tensor(-3.6554e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.125483
Average KL loss: 0.404943
Average total loss: 0.530426
tensor(-12.4292, device='cuda:0') tensor(1.5439, device='cuda:0') tensor(2.1338e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.126972
Average KL loss: 0.404926
Average total loss: 0.531897
tensor(-12.4313, device='cuda:0') tensor(1.5428, device='cuda:0') tensor(3.5319e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.126083
Average KL loss: 0.404900
Average total loss: 0.530983
tensor(-12.4333, device='cuda:0') tensor(1.5418, device='cuda:0') tensor(-2.2329e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.125619
Average KL loss: 0.404886
Average total loss: 0.530505
tensor(-12.4353, device='cuda:0') tensor(1.5407, device='cuda:0') tensor(-7.8603e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.124544
Average KL loss: 0.404861
Average total loss: 0.529405
tensor(-12.4373, device='cuda:0') tensor(1.5397, device='cuda:0') tensor(2.9105e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.128759
Average KL loss: 0.404843
Average total loss: 0.533602
tensor(-12.4392, device='cuda:0') tensor(1.5388, device='cuda:0') tensor(-2.2624e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.128092
Average KL loss: 0.404858
Average total loss: 0.532950
tensor(-12.4412, device='cuda:0') tensor(1.5378, device='cuda:0') tensor(-3.7828e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.123076
Average KL loss: 0.404830
Average total loss: 0.527905
tensor(-12.4432, device='cuda:0') tensor(1.5368, device='cuda:0') tensor(-1.1986e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.122163
Average KL loss: 0.404782
Average total loss: 0.526945
tensor(-12.4452, device='cuda:0') tensor(1.5358, device='cuda:0') tensor(-3.8053e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.120357
Average KL loss: 0.404760
Average total loss: 0.525116
tensor(-12.4471, device='cuda:0') tensor(1.5350, device='cuda:0') tensor(-2.9114e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.122140
Average KL loss: 0.404746
Average total loss: 0.526886
tensor(-12.4491, device='cuda:0') tensor(1.5340, device='cuda:0') tensor(-2.1654e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.122383
Average KL loss: 0.404718
Average total loss: 0.527101
tensor(-12.4510, device='cuda:0') tensor(1.5331, device='cuda:0') tensor(-4.0742e-11, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.120468
Average KL loss: 0.404698
Average total loss: 0.525165
tensor(-12.4530, device='cuda:0') tensor(1.5323, device='cuda:0') tensor(-7.6957e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.120296
Average KL loss: 0.404651
Average total loss: 0.524948
tensor(-12.4549, device='cuda:0') tensor(1.5314, device='cuda:0') tensor(-7.9618e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.120378
Average KL loss: 0.404613
Average total loss: 0.524991
tensor(-12.4569, device='cuda:0') tensor(1.5305, device='cuda:0') tensor(1.6490e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.120760
Average KL loss: 0.404582
Average total loss: 0.525342
tensor(-12.4588, device='cuda:0') tensor(1.5298, device='cuda:0') tensor(-1.3531e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.117842
Average KL loss: 0.404568
Average total loss: 0.522410
tensor(-12.4607, device='cuda:0') tensor(1.5290, device='cuda:0') tensor(2.0252e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.117922
Average KL loss: 0.404543
Average total loss: 0.522465
tensor(-12.4626, device='cuda:0') tensor(1.5281, device='cuda:0') tensor(-4.2332e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.117235
Average KL loss: 0.404515
Average total loss: 0.521751
tensor(-12.4645, device='cuda:0') tensor(1.5274, device='cuda:0') tensor(1.4933e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.116326
Average KL loss: 0.404466
Average total loss: 0.520792
tensor(-12.4664, device='cuda:0') tensor(1.5266, device='cuda:0') tensor(1.7736e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.117740
Average KL loss: 0.404441
Average total loss: 0.522180
tensor(-12.4683, device='cuda:0') tensor(1.5259, device='cuda:0') tensor(1.7741e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.115965
Average KL loss: 0.404431
Average total loss: 0.520396
tensor(-12.4702, device='cuda:0') tensor(1.5252, device='cuda:0') tensor(-3.4120e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.115505
Average KL loss: 0.404401
Average total loss: 0.519906
tensor(-12.4721, device='cuda:0') tensor(1.5244, device='cuda:0') tensor(-6.7994e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.117633
Average KL loss: 0.404344
Average total loss: 0.521977
tensor(-12.4740, device='cuda:0') tensor(1.5237, device='cuda:0') tensor(1.4969e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.115884
Average KL loss: 0.404302
Average total loss: 0.520186
tensor(-12.4759, device='cuda:0') tensor(1.5230, device='cuda:0') tensor(-4.8167e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.114778
Average KL loss: 0.404282
Average total loss: 0.519060
tensor(-12.4777, device='cuda:0') tensor(1.5224, device='cuda:0') tensor(-1.0724e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.115326
Average KL loss: 0.404243
Average total loss: 0.519569
tensor(-12.4796, device='cuda:0') tensor(1.5217, device='cuda:0') tensor(-1.5341e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.114870
Average KL loss: 0.404192
Average total loss: 0.519062
tensor(-12.4815, device='cuda:0') tensor(1.5211, device='cuda:0') tensor(-1.1646e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.112702
Average KL loss: 0.404176
Average total loss: 0.516878
tensor(-12.4833, device='cuda:0') tensor(1.5205, device='cuda:0') tensor(-1.0345e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.112746
Average KL loss: 0.404159
Average total loss: 0.516906
tensor(-12.4852, device='cuda:0') tensor(1.5199, device='cuda:0') tensor(4.5630e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.111200
Average KL loss: 0.404117
Average total loss: 0.515317
tensor(-12.4870, device='cuda:0') tensor(1.5193, device='cuda:0') tensor(-2.4531e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.113176
Average KL loss: 0.404101
Average total loss: 0.517276
tensor(-12.4889, device='cuda:0') tensor(1.5187, device='cuda:0') tensor(-1.8634e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.113984
Average KL loss: 0.404064
Average total loss: 0.518048
tensor(-12.4907, device='cuda:0') tensor(1.5182, device='cuda:0') tensor(2.0873e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.112991
Average KL loss: 0.404000
Average total loss: 0.516991
tensor(-12.4925, device='cuda:0') tensor(1.5176, device='cuda:0') tensor(4.5119e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.111848
Average KL loss: 0.403950
Average total loss: 0.515799
tensor(-12.4944, device='cuda:0') tensor(1.5171, device='cuda:0') tensor(-1.0668e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.110716
Average KL loss: 0.403930
Average total loss: 0.514646
tensor(-12.4962, device='cuda:0') tensor(1.5166, device='cuda:0') tensor(6.8712e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.107960
Average KL loss: 0.403894
Average total loss: 0.511854
tensor(-12.4980, device='cuda:0') tensor(1.5160, device='cuda:0') tensor(-1.8935e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.108719
Average KL loss: 0.403844
Average total loss: 0.512563
tensor(-12.4998, device='cuda:0') tensor(1.5155, device='cuda:0') tensor(-7.7585e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.107895
Average KL loss: 0.403805
Average total loss: 0.511700
tensor(-12.5016, device='cuda:0') tensor(1.5149, device='cuda:0') tensor(6.4289e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.107668
Average KL loss: 0.403751
Average total loss: 0.511419
tensor(-12.5034, device='cuda:0') tensor(1.5143, device='cuda:0') tensor(-2.9835e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.109052
Average KL loss: 0.403718
Average total loss: 0.512770
tensor(-12.5052, device='cuda:0') tensor(1.5138, device='cuda:0') tensor(-1.1866e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.109532
Average KL loss: 0.403671
Average total loss: 0.513203
tensor(-12.5070, device='cuda:0') tensor(1.5133, device='cuda:0') tensor(-2.2464e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.104870
Average KL loss: 0.403627
Average total loss: 0.508497
tensor(-12.5088, device='cuda:0') tensor(1.5128, device='cuda:0') tensor(-1.2295e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.108677
Average KL loss: 0.403594
Average total loss: 0.512272
tensor(-12.5106, device='cuda:0') tensor(1.5123, device='cuda:0') tensor(1.4233e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.107454
Average KL loss: 0.403546
Average total loss: 0.511000
tensor(-12.5124, device='cuda:0') tensor(1.5118, device='cuda:0') tensor(-1.6193e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.107249
Average KL loss: 0.403492
Average total loss: 0.510741
tensor(-12.5142, device='cuda:0') tensor(1.5113, device='cuda:0') tensor(-3.2707e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.108232
Average KL loss: 0.403446
Average total loss: 0.511678
tensor(-12.5159, device='cuda:0') tensor(1.5109, device='cuda:0') tensor(-9.5335e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.107226
Average KL loss: 0.403413
Average total loss: 0.510639
tensor(-12.5177, device='cuda:0') tensor(1.5105, device='cuda:0') tensor(1.0279e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.103789
Average KL loss: 0.403376
Average total loss: 0.507165
tensor(-12.5195, device='cuda:0') tensor(1.5101, device='cuda:0') tensor(-6.8694e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.104398
Average KL loss: 0.403313
Average total loss: 0.507711
tensor(-12.5212, device='cuda:0') tensor(1.5097, device='cuda:0') tensor(1.8094e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.105704
Average KL loss: 0.403259
Average total loss: 0.508963
tensor(-12.5230, device='cuda:0') tensor(1.5093, device='cuda:0') tensor(-3.7048e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.102678
Average KL loss: 0.403225
Average total loss: 0.505903
tensor(-12.5247, device='cuda:0') tensor(1.5090, device='cuda:0') tensor(-2.0662e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.103212
Average KL loss: 0.403164
Average total loss: 0.506376
tensor(-12.5265, device='cuda:0') tensor(1.5086, device='cuda:0') tensor(9.5228e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.103710
Average KL loss: 0.403110
Average total loss: 0.506820
tensor(-12.5282, device='cuda:0') tensor(1.5081, device='cuda:0') tensor(-3.3314e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.102517
Average KL loss: 0.403046
Average total loss: 0.505563
tensor(-12.5300, device='cuda:0') tensor(1.5077, device='cuda:0') tensor(-2.1244e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.101990
Average KL loss: 0.403002
Average total loss: 0.504993
tensor(-12.5317, device='cuda:0') tensor(1.5073, device='cuda:0') tensor(3.2209e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.103789
Average KL loss: 0.402947
Average total loss: 0.506736
tensor(-12.5334, device='cuda:0') tensor(1.5070, device='cuda:0') tensor(1.6569e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.102900
Average KL loss: 0.402905
Average total loss: 0.505805
tensor(-12.5352, device='cuda:0') tensor(1.5067, device='cuda:0') tensor(1.8946e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.098419
Average KL loss: 0.402871
Average total loss: 0.501290
tensor(-12.5369, device='cuda:0') tensor(1.5063, device='cuda:0') tensor(-1.2654e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.103154
Average KL loss: 0.402825
Average total loss: 0.505979
tensor(-12.5386, device='cuda:0') tensor(1.5059, device='cuda:0') tensor(-4.5544e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.100923
Average KL loss: 0.402776
Average total loss: 0.503698
tensor(-12.5403, device='cuda:0') tensor(1.5055, device='cuda:0') tensor(5.7685e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.097978
Average KL loss: 0.402721
Average total loss: 0.500699
tensor(-12.5420, device='cuda:0') tensor(1.5052, device='cuda:0') tensor(5.9264e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.100560
Average KL loss: 0.402652
Average total loss: 0.503212
tensor(-12.5437, device='cuda:0') tensor(1.5049, device='cuda:0') tensor(-1.1318e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.100345
Average KL loss: 0.402583
Average total loss: 0.502928
tensor(-12.5454, device='cuda:0') tensor(1.5045, device='cuda:0') tensor(-1.6567e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.099492
Average KL loss: 0.402533
Average total loss: 0.502025
tensor(-12.5471, device='cuda:0') tensor(1.5042, device='cuda:0') tensor(-2.6026e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.098631
Average KL loss: 0.402493
Average total loss: 0.501124
tensor(-12.5488, device='cuda:0') tensor(1.5039, device='cuda:0') tensor(2.5426e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.096944
Average KL loss: 0.402442
Average total loss: 0.499386
tensor(-12.5505, device='cuda:0') tensor(1.5036, device='cuda:0') tensor(-5.9681e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.097018
Average KL loss: 0.402386
Average total loss: 0.499405
tensor(-12.5522, device='cuda:0') tensor(1.5032, device='cuda:0') tensor(-2.1927e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.099609
Average KL loss: 0.402300
Average total loss: 0.501909
tensor(-12.5539, device='cuda:0') tensor(1.5028, device='cuda:0') tensor(-1.0857e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.095065
Average KL loss: 0.402241
Average total loss: 0.497306
tensor(-12.5556, device='cuda:0') tensor(1.5025, device='cuda:0') tensor(2.8578e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.095616
Average KL loss: 0.402171
Average total loss: 0.497787
tensor(-12.5573, device='cuda:0') tensor(1.5022, device='cuda:0') tensor(3.1797e-11, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.097300
Average KL loss: 0.402110
Average total loss: 0.499410
tensor(-12.5590, device='cuda:0') tensor(1.5020, device='cuda:0') tensor(-1.7458e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.096161
Average KL loss: 0.402046
Average total loss: 0.498207
tensor(-12.5606, device='cuda:0') tensor(1.5017, device='cuda:0') tensor(2.4759e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.094672
Average KL loss: 0.401993
Average total loss: 0.496665
tensor(-12.5623, device='cuda:0') tensor(1.5013, device='cuda:0') tensor(1.6617e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.094176
Average KL loss: 0.401937
Average total loss: 0.496112
tensor(-12.5640, device='cuda:0') tensor(1.5010, device='cuda:0') tensor(-1.5195e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.095045
Average KL loss: 0.401864
Average total loss: 0.496909
tensor(-12.5656, device='cuda:0') tensor(1.5007, device='cuda:0') tensor(-2.3795e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.093129
Average KL loss: 0.401806
Average total loss: 0.494935
tensor(-12.5673, device='cuda:0') tensor(1.5005, device='cuda:0') tensor(1.2506e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.093922
Average KL loss: 0.401741
Average total loss: 0.495663
tensor(-12.5689, device='cuda:0') tensor(1.5002, device='cuda:0') tensor(7.1269e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.094022
Average KL loss: 0.401682
Average total loss: 0.495705
tensor(-12.5706, device='cuda:0') tensor(1.4999, device='cuda:0') tensor(-2.2233e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.091615
Average KL loss: 0.401612
Average total loss: 0.493227
tensor(-12.5722, device='cuda:0') tensor(1.4997, device='cuda:0') tensor(-1.7140e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.093742
Average KL loss: 0.401538
Average total loss: 0.495280
tensor(-12.5739, device='cuda:0') tensor(1.4994, device='cuda:0') tensor(-3.0552e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.091674
Average KL loss: 0.401490
Average total loss: 0.493163
tensor(-12.5755, device='cuda:0') tensor(1.4992, device='cuda:0') tensor(2.3871e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.090899
Average KL loss: 0.401444
Average total loss: 0.492342
tensor(-12.5771, device='cuda:0') tensor(1.4990, device='cuda:0') tensor(-6.0841e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.091945
Average KL loss: 0.401380
Average total loss: 0.493324
tensor(-12.5788, device='cuda:0') tensor(1.4988, device='cuda:0') tensor(-1.4871e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.093216
Average KL loss: 0.401320
Average total loss: 0.494536
tensor(-12.5804, device='cuda:0') tensor(1.4985, device='cuda:0') tensor(2.5656e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.090889
Average KL loss: 0.401261
Average total loss: 0.492151
tensor(-12.5820, device='cuda:0') tensor(1.4983, device='cuda:0') tensor(1.4197e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.093555
Average KL loss: 0.401202
Average total loss: 0.494757
tensor(-12.5836, device='cuda:0') tensor(1.4981, device='cuda:0') tensor(-4.2477e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.093262
Average KL loss: 0.401165
Average total loss: 0.494428
tensor(-12.5853, device='cuda:0') tensor(1.4980, device='cuda:0') tensor(-2.7479e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.091117
Average KL loss: 0.401112
Average total loss: 0.492228
tensor(-12.5869, device='cuda:0') tensor(1.4977, device='cuda:0') tensor(1.3205e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.088883
Average KL loss: 0.401033
Average total loss: 0.489916
tensor(-12.5885, device='cuda:0') tensor(1.4974, device='cuda:0') tensor(1.4604e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.090076
Average KL loss: 0.400966
Average total loss: 0.491042
tensor(-12.5901, device='cuda:0') tensor(1.4972, device='cuda:0') tensor(-7.8029e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.088801
Average KL loss: 0.400912
Average total loss: 0.489713
tensor(-12.5917, device='cuda:0') tensor(1.4970, device='cuda:0') tensor(9.5169e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.092468
Average KL loss: 0.400844
Average total loss: 0.493313
tensor(-12.5933, device='cuda:0') tensor(1.4968, device='cuda:0') tensor(3.7010e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.088546
Average KL loss: 0.400785
Average total loss: 0.489332
tensor(-12.5949, device='cuda:0') tensor(1.4966, device='cuda:0') tensor(1.7863e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.090922
Average KL loss: 0.400744
Average total loss: 0.491666
tensor(-12.5965, device='cuda:0') tensor(1.4965, device='cuda:0') tensor(-3.0106e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.090524
Average KL loss: 0.400691
Average total loss: 0.491215
tensor(-12.5981, device='cuda:0') tensor(1.4964, device='cuda:0') tensor(4.9467e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.087092
Average KL loss: 0.400616
Average total loss: 0.487708
tensor(-12.5997, device='cuda:0') tensor(1.4962, device='cuda:0') tensor(2.4123e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.090847
Average KL loss: 0.400545
Average total loss: 0.491392
tensor(-12.6013, device='cuda:0') tensor(1.4959, device='cuda:0') tensor(1.0448e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.089025
Average KL loss: 0.400481
Average total loss: 0.489506
tensor(-12.6029, device='cuda:0') tensor(1.4957, device='cuda:0') tensor(-9.1833e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.087299
Average KL loss: 0.400428
Average total loss: 0.487727
tensor(-12.6045, device='cuda:0') tensor(1.4955, device='cuda:0') tensor(-9.5131e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.086957
Average KL loss: 0.400355
Average total loss: 0.487312
tensor(-12.6060, device='cuda:0') tensor(1.4953, device='cuda:0') tensor(-1.2195e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.087024
Average KL loss: 0.400271
Average total loss: 0.487295
tensor(-12.6076, device='cuda:0') tensor(1.4951, device='cuda:0') tensor(-1.5597e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.086663
Average KL loss: 0.400192
Average total loss: 0.486855
tensor(-12.6092, device='cuda:0') tensor(1.4949, device='cuda:0') tensor(-5.0477e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.084916
Average KL loss: 0.400117
Average total loss: 0.485033
tensor(-12.6108, device='cuda:0') tensor(1.4947, device='cuda:0') tensor(-7.0785e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.086038
Average KL loss: 0.400038
Average total loss: 0.486076
tensor(-12.6123, device='cuda:0') tensor(1.4945, device='cuda:0') tensor(1.8199e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.086213
Average KL loss: 0.399965
Average total loss: 0.486178
tensor(-12.6139, device='cuda:0') tensor(1.4944, device='cuda:0') tensor(-3.1063e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.087335
Average KL loss: 0.399899
Average total loss: 0.487234
tensor(-12.6154, device='cuda:0') tensor(1.4941, device='cuda:0') tensor(-1.3144e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.086605
Average KL loss: 0.399803
Average total loss: 0.486408
tensor(-12.6170, device='cuda:0') tensor(1.4939, device='cuda:0') tensor(8.0149e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.084435
Average KL loss: 0.399741
Average total loss: 0.484176
tensor(-12.6186, device='cuda:0') tensor(1.4939, device='cuda:0') tensor(-2.9635e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.087323
Average KL loss: 0.399687
Average total loss: 0.487010
tensor(-12.6201, device='cuda:0') tensor(1.4937, device='cuda:0') tensor(-1.5311e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.085753
Average KL loss: 0.399630
Average total loss: 0.485383
tensor(-12.6217, device='cuda:0') tensor(1.4936, device='cuda:0') tensor(1.5924e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.086055
Average KL loss: 0.399568
Average total loss: 0.485623
tensor(-12.6232, device='cuda:0') tensor(1.4933, device='cuda:0') tensor(9.6811e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.083801
Average KL loss: 0.399481
Average total loss: 0.483282
tensor(-12.6248, device='cuda:0') tensor(1.4931, device='cuda:0') tensor(-4.4307e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.085049
Average KL loss: 0.399409
Average total loss: 0.484457
tensor(-12.6263, device='cuda:0') tensor(1.4930, device='cuda:0') tensor(-1.1266e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.083960
Average KL loss: 0.399329
Average total loss: 0.483289
tensor(-12.6278, device='cuda:0') tensor(1.4928, device='cuda:0') tensor(-5.6139e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.083824
Average KL loss: 0.399255
Average total loss: 0.483079
tensor(-12.6294, device='cuda:0') tensor(1.4927, device='cuda:0') tensor(-1.5598e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.082663
Average KL loss: 0.399191
Average total loss: 0.481854
 Percentile value: 6.053004932403565
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     872 /    1728             ( 50.46%) | total_pruned =     856 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     817 /   36864             (  2.22%) | total_pruned =   36047 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     946 /   36864             (  2.57%) | total_pruned =   35918 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     870 /   36864             (  2.36%) | total_pruned =   35994 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     825 /   36864             (  2.24%) | total_pruned =   36039 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1246 /   73728             (  1.69%) | total_pruned =   72482 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1566 /  147456             (  1.06%) | total_pruned =  145890 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     966 /    8192             ( 11.79%) | total_pruned =    7226 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1029 /  147456             (  0.70%) | total_pruned =  146427 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     866 /  147456             (  0.59%) | total_pruned =  146590 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2115 /  294912             (  0.72%) | total_pruned =  292797 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      73 /     256             ( 28.52%) | total_pruned =     183 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2330 /  589824             (  0.40%) | total_pruned =  587494 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1158 /   32768             (  3.53%) | total_pruned =   31610 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     853 /  589824             (  0.14%) | total_pruned =  588971 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     779 /  589824             (  0.13%) | total_pruned =  589045 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     202 /     256             ( 78.91%) | total_pruned =      54 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    1869 / 1179648             (  0.16%) | total_pruned = 1177779 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     275 /     512             ( 53.71%) | total_pruned =     237 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      63 /     512             ( 12.30%) | total_pruned =     449 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1319 / 2359296             (  0.06%) | total_pruned = 2357977 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     307 /     512             ( 59.96%) | total_pruned =     205 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     672 /  131072             (  0.51%) | total_pruned =  130400 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     245 /     512             ( 47.85%) | total_pruned =     267 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      54 /     512             ( 10.55%) | total_pruned =     458 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     665 / 2359296             (  0.03%) | total_pruned = 2358631 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     130 /     512             ( 25.39%) | total_pruned =     382 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     233 / 2359296             (  0.01%) | total_pruned = 2359063 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     329 /     512             ( 64.26%) | total_pruned =     183 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    1365 /    5120             ( 26.66%) | total_pruned =    3755 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 74/200 Loss: 0.015818 Accuracy: 82.04 100.00 % Best test Accuracy: 83.35%
tensor(-12.6309, device='cuda:0') tensor(1.4926, device='cuda:0') tensor(-4.1298e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.025732
Average KL loss: 0.391322
Average total loss: 0.417055
tensor(-12.6354, device='cuda:0') tensor(1.4239, device='cuda:0') tensor(2.3549e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.029899
Average KL loss: 0.376146
Average total loss: 0.406045
tensor(-12.6394, device='cuda:0') tensor(1.3704, device='cuda:0') tensor(3.9107e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.031685
Average KL loss: 0.360507
Average total loss: 0.392192
tensor(-12.6430, device='cuda:0') tensor(1.3248, device='cuda:0') tensor(1.7205e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.031982
Average KL loss: 0.342804
Average total loss: 0.374786
tensor(-12.6465, device='cuda:0') tensor(1.2849, device='cuda:0') tensor(-1.7726e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.032687
Average KL loss: 0.323578
Average total loss: 0.356265
tensor(-12.6497, device='cuda:0') tensor(1.2505, device='cuda:0') tensor(-7.4127e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.033597
Average KL loss: 0.306237
Average total loss: 0.339834
tensor(-12.6527, device='cuda:0') tensor(1.2222, device='cuda:0') tensor(-2.7959e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.035351
Average KL loss: 0.293541
Average total loss: 0.328892
tensor(-12.6555, device='cuda:0') tensor(1.1993, device='cuda:0') tensor(-1.8827e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.034200
Average KL loss: 0.285163
Average total loss: 0.319362
tensor(-12.6581, device='cuda:0') tensor(1.1806, device='cuda:0') tensor(-2.3010e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.036473
Average KL loss: 0.279719
Average total loss: 0.316192
tensor(-12.6605, device='cuda:0') tensor(1.1650, device='cuda:0') tensor(-2.5733e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.034462
Average KL loss: 0.276112
Average total loss: 0.310574
tensor(-12.6628, device='cuda:0') tensor(1.1518, device='cuda:0') tensor(-3.0977e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.033298
Average KL loss: 0.273617
Average total loss: 0.306915
tensor(-12.6651, device='cuda:0') tensor(1.1402, device='cuda:0') tensor(-1.4840e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.032292
Average KL loss: 0.271800
Average total loss: 0.304092
tensor(-12.6673, device='cuda:0') tensor(1.1300, device='cuda:0') tensor(-5.6722e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.031612
Average KL loss: 0.270423
Average total loss: 0.302035
tensor(-12.6694, device='cuda:0') tensor(1.1208, device='cuda:0') tensor(-1.9590e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.033597
Average KL loss: 0.269352
Average total loss: 0.302949
tensor(-12.6715, device='cuda:0') tensor(1.1126, device='cuda:0') tensor(-3.7291e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.030360
Average KL loss: 0.268491
Average total loss: 0.298851
tensor(-12.6735, device='cuda:0') tensor(1.1050, device='cuda:0') tensor(-4.0426e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.031795
Average KL loss: 0.267787
Average total loss: 0.299582
tensor(-12.6755, device='cuda:0') tensor(1.0980, device='cuda:0') tensor(-6.9305e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.032276
Average KL loss: 0.267201
Average total loss: 0.299477
tensor(-12.6775, device='cuda:0') tensor(1.0915, device='cuda:0') tensor(-7.1739e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.031307
Average KL loss: 0.266705
Average total loss: 0.298013
tensor(-12.6794, device='cuda:0') tensor(1.0856, device='cuda:0') tensor(-3.1143e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.031284
Average KL loss: 0.266282
Average total loss: 0.297566
tensor(-12.6813, device='cuda:0') tensor(1.0800, device='cuda:0') tensor(-2.2158e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.030229
Average KL loss: 0.265916
Average total loss: 0.296145
tensor(-12.6832, device='cuda:0') tensor(1.0748, device='cuda:0') tensor(-2.5806e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.029258
Average KL loss: 0.265597
Average total loss: 0.294856
tensor(-12.6850, device='cuda:0') tensor(1.0699, device='cuda:0') tensor(-2.9034e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.030514
Average KL loss: 0.265313
Average total loss: 0.295827
tensor(-12.6869, device='cuda:0') tensor(1.0653, device='cuda:0') tensor(-4.7329e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.029577
Average KL loss: 0.265058
Average total loss: 0.294635
tensor(-12.6887, device='cuda:0') tensor(1.0609, device='cuda:0') tensor(-1.7535e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.028070
Average KL loss: 0.264829
Average total loss: 0.292899
tensor(-12.6905, device='cuda:0') tensor(1.0568, device='cuda:0') tensor(-2.5612e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.026325
Average KL loss: 0.264618
Average total loss: 0.290943
tensor(-12.6923, device='cuda:0') tensor(1.0528, device='cuda:0') tensor(-6.8604e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.027368
Average KL loss: 0.264427
Average total loss: 0.291795
tensor(-12.6941, device='cuda:0') tensor(1.0492, device='cuda:0') tensor(-4.2615e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.025433
Average KL loss: 0.264252
Average total loss: 0.289685
tensor(-12.6958, device='cuda:0') tensor(1.0457, device='cuda:0') tensor(-8.7474e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.026963
Average KL loss: 0.264088
Average total loss: 0.291050
tensor(-12.6976, device='cuda:0') tensor(1.0423, device='cuda:0') tensor(-2.0649e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.023890
Average KL loss: 0.263934
Average total loss: 0.287824
tensor(-12.6993, device='cuda:0') tensor(1.0390, device='cuda:0') tensor(-2.6894e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.025814
Average KL loss: 0.263791
Average total loss: 0.289605
tensor(-12.7010, device='cuda:0') tensor(1.0359, device='cuda:0') tensor(-2.0511e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.025365
Average KL loss: 0.263660
Average total loss: 0.289025
tensor(-12.7027, device='cuda:0') tensor(1.0330, device='cuda:0') tensor(-1.3862e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.024606
Average KL loss: 0.263534
Average total loss: 0.288140
tensor(-12.7045, device='cuda:0') tensor(1.0301, device='cuda:0') tensor(-1.0133e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.025534
Average KL loss: 0.263413
Average total loss: 0.288947
tensor(-12.7061, device='cuda:0') tensor(1.0274, device='cuda:0') tensor(-2.8196e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.024688
Average KL loss: 0.263301
Average total loss: 0.287989
tensor(-12.7078, device='cuda:0') tensor(1.0248, device='cuda:0') tensor(-1.7973e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.024864
Average KL loss: 0.263193
Average total loss: 0.288057
tensor(-12.7095, device='cuda:0') tensor(1.0223, device='cuda:0') tensor(-1.4343e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.024867
Average KL loss: 0.263091
Average total loss: 0.287958
tensor(-12.7112, device='cuda:0') tensor(1.0199, device='cuda:0') tensor(-1.7235e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.021460
Average KL loss: 0.262995
Average total loss: 0.284455
tensor(-12.7128, device='cuda:0') tensor(1.0176, device='cuda:0') tensor(-6.1471e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.023732
Average KL loss: 0.262903
Average total loss: 0.286635
tensor(-12.7145, device='cuda:0') tensor(1.0153, device='cuda:0') tensor(-9.8799e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.021965
Average KL loss: 0.262817
Average total loss: 0.284782
tensor(-12.7161, device='cuda:0') tensor(1.0131, device='cuda:0') tensor(-1.6074e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.021374
Average KL loss: 0.262734
Average total loss: 0.284108
tensor(-12.7178, device='cuda:0') tensor(1.0109, device='cuda:0') tensor(-2.6497e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.023324
Average KL loss: 0.262652
Average total loss: 0.285976
tensor(-12.7194, device='cuda:0') tensor(1.0088, device='cuda:0') tensor(-1.8783e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.021047
Average KL loss: 0.262577
Average total loss: 0.283623
tensor(-12.7210, device='cuda:0') tensor(1.0068, device='cuda:0') tensor(-1.9921e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.023743
Average KL loss: 0.262504
Average total loss: 0.286247
tensor(-12.7226, device='cuda:0') tensor(1.0049, device='cuda:0') tensor(-3.1786e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.020850
Average KL loss: 0.262431
Average total loss: 0.283281
tensor(-12.7242, device='cuda:0') tensor(1.0031, device='cuda:0') tensor(-1.2763e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.018095
Average KL loss: 0.262357
Average total loss: 0.280452
tensor(-12.7258, device='cuda:0') tensor(1.0012, device='cuda:0') tensor(-6.6166e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.021299
Average KL loss: 0.262286
Average total loss: 0.283585
tensor(-12.7274, device='cuda:0') tensor(0.9994, device='cuda:0') tensor(-1.5611e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.022277
Average KL loss: 0.262218
Average total loss: 0.284495
tensor(-12.7290, device='cuda:0') tensor(0.9977, device='cuda:0') tensor(-3.5322e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.020873
Average KL loss: 0.262155
Average total loss: 0.283027
tensor(-12.7306, device='cuda:0') tensor(0.9960, device='cuda:0') tensor(-2.5221e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.020165
Average KL loss: 0.262091
Average total loss: 0.282256
tensor(-12.7322, device='cuda:0') tensor(0.9944, device='cuda:0') tensor(-1.6025e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.021638
Average KL loss: 0.262030
Average total loss: 0.283668
tensor(-12.7338, device='cuda:0') tensor(0.9929, device='cuda:0') tensor(-1.1367e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.019085
Average KL loss: 0.261968
Average total loss: 0.281053
tensor(-12.7353, device='cuda:0') tensor(0.9914, device='cuda:0') tensor(-1.3966e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.020726
Average KL loss: 0.261911
Average total loss: 0.282637
tensor(-12.7369, device='cuda:0') tensor(0.9899, device='cuda:0') tensor(-1.0288e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.017504
Average KL loss: 0.261857
Average total loss: 0.279360
tensor(-12.7385, device='cuda:0') tensor(0.9885, device='cuda:0') tensor(-1.2511e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.020171
Average KL loss: 0.261801
Average total loss: 0.281972
tensor(-12.7400, device='cuda:0') tensor(0.9871, device='cuda:0') tensor(-2.0180e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.018669
Average KL loss: 0.261748
Average total loss: 0.280417
tensor(-12.7416, device='cuda:0') tensor(0.9857, device='cuda:0') tensor(-1.0459e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.018098
Average KL loss: 0.261695
Average total loss: 0.279792
tensor(-12.7431, device='cuda:0') tensor(0.9844, device='cuda:0') tensor(-1.8739e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.017220
Average KL loss: 0.261645
Average total loss: 0.278865
tensor(-12.7446, device='cuda:0') tensor(0.9831, device='cuda:0') tensor(-7.3794e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.021178
Average KL loss: 0.261595
Average total loss: 0.282773
tensor(-12.7462, device='cuda:0') tensor(0.9818, device='cuda:0') tensor(-1.2777e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.019499
Average KL loss: 0.261545
Average total loss: 0.281045
tensor(-12.7477, device='cuda:0') tensor(0.9806, device='cuda:0') tensor(-1.5688e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.018468
Average KL loss: 0.261496
Average total loss: 0.279963
tensor(-12.7492, device='cuda:0') tensor(0.9794, device='cuda:0') tensor(-4.5500e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.018460
Average KL loss: 0.261447
Average total loss: 0.279908
tensor(-12.7508, device='cuda:0') tensor(0.9783, device='cuda:0') tensor(-1.5525e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.017265
Average KL loss: 0.261401
Average total loss: 0.278666
tensor(-12.7523, device='cuda:0') tensor(0.9771, device='cuda:0') tensor(-1.7209e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.017246
Average KL loss: 0.261352
Average total loss: 0.278598
tensor(-12.7538, device='cuda:0') tensor(0.9759, device='cuda:0') tensor(-5.4173e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.017215
Average KL loss: 0.261305
Average total loss: 0.278520
tensor(-12.7553, device='cuda:0') tensor(0.9747, device='cuda:0') tensor(-2.1395e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.016813
Average KL loss: 0.261258
Average total loss: 0.278070
tensor(-12.7568, device='cuda:0') tensor(0.9737, device='cuda:0') tensor(-1.6960e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.017076
Average KL loss: 0.261212
Average total loss: 0.278287
tensor(-12.7583, device='cuda:0') tensor(0.9726, device='cuda:0') tensor(-1.5171e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.017829
Average KL loss: 0.261166
Average total loss: 0.278995
tensor(-12.7598, device='cuda:0') tensor(0.9716, device='cuda:0') tensor(-2.4886e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.016191
Average KL loss: 0.261122
Average total loss: 0.277313
tensor(-12.7613, device='cuda:0') tensor(0.9705, device='cuda:0') tensor(-5.3434e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.016793
Average KL loss: 0.261079
Average total loss: 0.277872
tensor(-12.7628, device='cuda:0') tensor(0.9696, device='cuda:0') tensor(-2.9399e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.016629
Average KL loss: 0.261037
Average total loss: 0.277667
tensor(-12.7643, device='cuda:0') tensor(0.9686, device='cuda:0') tensor(-1.5403e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.017041
Average KL loss: 0.260993
Average total loss: 0.278034
tensor(-12.7658, device='cuda:0') tensor(0.9677, device='cuda:0') tensor(-5.2454e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.017008
Average KL loss: 0.260949
Average total loss: 0.277957
tensor(-12.7672, device='cuda:0') tensor(0.9668, device='cuda:0') tensor(-5.2191e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.014714
Average KL loss: 0.260906
Average total loss: 0.275620
tensor(-12.7687, device='cuda:0') tensor(0.9658, device='cuda:0') tensor(-5.5649e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.016424
Average KL loss: 0.260861
Average total loss: 0.277286
tensor(-12.7702, device='cuda:0') tensor(0.9650, device='cuda:0') tensor(-8.5185e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.016141
Average KL loss: 0.260816
Average total loss: 0.276957
tensor(-12.7717, device='cuda:0') tensor(0.9641, device='cuda:0') tensor(-1.3972e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.014663
Average KL loss: 0.260771
Average total loss: 0.275434
tensor(-12.7731, device='cuda:0') tensor(0.9632, device='cuda:0') tensor(-1.3648e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.015712
Average KL loss: 0.260728
Average total loss: 0.276440
tensor(-12.7746, device='cuda:0') tensor(0.9624, device='cuda:0') tensor(-1.2207e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.014101
Average KL loss: 0.260685
Average total loss: 0.274786
tensor(-12.7760, device='cuda:0') tensor(0.9616, device='cuda:0') tensor(-1.2524e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.015194
Average KL loss: 0.260642
Average total loss: 0.275836
tensor(-12.7775, device='cuda:0') tensor(0.9607, device='cuda:0') tensor(-8.4618e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.014944
Average KL loss: 0.260601
Average total loss: 0.275544
tensor(-12.7790, device='cuda:0') tensor(0.9600, device='cuda:0') tensor(-2.6036e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.017086
Average KL loss: 0.260559
Average total loss: 0.277645
tensor(-12.7804, device='cuda:0') tensor(0.9592, device='cuda:0') tensor(-1.3322e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.016583
Average KL loss: 0.260517
Average total loss: 0.277100
tensor(-12.7818, device='cuda:0') tensor(0.9585, device='cuda:0') tensor(-1.1557e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.015377
Average KL loss: 0.260471
Average total loss: 0.275848
tensor(-12.7833, device='cuda:0') tensor(0.9577, device='cuda:0') tensor(-1.2219e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.014638
Average KL loss: 0.260430
Average total loss: 0.275068
tensor(-12.7847, device='cuda:0') tensor(0.9571, device='cuda:0') tensor(-5.9374e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.014159
Average KL loss: 0.260389
Average total loss: 0.274548
tensor(-12.7862, device='cuda:0') tensor(0.9564, device='cuda:0') tensor(-1.9099e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.013911
Average KL loss: 0.260349
Average total loss: 0.274260
tensor(-12.7876, device='cuda:0') tensor(0.9556, device='cuda:0') tensor(-1.3345e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.013808
Average KL loss: 0.260308
Average total loss: 0.274116
tensor(-12.7890, device='cuda:0') tensor(0.9549, device='cuda:0') tensor(-5.1347e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.014113
Average KL loss: 0.260265
Average total loss: 0.274379
tensor(-12.7905, device='cuda:0') tensor(0.9543, device='cuda:0') tensor(-6.5056e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.014445
Average KL loss: 0.260226
Average total loss: 0.274671
tensor(-12.7919, device='cuda:0') tensor(0.9537, device='cuda:0') tensor(-6.8457e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.013556
Average KL loss: 0.260186
Average total loss: 0.273742
tensor(-12.7933, device='cuda:0') tensor(0.9530, device='cuda:0') tensor(-2.1378e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.013239
Average KL loss: 0.260142
Average total loss: 0.273381
tensor(-12.7947, device='cuda:0') tensor(0.9524, device='cuda:0') tensor(-2.2950e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.013454
Average KL loss: 0.260101
Average total loss: 0.273555
tensor(-12.7961, device='cuda:0') tensor(0.9517, device='cuda:0') tensor(-6.3950e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.012858
Average KL loss: 0.260057
Average total loss: 0.272914
tensor(-12.7976, device='cuda:0') tensor(0.9511, device='cuda:0') tensor(-6.0136e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.012720
Average KL loss: 0.260013
Average total loss: 0.272733
tensor(-12.7990, device='cuda:0') tensor(0.9505, device='cuda:0') tensor(-6.4117e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.014639
Average KL loss: 0.259967
Average total loss: 0.274606
tensor(-12.8004, device='cuda:0') tensor(0.9499, device='cuda:0') tensor(-1.0974e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.013400
Average KL loss: 0.259924
Average total loss: 0.273324
tensor(-12.8018, device='cuda:0') tensor(0.9492, device='cuda:0') tensor(-2.5345e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.013329
Average KL loss: 0.259885
Average total loss: 0.273213
tensor(-12.8032, device='cuda:0') tensor(0.9486, device='cuda:0') tensor(-2.9993e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.012957
Average KL loss: 0.259845
Average total loss: 0.272803
tensor(-12.8046, device='cuda:0') tensor(0.9481, device='cuda:0') tensor(-1.6038e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.013062
Average KL loss: 0.259803
Average total loss: 0.272865
tensor(-12.8060, device='cuda:0') tensor(0.9476, device='cuda:0') tensor(-6.7337e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.014065
Average KL loss: 0.259764
Average total loss: 0.273830
tensor(-12.8074, device='cuda:0') tensor(0.9471, device='cuda:0') tensor(-1.4150e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.013524
Average KL loss: 0.259728
Average total loss: 0.273252
tensor(-12.8088, device='cuda:0') tensor(0.9466, device='cuda:0') tensor(-8.3454e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.011432
Average KL loss: 0.259685
Average total loss: 0.271117
tensor(-12.8101, device='cuda:0') tensor(0.9460, device='cuda:0') tensor(-2.3551e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.013187
Average KL loss: 0.259642
Average total loss: 0.272830
tensor(-12.8115, device='cuda:0') tensor(0.9455, device='cuda:0') tensor(-8.2802e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.013565
Average KL loss: 0.259601
Average total loss: 0.273166
tensor(-12.8129, device='cuda:0') tensor(0.9450, device='cuda:0') tensor(-9.1743e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.013356
Average KL loss: 0.259561
Average total loss: 0.272916
tensor(-12.8143, device='cuda:0') tensor(0.9445, device='cuda:0') tensor(-1.8818e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.012873
Average KL loss: 0.259521
Average total loss: 0.272394
tensor(-12.8157, device='cuda:0') tensor(0.9440, device='cuda:0') tensor(-1.2883e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.013806
Average KL loss: 0.259479
Average total loss: 0.273285
tensor(-12.8170, device='cuda:0') tensor(0.9436, device='cuda:0') tensor(-9.1005e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.012045
Average KL loss: 0.259438
Average total loss: 0.271483
tensor(-12.8184, device='cuda:0') tensor(0.9431, device='cuda:0') tensor(-7.5471e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.012394
Average KL loss: 0.259397
Average total loss: 0.271791
tensor(-12.8198, device='cuda:0') tensor(0.9426, device='cuda:0') tensor(-1.0335e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.012553
Average KL loss: 0.259355
Average total loss: 0.271908
tensor(-12.8212, device='cuda:0') tensor(0.9422, device='cuda:0') tensor(-8.1227e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.011680
Average KL loss: 0.259315
Average total loss: 0.270996
tensor(-12.8225, device='cuda:0') tensor(0.9417, device='cuda:0') tensor(-6.6104e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.011551
Average KL loss: 0.259276
Average total loss: 0.270827
tensor(-12.8239, device='cuda:0') tensor(0.9413, device='cuda:0') tensor(-1.0787e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.010913
Average KL loss: 0.259239
Average total loss: 0.270152
tensor(-12.8252, device='cuda:0') tensor(0.9408, device='cuda:0') tensor(-4.2500e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.010095
Average KL loss: 0.259200
Average total loss: 0.269295
tensor(-12.8266, device='cuda:0') tensor(0.9404, device='cuda:0') tensor(-7.3310e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.011433
Average KL loss: 0.259158
Average total loss: 0.270590
tensor(-12.8280, device='cuda:0') tensor(0.9399, device='cuda:0') tensor(-1.4706e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.011247
Average KL loss: 0.259114
Average total loss: 0.270361
tensor(-12.8293, device='cuda:0') tensor(0.9395, device='cuda:0') tensor(-1.2056e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.011643
Average KL loss: 0.259072
Average total loss: 0.270715
tensor(-12.8307, device='cuda:0') tensor(0.9392, device='cuda:0') tensor(-8.4461e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.011498
Average KL loss: 0.259033
Average total loss: 0.270530
tensor(-12.8320, device='cuda:0') tensor(0.9388, device='cuda:0') tensor(-3.9571e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.011736
Average KL loss: 0.258993
Average total loss: 0.270730
tensor(-12.8334, device='cuda:0') tensor(0.9384, device='cuda:0') tensor(-8.4123e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.011318
Average KL loss: 0.258955
Average total loss: 0.270273
tensor(-12.8347, device='cuda:0') tensor(0.9380, device='cuda:0') tensor(-1.6114e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.010212
Average KL loss: 0.258916
Average total loss: 0.269128
tensor(-12.8361, device='cuda:0') tensor(0.9376, device='cuda:0') tensor(-5.3825e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.010856
Average KL loss: 0.258876
Average total loss: 0.269733
tensor(-12.8374, device='cuda:0') tensor(0.9372, device='cuda:0') tensor(-9.5835e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.012094
Average KL loss: 0.258838
Average total loss: 0.270932
tensor(-12.8387, device='cuda:0') tensor(0.9369, device='cuda:0') tensor(-1.1744e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.011990
Average KL loss: 0.258801
Average total loss: 0.270791
tensor(-12.8401, device='cuda:0') tensor(0.9366, device='cuda:0') tensor(-1.0169e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.010638
Average KL loss: 0.258761
Average total loss: 0.269399
tensor(-12.8414, device='cuda:0') tensor(0.9363, device='cuda:0') tensor(-1.1550e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.012417
Average KL loss: 0.258722
Average total loss: 0.271138
tensor(-12.8427, device='cuda:0') tensor(0.9360, device='cuda:0') tensor(-2.3045e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.012699
Average KL loss: 0.258683
Average total loss: 0.271382
tensor(-12.8441, device='cuda:0') tensor(0.9357, device='cuda:0') tensor(-8.7727e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.010430
Average KL loss: 0.258647
Average total loss: 0.269077
tensor(-12.8454, device='cuda:0') tensor(0.9353, device='cuda:0') tensor(-2.2233e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.011476
Average KL loss: 0.258607
Average total loss: 0.270083
tensor(-12.8467, device='cuda:0') tensor(0.9351, device='cuda:0') tensor(-6.0427e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.011447
Average KL loss: 0.258564
Average total loss: 0.270011
tensor(-12.8480, device='cuda:0') tensor(0.9348, device='cuda:0') tensor(-4.4630e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.010326
Average KL loss: 0.258523
Average total loss: 0.268849
tensor(-12.8493, device='cuda:0') tensor(0.9345, device='cuda:0') tensor(-7.3831e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.009752
Average KL loss: 0.258484
Average total loss: 0.268236
tensor(-12.8507, device='cuda:0') tensor(0.9342, device='cuda:0') tensor(-2.6322e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.011215
Average KL loss: 0.258445
Average total loss: 0.269660
tensor(-12.8520, device='cuda:0') tensor(0.9340, device='cuda:0') tensor(-1.8746e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.009489
Average KL loss: 0.258405
Average total loss: 0.267894
tensor(-12.8533, device='cuda:0') tensor(0.9337, device='cuda:0') tensor(-2.2051e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.010993
Average KL loss: 0.258361
Average total loss: 0.269355
tensor(-12.8546, device='cuda:0') tensor(0.9334, device='cuda:0') tensor(-5.4818e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.009951
Average KL loss: 0.258315
Average total loss: 0.268266
tensor(-12.8559, device='cuda:0') tensor(0.9332, device='cuda:0') tensor(-1.1620e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.010853
Average KL loss: 0.258269
Average total loss: 0.269122
tensor(-12.8572, device='cuda:0') tensor(0.9330, device='cuda:0') tensor(-1.9268e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.011570
Average KL loss: 0.258225
Average total loss: 0.269795
tensor(-12.8585, device='cuda:0') tensor(0.9327, device='cuda:0') tensor(-3.5205e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.010620
Average KL loss: 0.258180
Average total loss: 0.268801
tensor(-12.8598, device='cuda:0') tensor(0.9325, device='cuda:0') tensor(-4.3010e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.010301
Average KL loss: 0.258132
Average total loss: 0.268433
tensor(-12.8611, device='cuda:0') tensor(0.9323, device='cuda:0') tensor(-4.6626e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.009892
Average KL loss: 0.258086
Average total loss: 0.267978
tensor(-12.8624, device='cuda:0') tensor(0.9320, device='cuda:0') tensor(-5.3147e-11, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.010892
Average KL loss: 0.258040
Average total loss: 0.268932
tensor(-12.8637, device='cuda:0') tensor(0.9317, device='cuda:0') tensor(-5.8563e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.009803
Average KL loss: 0.257997
Average total loss: 0.267800
tensor(-12.8650, device='cuda:0') tensor(0.9315, device='cuda:0') tensor(-1.5782e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.010260
Average KL loss: 0.257950
Average total loss: 0.268209
tensor(-12.8663, device='cuda:0') tensor(0.9313, device='cuda:0') tensor(-1.1286e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.010535
Average KL loss: 0.257904
Average total loss: 0.268439
tensor(-12.8675, device='cuda:0') tensor(0.9311, device='cuda:0') tensor(-1.2334e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.009769
Average KL loss: 0.257863
Average total loss: 0.267632
tensor(-12.8688, device='cuda:0') tensor(0.9309, device='cuda:0') tensor(-2.1461e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.010851
Average KL loss: 0.257817
Average total loss: 0.268668
tensor(-12.8701, device='cuda:0') tensor(0.9307, device='cuda:0') tensor(-2.9580e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.010461
Average KL loss: 0.257776
Average total loss: 0.268237
tensor(-12.8714, device='cuda:0') tensor(0.9304, device='cuda:0') tensor(-1.3225e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.010215
Average KL loss: 0.257733
Average total loss: 0.267949
tensor(-12.8727, device='cuda:0') tensor(0.9302, device='cuda:0') tensor(-1.2575e-11, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.010369
Average KL loss: 0.257691
Average total loss: 0.268059
tensor(-12.8739, device='cuda:0') tensor(0.9300, device='cuda:0') tensor(-3.5669e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.009572
Average KL loss: 0.257647
Average total loss: 0.267220
tensor(-12.8752, device='cuda:0') tensor(0.9298, device='cuda:0') tensor(-3.0585e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.010848
Average KL loss: 0.257601
Average total loss: 0.268449
tensor(-12.8765, device='cuda:0') tensor(0.9296, device='cuda:0') tensor(-5.8307e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.010158
Average KL loss: 0.257552
Average total loss: 0.267710
tensor(-12.8778, device='cuda:0') tensor(0.9294, device='cuda:0') tensor(-1.6513e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.009543
Average KL loss: 0.257506
Average total loss: 0.267050
tensor(-12.8790, device='cuda:0') tensor(0.9292, device='cuda:0') tensor(-3.0144e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.010164
Average KL loss: 0.257464
Average total loss: 0.267627
tensor(-12.8803, device='cuda:0') tensor(0.9291, device='cuda:0') tensor(-1.9309e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.009937
Average KL loss: 0.257423
Average total loss: 0.267360
tensor(-12.8816, device='cuda:0') tensor(0.9290, device='cuda:0') tensor(-4.7773e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.009939
Average KL loss: 0.257382
Average total loss: 0.267321
tensor(-12.8828, device='cuda:0') tensor(0.9288, device='cuda:0') tensor(-6.4244e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.010187
Average KL loss: 0.257339
Average total loss: 0.267526
tensor(-12.8841, device='cuda:0') tensor(0.9287, device='cuda:0') tensor(-1.0641e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.008979
Average KL loss: 0.257296
Average total loss: 0.266275
tensor(-12.8854, device='cuda:0') tensor(0.9286, device='cuda:0') tensor(-4.2353e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.009023
Average KL loss: 0.257254
Average total loss: 0.266278
tensor(-12.8866, device='cuda:0') tensor(0.9284, device='cuda:0') tensor(-5.1274e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.009204
Average KL loss: 0.257211
Average total loss: 0.266415
tensor(-12.8879, device='cuda:0') tensor(0.9283, device='cuda:0') tensor(-1.2401e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.009108
Average KL loss: 0.257165
Average total loss: 0.266273
tensor(-12.8891, device='cuda:0') tensor(0.9281, device='cuda:0') tensor(-5.9275e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.010002
Average KL loss: 0.257123
Average total loss: 0.267125
tensor(-12.8904, device='cuda:0') tensor(0.9280, device='cuda:0') tensor(-5.2716e-11, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.009652
Average KL loss: 0.257081
Average total loss: 0.266733
tensor(-12.8916, device='cuda:0') tensor(0.9278, device='cuda:0') tensor(-1.6123e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.011196
Average KL loss: 0.257038
Average total loss: 0.268234
tensor(-12.8929, device='cuda:0') tensor(0.9277, device='cuda:0') tensor(-6.5371e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.009046
Average KL loss: 0.256992
Average total loss: 0.266039
tensor(-12.8941, device='cuda:0') tensor(0.9276, device='cuda:0') tensor(-3.8846e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.009013
Average KL loss: 0.256946
Average total loss: 0.265959
tensor(-12.8954, device='cuda:0') tensor(0.9274, device='cuda:0') tensor(-5.3104e-11, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.009470
Average KL loss: 0.256899
Average total loss: 0.266369
tensor(-12.8966, device='cuda:0') tensor(0.9272, device='cuda:0') tensor(-4.9452e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.009399
Average KL loss: 0.256850
Average total loss: 0.266249
tensor(-12.8979, device='cuda:0') tensor(0.9271, device='cuda:0') tensor(-1.9237e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.010649
Average KL loss: 0.256806
Average total loss: 0.267455
tensor(-12.8991, device='cuda:0') tensor(0.9270, device='cuda:0') tensor(-6.3527e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.008969
Average KL loss: 0.256761
Average total loss: 0.265731
tensor(-12.9003, device='cuda:0') tensor(0.9269, device='cuda:0') tensor(-1.9195e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.009620
Average KL loss: 0.256716
Average total loss: 0.266336
tensor(-12.9016, device='cuda:0') tensor(0.9268, device='cuda:0') tensor(-3.0036e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.009264
Average KL loss: 0.256674
Average total loss: 0.265938
tensor(-12.9028, device='cuda:0') tensor(0.9267, device='cuda:0') tensor(-1.0268e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.009618
Average KL loss: 0.256630
Average total loss: 0.266248
tensor(-12.9040, device='cuda:0') tensor(0.9266, device='cuda:0') tensor(-1.8692e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.008966
Average KL loss: 0.256584
Average total loss: 0.265550
tensor(-12.9053, device='cuda:0') tensor(0.9266, device='cuda:0') tensor(-6.9763e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.008967
Average KL loss: 0.256538
Average total loss: 0.265505
tensor(-12.9065, device='cuda:0') tensor(0.9265, device='cuda:0') tensor(-1.6736e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.008335
Average KL loss: 0.256494
Average total loss: 0.264829
tensor(-12.9077, device='cuda:0') tensor(0.9264, device='cuda:0') tensor(-4.7603e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.008665
Average KL loss: 0.256449
Average total loss: 0.265114
tensor(-12.9089, device='cuda:0') tensor(0.9263, device='cuda:0') tensor(-9.7087e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.008443
Average KL loss: 0.256401
Average total loss: 0.264844
tensor(-12.9102, device='cuda:0') tensor(0.9263, device='cuda:0') tensor(-2.8068e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.009252
Average KL loss: 0.256353
Average total loss: 0.265605
tensor(-12.9114, device='cuda:0') tensor(0.9262, device='cuda:0') tensor(8.5424e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.008556
Average KL loss: 0.256312
Average total loss: 0.264868
tensor(-12.9126, device='cuda:0') tensor(0.9262, device='cuda:0') tensor(-5.5970e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.008607
Average KL loss: 0.256269
Average total loss: 0.264876
tensor(-12.9138, device='cuda:0') tensor(0.9261, device='cuda:0') tensor(-5.3631e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.007956
Average KL loss: 0.256221
Average total loss: 0.264177
tensor(-12.9150, device='cuda:0') tensor(0.9260, device='cuda:0') tensor(-5.4647e-11, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.008758
Average KL loss: 0.256173
Average total loss: 0.264930
tensor(-12.9162, device='cuda:0') tensor(0.9260, device='cuda:0') tensor(-5.2054e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.009667
Average KL loss: 0.256127
Average total loss: 0.265794
tensor(-12.9174, device='cuda:0') tensor(0.9259, device='cuda:0') tensor(-2.0516e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.007914
Average KL loss: 0.256083
Average total loss: 0.263997
tensor(-12.9186, device='cuda:0') tensor(0.9258, device='cuda:0') tensor(-2.3196e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.008691
Average KL loss: 0.256041
Average total loss: 0.264733
tensor(-12.9198, device='cuda:0') tensor(0.9257, device='cuda:0') tensor(-3.7152e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.008763
Average KL loss: 0.256000
Average total loss: 0.264763
tensor(-12.9210, device='cuda:0') tensor(0.9257, device='cuda:0') tensor(-3.1420e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.008990
Average KL loss: 0.255954
Average total loss: 0.264944
tensor(-12.9222, device='cuda:0') tensor(0.9256, device='cuda:0') tensor(-1.6889e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.008652
Average KL loss: 0.255909
Average total loss: 0.264561
tensor(-12.9234, device='cuda:0') tensor(0.9256, device='cuda:0') tensor(-8.0034e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.009613
Average KL loss: 0.255863
Average total loss: 0.265476
tensor(-12.9246, device='cuda:0') tensor(0.9256, device='cuda:0') tensor(-3.8873e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.008486
Average KL loss: 0.255819
Average total loss: 0.264305
tensor(-12.9258, device='cuda:0') tensor(0.9255, device='cuda:0') tensor(-2.8314e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.008349
Average KL loss: 0.255774
Average total loss: 0.264123
tensor(-12.9270, device='cuda:0') tensor(0.9255, device='cuda:0') tensor(-5.9922e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.009627
Average KL loss: 0.255726
Average total loss: 0.265353
tensor(-12.9282, device='cuda:0') tensor(0.9255, device='cuda:0') tensor(-1.3605e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.008732
Average KL loss: 0.255682
Average total loss: 0.264414
tensor(-12.9294, device='cuda:0') tensor(0.9255, device='cuda:0') tensor(-7.7203e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.008660
Average KL loss: 0.255639
Average total loss: 0.264298
tensor(-12.9306, device='cuda:0') tensor(0.9254, device='cuda:0') tensor(-1.1680e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.008953
Average KL loss: 0.255598
Average total loss: 0.264550
tensor(-12.9318, device='cuda:0') tensor(0.9255, device='cuda:0') tensor(-6.2919e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.009353
Average KL loss: 0.255576
Average total loss: 0.264929
tensor(-12.9319, device='cuda:0') tensor(0.9255, device='cuda:0') tensor(-3.3064e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.007983
Average KL loss: 0.255572
Average total loss: 0.263556
tensor(-12.9320, device='cuda:0') tensor(0.9255, device='cuda:0') tensor(-4.1208e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.009416
Average KL loss: 0.255568
Average total loss: 0.264985
 Percentile value: 7.561145830154419
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =     666 /    1728             ( 38.54%) | total_pruned =    1062 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     234 /   36864             (  0.63%) | total_pruned =   36630 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     279 /   36864             (  0.76%) | total_pruned =   36585 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     232 /   36864             (  0.63%) | total_pruned =   36632 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     255 /   36864             (  0.69%) | total_pruned =   36609 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     326 /   73728             (  0.44%) | total_pruned =   73402 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     390 /  147456             (  0.26%) | total_pruned =  147066 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     308 /    8192             (  3.76%) | total_pruned =    7884 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     246 /  147456             (  0.17%) | total_pruned =  147210 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     181 /  147456             (  0.12%) | total_pruned =  147275 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     405 /  294912             (  0.14%) | total_pruned =  294507 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     420 /  589824             (  0.07%) | total_pruned =  589404 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     182 /     256             ( 71.09%) | total_pruned =      74 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     251 /   32768             (  0.77%) | total_pruned =   32517 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     181 /     256             ( 70.70%) | total_pruned =      75 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     196 /  589824             (  0.03%) | total_pruned =  589628 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      84 /     256             ( 32.81%) | total_pruned =     172 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     148 /  589824             (  0.03%) | total_pruned =  589676 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     136 /     256             ( 53.12%) | total_pruned =     120 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     309 / 1179648             (  0.03%) | total_pruned = 1179339 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     192 /     512             ( 37.50%) | total_pruned =     320 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     195 / 2359296             (  0.01%) | total_pruned = 2359101 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     176 /     512             ( 34.38%) | total_pruned =     336 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     106 /  131072             (  0.08%) | total_pruned =  130966 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     126 /     512             ( 24.61%) | total_pruned =     386 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     124 / 2359296             (  0.01%) | total_pruned = 2359172 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      11 / 2359296             (  0.00%) | total_pruned = 2359285 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     128 /     512             ( 25.00%) | total_pruned =     384 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     385 /    5120             (  7.52%) | total_pruned =    4735 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 199/200 Loss: 0.951484 Accuracy: 61.76 68.51 % Best test Accuracy: 61.91%
