Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/200 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-8.0686e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302770
Average KL loss: 0.026034
Average total loss: 2.328804
tensor(-0.0002, device='cuda:0') tensor(2.9421e-07, device='cuda:0') tensor(-6.0149e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.303090
Average KL loss: 0.023052
Average total loss: 2.326142
tensor(1.3992e-05, device='cuda:0') tensor(2.5728e-07, device='cuda:0') tensor(3.2854e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.302948
Average KL loss: 0.023090
Average total loss: 2.326038
tensor(1.3850e-06, device='cuda:0') tensor(3.1531e-07, device='cuda:0') tensor(2.0959e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.302944
Average KL loss: 0.023139
Average total loss: 2.326083
tensor(1.7494e-07, device='cuda:0') tensor(4.0926e-07, device='cuda:0') tensor(-2.4891e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.303234
Average KL loss: 0.023133
Average total loss: 2.326367
tensor(3.6578e-07, device='cuda:0') tensor(3.1626e-07, device='cuda:0') tensor(-1.4339e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.303003
Average KL loss: 0.023090
Average total loss: 2.326093
tensor(1.8623e-07, device='cuda:0') tensor(2.8039e-07, device='cuda:0') tensor(1.9272e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.302760
Average KL loss: 0.023137
Average total loss: 2.325897
tensor(1.1221e-06, device='cuda:0') tensor(3.7514e-07, device='cuda:0') tensor(-4.4976e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.302756
Average KL loss: 0.023192
Average total loss: 2.325947
tensor(-1.5305e-07, device='cuda:0') tensor(3.5032e-07, device='cuda:0') tensor(8.6944e-11, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.302909
Average KL loss: 0.023194
Average total loss: 2.326102
tensor(4.4687e-07, device='cuda:0') tensor(3.8140e-07, device='cuda:0') tensor(-1.4673e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.302694
Average KL loss: 0.023210
Average total loss: 2.325904
tensor(6.9932e-07, device='cuda:0') tensor(3.5748e-07, device='cuda:0') tensor(-4.4382e-11, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.303046
Average KL loss: 0.023194
Average total loss: 2.326240
tensor(1.8797e-06, device='cuda:0') tensor(5.1795e-07, device='cuda:0') tensor(4.2747e-12, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.302804
Average KL loss: 0.023257
Average total loss: 2.326061
tensor(8.1547e-07, device='cuda:0') tensor(3.9379e-07, device='cuda:0') tensor(-2.4719e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.302727
Average KL loss: 0.023247
Average total loss: 2.325974
tensor(7.4734e-07, device='cuda:0') tensor(4.2553e-07, device='cuda:0') tensor(2.2773e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.302732
Average KL loss: 0.023213
Average total loss: 2.325945
tensor(9.2312e-07, device='cuda:0') tensor(4.3480e-07, device='cuda:0') tensor(3.3798e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.302944
Average KL loss: 0.023219
Average total loss: 2.326163
tensor(9.5581e-07, device='cuda:0') tensor(3.7324e-07, device='cuda:0') tensor(-2.8220e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.302857
Average KL loss: 0.023278
Average total loss: 2.326135
tensor(3.7628e-07, device='cuda:0') tensor(3.5675e-07, device='cuda:0') tensor(-2.8344e-12, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.302972
Average KL loss: 0.023143
Average total loss: 2.326115
tensor(-7.9866e-08, device='cuda:0') tensor(3.8568e-07, device='cuda:0') tensor(-1.7445e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.302661
Average KL loss: 0.023254
Average total loss: 2.325915
tensor(6.4165e-07, device='cuda:0') tensor(4.1398e-07, device='cuda:0') tensor(1.8571e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.302672
Average KL loss: 0.022897
Average total loss: 2.325569
tensor(9.2553e-07, device='cuda:0') tensor(1.0171e-07, device='cuda:0') tensor(1.6969e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.302860
Average KL loss: 0.022776
Average total loss: 2.325636
tensor(7.9123e-07, device='cuda:0') tensor(7.6990e-08, device='cuda:0') tensor(2.1449e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.302494
Average KL loss: 0.022760
Average total loss: 2.325253
tensor(6.2366e-07, device='cuda:0') tensor(7.0753e-08, device='cuda:0') tensor(-4.1085e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.302927
Average KL loss: 0.022749
Average total loss: 2.325676
tensor(5.2711e-07, device='cuda:0') tensor(6.4002e-08, device='cuda:0') tensor(-5.0863e-11, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.302873
Average KL loss: 0.022742
Average total loss: 2.325615
tensor(8.0643e-07, device='cuda:0') tensor(6.5462e-08, device='cuda:0') tensor(-2.1635e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.303029
Average KL loss: 0.022744
Average total loss: 2.325773
tensor(5.7867e-07, device='cuda:0') tensor(6.5881e-08, device='cuda:0') tensor(8.2465e-11, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.302860
Average KL loss: 0.022741
Average total loss: 2.325601
tensor(7.2778e-07, device='cuda:0') tensor(5.8597e-08, device='cuda:0') tensor(6.6718e-13, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.302613
Average KL loss: 0.022741
Average total loss: 2.325353
tensor(6.1809e-07, device='cuda:0') tensor(6.1844e-08, device='cuda:0') tensor(7.8154e-12, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.303016
Average KL loss: 0.022739
Average total loss: 2.325755
tensor(6.1325e-07, device='cuda:0') tensor(5.5163e-08, device='cuda:0') tensor(-8.2467e-11, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.303024
Average KL loss: 0.022740
Average total loss: 2.325764
tensor(6.4928e-07, device='cuda:0') tensor(6.3450e-08, device='cuda:0') tensor(3.1740e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.302807
Average KL loss: 0.022745
Average total loss: 2.325552
tensor(5.9416e-07, device='cuda:0') tensor(5.8163e-08, device='cuda:0') tensor(-2.6592e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.303060
Average KL loss: 0.022736
Average total loss: 2.325795
tensor(4.4520e-07, device='cuda:0') tensor(5.3231e-08, device='cuda:0') tensor(7.2805e-11, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.302716
Average KL loss: 0.022749
Average total loss: 2.325465
tensor(9.1229e-07, device='cuda:0') tensor(7.3145e-08, device='cuda:0') tensor(-3.0618e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.302727
Average KL loss: 0.022747
Average total loss: 2.325473
tensor(6.2086e-07, device='cuda:0') tensor(6.3637e-08, device='cuda:0') tensor(-1.3530e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 2.303008
Average KL loss: 0.022723
Average total loss: 2.325731
tensor(8.3203e-07, device='cuda:0') tensor(4.3198e-08, device='cuda:0') tensor(1.7533e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 2.303301
Average KL loss: 0.022712
Average total loss: 2.326013
tensor(8.0396e-07, device='cuda:0') tensor(3.9828e-08, device='cuda:0') tensor(-1.3865e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 2.303005
Average KL loss: 0.022708
Average total loss: 2.325712
tensor(6.8856e-07, device='cuda:0') tensor(3.7358e-08, device='cuda:0') tensor(8.1470e-11, device='cuda:0')
Epoch 36
Average batch original loss after noise: 2.302898
Average KL loss: 0.022706
Average total loss: 2.325603
tensor(6.2160e-07, device='cuda:0') tensor(3.5546e-08, device='cuda:0') tensor(2.5400e-13, device='cuda:0')
Epoch 37
Average batch original loss after noise: 2.302799
Average KL loss: 0.022704
Average total loss: 2.325502
tensor(8.0643e-07, device='cuda:0') tensor(3.5409e-08, device='cuda:0') tensor(2.2709e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 2.302687
Average KL loss: 0.022703
Average total loss: 2.325391
tensor(7.8484e-07, device='cuda:0') tensor(3.5098e-08, device='cuda:0') tensor(1.3046e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 2.302695
Average KL loss: 0.022702
Average total loss: 2.325397
tensor(6.5856e-07, device='cuda:0') tensor(3.3388e-08, device='cuda:0') tensor(-1.4907e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 2.302543
Average KL loss: 0.022702
Average total loss: 2.325245
tensor(6.8326e-07, device='cuda:0') tensor(3.3479e-08, device='cuda:0') tensor(1.4422e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 2.302760
Average KL loss: 0.022700
Average total loss: 2.325460
tensor(6.3485e-07, device='cuda:0') tensor(3.1979e-08, device='cuda:0') tensor(1.3560e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 2.303089
Average KL loss: 0.022700
Average total loss: 2.325789
tensor(7.0343e-07, device='cuda:0') tensor(3.2939e-08, device='cuda:0') tensor(2.4760e-11, device='cuda:0')
Epoch 43
Average batch original loss after noise: 2.303046
Average KL loss: 0.022700
Average total loss: 2.325746
tensor(5.9232e-07, device='cuda:0') tensor(3.1701e-08, device='cuda:0') tensor(-2.5520e-11, device='cuda:0')
Epoch 44
Average batch original loss after noise: 2.302945
Average KL loss: 0.022698
Average total loss: 2.325643
tensor(5.3680e-07, device='cuda:0') tensor(3.0390e-08, device='cuda:0') tensor(-7.1650e-12, device='cuda:0')
Epoch 45
Average batch original loss after noise: 2.302744
Average KL loss: 0.022697
Average total loss: 2.325440
tensor(5.7254e-07, device='cuda:0') tensor(2.9939e-08, device='cuda:0') tensor(-1.0018e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 2.302477
Average KL loss: 0.022696
Average total loss: 2.325173
tensor(6.1863e-07, device='cuda:0') tensor(2.9799e-08, device='cuda:0') tensor(1.4121e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 2.302743
Average KL loss: 0.022696
Average total loss: 2.325439
tensor(6.4142e-07, device='cuda:0') tensor(2.9678e-08, device='cuda:0') tensor(5.3197e-11, device='cuda:0')
Epoch 48
Average batch original loss after noise: 2.302966
Average KL loss: 0.022696
Average total loss: 2.325662
tensor(6.3158e-07, device='cuda:0') tensor(2.9665e-08, device='cuda:0') tensor(3.1938e-11, device='cuda:0')
Epoch 49
Average batch original loss after noise: 2.302871
Average KL loss: 0.022696
Average total loss: 2.325567
tensor(6.0087e-07, device='cuda:0') tensor(2.9559e-08, device='cuda:0') tensor(3.3836e-11, device='cuda:0')
Epoch 50
Average batch original loss after noise: 2.302885
Average KL loss: 0.022696
Average total loss: 2.325580
tensor(6.0257e-07, device='cuda:0') tensor(2.9451e-08, device='cuda:0') tensor(-3.0226e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 2.302648
Average KL loss: 0.022696
Average total loss: 2.325344
tensor(6.2831e-07, device='cuda:0') tensor(2.9396e-08, device='cuda:0') tensor(5.1201e-11, device='cuda:0')
Epoch 52
Average batch original loss after noise: 2.302744
Average KL loss: 0.022695
Average total loss: 2.325439
tensor(6.0182e-07, device='cuda:0') tensor(2.9302e-08, device='cuda:0') tensor(3.9323e-11, device='cuda:0')
Epoch 53
Average batch original loss after noise: 2.302885
Average KL loss: 0.022695
Average total loss: 2.325580
tensor(5.9066e-07, device='cuda:0') tensor(2.9265e-08, device='cuda:0') tensor(-6.8806e-11, device='cuda:0')
 Percentile value: 5.245729062153256e-06
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =     349 /    1728             ( 20.20%) | total_pruned =    1379 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
bn1.bias             | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5751 /   36864             ( 15.60%) | total_pruned =   31113 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   13364 /   36864             ( 36.25%) | total_pruned =   23500 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   13141 /   36864             ( 35.65%) | total_pruned =   23723 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   15636 /   36864             ( 42.42%) | total_pruned =   21228 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   37440 /   73728             ( 50.78%) | total_pruned =   36288 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   73975 /  147456             ( 50.17%) | total_pruned =   73481 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4344 /    8192             ( 53.03%) | total_pruned =    3848 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   52279 /  147456             ( 35.45%) | total_pruned =   95177 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   46889 /  147456             ( 31.80%) | total_pruned =  100567 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  146171 /  294912             ( 49.56%) | total_pruned =  148741 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  264124 /  589824             ( 44.78%) | total_pruned =  325700 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   14804 /   32768             ( 45.18%) | total_pruned =   17964 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     185 /     256             ( 72.27%) | total_pruned =      71 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  165786 /  589824             ( 28.11%) | total_pruned =  424038 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     155 /     256             ( 60.55%) | total_pruned =     101 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     109 /     256             ( 42.58%) | total_pruned =     147 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  127700 /  589824             ( 21.65%) | total_pruned =  462124 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      48 /     256             ( 18.75%) | total_pruned =     208 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  425908 / 1179648             ( 36.10%) | total_pruned =  753740 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     364 /     512             ( 71.09%) | total_pruned =     148 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     141 /     512             ( 27.54%) | total_pruned =     371 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  664252 / 2359296             ( 28.15%) | total_pruned = 1695044 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     378 /     512             ( 73.83%) | total_pruned =     134 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     146 /     512             ( 28.52%) | total_pruned =     366 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   42597 /  131072             ( 32.50%) | total_pruned =   88475 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     368 /     512             ( 71.88%) | total_pruned =     144 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     136 /     512             ( 26.56%) | total_pruned =     376 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  621573 / 2359296             ( 26.35%) | total_pruned = 1737723 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     368 /     512             ( 71.88%) | total_pruned =     144 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     183 /     512             ( 35.74%) | total_pruned =     329 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  609881 / 2359296             ( 25.85%) | total_pruned = 1749415 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     408 /     512             ( 79.69%) | total_pruned =     104 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     243 /     512             ( 47.46%) | total_pruned =     269 | shape = torch.Size([512])
linear.weight        | nonzeros =    2687 /    5120             ( 52.48%) | total_pruned =    2433 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       8 /      10             ( 80.00%) | total_pruned =       2 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 60/200 Loss: 0.015509 Accuracy: 88.96 100.00 % Best test Accuracy: 89.10%
tensor(6.1643e-07, device='cuda:0') tensor(2.9171e-08, device='cuda:0') tensor(-7.1187e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.299688
Average KL loss: 0.035173
Average total loss: 2.334861
tensor(-0.0001, device='cuda:0') tensor(8.7690e-06, device='cuda:0') tensor(-3.1381e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.296696
Average KL loss: 0.036908
Average total loss: 2.333604
tensor(2.1141e-05, device='cuda:0') tensor(1.3468e-05, device='cuda:0') tensor(-8.4055e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.293115
Average KL loss: 0.041797
Average total loss: 2.334911
tensor(1.7933e-05, device='cuda:0') tensor(1.3935e-05, device='cuda:0') tensor(-4.7488e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.292812
Average KL loss: 0.044083
Average total loss: 2.336894
tensor(2.4264e-05, device='cuda:0') tensor(1.7202e-05, device='cuda:0') tensor(-4.1044e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.283606
Average KL loss: 0.048817
Average total loss: 2.332424
tensor(2.8848e-05, device='cuda:0') tensor(2.1413e-05, device='cuda:0') tensor(1.6353e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.280406
Average KL loss: 0.056396
Average total loss: 2.336802
tensor(3.3767e-05, device='cuda:0') tensor(2.5737e-05, device='cuda:0') tensor(-7.6689e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.276307
Average KL loss: 0.060621
Average total loss: 2.336927
tensor(3.5334e-05, device='cuda:0') tensor(2.9768e-05, device='cuda:0') tensor(-2.4896e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.270756
Average KL loss: 0.065099
Average total loss: 2.335855
tensor(3.9534e-05, device='cuda:0') tensor(3.6316e-05, device='cuda:0') tensor(-9.1494e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.246281
Average KL loss: 0.078485
Average total loss: 2.324766
tensor(5.7075e-05, device='cuda:0') tensor(4.5771e-05, device='cuda:0') tensor(-4.9696e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.232841
Average KL loss: 0.090948
Average total loss: 2.323788
tensor(6.5212e-05, device='cuda:0') tensor(5.3958e-05, device='cuda:0') tensor(-9.3260e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.212732
Average KL loss: 0.104351
Average total loss: 2.317083
tensor(7.4871e-05, device='cuda:0') tensor(6.7258e-05, device='cuda:0') tensor(-4.9867e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.203375
Average KL loss: 0.119000
Average total loss: 2.322376
tensor(8.3756e-05, device='cuda:0') tensor(7.4949e-05, device='cuda:0') tensor(-1.8927e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.177615
Average KL loss: 0.131049
Average total loss: 2.308664
tensor(9.7020e-05, device='cuda:0') tensor(8.8619e-05, device='cuda:0') tensor(9.1012e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.145362
Average KL loss: 0.148860
Average total loss: 2.294222
tensor(0.0001, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-1.1458e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.119224
Average KL loss: 0.169975
Average total loss: 2.289199
tensor(0.0001, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(3.1695e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.090816
Average KL loss: 0.180304
Average total loss: 2.271121
tensor(0.0001, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(7.2858e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.056043
Average KL loss: 0.198295
Average total loss: 2.254338
tensor(0.0002, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-2.5389e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.043054
Average KL loss: 0.218264
Average total loss: 2.261319
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-2.6033e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.023292
Average KL loss: 0.236433
Average total loss: 2.259725
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-1.6266e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.962751
Average KL loss: 0.251623
Average total loss: 2.214375
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-4.6204e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.958879
Average KL loss: 0.272982
Average total loss: 2.231860
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-2.8808e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.917832
Average KL loss: 0.289143
Average total loss: 2.206975
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-9.5907e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.870646
Average KL loss: 0.302010
Average total loss: 2.172656
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-6.2045e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.836793
Average KL loss: 0.324230
Average total loss: 2.161023
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(1.2906e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.802382
Average KL loss: 0.342903
Average total loss: 2.145284
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-4.6469e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.771971
Average KL loss: 0.364730
Average total loss: 2.136701
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-3.7688e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.735871
Average KL loss: 0.379365
Average total loss: 2.115236
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-7.0400e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.713193
Average KL loss: 0.392288
Average total loss: 2.105481
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.3924e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.700127
Average KL loss: 0.408496
Average total loss: 2.108623
tensor(0.0003, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.1739e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.649446
Average KL loss: 0.417892
Average total loss: 2.067338
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.6454e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.632045
Average KL loss: 0.434094
Average total loss: 2.066139
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-8.3385e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.618297
Average KL loss: 0.448298
Average total loss: 2.066596
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-3.9942e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.574203
Average KL loss: 0.461804
Average total loss: 2.036007
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.7641e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.536472
Average KL loss: 0.471164
Average total loss: 2.007636
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.0729e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.521290
Average KL loss: 0.483441
Average total loss: 2.004730
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.4259e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.513063
Average KL loss: 0.500040
Average total loss: 2.013103
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.9566e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.478405
Average KL loss: 0.509437
Average total loss: 1.987842
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.4940e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.467053
Average KL loss: 0.515816
Average total loss: 1.982869
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.8334e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.437426
Average KL loss: 0.520883
Average total loss: 1.958309
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.0505e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.423016
Average KL loss: 0.529597
Average total loss: 1.952613
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.0800e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.429964
Average KL loss: 0.544490
Average total loss: 1.974454
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.6066e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.405824
Average KL loss: 0.548503
Average total loss: 1.954327
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-6.2180e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.381358
Average KL loss: 0.557206
Average total loss: 1.938564
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.8712e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.376858
Average KL loss: 0.562913
Average total loss: 1.939771
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-7.9204e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.348616
Average KL loss: 0.567006
Average total loss: 1.915622
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.8613e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.344916
Average KL loss: 0.577100
Average total loss: 1.922016
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.6085e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.335221
Average KL loss: 0.582583
Average total loss: 1.917804
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-3.0860e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.314350
Average KL loss: 0.588184
Average total loss: 1.902534
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-3.7954e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.315317
Average KL loss: 0.589081
Average total loss: 1.904398
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-7.3110e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.292376
Average KL loss: 0.599741
Average total loss: 1.892117
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(8.6391e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.286061
Average KL loss: 0.606124
Average total loss: 1.892185
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.6646e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.275588
Average KL loss: 0.607411
Average total loss: 1.882999
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.7629e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.261806
Average KL loss: 0.612897
Average total loss: 1.874702
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-4.2477e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.277743
Average KL loss: 0.618561
Average total loss: 1.896305
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.1145e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.252858
Average KL loss: 0.625374
Average total loss: 1.878232
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.3374e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.226235
Average KL loss: 0.624432
Average total loss: 1.850667
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.3056e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.236842
Average KL loss: 0.629466
Average total loss: 1.866308
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(4.5163e-11, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.226689
Average KL loss: 0.634434
Average total loss: 1.861123
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-9.4165e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.230605
Average KL loss: 0.638497
Average total loss: 1.869102
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-6.3042e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.222344
Average KL loss: 0.646136
Average total loss: 1.868480
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-7.1456e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.217427
Average KL loss: 0.646564
Average total loss: 1.863991
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.4893e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.199610
Average KL loss: 0.654894
Average total loss: 1.854504
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-8.2848e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.187565
Average KL loss: 0.654340
Average total loss: 1.841905
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.1321e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.189453
Average KL loss: 0.658602
Average total loss: 1.848055
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-5.4804e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.185523
Average KL loss: 0.663979
Average total loss: 1.849502
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-8.7080e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.149902
Average KL loss: 0.668322
Average total loss: 1.818225
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.4377e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.166455
Average KL loss: 0.672214
Average total loss: 1.838669
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.7071e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.164293
Average KL loss: 0.679048
Average total loss: 1.843341
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-9.9354e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.163519
Average KL loss: 0.681966
Average total loss: 1.845485
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.0740e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.144802
Average KL loss: 0.686226
Average total loss: 1.831028
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-6.5809e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.156779
Average KL loss: 0.685770
Average total loss: 1.842549
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(9.8656e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.142027
Average KL loss: 0.688999
Average total loss: 1.831026
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.8350e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.114796
Average KL loss: 0.692087
Average total loss: 1.806883
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.1674e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.121729
Average KL loss: 0.692433
Average total loss: 1.814163
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-6.4459e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.123862
Average KL loss: 0.698020
Average total loss: 1.821882
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.0513e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.111467
Average KL loss: 0.702081
Average total loss: 1.813548
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(3.6288e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.110852
Average KL loss: 0.703320
Average total loss: 1.814171
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-4.3076e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.101027
Average KL loss: 0.705038
Average total loss: 1.806065
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.4000e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.093920
Average KL loss: 0.706984
Average total loss: 1.800904
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.0280e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.097477
Average KL loss: 0.712693
Average total loss: 1.810170
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.1096e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.088594
Average KL loss: 0.711731
Average total loss: 1.800324
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-4.7634e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.073599
Average KL loss: 0.713625
Average total loss: 1.787224
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.2009e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.098784
Average KL loss: 0.716257
Average total loss: 1.815041
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(8.3519e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.085346
Average KL loss: 0.718855
Average total loss: 1.804201
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-6.6849e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.087326
Average KL loss: 0.724791
Average total loss: 1.812117
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.2270e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.063597
Average KL loss: 0.726520
Average total loss: 1.790117
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.4766e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.064027
Average KL loss: 0.727917
Average total loss: 1.791944
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-9.9340e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.071976
Average KL loss: 0.731021
Average total loss: 1.802997
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-8.3844e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.057563
Average KL loss: 0.733270
Average total loss: 1.790834
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.7162e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.059804
Average KL loss: 0.731203
Average total loss: 1.791008
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-3.8044e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.060619
Average KL loss: 0.732559
Average total loss: 1.793177
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.8897e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.061855
Average KL loss: 0.739916
Average total loss: 1.801771
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.7655e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.057420
Average KL loss: 0.740294
Average total loss: 1.797713
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.8597e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.047144
Average KL loss: 0.729463
Average total loss: 1.776608
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-3.9134e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.053121
Average KL loss: 0.712716
Average total loss: 1.765837
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0959e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.043782
Average KL loss: 0.704940
Average total loss: 1.748722
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.3470e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.040082
Average KL loss: 0.700427
Average total loss: 1.740509
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.5127e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.031838
Average KL loss: 0.697191
Average total loss: 1.729029
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(5.7354e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.045609
Average KL loss: 0.694825
Average total loss: 1.740434
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(7.7843e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.042351
Average KL loss: 0.693095
Average total loss: 1.735445
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.8999e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.031391
Average KL loss: 0.691669
Average total loss: 1.723061
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.1913e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.034588
Average KL loss: 0.690404
Average total loss: 1.724992
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.4442e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.041620
Average KL loss: 0.689824
Average total loss: 1.731444
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.3343e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.038328
Average KL loss: 0.688775
Average total loss: 1.727103
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(4.6663e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.046752
Average KL loss: 0.688116
Average total loss: 1.734867
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(9.5733e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.041343
Average KL loss: 0.688236
Average total loss: 1.729578
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.5238e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.033894
Average KL loss: 0.688277
Average total loss: 1.722172
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-3.4422e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.044072
Average KL loss: 0.687981
Average total loss: 1.732053
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-8.2259e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.037205
Average KL loss: 0.688084
Average total loss: 1.725289
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.0262e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.051996
Average KL loss: 0.687861
Average total loss: 1.739856
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-8.8405e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.040900
Average KL loss: 0.687982
Average total loss: 1.728882
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(7.7805e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.040150
Average KL loss: 0.687746
Average total loss: 1.727895
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-9.0334e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.050355
Average KL loss: 0.687558
Average total loss: 1.737912
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.0600e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.038548
Average KL loss: 0.687843
Average total loss: 1.726391
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.2457e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.042216
Average KL loss: 0.688180
Average total loss: 1.730397
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.0013e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.055789
Average KL loss: 0.688665
Average total loss: 1.744454
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.0071e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.044516
Average KL loss: 0.688460
Average total loss: 1.732976
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.8334e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.044343
Average KL loss: 0.688473
Average total loss: 1.732816
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-8.0978e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.030738
Average KL loss: 0.688228
Average total loss: 1.718967
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-8.7805e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.036674
Average KL loss: 0.687821
Average total loss: 1.724494
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.0366e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.030136
Average KL loss: 0.687496
Average total loss: 1.717632
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.1143e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.044643
Average KL loss: 0.687180
Average total loss: 1.731823
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(9.9789e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.044581
Average KL loss: 0.686923
Average total loss: 1.731504
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0698e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.040273
Average KL loss: 0.686717
Average total loss: 1.726990
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.8933e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.045297
Average KL loss: 0.686570
Average total loss: 1.731867
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.5231e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.044242
Average KL loss: 0.686419
Average total loss: 1.730661
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(9.3631e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.038379
Average KL loss: 0.686240
Average total loss: 1.724618
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.0690e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.043543
Average KL loss: 0.686083
Average total loss: 1.729626
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-3.4229e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.042496
Average KL loss: 0.685977
Average total loss: 1.728473
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-8.6519e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.042572
Average KL loss: 0.685885
Average total loss: 1.728457
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(4.3890e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.037469
Average KL loss: 0.685733
Average total loss: 1.723202
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-5.6255e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.038559
Average KL loss: 0.685576
Average total loss: 1.724135
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.8301e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.043071
Average KL loss: 0.685500
Average total loss: 1.728571
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-4.9479e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.039852
Average KL loss: 0.685484
Average total loss: 1.725337
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-4.3005e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.045204
Average KL loss: 0.685467
Average total loss: 1.730672
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-5.4823e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.042938
Average KL loss: 0.685451
Average total loss: 1.728388
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.4296e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.039279
Average KL loss: 0.685436
Average total loss: 1.724715
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.5267e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.039062
Average KL loss: 0.685421
Average total loss: 1.724483
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-5.6116e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.040738
Average KL loss: 0.685405
Average total loss: 1.726143
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.3542e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.047135
Average KL loss: 0.685390
Average total loss: 1.732525
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.4677e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.041213
Average KL loss: 0.685375
Average total loss: 1.726588
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.8923e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.045861
Average KL loss: 0.685360
Average total loss: 1.731222
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.3003e-09, device='cuda:0')
 Percentile value: 0.003850675886496901
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =     180 /    1728             ( 10.42%) | total_pruned =    1548 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
bn1.bias             | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1700 /   36864             (  4.61%) | total_pruned =   35164 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5316 /   36864             ( 14.42%) | total_pruned =   31548 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    5179 /   36864             ( 14.05%) | total_pruned =   31685 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    6515 /   36864             ( 17.67%) | total_pruned =   30349 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   19227 /   73728             ( 26.08%) | total_pruned =   54501 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   37416 /  147456             ( 25.37%) | total_pruned =  110040 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2225 /    8192             ( 27.16%) | total_pruned =    5967 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   15155 /  147456             ( 10.28%) | total_pruned =  132301 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    7266 /  147456             (  4.93%) | total_pruned =  140190 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   73001 /  294912             ( 24.75%) | total_pruned =  221911 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  112045 /  589824             ( 19.00%) | total_pruned =  477779 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5777 /   32768             ( 17.63%) | total_pruned =   26991 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   50713 /  589824             (  8.60%) | total_pruned =  539111 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     148 /     256             ( 57.81%) | total_pruned =     108 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   27237 /  589824             (  4.62%) | total_pruned =  562587 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     136 /     256             ( 53.12%) | total_pruned =     120 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  157644 / 1179648             ( 13.36%) | total_pruned = 1022004 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     349 /     512             ( 68.16%) | total_pruned =     163 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  164104 / 2359296             (  6.96%) | total_pruned = 2195192 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     268 /     512             ( 52.34%) | total_pruned =     244 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   13357 /  131072             ( 10.19%) | total_pruned =  117715 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     236 /     512             ( 46.09%) | total_pruned =     276 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  138615 / 2359296             (  5.88%) | total_pruned = 2220681 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     311 /     512             ( 60.74%) | total_pruned =     201 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  158162 / 2359296             (  6.70%) | total_pruned = 2201134 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     310 /     512             ( 60.55%) | total_pruned =     202 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
linear.weight        | nonzeros =    1677 /    5120             ( 32.75%) | total_pruned =    3443 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 62/200 Loss: 0.014053 Accuracy: 88.55 100.00 % Best test Accuracy: 88.64%
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.6829e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.664962
Average KL loss: 0.656179
Average total loss: 2.321142
tensor(0.0003, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-8.3683e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.557225
Average KL loss: 0.666618
Average total loss: 2.223843
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-5.0320e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.483598
Average KL loss: 0.668176
Average total loss: 2.151774
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.3568e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.428386
Average KL loss: 0.667616
Average total loss: 2.096001
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.0743e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.399109
Average KL loss: 0.668003
Average total loss: 2.067112
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.1552e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.392340
Average KL loss: 0.669951
Average total loss: 2.062291
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.4475e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.349326
Average KL loss: 0.668732
Average total loss: 2.018058
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-3.5637e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.334009
Average KL loss: 0.670141
Average total loss: 2.004151
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.5900e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.347519
Average KL loss: 0.673664
Average total loss: 2.021182
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-5.9810e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.299865
Average KL loss: 0.673659
Average total loss: 1.973524
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.1290e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.292615
Average KL loss: 0.677228
Average total loss: 1.969843
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.7112e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.296390
Average KL loss: 0.676274
Average total loss: 1.972664
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(8.0233e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.281291
Average KL loss: 0.680295
Average total loss: 1.961586
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(3.6651e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.284105
Average KL loss: 0.683131
Average total loss: 1.967237
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.3862e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.266504
Average KL loss: 0.684576
Average total loss: 1.951079
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-6.9682e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.267752
Average KL loss: 0.685254
Average total loss: 1.953006
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-6.2741e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.239383
Average KL loss: 0.688525
Average total loss: 1.927908
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(5.6792e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.229015
Average KL loss: 0.690142
Average total loss: 1.919157
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(8.7277e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.229585
Average KL loss: 0.690639
Average total loss: 1.920223
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(6.7338e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.219993
Average KL loss: 0.692133
Average total loss: 1.912126
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.6617e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.222326
Average KL loss: 0.694694
Average total loss: 1.917019
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(9.8994e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.227995
Average KL loss: 0.694002
Average total loss: 1.921997
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-3.1749e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.213968
Average KL loss: 0.696481
Average total loss: 1.910449
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-4.1610e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.225054
Average KL loss: 0.700557
Average total loss: 1.925611
tensor(0.0007, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.2205e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.212930
Average KL loss: 0.700730
Average total loss: 1.913660
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(4.0492e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.200860
Average KL loss: 0.701918
Average total loss: 1.902778
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-6.9868e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.208003
Average KL loss: 0.706384
Average total loss: 1.914387
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.5266e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.192657
Average KL loss: 0.707524
Average total loss: 1.900182
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(3.8500e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.206417
Average KL loss: 0.710550
Average total loss: 1.916967
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-4.9499e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.206702
Average KL loss: 0.707790
Average total loss: 1.914492
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(3.3365e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.175030
Average KL loss: 0.709950
Average total loss: 1.884980
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(8.3359e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.186591
Average KL loss: 0.709653
Average total loss: 1.896244
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-3.7003e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.184038
Average KL loss: 0.712259
Average total loss: 1.896297
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-3.1915e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.183982
Average KL loss: 0.716464
Average total loss: 1.900445
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.3238e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.173958
Average KL loss: 0.714943
Average total loss: 1.888901
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.5700e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.174082
Average KL loss: 0.715892
Average total loss: 1.889974
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.9970e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.166069
Average KL loss: 0.718542
Average total loss: 1.884611
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.3778e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.168740
Average KL loss: 0.718211
Average total loss: 1.886951
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.4156e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.165571
Average KL loss: 0.721866
Average total loss: 1.887437
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-9.8754e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.165581
Average KL loss: 0.722727
Average total loss: 1.888308
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.3953e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.151285
Average KL loss: 0.719661
Average total loss: 1.870946
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-3.0037e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.145976
Average KL loss: 0.725019
Average total loss: 1.870995
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.2108e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.145614
Average KL loss: 0.723660
Average total loss: 1.869274
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.0131e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.149557
Average KL loss: 0.726466
Average total loss: 1.876023
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.0122e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.143996
Average KL loss: 0.727748
Average total loss: 1.871744
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.1976e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.138530
Average KL loss: 0.729136
Average total loss: 1.867666
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.9869e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.133892
Average KL loss: 0.727846
Average total loss: 1.861738
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.7011e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.144854
Average KL loss: 0.729857
Average total loss: 1.874711
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.6289e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.160905
Average KL loss: 0.729483
Average total loss: 1.890388
tensor(0.0007, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.3474e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.129633
Average KL loss: 0.731385
Average total loss: 1.861018
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.7470e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.128949
Average KL loss: 0.732500
Average total loss: 1.861449
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.6480e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.128035
Average KL loss: 0.732908
Average total loss: 1.860943
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.3815e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.129162
Average KL loss: 0.736098
Average total loss: 1.865260
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.5623e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.138472
Average KL loss: 0.737862
Average total loss: 1.876334
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.9584e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.123826
Average KL loss: 0.737486
Average total loss: 1.861311
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.5821e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.138691
Average KL loss: 0.738707
Average total loss: 1.877398
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.7590e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.120760
Average KL loss: 0.736681
Average total loss: 1.857440
tensor(0.0007, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.1255e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.117905
Average KL loss: 0.739720
Average total loss: 1.857625
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.2204e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.126346
Average KL loss: 0.737268
Average total loss: 1.863614
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.5146e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.120637
Average KL loss: 0.738489
Average total loss: 1.859126
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.7644e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.115284
Average KL loss: 0.739341
Average total loss: 1.854625
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.2614e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.102730
Average KL loss: 0.738052
Average total loss: 1.840781
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.2910e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.124984
Average KL loss: 0.741143
Average total loss: 1.866127
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.1722e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.114331
Average KL loss: 0.741677
Average total loss: 1.856008
tensor(0.0007, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.6021e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.113236
Average KL loss: 0.742720
Average total loss: 1.855956
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.9747e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.110553
Average KL loss: 0.742414
Average total loss: 1.852967
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.8402e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.116641
Average KL loss: 0.742366
Average total loss: 1.859007
tensor(0.0007, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.5537e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.102766
Average KL loss: 0.741789
Average total loss: 1.844555
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(7.7102e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.126149
Average KL loss: 0.743502
Average total loss: 1.869651
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(6.9848e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.106706
Average KL loss: 0.747949
Average total loss: 1.854655
tensor(0.0007, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(5.5902e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.103002
Average KL loss: 0.747058
Average total loss: 1.850060
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.3241e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.123650
Average KL loss: 0.748326
Average total loss: 1.871976
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.4982e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.121853
Average KL loss: 0.748298
Average total loss: 1.870151
tensor(0.0007, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(2.7074e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.105041
Average KL loss: 0.739708
Average total loss: 1.844749
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(2.0345e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.118807
Average KL loss: 0.727478
Average total loss: 1.846285
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.1593e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.109481
Average KL loss: 0.720587
Average total loss: 1.830068
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(6.0108e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.112149
Average KL loss: 0.716039
Average total loss: 1.828189
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.1087e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.106023
Average KL loss: 0.712881
Average total loss: 1.818904
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(3.1592e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.101624
Average KL loss: 0.710641
Average total loss: 1.812265
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.7983e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.109113
Average KL loss: 0.708798
Average total loss: 1.817910
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.2936e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.098231
Average KL loss: 0.707024
Average total loss: 1.805255
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.3505e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.111404
Average KL loss: 0.705761
Average total loss: 1.817166
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.3046e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.103295
Average KL loss: 0.704911
Average total loss: 1.808206
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.0262e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.099741
Average KL loss: 0.704092
Average total loss: 1.803833
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.4082e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.105837
Average KL loss: 0.702928
Average total loss: 1.808766
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.2892e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.103375
Average KL loss: 0.702066
Average total loss: 1.805441
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.3939e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.100022
Average KL loss: 0.701482
Average total loss: 1.801504
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.4251e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.105643
Average KL loss: 0.700952
Average total loss: 1.806595
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.3400e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.096171
Average KL loss: 0.700228
Average total loss: 1.796399
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.9227e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.121075
Average KL loss: 0.699692
Average total loss: 1.820767
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.6324e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.107256
Average KL loss: 0.699475
Average total loss: 1.806731
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.5063e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.103798
Average KL loss: 0.698759
Average total loss: 1.802557
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.1745e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.113786
Average KL loss: 0.698386
Average total loss: 1.812172
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.9525e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.098378
Average KL loss: 0.698127
Average total loss: 1.796505
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(9.3044e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.113526
Average KL loss: 0.697777
Average total loss: 1.811303
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.7322e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.100888
Average KL loss: 0.697628
Average total loss: 1.798517
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(7.2177e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.110638
Average KL loss: 0.697722
Average total loss: 1.808360
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.5284e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.100693
Average KL loss: 0.698050
Average total loss: 1.798743
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.6199e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.104260
Average KL loss: 0.697740
Average total loss: 1.802000
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.8883e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.104292
Average KL loss: 0.697411
Average total loss: 1.801703
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.1015e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.104398
Average KL loss: 0.697168
Average total loss: 1.801566
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(7.3156e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.114377
Average KL loss: 0.696907
Average total loss: 1.811285
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(7.5572e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.096440
Average KL loss: 0.696673
Average total loss: 1.793113
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.4314e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.107797
Average KL loss: 0.696451
Average total loss: 1.804249
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(9.9879e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.100769
Average KL loss: 0.696254
Average total loss: 1.797023
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.0119e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.111443
Average KL loss: 0.696078
Average total loss: 1.807521
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1660e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.103421
Average KL loss: 0.695919
Average total loss: 1.799340
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.8264e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.110587
Average KL loss: 0.695793
Average total loss: 1.806380
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-9.2757e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.107657
Average KL loss: 0.695710
Average total loss: 1.803367
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.4468e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.108632
Average KL loss: 0.695622
Average total loss: 1.804254
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.3826e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.119230
Average KL loss: 0.695510
Average total loss: 1.814740
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(7.8839e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.099757
Average KL loss: 0.695400
Average total loss: 1.795157
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.9567e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.110907
Average KL loss: 0.695288
Average total loss: 1.806196
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.3372e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.096018
Average KL loss: 0.695184
Average total loss: 1.791202
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.1203e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.096682
Average KL loss: 0.695112
Average total loss: 1.791794
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1692e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.105740
Average KL loss: 0.695010
Average total loss: 1.800750
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.0720e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.093511
Average KL loss: 0.694917
Average total loss: 1.788428
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.5687e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.097631
Average KL loss: 0.694824
Average total loss: 1.792455
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.6505e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.122108
Average KL loss: 0.694770
Average total loss: 1.816878
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.9999e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.102463
Average KL loss: 0.694722
Average total loss: 1.797185
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.7423e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.103217
Average KL loss: 0.694627
Average total loss: 1.797844
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.9990e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.110103
Average KL loss: 0.694555
Average total loss: 1.804658
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.3295e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.099425
Average KL loss: 0.694502
Average total loss: 1.793927
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.4888e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.102746
Average KL loss: 0.694458
Average total loss: 1.797204
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.9081e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.114389
Average KL loss: 0.694404
Average total loss: 1.808793
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.2454e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.116860
Average KL loss: 0.694346
Average total loss: 1.811206
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.5217e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.093032
Average KL loss: 0.694311
Average total loss: 1.787343
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.9598e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.123863
Average KL loss: 0.694267
Average total loss: 1.818130
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.7072e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.091714
Average KL loss: 0.694246
Average total loss: 1.785960
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.6456e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.118628
Average KL loss: 0.694198
Average total loss: 1.812826
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.1380e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.101893
Average KL loss: 0.694127
Average total loss: 1.796020
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(9.5589e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.110518
Average KL loss: 0.694064
Average total loss: 1.804582
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.4812e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.106554
Average KL loss: 0.693997
Average total loss: 1.800550
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.7120e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.109423
Average KL loss: 0.693968
Average total loss: 1.803391
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.6733e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.104974
Average KL loss: 0.693948
Average total loss: 1.798922
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.6383e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.119265
Average KL loss: 0.693856
Average total loss: 1.813122
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1280e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.105807
Average KL loss: 0.693799
Average total loss: 1.799606
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.6288e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.113893
Average KL loss: 0.693755
Average total loss: 1.807648
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.0383e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.105865
Average KL loss: 0.693739
Average total loss: 1.799604
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.6111e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.105984
Average KL loss: 0.693701
Average total loss: 1.799684
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.5102e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.100155
Average KL loss: 0.693676
Average total loss: 1.793831
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-9.7917e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.096009
Average KL loss: 0.693668
Average total loss: 1.789676
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(7.7856e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.110318
Average KL loss: 0.693659
Average total loss: 1.803977
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-9.4949e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.100414
Average KL loss: 0.693654
Average total loss: 1.794068
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.0069e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.113433
Average KL loss: 0.693648
Average total loss: 1.807081
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.9639e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.114185
Average KL loss: 0.693643
Average total loss: 1.807829
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.8009e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.094194
Average KL loss: 0.693638
Average total loss: 1.787832
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.7235e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.093143
Average KL loss: 0.693630
Average total loss: 1.786773
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.7451e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.102684
Average KL loss: 0.693621
Average total loss: 1.796306
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.4319e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.097500
Average KL loss: 0.693616
Average total loss: 1.791116
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.2104e-08, device='cuda:0')
 Percentile value: 0.015166503190994258
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =     107 /    1728             (  6.19%) | total_pruned =    1621 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     564 /   36864             (  1.53%) | total_pruned =   36300 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1418 /   36864             (  3.85%) | total_pruned =   35446 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1115 /   36864             (  3.02%) | total_pruned =   35749 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2331 /   36864             (  6.32%) | total_pruned =   34533 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8725 /   73728             ( 11.83%) | total_pruned =   65003 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   15309 /  147456             ( 10.38%) | total_pruned =  132147 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1039 /    8192             ( 12.68%) | total_pruned =    7153 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    6113 /  147456             (  4.15%) | total_pruned =  141343 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2378 /  147456             (  1.61%) | total_pruned =  145078 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   35143 /  294912             ( 11.92%) | total_pruned =  259769 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   53773 /  589824             (  9.12%) | total_pruned =  536051 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     205 /     256             ( 80.08%) | total_pruned =      51 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2198 /   32768             (  6.71%) | total_pruned =   30570 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     121 /     256             ( 47.27%) | total_pruned =     135 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   23250 /  589824             (  3.94%) | total_pruned =  566574 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     140 /     256             ( 54.69%) | total_pruned =     116 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    9974 /  589824             (  1.69%) | total_pruned =  579850 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     105 /     256             ( 41.02%) | total_pruned =     151 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   62551 / 1179648             (  5.30%) | total_pruned = 1117097 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     320 /     512             ( 62.50%) | total_pruned =     192 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   37990 / 2359296             (  1.61%) | total_pruned = 2321306 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     160 /     512             ( 31.25%) | total_pruned =     352 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2117 /  131072             (  1.62%) | total_pruned =  128955 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     111 /     512             ( 21.68%) | total_pruned =     401 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   17715 / 2359296             (  0.75%) | total_pruned = 2341581 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     229 /     512             ( 44.73%) | total_pruned =     283 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   14789 / 2359296             (  0.63%) | total_pruned = 2344507 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     143 /     512             ( 27.93%) | total_pruned =     369 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
linear.weight        | nonzeros =     639 /    5120             ( 12.48%) | total_pruned =    4481 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 56/200 Loss: 0.020515 Accuracy: 87.66 100.00 % Best test Accuracy: 87.66%
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1886e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.675871
Average KL loss: 0.649788
Average total loss: 2.325660
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0003e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.532270
Average KL loss: 0.660230
Average total loss: 2.192500
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.9947e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.489075
Average KL loss: 0.674240
Average total loss: 2.163315
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(3.9476e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.464223
Average KL loss: 0.680606
Average total loss: 2.144830
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.2621e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.435262
Average KL loss: 0.681698
Average total loss: 2.116960
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-8.4326e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.408314
Average KL loss: 0.683407
Average total loss: 2.091721
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(3.1973e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.395208
Average KL loss: 0.683983
Average total loss: 2.079191
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.2654e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.375478
Average KL loss: 0.688187
Average total loss: 2.063664
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(8.8916e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.365026
Average KL loss: 0.689952
Average total loss: 2.054979
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-5.0076e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.354747
Average KL loss: 0.689414
Average total loss: 2.044161
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.4024e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.359039
Average KL loss: 0.690382
Average total loss: 2.049420
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(4.4431e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.344555
Average KL loss: 0.690524
Average total loss: 2.035079
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(3.6824e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.330327
Average KL loss: 0.689908
Average total loss: 2.020235
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.1770e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.346895
Average KL loss: 0.693510
Average total loss: 2.040406
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.0006e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.306884
Average KL loss: 0.694971
Average total loss: 2.001855
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(6.8257e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.325421
Average KL loss: 0.691930
Average total loss: 2.017351
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-3.5147e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.315239
Average KL loss: 0.695149
Average total loss: 2.010388
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.7362e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.321031
Average KL loss: 0.699290
Average total loss: 2.020321
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(5.3748e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.310333
Average KL loss: 0.699893
Average total loss: 2.010226
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.6369e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.312343
Average KL loss: 0.700500
Average total loss: 2.012843
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-5.0180e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.309867
Average KL loss: 0.701110
Average total loss: 2.010976
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.7670e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.307994
Average KL loss: 0.699481
Average total loss: 2.007475
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0174e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.298669
Average KL loss: 0.697839
Average total loss: 1.996509
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.1600e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.292644
Average KL loss: 0.697020
Average total loss: 1.989665
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(3.6564e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.304681
Average KL loss: 0.698611
Average total loss: 2.003291
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(3.7214e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.290422
Average KL loss: 0.699995
Average total loss: 1.990416
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.1954e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.299219
Average KL loss: 0.696224
Average total loss: 1.995443
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.7298e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.280255
Average KL loss: 0.698155
Average total loss: 1.978409
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.7474e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.288286
Average KL loss: 0.694122
Average total loss: 1.982408
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.5669e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.298112
Average KL loss: 0.695238
Average total loss: 1.993351
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.9081e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.276941
Average KL loss: 0.698256
Average total loss: 1.975197
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(8.3293e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.286239
Average KL loss: 0.697936
Average total loss: 1.984175
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-3.1660e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.291039
Average KL loss: 0.698582
Average total loss: 1.989621
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(4.1456e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.293901
Average KL loss: 0.698144
Average total loss: 1.992045
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.7280e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.287040
Average KL loss: 0.695526
Average total loss: 1.982566
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-4.6305e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.303067
Average KL loss: 0.697524
Average total loss: 2.000590
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.8082e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.288341
Average KL loss: 0.699171
Average total loss: 1.987513
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.4007e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.290023
Average KL loss: 0.700130
Average total loss: 1.990153
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.6629e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.294316
Average KL loss: 0.704067
Average total loss: 1.998383
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.4056e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.265121
Average KL loss: 0.705290
Average total loss: 1.970411
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.2126e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.267815
Average KL loss: 0.702196
Average total loss: 1.970011
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.2461e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.284391
Average KL loss: 0.702895
Average total loss: 1.987286
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.8459e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.274264
Average KL loss: 0.705022
Average total loss: 1.979285
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.1442e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.265939
Average KL loss: 0.703762
Average total loss: 1.969701
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.9738e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.263513
Average KL loss: 0.703234
Average total loss: 1.966748
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(9.5767e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.278690
Average KL loss: 0.704197
Average total loss: 1.982887
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.7447e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.269912
Average KL loss: 0.702857
Average total loss: 1.972768
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.9611e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.278892
Average KL loss: 0.705604
Average total loss: 1.984496
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.5155e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.271870
Average KL loss: 0.704384
Average total loss: 1.976254
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.0919e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.278839
Average KL loss: 0.702371
Average total loss: 1.981210
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.1657e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.277528
Average KL loss: 0.705532
Average total loss: 1.983060
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.7933e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.262286
Average KL loss: 0.707046
Average total loss: 1.969331
tensor(0.0007, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.1750e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.256645
Average KL loss: 0.704136
Average total loss: 1.960781
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1364e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.265326
Average KL loss: 0.705765
Average total loss: 1.971091
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.1703e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.281392
Average KL loss: 0.707816
Average total loss: 1.989208
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.1441e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.253817
Average KL loss: 0.706719
Average total loss: 1.960536
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1474e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.276134
Average KL loss: 0.708682
Average total loss: 1.984816
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.0653e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.280969
Average KL loss: 0.706836
Average total loss: 1.987805
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.3366e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.248115
Average KL loss: 0.705731
Average total loss: 1.953847
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.5473e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.271302
Average KL loss: 0.706265
Average total loss: 1.977566
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.8429e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.286660
Average KL loss: 0.710092
Average total loss: 1.996752
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(7.6584e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.259873
Average KL loss: 0.711188
Average total loss: 1.971061
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.3329e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.266926
Average KL loss: 0.710462
Average total loss: 1.977388
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.2442e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.254898
Average KL loss: 0.710165
Average total loss: 1.965063
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.0991e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.272223
Average KL loss: 0.710345
Average total loss: 1.982569
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.9281e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.260941
Average KL loss: 0.709938
Average total loss: 1.970879
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.8105e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.269937
Average KL loss: 0.711381
Average total loss: 1.981318
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(7.3906e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.255896
Average KL loss: 0.712817
Average total loss: 1.968713
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.1119e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.251880
Average KL loss: 0.714775
Average total loss: 1.966656
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-5.7738e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.267557
Average KL loss: 0.718163
Average total loss: 1.985720
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(6.4848e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.249196
Average KL loss: 0.715120
Average total loss: 1.964316
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.7050e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.258311
Average KL loss: 0.707721
Average total loss: 1.966032
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-7.5177e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.249852
Average KL loss: 0.702248
Average total loss: 1.952100
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.4979e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.250637
Average KL loss: 0.698431
Average total loss: 1.949068
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.5609e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.246779
Average KL loss: 0.695314
Average total loss: 1.942093
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-4.3726e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.252965
Average KL loss: 0.692989
Average total loss: 1.945955
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.9648e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.254272
Average KL loss: 0.691033
Average total loss: 1.945305
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.8935e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.246751
Average KL loss: 0.689024
Average total loss: 1.935776
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.4799e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.248047
Average KL loss: 0.687385
Average total loss: 1.935432
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.6026e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.261143
Average KL loss: 0.686031
Average total loss: 1.947174
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.5167e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.237626
Average KL loss: 0.685180
Average total loss: 1.922807
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1477e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.250922
Average KL loss: 0.684088
Average total loss: 1.935010
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.1494e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.244235
Average KL loss: 0.683410
Average total loss: 1.927645
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.9597e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.266798
Average KL loss: 0.682787
Average total loss: 1.949585
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.1118e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.251408
Average KL loss: 0.682134
Average total loss: 1.933542
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.0092e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.261959
Average KL loss: 0.681626
Average total loss: 1.943585
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.0388e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.264802
Average KL loss: 0.681198
Average total loss: 1.946001
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.0290e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.255685
Average KL loss: 0.680841
Average total loss: 1.936526
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.8819e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.255832
Average KL loss: 0.680376
Average total loss: 1.936208
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.7953e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.245797
Average KL loss: 0.679969
Average total loss: 1.925766
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.6627e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.242191
Average KL loss: 0.679489
Average total loss: 1.921679
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.6361e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.245640
Average KL loss: 0.678830
Average total loss: 1.924470
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.7665e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.259636
Average KL loss: 0.678523
Average total loss: 1.938159
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.5070e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.259977
Average KL loss: 0.678681
Average total loss: 1.938659
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.6024e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.258451
Average KL loss: 0.678584
Average total loss: 1.937035
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.9909e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.239644
Average KL loss: 0.678595
Average total loss: 1.918239
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.6558e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.255531
Average KL loss: 0.678507
Average total loss: 1.934037
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.3612e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.265934
Average KL loss: 0.678144
Average total loss: 1.944078
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.0565e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.243023
Average KL loss: 0.677871
Average total loss: 1.920895
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.8370e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.248961
Average KL loss: 0.677420
Average total loss: 1.926381
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.4087e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.249210
Average KL loss: 0.677082
Average total loss: 1.926292
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.7585e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.247350
Average KL loss: 0.676916
Average total loss: 1.924266
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.0837e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.248655
Average KL loss: 0.676800
Average total loss: 1.925455
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.1550e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.269951
Average KL loss: 0.676744
Average total loss: 1.946695
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.7157e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.244554
Average KL loss: 0.677069
Average total loss: 1.921623
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.0931e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.250341
Average KL loss: 0.676986
Average total loss: 1.927326
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(7.5968e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.248681
Average KL loss: 0.676503
Average total loss: 1.925184
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.0545e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.252436
Average KL loss: 0.676275
Average total loss: 1.928711
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.8774e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.249210
Average KL loss: 0.676138
Average total loss: 1.925348
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.1581e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.246030
Average KL loss: 0.675991
Average total loss: 1.922021
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.6272e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.256235
Average KL loss: 0.675873
Average total loss: 1.932107
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.7579e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.245599
Average KL loss: 0.675783
Average total loss: 1.921382
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.7029e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.239638
Average KL loss: 0.675697
Average total loss: 1.915335
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.5573e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.256992
Average KL loss: 0.675594
Average total loss: 1.932587
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.9993e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.258686
Average KL loss: 0.675475
Average total loss: 1.934161
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.0449e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.258416
Average KL loss: 0.675358
Average total loss: 1.933775
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.7015e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.256827
Average KL loss: 0.675285
Average total loss: 1.932112
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.0892e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.250010
Average KL loss: 0.675194
Average total loss: 1.925204
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.0673e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.241704
Average KL loss: 0.675122
Average total loss: 1.916827
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.5413e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.259448
Average KL loss: 0.675011
Average total loss: 1.934459
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.4790e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.253250
Average KL loss: 0.674928
Average total loss: 1.928179
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.6253e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.235404
Average KL loss: 0.674840
Average total loss: 1.910244
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.1057e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.251595
Average KL loss: 0.674742
Average total loss: 1.926337
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.4039e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.256051
Average KL loss: 0.674679
Average total loss: 1.930731
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1693e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.263724
Average KL loss: 0.674612
Average total loss: 1.938336
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.9283e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.245477
Average KL loss: 0.674538
Average total loss: 1.920015
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.9901e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.250040
Average KL loss: 0.674434
Average total loss: 1.924474
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.0009e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.244017
Average KL loss: 0.674352
Average total loss: 1.918369
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.6303e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.264895
Average KL loss: 0.674272
Average total loss: 1.939166
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1455e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.258997
Average KL loss: 0.674218
Average total loss: 1.933215
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.5713e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.257693
Average KL loss: 0.674167
Average total loss: 1.931860
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.9880e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.261999
Average KL loss: 0.674112
Average total loss: 1.936111
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.1671e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.244854
Average KL loss: 0.674065
Average total loss: 1.918919
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.0564e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.243433
Average KL loss: 0.674039
Average total loss: 1.917472
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.7061e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.245248
Average KL loss: 0.674032
Average total loss: 1.919280
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.3101e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.242138
Average KL loss: 0.674025
Average total loss: 1.916163
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(7.3547e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.270689
Average KL loss: 0.674018
Average total loss: 1.944707
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1454e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.255246
Average KL loss: 0.674011
Average total loss: 1.929256
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.2552e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.255438
Average KL loss: 0.674003
Average total loss: 1.929441
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.8805e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.252878
Average KL loss: 0.673994
Average total loss: 1.926872
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.2967e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.247840
Average KL loss: 0.673988
Average total loss: 1.921828
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.1383e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.249809
Average KL loss: 0.673982
Average total loss: 1.923792
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.2593e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.249812
Average KL loss: 0.673977
Average total loss: 1.923789
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.6124e-10, device='cuda:0')
 Percentile value: 0.05212223529815674
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =      78 /    1728             (  4.51%) | total_pruned =    1650 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     222 /   36864             (  0.60%) | total_pruned =   36642 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     464 /   36864             (  1.26%) | total_pruned =   36400 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     477 /   36864             (  1.29%) | total_pruned =   36387 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1165 /   36864             (  3.16%) | total_pruned =   35699 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3523 /   73728             (  4.78%) | total_pruned =   70205 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5992 /  147456             (  4.06%) | total_pruned =  141464 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     416 /    8192             (  5.08%) | total_pruned =    7776 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1792 /  147456             (  1.22%) | total_pruned =  145664 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     744 /  147456             (  0.50%) | total_pruned =  146712 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   13349 /  294912             (  4.53%) | total_pruned =  281563 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   19729 /  589824             (  3.34%) | total_pruned =  570095 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     189 /     256             ( 73.83%) | total_pruned =      67 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     631 /   32768             (  1.93%) | total_pruned =   32137 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    7737 /  589824             (  1.31%) | total_pruned =  582087 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     130 /     256             ( 50.78%) | total_pruned =     126 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2558 /  589824             (  0.43%) | total_pruned =  587266 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      73 /     256             ( 28.52%) | total_pruned =     183 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   15113 / 1179648             (  1.28%) | total_pruned = 1164535 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     260 /     512             ( 50.78%) | total_pruned =     252 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    8186 / 2359296             (  0.35%) | total_pruned = 2351110 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     346 /  131072             (  0.26%) | total_pruned =  130726 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3227 / 2359296             (  0.14%) | total_pruned = 2356069 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     133 /     512             ( 25.98%) | total_pruned =     379 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2640 / 2359296             (  0.11%) | total_pruned = 2356656 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
linear.weight        | nonzeros =     251 /    5120             (  4.90%) | total_pruned =    4869 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 55/200 Loss: 0.038911 Accuracy: 84.52 99.98 % Best test Accuracy: 85.28%
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.4605e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.872569
Average KL loss: 0.612684
Average total loss: 2.485253
tensor(0.0002, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-8.2225e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.780863
Average KL loss: 0.609570
Average total loss: 2.390433
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.6107e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.686960
Average KL loss: 0.626929
Average total loss: 2.313889
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0748e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.609397
Average KL loss: 0.643395
Average total loss: 2.252792
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.0431e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.573227
Average KL loss: 0.654280
Average total loss: 2.227507
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-5.6851e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.561043
Average KL loss: 0.664775
Average total loss: 2.225819
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.6589e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.532301
Average KL loss: 0.668381
Average total loss: 2.200682
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(4.7783e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.511922
Average KL loss: 0.672520
Average total loss: 2.184443
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.0891e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.501577
Average KL loss: 0.673258
Average total loss: 2.174835
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-5.4644e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.498762
Average KL loss: 0.676865
Average total loss: 2.175627
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.4030e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.480933
Average KL loss: 0.679815
Average total loss: 2.160748
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.5750e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.496179
Average KL loss: 0.681621
Average total loss: 2.177801
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(3.5656e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.479188
Average KL loss: 0.684652
Average total loss: 2.163839
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(3.0174e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.440098
Average KL loss: 0.684012
Average total loss: 2.124110
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.1289e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.453856
Average KL loss: 0.682982
Average total loss: 2.136838
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.1907e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.469321
Average KL loss: 0.682727
Average total loss: 2.152048
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.3628e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.441902
Average KL loss: 0.682321
Average total loss: 2.124223
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.4308e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.445512
Average KL loss: 0.682416
Average total loss: 2.127928
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(9.2917e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.452789
Average KL loss: 0.682260
Average total loss: 2.135049
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0427e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.456287
Average KL loss: 0.684440
Average total loss: 2.140727
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(7.0843e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.449194
Average KL loss: 0.685063
Average total loss: 2.134257
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(3.1237e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.423338
Average KL loss: 0.686294
Average total loss: 2.109631
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.1182e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.443794
Average KL loss: 0.685744
Average total loss: 2.129538
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-8.7253e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.432184
Average KL loss: 0.684723
Average total loss: 2.116907
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.9836e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.430894
Average KL loss: 0.683937
Average total loss: 2.114831
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(3.9321e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.411201
Average KL loss: 0.684993
Average total loss: 2.096195
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0865e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.431034
Average KL loss: 0.685183
Average total loss: 2.116217
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.4431e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.422989
Average KL loss: 0.684382
Average total loss: 2.107370
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(5.4274e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.416465
Average KL loss: 0.685116
Average total loss: 2.101581
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.4200e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.418131
Average KL loss: 0.685163
Average total loss: 2.103294
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.8515e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.417396
Average KL loss: 0.686228
Average total loss: 2.103624
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.6455e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.423991
Average KL loss: 0.687537
Average total loss: 2.111528
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-3.3348e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.404739
Average KL loss: 0.687423
Average total loss: 2.092162
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-8.7669e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.434830
Average KL loss: 0.686082
Average total loss: 2.120912
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.0830e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.425957
Average KL loss: 0.688242
Average total loss: 2.114199
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.8195e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.396649
Average KL loss: 0.687971
Average total loss: 2.084620
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.7214e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.415708
Average KL loss: 0.685843
Average total loss: 2.101550
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.9613e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.417575
Average KL loss: 0.685134
Average total loss: 2.102708
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.6994e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.420883
Average KL loss: 0.684157
Average total loss: 2.105040
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.0886e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.382853
Average KL loss: 0.682902
Average total loss: 2.065755
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.8584e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.419796
Average KL loss: 0.682779
Average total loss: 2.102575
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.7247e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.404282
Average KL loss: 0.686359
Average total loss: 2.090641
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.9453e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.399346
Average KL loss: 0.686269
Average total loss: 2.085615
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.2660e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.396299
Average KL loss: 0.685007
Average total loss: 2.081307
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.9065e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.416951
Average KL loss: 0.683277
Average total loss: 2.100228
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.7684e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.391197
Average KL loss: 0.682829
Average total loss: 2.074026
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.3482e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.406240
Average KL loss: 0.681018
Average total loss: 2.087258
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.7805e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.392186
Average KL loss: 0.682044
Average total loss: 2.074230
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.4498e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.395775
Average KL loss: 0.682091
Average total loss: 2.077866
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.4149e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.410325
Average KL loss: 0.682905
Average total loss: 2.093231
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.0782e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.402916
Average KL loss: 0.680624
Average total loss: 2.083539
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.0423e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.408942
Average KL loss: 0.679148
Average total loss: 2.088090
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1600e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.422044
Average KL loss: 0.676532
Average total loss: 2.098576
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.6855e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.402399
Average KL loss: 0.674332
Average total loss: 2.076731
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.9615e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.403085
Average KL loss: 0.672558
Average total loss: 2.075644
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.3378e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.412843
Average KL loss: 0.671081
Average total loss: 2.083923
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.8825e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.388864
Average KL loss: 0.669771
Average total loss: 2.058636
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.0265e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.402543
Average KL loss: 0.668612
Average total loss: 2.071155
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.5863e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.399896
Average KL loss: 0.667584
Average total loss: 2.067480
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.6177e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.411903
Average KL loss: 0.666628
Average total loss: 2.078531
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.7269e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.382149
Average KL loss: 0.665582
Average total loss: 2.047731
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.7476e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.389561
Average KL loss: 0.664460
Average total loss: 2.054021
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.4976e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.389945
Average KL loss: 0.663656
Average total loss: 2.053601
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.0068e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.394599
Average KL loss: 0.662796
Average total loss: 2.057395
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.8148e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.391740
Average KL loss: 0.662313
Average total loss: 2.054054
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.9152e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.405255
Average KL loss: 0.661767
Average total loss: 2.067022
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.6317e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.397186
Average KL loss: 0.661214
Average total loss: 2.058400
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.6835e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.381772
Average KL loss: 0.660573
Average total loss: 2.042345
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.1838e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.409302
Average KL loss: 0.660200
Average total loss: 2.069502
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.5656e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.393535
Average KL loss: 0.659856
Average total loss: 2.053391
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.1557e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.397129
Average KL loss: 0.659544
Average total loss: 2.056673
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.0198e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.392252
Average KL loss: 0.659325
Average total loss: 2.051577
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.4988e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.385162
Average KL loss: 0.658652
Average total loss: 2.043815
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.0129e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.403197
Average KL loss: 0.658006
Average total loss: 2.061204
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.8012e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.383718
Average KL loss: 0.657848
Average total loss: 2.041566
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.5046e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.397290
Average KL loss: 0.657496
Average total loss: 2.054786
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.4220e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.396657
Average KL loss: 0.657277
Average total loss: 2.053934
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.7246e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.397257
Average KL loss: 0.657152
Average total loss: 2.054409
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.6029e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.394257
Average KL loss: 0.656717
Average total loss: 2.050974
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.4307e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.398497
Average KL loss: 0.656694
Average total loss: 2.055191
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.0630e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.376548
Average KL loss: 0.656398
Average total loss: 2.032946
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.7055e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.408279
Average KL loss: 0.656039
Average total loss: 2.064319
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.6530e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.407700
Average KL loss: 0.655896
Average total loss: 2.063596
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.1653e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.404742
Average KL loss: 0.655874
Average total loss: 2.060615
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.0546e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.392766
Average KL loss: 0.655564
Average total loss: 2.048330
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.7489e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.392057
Average KL loss: 0.655480
Average total loss: 2.047537
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.5271e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.404081
Average KL loss: 0.655437
Average total loss: 2.059518
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.0606e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.398781
Average KL loss: 0.655172
Average total loss: 2.053953
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.0734e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.396548
Average KL loss: 0.655193
Average total loss: 2.051741
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.3189e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.395590
Average KL loss: 0.655028
Average total loss: 2.050618
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.3439e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.384973
Average KL loss: 0.654799
Average total loss: 2.039772
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.7582e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.399400
Average KL loss: 0.654787
Average total loss: 2.054188
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.6853e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.415370
Average KL loss: 0.654816
Average total loss: 2.070185
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.5261e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.406371
Average KL loss: 0.654768
Average total loss: 2.061140
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.5135e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.397138
Average KL loss: 0.654741
Average total loss: 2.051879
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.0740e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.387965
Average KL loss: 0.654699
Average total loss: 2.042664
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.3409e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.389988
Average KL loss: 0.654643
Average total loss: 2.044631
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.2918e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.392592
Average KL loss: 0.654595
Average total loss: 2.047187
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.6915e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.390002
Average KL loss: 0.654542
Average total loss: 2.044544
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.2228e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.407751
Average KL loss: 0.654484
Average total loss: 2.062235
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.3169e-11, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.395381
Average KL loss: 0.654439
Average total loss: 2.049820
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.7133e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.390003
Average KL loss: 0.654385
Average total loss: 2.044388
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.7624e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.394690
Average KL loss: 0.654338
Average total loss: 2.049028
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.6904e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.396252
Average KL loss: 0.654328
Average total loss: 2.050579
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.4279e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.405248
Average KL loss: 0.654326
Average total loss: 2.059574
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.1408e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.391779
Average KL loss: 0.654320
Average total loss: 2.046099
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.1351e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.401022
Average KL loss: 0.654315
Average total loss: 2.055337
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.7120e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.398377
Average KL loss: 0.654311
Average total loss: 2.052689
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.1244e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.387523
Average KL loss: 0.654306
Average total loss: 2.041829
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1518e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.389205
Average KL loss: 0.654301
Average total loss: 2.043506
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.6855e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.405141
Average KL loss: 0.654298
Average total loss: 2.059439
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-9.3614e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.394838
Average KL loss: 0.654293
Average total loss: 2.049131
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-9.4361e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.397927
Average KL loss: 0.654288
Average total loss: 2.052216
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.9758e-09, device='cuda:0')
 Percentile value: 0.1592087596654892
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =      68 /    1728             (  3.94%) | total_pruned =    1660 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     100 /   36864             (  0.27%) | total_pruned =   36764 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     195 /   36864             (  0.53%) | total_pruned =   36669 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     283 /   36864             (  0.77%) | total_pruned =   36581 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     624 /   36864             (  1.69%) | total_pruned =   36240 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1676 /   73728             (  2.27%) | total_pruned =   72052 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2291 /  147456             (  1.55%) | total_pruned =  145165 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     195 /    8192             (  2.38%) | total_pruned =    7997 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     464 /  147456             (  0.31%) | total_pruned =  146992 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     214 /  147456             (  0.15%) | total_pruned =  147242 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    4335 /  294912             (  1.47%) | total_pruned =  290577 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     180 /     256             ( 70.31%) | total_pruned =      76 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    5894 /  589824             (  1.00%) | total_pruned =  583930 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     145 /     256             ( 56.64%) | total_pruned =     111 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     204 /   32768             (  0.62%) | total_pruned =   32564 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2039 /  589824             (  0.35%) | total_pruned =  587785 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     699 /  589824             (  0.12%) | total_pruned =  589125 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      41 /     256             ( 16.02%) | total_pruned =     215 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    3220 / 1179648             (  0.27%) | total_pruned = 1176428 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     161 /     512             ( 31.45%) | total_pruned =     351 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1895 / 2359296             (  0.08%) | total_pruned = 2357401 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      62 /     512             ( 12.11%) | total_pruned =     450 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     105 /  131072             (  0.08%) | total_pruned =  130967 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     695 / 2359296             (  0.03%) | total_pruned = 2358601 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      71 /     512             ( 13.87%) | total_pruned =     441 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     540 / 2359296             (  0.02%) | total_pruned = 2358756 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
linear.weight        | nonzeros =      92 /    5120             (  1.80%) | total_pruned =    5028 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 199/200 Loss: 0.231719 Accuracy: 80.08 99.14 % Best test Accuracy: 82.99%
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.1053e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.197456
Average KL loss: 0.578808
Average total loss: 2.776264
tensor(0.0001, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-7.9566e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.042591
Average KL loss: 0.543048
Average total loss: 2.585639
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(9.5920e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.971305
Average KL loss: 0.543503
Average total loss: 2.514808
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-3.4166e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.933457
Average KL loss: 0.549459
Average total loss: 2.482916
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.9160e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.882165
Average KL loss: 0.556209
Average total loss: 2.438375
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.9522e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.844528
Average KL loss: 0.563239
Average total loss: 2.407767
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.1078e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.814126
Average KL loss: 0.569789
Average total loss: 2.383915
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.9594e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.784685
Average KL loss: 0.575693
Average total loss: 2.360379
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-5.0179e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.729766
Average KL loss: 0.579814
Average total loss: 2.309580
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.3296e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.738051
Average KL loss: 0.583292
Average total loss: 2.321342
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.3108e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.723560
Average KL loss: 0.587020
Average total loss: 2.310580
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.7979e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.715940
Average KL loss: 0.591331
Average total loss: 2.307271
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.3065e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.710442
Average KL loss: 0.593835
Average total loss: 2.304277
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(9.0958e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.689210
Average KL loss: 0.596793
Average total loss: 2.286003
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.5020e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.695657
Average KL loss: 0.598746
Average total loss: 2.294403
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(2.2533e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.646041
Average KL loss: 0.600624
Average total loss: 2.246666
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(7.3318e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.667117
Average KL loss: 0.601507
Average total loss: 2.268625
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(2.1817e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.653648
Average KL loss: 0.604368
Average total loss: 2.258015
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-4.4013e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.633992
Average KL loss: 0.605716
Average total loss: 2.239708
tensor(0.0003, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.1150e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.653647
Average KL loss: 0.607579
Average total loss: 2.261225
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-8.6271e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.627856
Average KL loss: 0.608510
Average total loss: 2.236366
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-5.8789e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.658730
Average KL loss: 0.609101
Average total loss: 2.267832
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.4611e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.640048
Average KL loss: 0.611218
Average total loss: 2.251266
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-9.4614e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.605105
Average KL loss: 0.612176
Average total loss: 2.217281
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(3.2548e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.605901
Average KL loss: 0.611546
Average total loss: 2.217448
tensor(0.0003, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.4185e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.597051
Average KL loss: 0.612275
Average total loss: 2.209327
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.0206e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.592427
Average KL loss: 0.612156
Average total loss: 2.204583
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.8427e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.605410
Average KL loss: 0.612303
Average total loss: 2.217713
tensor(0.0003, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.0630e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.588003
Average KL loss: 0.612510
Average total loss: 2.200514
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(3.4866e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.602706
Average KL loss: 0.613314
Average total loss: 2.216020
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(3.3746e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.592790
Average KL loss: 0.613398
Average total loss: 2.206188
tensor(0.0003, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.8473e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.587001
Average KL loss: 0.612319
Average total loss: 2.199319
tensor(0.0003, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-3.0947e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.584414
Average KL loss: 0.612824
Average total loss: 2.197237
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-4.7990e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.586175
Average KL loss: 0.614238
Average total loss: 2.200413
tensor(0.0003, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.5227e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.590026
Average KL loss: 0.616481
Average total loss: 2.206507
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.2811e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.606596
Average KL loss: 0.618107
Average total loss: 2.224703
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.5167e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.579345
Average KL loss: 0.617824
Average total loss: 2.197169
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.3790e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.576377
Average KL loss: 0.617089
Average total loss: 2.193467
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.6998e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.574517
Average KL loss: 0.617650
Average total loss: 2.192166
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.1625e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.567028
Average KL loss: 0.616644
Average total loss: 2.183672
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.1770e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.586067
Average KL loss: 0.614191
Average total loss: 2.200258
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-4.6382e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.568450
Average KL loss: 0.614556
Average total loss: 2.183006
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0945e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.554749
Average KL loss: 0.614518
Average total loss: 2.169266
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-8.9538e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.567630
Average KL loss: 0.613535
Average total loss: 2.181165
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.6630e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.567539
Average KL loss: 0.614008
Average total loss: 2.181547
tensor(7.2897e-05, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-9.3556e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.548869
Average KL loss: 0.615238
Average total loss: 2.164107
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-3.0713e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.556502
Average KL loss: 0.614019
Average total loss: 2.170521
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.0947e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.573027
Average KL loss: 0.614540
Average total loss: 2.187568
tensor(0.0001, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-6.0150e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.568188
Average KL loss: 0.616945
Average total loss: 2.185133
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.3029e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.565255
Average KL loss: 0.617744
Average total loss: 2.183000
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(8.2867e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.563960
Average KL loss: 0.617611
Average total loss: 2.181571
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.7044e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.547996
Average KL loss: 0.617055
Average total loss: 2.165050
tensor(-5.7893e-05, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0802e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.542555
Average KL loss: 0.616322
Average total loss: 2.158877
tensor(1.4659e-06, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.8346e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.563619
Average KL loss: 0.615306
Average total loss: 2.178925
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.3525e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.552761
Average KL loss: 0.617721
Average total loss: 2.170482
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.4271e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.548675
Average KL loss: 0.619127
Average total loss: 2.167802
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(5.5808e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.546441
Average KL loss: 0.619132
Average total loss: 2.165572
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(9.8866e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.523645
Average KL loss: 0.618504
Average total loss: 2.142148
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-6.2185e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.554931
Average KL loss: 0.617041
Average total loss: 2.171972
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.9481e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.555604
Average KL loss: 0.619158
Average total loss: 2.174762
tensor(7.2428e-06, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.7799e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.537391
Average KL loss: 0.620564
Average total loss: 2.157954
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0475e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.548323
Average KL loss: 0.621338
Average total loss: 2.169661
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.1520e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.543465
Average KL loss: 0.622259
Average total loss: 2.165725
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(3.3908e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.531812
Average KL loss: 0.624665
Average total loss: 2.156477
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.4228e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.539204
Average KL loss: 0.623173
Average total loss: 2.162378
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0771e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.541269
Average KL loss: 0.623404
Average total loss: 2.164672
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.2390e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.548138
Average KL loss: 0.622569
Average total loss: 2.170708
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.3753e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.548147
Average KL loss: 0.622689
Average total loss: 2.170837
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.2611e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.528981
Average KL loss: 0.621962
Average total loss: 2.150943
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.3455e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.542757
Average KL loss: 0.621502
Average total loss: 2.164259
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.5369e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.535293
Average KL loss: 0.620784
Average total loss: 2.156077
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.8160e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.524461
Average KL loss: 0.620108
Average total loss: 2.144568
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.1116e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.529170
Average KL loss: 0.619339
Average total loss: 2.148509
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.2341e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.517375
Average KL loss: 0.618553
Average total loss: 2.135928
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.7775e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.531023
Average KL loss: 0.617863
Average total loss: 2.148886
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.5756e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.541334
Average KL loss: 0.617329
Average total loss: 2.158663
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.7549e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.541901
Average KL loss: 0.616736
Average total loss: 2.158637
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.0282e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.544617
Average KL loss: 0.616250
Average total loss: 2.160867
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.7270e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.527381
Average KL loss: 0.615794
Average total loss: 2.143175
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.3784e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.543152
Average KL loss: 0.615615
Average total loss: 2.158767
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.2419e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.544653
Average KL loss: 0.615241
Average total loss: 2.159894
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.8432e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.533582
Average KL loss: 0.614710
Average total loss: 2.148292
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.1281e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.539825
Average KL loss: 0.614281
Average total loss: 2.154105
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.9351e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.531120
Average KL loss: 0.613834
Average total loss: 2.144955
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.9059e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.520434
Average KL loss: 0.613499
Average total loss: 2.133933
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.6451e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.523430
Average KL loss: 0.613175
Average total loss: 2.136605
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(7.4438e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.544970
Average KL loss: 0.613027
Average total loss: 2.157998
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.2135e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.513556
Average KL loss: 0.612718
Average total loss: 2.126274
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.3282e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.520043
Average KL loss: 0.612360
Average total loss: 2.132402
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.0356e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.523926
Average KL loss: 0.611986
Average total loss: 2.135912
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.2764e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.547701
Average KL loss: 0.611553
Average total loss: 2.159254
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.0914e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.520969
Average KL loss: 0.611184
Average total loss: 2.132153
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.7380e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.536446
Average KL loss: 0.610830
Average total loss: 2.147276
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.3124e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.544974
Average KL loss: 0.610554
Average total loss: 2.155527
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.8548e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.525419
Average KL loss: 0.610346
Average total loss: 2.135765
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.0750e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.547893
Average KL loss: 0.610141
Average total loss: 2.158034
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.2076e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.532590
Average KL loss: 0.610098
Average total loss: 2.142688
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.3762e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.543599
Average KL loss: 0.609974
Average total loss: 2.153573
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.1492e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.521264
Average KL loss: 0.609744
Average total loss: 2.131008
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.3195e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.506978
Average KL loss: 0.609633
Average total loss: 2.116611
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.3293e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.532854
Average KL loss: 0.609584
Average total loss: 2.142439
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.6590e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.533544
Average KL loss: 0.609561
Average total loss: 2.143105
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.0848e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.530373
Average KL loss: 0.609525
Average total loss: 2.139899
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.5211e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.537370
Average KL loss: 0.609493
Average total loss: 2.146863
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.0288e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.531325
Average KL loss: 0.609454
Average total loss: 2.140780
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.7187e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.538111
Average KL loss: 0.609425
Average total loss: 2.147537
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.0614e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.516005
Average KL loss: 0.609386
Average total loss: 2.125390
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(9.5290e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.537787
Average KL loss: 0.609340
Average total loss: 2.147127
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(8.7843e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.531824
Average KL loss: 0.609310
Average total loss: 2.141134
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.4040e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.535386
Average KL loss: 0.609278
Average total loss: 2.144664
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.5502e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.523602
Average KL loss: 0.609238
Average total loss: 2.132840
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(5.1868e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.525769
Average KL loss: 0.609212
Average total loss: 2.134981
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.2249e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.519638
Average KL loss: 0.609209
Average total loss: 2.128847
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.1506e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.531630
Average KL loss: 0.609205
Average total loss: 2.140836
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.5933e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.528643
Average KL loss: 0.609202
Average total loss: 2.137845
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.8286e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.533992
Average KL loss: 0.609200
Average total loss: 2.143192
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.2176e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.534933
Average KL loss: 0.609198
Average total loss: 2.144132
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.4386e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.542296
Average KL loss: 0.609195
Average total loss: 2.151491
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.2978e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.526744
Average KL loss: 0.609194
Average total loss: 2.135939
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.4619e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.522053
Average KL loss: 0.609190
Average total loss: 2.131243
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.4899e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.537491
Average KL loss: 0.609187
Average total loss: 2.146678
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.9311e-09, device='cuda:0')
 Percentile value: 0.45406369566917393
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =      63 /    1728             (  3.65%) | total_pruned =    1665 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      52 /   36864             (  0.14%) | total_pruned =   36812 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      88 /   36864             (  0.24%) | total_pruned =   36776 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     147 /   36864             (  0.40%) | total_pruned =   36717 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     305 /   36864             (  0.83%) | total_pruned =   36559 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     742 /   73728             (  1.01%) | total_pruned =   72986 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     951 /  147456             (  0.64%) | total_pruned =  146505 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      64 /    8192             (  0.78%) | total_pruned =    8128 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     120 /  147456             (  0.08%) | total_pruned =  147336 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =      53 /  147456             (  0.04%) | total_pruned =  147403 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1269 /  294912             (  0.43%) | total_pruned =  293643 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1356 /  589824             (  0.23%) | total_pruned =  588468 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      48 /   32768             (  0.15%) | total_pruned =   32720 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     501 /  589824             (  0.08%) | total_pruned =  589323 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      67 /     256             ( 26.17%) | total_pruned =     189 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     197 /  589824             (  0.03%) | total_pruned =  589627 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     594 / 1179648             (  0.05%) | total_pruned = 1179054 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      81 /     512             ( 15.82%) | total_pruned =     431 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     460 / 2359296             (  0.02%) | total_pruned = 2358836 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      27 /  131072             (  0.02%) | total_pruned =  131045 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     143 / 2359296             (  0.01%) | total_pruned = 2359153 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     106 / 2359296             (  0.00%) | total_pruned = 2359190 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
linear.weight        | nonzeros =      48 /    5120             (  0.94%) | total_pruned =    5072 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 144/200 Loss: 0.470959 Accuracy: 74.68 82.50 % Best test Accuracy: 75.07%
