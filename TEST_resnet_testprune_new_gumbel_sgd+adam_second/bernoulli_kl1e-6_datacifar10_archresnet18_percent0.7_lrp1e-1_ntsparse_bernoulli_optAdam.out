Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(3.5847e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.258087
Average KL loss: 3.489915
Average total loss: 4.748001
tensor(-1.5609, device='cuda:0') tensor(1.5235, device='cuda:0') tensor(7.9051e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.709008
Average KL loss: 2.316521
Average total loss: 3.025530
tensor(-2.1079, device='cuda:0') tensor(2.4152, device='cuda:0') tensor(5.5835e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.511428
Average KL loss: 1.948673
Average total loss: 2.460101
tensor(-2.4604, device='cuda:0') tensor(2.9522, device='cuda:0') tensor(5.2763e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.388509
Average KL loss: 1.723629
Average total loss: 2.112138
tensor(-2.7333, device='cuda:0') tensor(3.3536, device='cuda:0') tensor(5.4177e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.305900
Average KL loss: 1.563625
Average total loss: 1.869525
tensor(-2.9593, device='cuda:0') tensor(3.6717, device='cuda:0') tensor(4.9030e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.251401
Average KL loss: 1.440748
Average total loss: 1.692150
tensor(-3.1534, device='cuda:0') tensor(3.9397, device='cuda:0') tensor(4.3170e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.200852
Average KL loss: 1.342980
Average total loss: 1.543833
tensor(-3.3242, device='cuda:0') tensor(4.1663, device='cuda:0') tensor(4.3080e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.165080
Average KL loss: 1.262189
Average total loss: 1.427269
tensor(-3.4775, device='cuda:0') tensor(4.3640, device='cuda:0') tensor(3.4847e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.136321
Average KL loss: 1.192086
Average total loss: 1.328407
tensor(-3.6172, device='cuda:0') tensor(4.5254, device='cuda:0') tensor(3.7394e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.114319
Average KL loss: 1.131068
Average total loss: 1.245387
tensor(-3.7455, device='cuda:0') tensor(4.6694, device='cuda:0') tensor(3.6895e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.101104
Average KL loss: 1.076791
Average total loss: 1.177895
tensor(-3.8644, device='cuda:0') tensor(4.7936, device='cuda:0') tensor(3.9943e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.084494
Average KL loss: 1.028287
Average total loss: 1.112781
tensor(-3.9755, device='cuda:0') tensor(4.9021, device='cuda:0') tensor(3.2655e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.079674
Average KL loss: 0.984647
Average total loss: 1.064322
tensor(-4.0797, device='cuda:0') tensor(5.0055, device='cuda:0') tensor(3.1529e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.068270
Average KL loss: 0.946303
Average total loss: 1.014573
tensor(-4.1779, device='cuda:0') tensor(5.0961, device='cuda:0') tensor(2.9661e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.063639
Average KL loss: 0.910211
Average total loss: 0.973850
tensor(-4.2708, device='cuda:0') tensor(5.1747, device='cuda:0') tensor(2.7636e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.055877
Average KL loss: 0.877038
Average total loss: 0.932915
tensor(-4.3590, device='cuda:0') tensor(5.2454, device='cuda:0') tensor(3.0766e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.047879
Average KL loss: 0.845897
Average total loss: 0.893776
tensor(-4.4432, device='cuda:0') tensor(5.3010, device='cuda:0') tensor(2.6552e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.048382
Average KL loss: 0.816481
Average total loss: 0.864863
tensor(-4.5237, device='cuda:0') tensor(5.3569, device='cuda:0') tensor(2.4394e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.044269
Average KL loss: 0.790936
Average total loss: 0.835205
tensor(-4.6004, device='cuda:0') tensor(5.4183, device='cuda:0') tensor(2.4299e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.042251
Average KL loss: 0.767345
Average total loss: 0.809596
tensor(-4.6743, device='cuda:0') tensor(5.4708, device='cuda:0') tensor(2.2439e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.039149
Average KL loss: 0.745454
Average total loss: 0.784603
tensor(-4.7453, device='cuda:0') tensor(5.5213, device='cuda:0') tensor(2.2882e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.036627
Average KL loss: 0.724628
Average total loss: 0.761255
tensor(-4.8139, device='cuda:0') tensor(5.5677, device='cuda:0') tensor(2.2395e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.035825
Average KL loss: 0.705434
Average total loss: 0.741259
tensor(-4.8800, device='cuda:0') tensor(5.6126, device='cuda:0') tensor(2.1913e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.033051
Average KL loss: 0.687025
Average total loss: 0.720076
tensor(-4.9439, device='cuda:0') tensor(5.6508, device='cuda:0') tensor(2.1132e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.032912
Average KL loss: 0.669652
Average total loss: 0.702564
tensor(-5.0058, device='cuda:0') tensor(5.6891, device='cuda:0') tensor(1.9105e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.029319
Average KL loss: 0.653010
Average total loss: 0.682329
tensor(-5.0660, device='cuda:0') tensor(5.7199, device='cuda:0') tensor(2.1518e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.027694
Average KL loss: 0.637192
Average total loss: 0.664886
tensor(-5.1242, device='cuda:0') tensor(5.7494, device='cuda:0') tensor(1.8593e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.030193
Average KL loss: 0.622966
Average total loss: 0.653159
tensor(-5.1807, device='cuda:0') tensor(5.7916, device='cuda:0') tensor(1.6577e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.028440
Average KL loss: 0.610775
Average total loss: 0.639215
tensor(-5.2358, device='cuda:0') tensor(5.8327, device='cuda:0') tensor(1.6951e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.026825
Average KL loss: 0.598281
Average total loss: 0.625106
tensor(-5.2897, device='cuda:0') tensor(5.8651, device='cuda:0') tensor(1.5927e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.024324
Average KL loss: 0.586124
Average total loss: 0.610448
tensor(-5.3421, device='cuda:0') tensor(5.8912, device='cuda:0') tensor(1.6769e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.023473
Average KL loss: 0.573791
Average total loss: 0.597264
tensor(-5.3934, device='cuda:0') tensor(5.9142, device='cuda:0') tensor(1.4602e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.024502
Average KL loss: 0.562706
Average total loss: 0.587208
tensor(-5.4431, device='cuda:0') tensor(5.9443, device='cuda:0') tensor(1.6503e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.022110
Average KL loss: 0.552345
Average total loss: 0.574455
tensor(-5.4918, device='cuda:0') tensor(5.9682, device='cuda:0') tensor(1.5723e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.023181
Average KL loss: 0.542269
Average total loss: 0.565450
tensor(-5.5396, device='cuda:0') tensor(5.9971, device='cuda:0') tensor(1.5624e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.020510
Average KL loss: 0.532931
Average total loss: 0.553441
tensor(-5.5863, device='cuda:0') tensor(6.0191, device='cuda:0') tensor(1.3604e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.020864
Average KL loss: 0.523183
Average total loss: 0.544047
tensor(-5.6320, device='cuda:0') tensor(6.0395, device='cuda:0') tensor(1.4924e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.020243
Average KL loss: 0.514744
Average total loss: 0.534987
tensor(-5.6767, device='cuda:0') tensor(6.0648, device='cuda:0') tensor(1.2577e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.019715
Average KL loss: 0.506437
Average total loss: 0.526151
tensor(-5.7207, device='cuda:0') tensor(6.0878, device='cuda:0') tensor(1.2747e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.019329
Average KL loss: 0.498650
Average total loss: 0.517979
tensor(-5.7637, device='cuda:0') tensor(6.1126, device='cuda:0') tensor(1.2053e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.019064
Average KL loss: 0.491239
Average total loss: 0.510303
tensor(-5.8060, device='cuda:0') tensor(6.1366, device='cuda:0') tensor(1.2471e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.017263
Average KL loss: 0.483869
Average total loss: 0.501132
tensor(-5.8476, device='cuda:0') tensor(6.1522, device='cuda:0') tensor(1.2591e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.017074
Average KL loss: 0.476168
Average total loss: 0.493243
tensor(-5.8884, device='cuda:0') tensor(6.1692, device='cuda:0') tensor(1.2082e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.016711
Average KL loss: 0.468875
Average total loss: 0.485585
tensor(-5.9285, device='cuda:0') tensor(6.1839, device='cuda:0') tensor(1.1313e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.017686
Average KL loss: 0.462354
Average total loss: 0.480039
tensor(-5.9678, device='cuda:0') tensor(6.2073, device='cuda:0') tensor(1.0758e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.016776
Average KL loss: 0.456519
Average total loss: 0.473295
tensor(-6.0064, device='cuda:0') tensor(6.2290, device='cuda:0') tensor(9.2699e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.016576
Average KL loss: 0.450680
Average total loss: 0.467256
tensor(-6.0446, device='cuda:0') tensor(6.2473, device='cuda:0') tensor(7.8283e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.016070
Average KL loss: 0.444812
Average total loss: 0.460882
tensor(-6.0824, device='cuda:0') tensor(6.2662, device='cuda:0') tensor(9.8449e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.016464
Average KL loss: 0.439363
Average total loss: 0.455827
tensor(-6.1192, device='cuda:0') tensor(6.2873, device='cuda:0') tensor(1.0592e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.016387
Average KL loss: 0.434535
Average total loss: 0.450922
tensor(-6.1556, device='cuda:0') tensor(6.3106, device='cuda:0') tensor(9.6837e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.016117
Average KL loss: 0.429817
Average total loss: 0.445934
tensor(-6.1915, device='cuda:0') tensor(6.3325, device='cuda:0') tensor(9.0519e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.016185
Average KL loss: 0.425109
Average total loss: 0.441294
tensor(-6.2271, device='cuda:0') tensor(6.3544, device='cuda:0') tensor(9.8766e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.014796
Average KL loss: 0.420561
Average total loss: 0.435357
tensor(-6.2621, device='cuda:0') tensor(6.3713, device='cuda:0') tensor(9.0059e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.012837
Average KL loss: 0.415642
Average total loss: 0.428479
tensor(-6.2967, device='cuda:0') tensor(6.3816, device='cuda:0') tensor(8.3289e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.013544
Average KL loss: 0.410236
Average total loss: 0.423780
tensor(-6.3308, device='cuda:0') tensor(6.3907, device='cuda:0') tensor(8.8496e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.014314
Average KL loss: 0.405822
Average total loss: 0.420136
tensor(-6.3644, device='cuda:0') tensor(6.4108, device='cuda:0') tensor(7.6251e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.014262
Average KL loss: 0.402076
Average total loss: 0.416338
tensor(-6.3976, device='cuda:0') tensor(6.4315, device='cuda:0') tensor(7.9695e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.013292
Average KL loss: 0.398243
Average total loss: 0.411536
tensor(-6.4302, device='cuda:0') tensor(6.4476, device='cuda:0') tensor(7.8542e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.013255
Average KL loss: 0.394678
Average total loss: 0.407933
tensor(-6.4625, device='cuda:0') tensor(6.4696, device='cuda:0') tensor(7.8779e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.013354
Average KL loss: 0.391023
Average total loss: 0.404376
tensor(-6.4945, device='cuda:0') tensor(6.4835, device='cuda:0') tensor(8.1335e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.012959
Average KL loss: 0.387245
Average total loss: 0.400203
tensor(-6.5261, device='cuda:0') tensor(6.4998, device='cuda:0') tensor(5.7144e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.011795
Average KL loss: 0.383654
Average total loss: 0.395449
tensor(-6.5573, device='cuda:0') tensor(6.5132, device='cuda:0') tensor(7.4709e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.011956
Average KL loss: 0.379968
Average total loss: 0.391924
tensor(-6.5882, device='cuda:0') tensor(6.5276, device='cuda:0') tensor(6.3426e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.011663
Average KL loss: 0.376322
Average total loss: 0.387986
tensor(-6.6187, device='cuda:0') tensor(6.5373, device='cuda:0') tensor(7.4828e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.011332
Average KL loss: 0.372770
Average total loss: 0.384101
tensor(-6.6489, device='cuda:0') tensor(6.5487, device='cuda:0') tensor(6.9250e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.011204
Average KL loss: 0.369052
Average total loss: 0.380257
tensor(-6.6788, device='cuda:0') tensor(6.5566, device='cuda:0') tensor(7.0011e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.010908
Average KL loss: 0.365715
Average total loss: 0.376623
tensor(-6.7084, device='cuda:0') tensor(6.5677, device='cuda:0') tensor(5.5465e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.010195
Average KL loss: 0.362223
Average total loss: 0.372418
tensor(-6.7377, device='cuda:0') tensor(6.5740, device='cuda:0') tensor(7.1683e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.010832
Average KL loss: 0.358732
Average total loss: 0.369564
tensor(-6.7667, device='cuda:0') tensor(6.5841, device='cuda:0') tensor(4.7998e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.010550
Average KL loss: 0.355778
Average total loss: 0.366327
tensor(-6.7953, device='cuda:0') tensor(6.5958, device='cuda:0') tensor(5.7450e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.010527
Average KL loss: 0.352888
Average total loss: 0.363415
tensor(-6.8236, device='cuda:0') tensor(6.6078, device='cuda:0') tensor(5.5925e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.011566
Average KL loss: 0.350320
Average total loss: 0.361886
tensor(-6.8517, device='cuda:0') tensor(6.6258, device='cuda:0') tensor(5.9999e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.010916
Average KL loss: 0.348219
Average total loss: 0.359135
tensor(-6.8796, device='cuda:0') tensor(6.6415, device='cuda:0') tensor(5.2969e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.010960
Average KL loss: 0.345924
Average total loss: 0.356884
tensor(-6.9071, device='cuda:0') tensor(6.6584, device='cuda:0') tensor(6.3496e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.010013
Average KL loss: 0.343700
Average total loss: 0.353713
tensor(-6.9346, device='cuda:0') tensor(6.6707, device='cuda:0') tensor(5.9248e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.010855
Average KL loss: 0.341125
Average total loss: 0.351980
tensor(-6.9618, device='cuda:0') tensor(6.6862, device='cuda:0') tensor(6.2505e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.009596
Average KL loss: 0.338829
Average total loss: 0.348424
tensor(-6.9889, device='cuda:0') tensor(6.6953, device='cuda:0') tensor(5.4409e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.010376
Average KL loss: 0.336270
Average total loss: 0.346645
tensor(-7.0155, device='cuda:0') tensor(6.7096, device='cuda:0') tensor(5.7292e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.009604
Average KL loss: 0.334317
Average total loss: 0.343921
tensor(-7.0420, device='cuda:0') tensor(6.7250, device='cuda:0') tensor(4.6337e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.009032
Average KL loss: 0.331791
Average total loss: 0.340823
tensor(-7.0683, device='cuda:0') tensor(6.7292, device='cuda:0') tensor(5.5702e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.009838
Average KL loss: 0.329290
Average total loss: 0.339128
tensor(-7.0943, device='cuda:0') tensor(6.7412, device='cuda:0') tensor(5.1424e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.008841
Average KL loss: 0.327354
Average total loss: 0.336196
tensor(-7.1201, device='cuda:0') tensor(6.7517, device='cuda:0') tensor(5.6297e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.008993
Average KL loss: 0.324932
Average total loss: 0.333924
tensor(-7.1457, device='cuda:0') tensor(6.7599, device='cuda:0') tensor(4.6897e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.010536
Average KL loss: 0.323006
Average total loss: 0.333542
tensor(-7.1709, device='cuda:0') tensor(6.7793, device='cuda:0') tensor(4.9789e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.008253
Average KL loss: 0.321329
Average total loss: 0.329582
tensor(-7.1962, device='cuda:0') tensor(6.7887, device='cuda:0') tensor(4.9890e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.008915
Average KL loss: 0.319070
Average total loss: 0.327985
tensor(-7.2212, device='cuda:0') tensor(6.7961, device='cuda:0') tensor(4.2628e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.009550
Average KL loss: 0.317266
Average total loss: 0.326816
tensor(-7.2462, device='cuda:0') tensor(6.8112, device='cuda:0') tensor(5.0092e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.009293
Average KL loss: 0.315448
Average total loss: 0.324742
tensor(-7.2707, device='cuda:0') tensor(6.8215, device='cuda:0') tensor(4.5442e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.008294
Average KL loss: 0.313580
Average total loss: 0.321874
tensor(-7.2951, device='cuda:0') tensor(6.8288, device='cuda:0') tensor(4.0520e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.008387
Average KL loss: 0.311368
Average total loss: 0.319755
tensor(-7.3194, device='cuda:0') tensor(6.8353, device='cuda:0') tensor(4.6123e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.007959
Average KL loss: 0.309177
Average total loss: 0.317136
tensor(-7.3435, device='cuda:0') tensor(6.8386, device='cuda:0') tensor(4.5296e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.008590
Average KL loss: 0.307161
Average total loss: 0.315750
tensor(-7.3674, device='cuda:0') tensor(6.8494, device='cuda:0') tensor(3.8445e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.007841
Average KL loss: 0.305661
Average total loss: 0.313502
tensor(-7.3911, device='cuda:0') tensor(6.8581, device='cuda:0') tensor(3.9374e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.008389
Average KL loss: 0.303824
Average total loss: 0.312214
tensor(-7.4148, device='cuda:0') tensor(6.8671, device='cuda:0') tensor(4.0870e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.008862
Average KL loss: 0.302335
Average total loss: 0.311197
tensor(-7.4382, device='cuda:0') tensor(6.8814, device='cuda:0') tensor(4.1315e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.008046
Average KL loss: 0.301104
Average total loss: 0.309150
tensor(-7.4614, device='cuda:0') tensor(6.8938, device='cuda:0') tensor(2.7782e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.007839
Average KL loss: 0.299404
Average total loss: 0.307243
tensor(-7.4845, device='cuda:0') tensor(6.8995, device='cuda:0') tensor(4.1440e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.007767
Average KL loss: 0.297474
Average total loss: 0.305241
tensor(-7.5074, device='cuda:0') tensor(6.9033, device='cuda:0') tensor(4.1000e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.008363
Average KL loss: 0.295926
Average total loss: 0.304288
tensor(-7.5301, device='cuda:0') tensor(6.9160, device='cuda:0') tensor(3.5258e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.006959
Average KL loss: 0.294462
Average total loss: 0.301421
tensor(-7.5528, device='cuda:0') tensor(6.9188, device='cuda:0') tensor(3.6229e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.006828
Average KL loss: 0.292414
Average total loss: 0.299242
tensor(-7.5753, device='cuda:0') tensor(6.9200, device='cuda:0') tensor(3.1174e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.007319
Average KL loss: 0.290498
Average total loss: 0.297817
tensor(-7.5977, device='cuda:0') tensor(6.9242, device='cuda:0') tensor(3.6234e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.007324
Average KL loss: 0.288949
Average total loss: 0.296274
tensor(-7.6199, device='cuda:0') tensor(6.9305, device='cuda:0') tensor(3.8392e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.007299
Average KL loss: 0.287419
Average total loss: 0.294718
tensor(-7.6420, device='cuda:0') tensor(6.9370, device='cuda:0') tensor(3.9081e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.007132
Average KL loss: 0.285664
Average total loss: 0.292796
tensor(-7.6640, device='cuda:0') tensor(6.9396, device='cuda:0') tensor(3.5974e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.007151
Average KL loss: 0.284238
Average total loss: 0.291389
tensor(-7.6858, device='cuda:0') tensor(6.9485, device='cuda:0') tensor(3.3508e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.006386
Average KL loss: 0.282648
Average total loss: 0.289034
tensor(-7.7075, device='cuda:0') tensor(6.9480, device='cuda:0') tensor(3.1566e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.006685
Average KL loss: 0.280853
Average total loss: 0.287539
tensor(-7.7290, device='cuda:0') tensor(6.9490, device='cuda:0') tensor(3.2105e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.006786
Average KL loss: 0.279248
Average total loss: 0.286034
tensor(-7.7503, device='cuda:0') tensor(6.9530, device='cuda:0') tensor(3.4952e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.007358
Average KL loss: 0.277783
Average total loss: 0.285140
tensor(-7.7717, device='cuda:0') tensor(6.9593, device='cuda:0') tensor(2.9079e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.006737
Average KL loss: 0.276661
Average total loss: 0.283398
tensor(-7.7928, device='cuda:0') tensor(6.9684, device='cuda:0') tensor(3.0233e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.007064
Average KL loss: 0.275405
Average total loss: 0.282468
tensor(-7.8138, device='cuda:0') tensor(6.9753, device='cuda:0') tensor(3.0486e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.006747
Average KL loss: 0.274324
Average total loss: 0.281070
tensor(-7.8348, device='cuda:0') tensor(6.9842, device='cuda:0') tensor(2.5388e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.006177
Average KL loss: 0.273027
Average total loss: 0.279204
tensor(-7.8556, device='cuda:0') tensor(6.9879, device='cuda:0') tensor(2.8412e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.006323
Average KL loss: 0.271475
Average total loss: 0.277798
tensor(-7.8763, device='cuda:0') tensor(6.9894, device='cuda:0') tensor(2.8906e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.006224
Average KL loss: 0.270282
Average total loss: 0.276507
tensor(-7.8968, device='cuda:0') tensor(6.9964, device='cuda:0') tensor(2.7464e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.006106
Average KL loss: 0.268915
Average total loss: 0.275020
tensor(-7.9171, device='cuda:0') tensor(6.9980, device='cuda:0') tensor(2.0563e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.006710
Average KL loss: 0.267669
Average total loss: 0.274378
tensor(-7.9374, device='cuda:0') tensor(7.0062, device='cuda:0') tensor(2.9293e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.006760
Average KL loss: 0.266725
Average total loss: 0.273485
tensor(-7.9577, device='cuda:0') tensor(7.0158, device='cuda:0') tensor(2.4994e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.006324
Average KL loss: 0.265827
Average total loss: 0.272151
tensor(-7.9776, device='cuda:0') tensor(7.0225, device='cuda:0') tensor(2.6472e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.006645
Average KL loss: 0.264622
Average total loss: 0.271267
tensor(-7.9977, device='cuda:0') tensor(7.0282, device='cuda:0') tensor(3.0010e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.006473
Average KL loss: 0.263685
Average total loss: 0.270158
tensor(-8.0176, device='cuda:0') tensor(7.0368, device='cuda:0') tensor(2.4799e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.006800
Average KL loss: 0.262838
Average total loss: 0.269638
tensor(-8.0376, device='cuda:0') tensor(7.0487, device='cuda:0') tensor(2.3924e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.006763
Average KL loss: 0.262230
Average total loss: 0.268993
tensor(-8.0573, device='cuda:0') tensor(7.0608, device='cuda:0') tensor(1.9303e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.007163
Average KL loss: 0.261623
Average total loss: 0.268785
tensor(-8.0770, device='cuda:0') tensor(7.0768, device='cuda:0') tensor(2.3285e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.006118
Average KL loss: 0.260897
Average total loss: 0.267015
tensor(-8.0966, device='cuda:0') tensor(7.0801, device='cuda:0') tensor(2.4323e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.005701
Average KL loss: 0.259675
Average total loss: 0.265377
tensor(-8.1161, device='cuda:0') tensor(7.0814, device='cuda:0') tensor(2.5765e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.006031
Average KL loss: 0.258502
Average total loss: 0.264533
tensor(-8.1355, device='cuda:0') tensor(7.0869, device='cuda:0') tensor(2.5533e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.006707
Average KL loss: 0.257526
Average total loss: 0.264233
tensor(-8.1548, device='cuda:0') tensor(7.0950, device='cuda:0') tensor(2.1865e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.005872
Average KL loss: 0.256728
Average total loss: 0.262600
tensor(-8.1739, device='cuda:0') tensor(7.1002, device='cuda:0') tensor(2.6826e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.005997
Average KL loss: 0.255628
Average total loss: 0.261625
tensor(-8.1931, device='cuda:0') tensor(7.1021, device='cuda:0') tensor(2.2238e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.005573
Average KL loss: 0.254548
Average total loss: 0.260121
tensor(-8.2121, device='cuda:0') tensor(7.1038, device='cuda:0') tensor(1.3868e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.005792
Average KL loss: 0.253368
Average total loss: 0.259160
tensor(-8.2309, device='cuda:0') tensor(7.1075, device='cuda:0') tensor(2.4969e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.005969
Average KL loss: 0.252509
Average total loss: 0.258478
tensor(-8.2498, device='cuda:0') tensor(7.1138, device='cuda:0') tensor(2.4005e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.005687
Average KL loss: 0.251367
Average total loss: 0.257054
tensor(-8.2684, device='cuda:0') tensor(7.1146, device='cuda:0') tensor(2.3826e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.006252
Average KL loss: 0.250480
Average total loss: 0.256731
tensor(-8.2869, device='cuda:0') tensor(7.1244, device='cuda:0') tensor(1.9157e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.005918
Average KL loss: 0.249877
Average total loss: 0.255795
tensor(-8.3055, device='cuda:0') tensor(7.1306, device='cuda:0') tensor(2.3375e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.005717
Average KL loss: 0.249012
Average total loss: 0.254730
tensor(-8.3239, device='cuda:0') tensor(7.1359, device='cuda:0') tensor(2.2052e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.006056
Average KL loss: 0.248073
Average total loss: 0.254129
tensor(-8.3422, device='cuda:0') tensor(7.1418, device='cuda:0') tensor(1.8159e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.005740
Average KL loss: 0.247417
Average total loss: 0.253157
tensor(-8.3603, device='cuda:0') tensor(7.1482, device='cuda:0') tensor(1.7667e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.005936
Average KL loss: 0.246726
Average total loss: 0.252661
tensor(-8.3784, device='cuda:0') tensor(7.1556, device='cuda:0') tensor(1.9546e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.005814
Average KL loss: 0.246130
Average total loss: 0.251944
tensor(-8.3963, device='cuda:0') tensor(7.1655, device='cuda:0') tensor(2.3873e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.005733
Average KL loss: 0.245368
Average total loss: 0.251101
tensor(-8.4143, device='cuda:0') tensor(7.1686, device='cuda:0') tensor(2.0219e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.005912
Average KL loss: 0.244670
Average total loss: 0.250582
tensor(-8.4322, device='cuda:0') tensor(7.1759, device='cuda:0') tensor(2.0888e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.005852
Average KL loss: 0.244095
Average total loss: 0.249947
tensor(-8.4498, device='cuda:0') tensor(7.1835, device='cuda:0') tensor(2.0086e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.005968
Average KL loss: 0.243413
Average total loss: 0.249381
tensor(-8.4676, device='cuda:0') tensor(7.1890, device='cuda:0') tensor(1.5416e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.005516
Average KL loss: 0.242771
Average total loss: 0.248287
tensor(-8.4851, device='cuda:0') tensor(7.1958, device='cuda:0') tensor(1.5603e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.005462
Average KL loss: 0.241939
Average total loss: 0.247401
tensor(-8.5026, device='cuda:0') tensor(7.1966, device='cuda:0') tensor(1.8188e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.005165
Average KL loss: 0.241036
Average total loss: 0.246201
tensor(-8.5201, device='cuda:0') tensor(7.1977, device='cuda:0') tensor(1.8712e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.004891
Average KL loss: 0.239956
Average total loss: 0.244846
tensor(-8.5375, device='cuda:0') tensor(7.1955, device='cuda:0') tensor(1.4055e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.005076
Average KL loss: 0.239008
Average total loss: 0.244084
tensor(-8.5546, device='cuda:0') tensor(7.1970, device='cuda:0') tensor(1.7191e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.005333
Average KL loss: 0.238112
Average total loss: 0.243445
tensor(-8.5717, device='cuda:0') tensor(7.1999, device='cuda:0') tensor(1.7127e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.005402
Average KL loss: 0.237392
Average total loss: 0.242794
tensor(-8.5888, device='cuda:0') tensor(7.2047, device='cuda:0') tensor(2.3041e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.005230
Average KL loss: 0.236877
Average total loss: 0.242108
tensor(-8.6057, device='cuda:0') tensor(7.2119, device='cuda:0') tensor(1.9457e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.005506
Average KL loss: 0.236170
Average total loss: 0.241677
tensor(-8.6226, device='cuda:0') tensor(7.2164, device='cuda:0') tensor(1.3891e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.005255
Average KL loss: 0.235495
Average total loss: 0.240750
tensor(-8.6395, device='cuda:0') tensor(7.2188, device='cuda:0') tensor(1.8864e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.005519
Average KL loss: 0.234864
Average total loss: 0.240384
tensor(-8.6561, device='cuda:0') tensor(7.2255, device='cuda:0') tensor(1.4039e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.005071
Average KL loss: 0.234333
Average total loss: 0.239403
tensor(-8.6728, device='cuda:0') tensor(7.2290, device='cuda:0') tensor(1.8266e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.005605
Average KL loss: 0.233766
Average total loss: 0.239372
tensor(-8.6892, device='cuda:0') tensor(7.2373, device='cuda:0') tensor(1.7213e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.005396
Average KL loss: 0.233353
Average total loss: 0.238749
tensor(-8.7057, device='cuda:0') tensor(7.2447, device='cuda:0') tensor(1.4734e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.005033
Average KL loss: 0.232594
Average total loss: 0.237627
tensor(-8.7222, device='cuda:0') tensor(7.2460, device='cuda:0') tensor(1.6285e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.004858
Average KL loss: 0.231882
Average total loss: 0.236740
tensor(-8.7385, device='cuda:0') tensor(7.2486, device='cuda:0') tensor(1.5630e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.005157
Average KL loss: 0.231200
Average total loss: 0.236357
tensor(-8.7548, device='cuda:0') tensor(7.2524, device='cuda:0') tensor(1.8192e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.004847
Average KL loss: 0.230558
Average total loss: 0.235406
tensor(-8.7710, device='cuda:0') tensor(7.2544, device='cuda:0') tensor(1.7337e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.005293
Average KL loss: 0.229915
Average total loss: 0.235208
tensor(-8.7871, device='cuda:0') tensor(7.2603, device='cuda:0') tensor(1.5528e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.005033
Average KL loss: 0.229422
Average total loss: 0.234456
tensor(-8.8031, device='cuda:0') tensor(7.2631, device='cuda:0') tensor(1.2836e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.005169
Average KL loss: 0.228791
Average total loss: 0.233960
tensor(-8.8191, device='cuda:0') tensor(7.2665, device='cuda:0') tensor(1.4891e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.004992
Average KL loss: 0.228180
Average total loss: 0.233172
tensor(-8.8351, device='cuda:0') tensor(7.2696, device='cuda:0') tensor(1.6123e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.004852
Average KL loss: 0.227517
Average total loss: 0.232370
tensor(-8.8509, device='cuda:0') tensor(7.2716, device='cuda:0') tensor(1.4031e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.004931
Average KL loss: 0.226849
Average total loss: 0.231780
tensor(-8.8667, device='cuda:0') tensor(7.2735, device='cuda:0') tensor(1.4936e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.004942
Average KL loss: 0.226147
Average total loss: 0.231089
tensor(-8.8823, device='cuda:0') tensor(7.2762, device='cuda:0') tensor(1.2283e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.004790
Average KL loss: 0.225676
Average total loss: 0.230466
tensor(-8.8979, device='cuda:0') tensor(7.2819, device='cuda:0') tensor(1.7447e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.005112
Average KL loss: 0.225311
Average total loss: 0.230423
tensor(-8.9135, device='cuda:0') tensor(7.2863, device='cuda:0') tensor(1.4037e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.005216
Average KL loss: 0.224811
Average total loss: 0.230028
tensor(-8.9290, device='cuda:0') tensor(7.2910, device='cuda:0') tensor(1.3021e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.004876
Average KL loss: 0.224371
Average total loss: 0.229247
tensor(-8.9444, device='cuda:0') tensor(7.2944, device='cuda:0') tensor(1.9191e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.004691
Average KL loss: 0.223752
Average total loss: 0.228443
tensor(-8.9596, device='cuda:0') tensor(7.2959, device='cuda:0') tensor(1.1834e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.004531
Average KL loss: 0.223088
Average total loss: 0.227619
tensor(-8.9750, device='cuda:0') tensor(7.2951, device='cuda:0') tensor(1.2026e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.004837
Average KL loss: 0.222406
Average total loss: 0.227243
tensor(-8.9902, device='cuda:0') tensor(7.2962, device='cuda:0') tensor(1.3793e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.005119
Average KL loss: 0.221856
Average total loss: 0.226975
tensor(-9.0054, device='cuda:0') tensor(7.2990, device='cuda:0') tensor(9.4825e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.004840
Average KL loss: 0.221445
Average total loss: 0.226285
tensor(-9.0204, device='cuda:0') tensor(7.3038, device='cuda:0') tensor(9.3436e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.004998
Average KL loss: 0.220915
Average total loss: 0.225913
tensor(-9.0354, device='cuda:0') tensor(7.3068, device='cuda:0') tensor(1.4408e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.004964
Average KL loss: 0.220442
Average total loss: 0.225406
tensor(-9.0504, device='cuda:0') tensor(7.3114, device='cuda:0') tensor(1.3962e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.004739
Average KL loss: 0.219926
Average total loss: 0.224666
tensor(-9.0653, device='cuda:0') tensor(7.3130, device='cuda:0') tensor(1.5051e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.004936
Average KL loss: 0.219307
Average total loss: 0.224243
tensor(-9.0800, device='cuda:0') tensor(7.3153, device='cuda:0') tensor(1.2361e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.004887
Average KL loss: 0.218997
Average total loss: 0.223884
tensor(-9.0947, device='cuda:0') tensor(7.3229, device='cuda:0') tensor(1.0261e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.004919
Average KL loss: 0.218646
Average total loss: 0.223565
tensor(-9.1093, device='cuda:0') tensor(7.3281, device='cuda:0') tensor(1.2822e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.004939
Average KL loss: 0.218191
Average total loss: 0.223130
tensor(-9.1239, device='cuda:0') tensor(7.3294, device='cuda:0') tensor(1.1253e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.004446
Average KL loss: 0.217757
Average total loss: 0.222203
tensor(-9.1384, device='cuda:0') tensor(7.3314, device='cuda:0') tensor(1.1200e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.004642
Average KL loss: 0.217166
Average total loss: 0.221808
tensor(-9.1527, device='cuda:0') tensor(7.3322, device='cuda:0') tensor(9.6669e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.004780
Average KL loss: 0.216712
Average total loss: 0.221492
tensor(-9.1670, device='cuda:0') tensor(7.3375, device='cuda:0') tensor(1.2197e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.004839
Average KL loss: 0.216277
Average total loss: 0.221116
tensor(-9.1812, device='cuda:0') tensor(7.3409, device='cuda:0') tensor(1.1223e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.004904
Average KL loss: 0.215925
Average total loss: 0.220829
tensor(-9.1954, device='cuda:0') tensor(7.3470, device='cuda:0') tensor(1.1694e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.004645
Average KL loss: 0.215600
Average total loss: 0.220245
tensor(-9.2095, device='cuda:0') tensor(7.3488, device='cuda:0') tensor(8.3765e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.004546
Average KL loss: 0.215122
Average total loss: 0.219669
tensor(-9.2236, device='cuda:0') tensor(7.3512, device='cuda:0') tensor(1.2894e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.004477
Average KL loss: 0.214566
Average total loss: 0.219043
tensor(-9.2376, device='cuda:0') tensor(7.3522, device='cuda:0') tensor(8.8856e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.004307
Average KL loss: 0.213974
Average total loss: 0.218281
tensor(-9.2516, device='cuda:0') tensor(7.3511, device='cuda:0') tensor(1.2555e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.003942
Average KL loss: 0.213246
Average total loss: 0.217188
tensor(-9.2655, device='cuda:0') tensor(7.3465, device='cuda:0') tensor(1.0831e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.004575
Average KL loss: 0.212606
Average total loss: 0.217181
tensor(-9.2794, device='cuda:0') tensor(7.3474, device='cuda:0') tensor(1.2507e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.004697
Average KL loss: 0.212193
Average total loss: 0.216890
tensor(-9.2931, device='cuda:0') tensor(7.3510, device='cuda:0') tensor(1.0833e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.004404
Average KL loss: 0.211866
Average total loss: 0.216270
 Percentile value: -6.942123889923096
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1682 /    1728             ( 97.34%) | total_pruned =      46 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   30023 /   36864             ( 81.44%) | total_pruned =    6841 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   30063 /   36864             ( 81.55%) | total_pruned =    6801 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   28922 /   36864             ( 78.46%) | total_pruned =    7942 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   27688 /   36864             ( 75.11%) | total_pruned =    9176 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   53662 /   73728             ( 72.78%) | total_pruned =   20066 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   98254 /  147456             ( 66.63%) | total_pruned =   49202 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7584 /    8192             ( 92.58%) | total_pruned =     608 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   85420 /  147456             ( 57.93%) | total_pruned =   62036 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   85592 /  147456             ( 58.05%) | total_pruned =   61864 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  182649 /  294912             ( 61.93%) | total_pruned =  112263 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  328175 /  589824             ( 55.64%) | total_pruned =  261649 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   27226 /   32768             ( 83.09%) | total_pruned =    5542 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  238157 /  589824             ( 40.38%) | total_pruned =  351667 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  234462 /  589824             ( 39.75%) | total_pruned =  355362 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  559218 / 1179648             ( 47.41%) | total_pruned =  620430 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     494 /     512             ( 96.48%) | total_pruned =      18 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  683445 / 2359296             ( 28.97%) | total_pruned = 1675851 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   84253 /  131072             ( 64.28%) | total_pruned =   46819 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  329396 / 2359296             ( 13.96%) | total_pruned = 2029900 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  223227 / 2359296             (  9.46%) | total_pruned = 2136069 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     492 /     512             ( 96.09%) | total_pruned =      20 | shape = torch.Size([512])
linear.weight        | nonzeros =    5059 /    5120             ( 98.81%) | total_pruned =      61 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 51/200 Loss: 0.000043 Accuracy: 86.26 100.00 % Best test Accuracy: 86.30%
tensor(-9.3068, device='cuda:0') tensor(7.3540, device='cuda:0') tensor(-7.2294e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.135788
Average KL loss: 0.208736
Average total loss: 0.344523
tensor(-9.3997, device='cuda:0') tensor(6.7832, device='cuda:0') tensor(-1.0610e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.085382
Average KL loss: 0.207438
Average total loss: 0.292820
tensor(-9.4562, device='cuda:0') tensor(6.5660, device='cuda:0') tensor(4.4500e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.069083
Average KL loss: 0.206797
Average total loss: 0.275880
tensor(-9.5012, device='cuda:0') tensor(6.4362, device='cuda:0') tensor(-5.7049e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.055737
Average KL loss: 0.206266
Average total loss: 0.262003
tensor(-9.5398, device='cuda:0') tensor(6.3518, device='cuda:0') tensor(-1.2746e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.047225
Average KL loss: 0.205842
Average total loss: 0.253068
tensor(-9.5742, device='cuda:0') tensor(6.2940, device='cuda:0') tensor(-1.7092e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.042652
Average KL loss: 0.205463
Average total loss: 0.248115
tensor(-9.6056, device='cuda:0') tensor(6.2539, device='cuda:0') tensor(-6.7789e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.040017
Average KL loss: 0.205147
Average total loss: 0.245164
tensor(-9.6346, device='cuda:0') tensor(6.2262, device='cuda:0') tensor(-1.4669e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.037364
Average KL loss: 0.204859
Average total loss: 0.242223
tensor(-9.6617, device='cuda:0') tensor(6.2083, device='cuda:0') tensor(7.0861e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.032415
Average KL loss: 0.204648
Average total loss: 0.237062
tensor(-9.6873, device='cuda:0') tensor(6.1949, device='cuda:0') tensor(8.8259e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.033043
Average KL loss: 0.204446
Average total loss: 0.237489
tensor(-9.7115, device='cuda:0') tensor(6.1900, device='cuda:0') tensor(-1.4032e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.027428
Average KL loss: 0.204333
Average total loss: 0.231762
tensor(-9.7346, device='cuda:0') tensor(6.1867, device='cuda:0') tensor(3.3509e-11, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.028330
Average KL loss: 0.204200
Average total loss: 0.232530
tensor(-9.7568, device='cuda:0') tensor(6.1868, device='cuda:0') tensor(9.8401e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.026470
Average KL loss: 0.204080
Average total loss: 0.230549
tensor(-9.7781, device='cuda:0') tensor(6.1896, device='cuda:0') tensor(4.5772e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.025482
Average KL loss: 0.204029
Average total loss: 0.229511
tensor(-9.7986, device='cuda:0') tensor(6.1944, device='cuda:0') tensor(-1.7386e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.023707
Average KL loss: 0.204053
Average total loss: 0.227761
tensor(-9.8183, device='cuda:0') tensor(6.2026, device='cuda:0') tensor(-2.1974e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.022736
Average KL loss: 0.204047
Average total loss: 0.226783
tensor(-9.8375, device='cuda:0') tensor(6.2096, device='cuda:0') tensor(1.9409e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.021130
Average KL loss: 0.204008
Average total loss: 0.225138
tensor(-9.8560, device='cuda:0') tensor(6.2181, device='cuda:0') tensor(1.3361e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.019989
Average KL loss: 0.204036
Average total loss: 0.224026
tensor(-9.8740, device='cuda:0') tensor(6.2282, device='cuda:0') tensor(1.5696e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.019352
Average KL loss: 0.204057
Average total loss: 0.223408
tensor(-9.8916, device='cuda:0') tensor(6.2381, device='cuda:0') tensor(-2.3163e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.017198
Average KL loss: 0.203989
Average total loss: 0.221186
tensor(-9.9088, device='cuda:0') tensor(6.2467, device='cuda:0') tensor(9.1840e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.017127
Average KL loss: 0.203898
Average total loss: 0.221026
tensor(-9.9255, device='cuda:0') tensor(6.2558, device='cuda:0') tensor(-7.0003e-11, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.017667
Average KL loss: 0.203835
Average total loss: 0.221502
tensor(-9.9419, device='cuda:0') tensor(6.2651, device='cuda:0') tensor(6.3915e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.015130
Average KL loss: 0.203727
Average total loss: 0.218858
tensor(-9.9579, device='cuda:0') tensor(6.2747, device='cuda:0') tensor(5.7637e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.015511
Average KL loss: 0.203629
Average total loss: 0.219140
tensor(-9.9735, device='cuda:0') tensor(6.2848, device='cuda:0') tensor(5.6099e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.014618
Average KL loss: 0.203591
Average total loss: 0.218209
tensor(-9.9888, device='cuda:0') tensor(6.2952, device='cuda:0') tensor(1.0553e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.013705
Average KL loss: 0.203460
Average total loss: 0.217164
tensor(-10.0038, device='cuda:0') tensor(6.3047, device='cuda:0') tensor(1.4218e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.013273
Average KL loss: 0.203344
Average total loss: 0.216617
tensor(-10.0185, device='cuda:0') tensor(6.3145, device='cuda:0') tensor(4.9480e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.013446
Average KL loss: 0.203235
Average total loss: 0.216681
tensor(-10.0330, device='cuda:0') tensor(6.3242, device='cuda:0') tensor(4.1178e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.013598
Average KL loss: 0.203120
Average total loss: 0.216718
tensor(-10.0472, device='cuda:0') tensor(6.3342, device='cuda:0') tensor(1.5906e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.013200
Average KL loss: 0.203066
Average total loss: 0.216267
tensor(-10.0611, device='cuda:0') tensor(6.3454, device='cuda:0') tensor(6.0207e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.012507
Average KL loss: 0.202928
Average total loss: 0.215435
tensor(-10.0748, device='cuda:0') tensor(6.3547, device='cuda:0') tensor(6.1957e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.011900
Average KL loss: 0.202811
Average total loss: 0.214712
tensor(-10.0882, device='cuda:0') tensor(6.3642, device='cuda:0') tensor(-3.2932e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.011602
Average KL loss: 0.202676
Average total loss: 0.214278
tensor(-10.1015, device='cuda:0') tensor(6.3739, device='cuda:0') tensor(1.3510e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.011621
Average KL loss: 0.202529
Average total loss: 0.214151
tensor(-10.1146, device='cuda:0') tensor(6.3832, device='cuda:0') tensor(7.7581e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.009766
Average KL loss: 0.202361
Average total loss: 0.212127
tensor(-10.1275, device='cuda:0') tensor(6.3907, device='cuda:0') tensor(9.4114e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.010927
Average KL loss: 0.202156
Average total loss: 0.213083
tensor(-10.1401, device='cuda:0') tensor(6.3985, device='cuda:0') tensor(6.7580e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.010352
Average KL loss: 0.201948
Average total loss: 0.212300
tensor(-10.1526, device='cuda:0') tensor(6.4064, device='cuda:0') tensor(5.8259e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.010615
Average KL loss: 0.201702
Average total loss: 0.212317
tensor(-10.1649, device='cuda:0') tensor(6.4130, device='cuda:0') tensor(4.8660e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.009995
Average KL loss: 0.201494
Average total loss: 0.211490
tensor(-10.1770, device='cuda:0') tensor(6.4233, device='cuda:0') tensor(2.8155e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.009270
Average KL loss: 0.201304
Average total loss: 0.210574
tensor(-10.1889, device='cuda:0') tensor(6.4302, device='cuda:0') tensor(6.1139e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.009456
Average KL loss: 0.201024
Average total loss: 0.210480
tensor(-10.2006, device='cuda:0') tensor(6.4374, device='cuda:0') tensor(-4.2929e-11, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.010304
Average KL loss: 0.200880
Average total loss: 0.211185
tensor(-10.2122, device='cuda:0') tensor(6.4472, device='cuda:0') tensor(1.1802e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.009657
Average KL loss: 0.200681
Average total loss: 0.210338
tensor(-10.2237, device='cuda:0') tensor(6.4534, device='cuda:0') tensor(1.2862e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.008673
Average KL loss: 0.200431
Average total loss: 0.209104
tensor(-10.2351, device='cuda:0') tensor(6.4593, device='cuda:0') tensor(9.0391e-11, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.008868
Average KL loss: 0.200183
Average total loss: 0.209051
tensor(-10.2463, device='cuda:0') tensor(6.4661, device='cuda:0') tensor(3.6664e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.007987
Average KL loss: 0.199974
Average total loss: 0.207961
tensor(-10.2574, device='cuda:0') tensor(6.4717, device='cuda:0') tensor(7.4113e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.008198
Average KL loss: 0.199670
Average total loss: 0.207868
tensor(-10.2683, device='cuda:0') tensor(6.4773, device='cuda:0') tensor(7.8986e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.007753
Average KL loss: 0.199369
Average total loss: 0.207121
tensor(-10.2792, device='cuda:0') tensor(6.4821, device='cuda:0') tensor(1.1067e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.008120
Average KL loss: 0.199072
Average total loss: 0.207192
tensor(-10.2899, device='cuda:0') tensor(6.4876, device='cuda:0') tensor(7.5760e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.007753
Average KL loss: 0.198775
Average total loss: 0.206528
tensor(-10.3004, device='cuda:0') tensor(6.4927, device='cuda:0') tensor(8.9358e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.007025
Average KL loss: 0.198501
Average total loss: 0.205526
tensor(-10.3108, device='cuda:0') tensor(6.4982, device='cuda:0') tensor(1.2797e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.007502
Average KL loss: 0.198193
Average total loss: 0.205696
tensor(-10.3212, device='cuda:0') tensor(6.5024, device='cuda:0') tensor(9.9959e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.006875
Average KL loss: 0.197853
Average total loss: 0.204728
tensor(-10.3315, device='cuda:0') tensor(6.5067, device='cuda:0') tensor(4.5113e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.007441
Average KL loss: 0.197563
Average total loss: 0.205004
tensor(-10.3416, device='cuda:0') tensor(6.5122, device='cuda:0') tensor(-1.7173e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.007329
Average KL loss: 0.197293
Average total loss: 0.204622
tensor(-10.3516, device='cuda:0') tensor(6.5173, device='cuda:0') tensor(-4.7747e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.007451
Average KL loss: 0.197007
Average total loss: 0.204458
tensor(-10.3615, device='cuda:0') tensor(6.5221, device='cuda:0') tensor(1.1239e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.006550
Average KL loss: 0.196653
Average total loss: 0.203203
tensor(-10.3714, device='cuda:0') tensor(6.5250, device='cuda:0') tensor(2.5318e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.006945
Average KL loss: 0.196353
Average total loss: 0.203298
tensor(-10.3811, device='cuda:0') tensor(6.5295, device='cuda:0') tensor(3.5019e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.006524
Average KL loss: 0.196113
Average total loss: 0.202637
tensor(-10.3908, device='cuda:0') tensor(6.5332, device='cuda:0') tensor(6.1731e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.006148
Average KL loss: 0.195796
Average total loss: 0.201943
tensor(-10.4003, device='cuda:0') tensor(6.5362, device='cuda:0') tensor(8.1245e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.006319
Average KL loss: 0.195432
Average total loss: 0.201752
tensor(-10.4099, device='cuda:0') tensor(6.5392, device='cuda:0') tensor(6.2272e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.006180
Average KL loss: 0.195086
Average total loss: 0.201266
tensor(-10.4193, device='cuda:0') tensor(6.5419, device='cuda:0') tensor(1.0075e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.006050
Average KL loss: 0.194695
Average total loss: 0.200745
tensor(-10.4287, device='cuda:0') tensor(6.5434, device='cuda:0') tensor(4.4615e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.005284
Average KL loss: 0.194351
Average total loss: 0.199635
tensor(-10.4379, device='cuda:0') tensor(6.5453, device='cuda:0') tensor(7.9165e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.005925
Average KL loss: 0.193972
Average total loss: 0.199897
tensor(-10.4470, device='cuda:0') tensor(6.5469, device='cuda:0') tensor(1.0062e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.006284
Average KL loss: 0.193685
Average total loss: 0.199969
tensor(-10.4561, device='cuda:0') tensor(6.5519, device='cuda:0') tensor(2.7517e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.005779
Average KL loss: 0.193405
Average total loss: 0.199185
tensor(-10.4651, device='cuda:0') tensor(6.5544, device='cuda:0') tensor(4.4749e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.005768
Average KL loss: 0.193082
Average total loss: 0.198850
tensor(-10.4740, device='cuda:0') tensor(6.5580, device='cuda:0') tensor(7.7805e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.005701
Average KL loss: 0.192739
Average total loss: 0.198439
tensor(-10.4829, device='cuda:0') tensor(6.5599, device='cuda:0') tensor(6.9665e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.006039
Average KL loss: 0.192418
Average total loss: 0.198457
tensor(-10.4916, device='cuda:0') tensor(6.5636, device='cuda:0') tensor(4.5737e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.006322
Average KL loss: 0.192113
Average total loss: 0.198435
tensor(-10.5004, device='cuda:0') tensor(6.5676, device='cuda:0') tensor(7.8081e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.005865
Average KL loss: 0.191857
Average total loss: 0.197722
tensor(-10.5090, device='cuda:0') tensor(6.5715, device='cuda:0') tensor(6.9108e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.005270
Average KL loss: 0.191551
Average total loss: 0.196821
tensor(-10.5175, device='cuda:0') tensor(6.5742, device='cuda:0') tensor(6.8743e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.005343
Average KL loss: 0.191220
Average total loss: 0.196563
tensor(-10.5259, device='cuda:0') tensor(6.5761, device='cuda:0') tensor(5.9665e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.005412
Average KL loss: 0.190918
Average total loss: 0.196331
tensor(-10.5344, device='cuda:0') tensor(6.5784, device='cuda:0') tensor(9.5277e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.006035
Average KL loss: 0.190633
Average total loss: 0.196668
tensor(-10.5427, device='cuda:0') tensor(6.5822, device='cuda:0') tensor(5.3749e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.005378
Average KL loss: 0.190371
Average total loss: 0.195749
tensor(-10.5510, device='cuda:0') tensor(6.5849, device='cuda:0') tensor(5.5202e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.005109
Average KL loss: 0.190005
Average total loss: 0.195115
tensor(-10.5592, device='cuda:0') tensor(6.5864, device='cuda:0') tensor(5.6224e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.005472
Average KL loss: 0.189711
Average total loss: 0.195182
tensor(-10.5674, device='cuda:0') tensor(6.5893, device='cuda:0') tensor(7.9613e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.005278
Average KL loss: 0.189404
Average total loss: 0.194682
tensor(-10.5756, device='cuda:0') tensor(6.5897, device='cuda:0') tensor(4.1284e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.005500
Average KL loss: 0.189037
Average total loss: 0.194537
tensor(-10.5837, device='cuda:0') tensor(6.5920, device='cuda:0') tensor(9.1612e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.005940
Average KL loss: 0.188739
Average total loss: 0.194679
tensor(-10.5917, device='cuda:0') tensor(6.5954, device='cuda:0') tensor(-7.9922e-11, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.005408
Average KL loss: 0.188496
Average total loss: 0.193904
tensor(-10.5997, device='cuda:0') tensor(6.5988, device='cuda:0') tensor(4.1000e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.005224
Average KL loss: 0.188176
Average total loss: 0.193400
tensor(-10.6076, device='cuda:0') tensor(6.5999, device='cuda:0') tensor(7.6011e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.004753
Average KL loss: 0.187828
Average total loss: 0.192581
tensor(-10.6154, device='cuda:0') tensor(6.6003, device='cuda:0') tensor(4.4283e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.004876
Average KL loss: 0.187473
Average total loss: 0.192348
tensor(-10.6233, device='cuda:0') tensor(6.6014, device='cuda:0') tensor(7.1387e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.005181
Average KL loss: 0.187165
Average total loss: 0.192345
tensor(-10.6309, device='cuda:0') tensor(6.6043, device='cuda:0') tensor(6.6203e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.005265
Average KL loss: 0.186867
Average total loss: 0.192132
tensor(-10.6387, device='cuda:0') tensor(6.6056, device='cuda:0') tensor(2.8317e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.004668
Average KL loss: 0.186562
Average total loss: 0.191230
tensor(-10.6463, device='cuda:0') tensor(6.6070, device='cuda:0') tensor(6.0604e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.004954
Average KL loss: 0.186247
Average total loss: 0.191201
tensor(-10.6539, device='cuda:0') tensor(6.6084, device='cuda:0') tensor(4.8977e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.004529
Average KL loss: 0.185917
Average total loss: 0.190446
tensor(-10.6614, device='cuda:0') tensor(6.6087, device='cuda:0') tensor(5.2945e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.004867
Average KL loss: 0.185616
Average total loss: 0.190483
tensor(-10.6689, device='cuda:0') tensor(6.6096, device='cuda:0') tensor(7.3329e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.005011
Average KL loss: 0.185303
Average total loss: 0.190314
tensor(-10.6765, device='cuda:0') tensor(6.6101, device='cuda:0') tensor(7.1812e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.005038
Average KL loss: 0.184983
Average total loss: 0.190022
tensor(-10.6839, device='cuda:0') tensor(6.6122, device='cuda:0') tensor(3.2429e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.005472
Average KL loss: 0.184720
Average total loss: 0.190193
tensor(-10.6912, device='cuda:0') tensor(6.6151, device='cuda:0') tensor(5.0965e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.005471
Average KL loss: 0.184518
Average total loss: 0.189990
tensor(-10.6985, device='cuda:0') tensor(6.6184, device='cuda:0') tensor(5.8022e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.005184
Average KL loss: 0.184285
Average total loss: 0.189469
tensor(-10.7057, device='cuda:0') tensor(6.6221, device='cuda:0') tensor(8.4975e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.005239
Average KL loss: 0.184077
Average total loss: 0.189315
tensor(-10.7129, device='cuda:0') tensor(6.6243, device='cuda:0') tensor(8.3536e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.004952
Average KL loss: 0.183811
Average total loss: 0.188763
tensor(-10.7201, device='cuda:0') tensor(6.6273, device='cuda:0') tensor(2.8291e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.004937
Average KL loss: 0.183577
Average total loss: 0.188514
tensor(-10.7271, device='cuda:0') tensor(6.6297, device='cuda:0') tensor(2.5683e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.004611
Average KL loss: 0.183357
Average total loss: 0.187968
tensor(-10.7342, device='cuda:0') tensor(6.6319, device='cuda:0') tensor(5.6084e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.004692
Average KL loss: 0.183085
Average total loss: 0.187777
tensor(-10.7412, device='cuda:0') tensor(6.6334, device='cuda:0') tensor(1.4889e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.004846
Average KL loss: 0.182836
Average total loss: 0.187682
tensor(-10.7482, device='cuda:0') tensor(6.6353, device='cuda:0') tensor(6.0045e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.005093
Average KL loss: 0.182606
Average total loss: 0.187700
tensor(-10.7552, device='cuda:0') tensor(6.6372, device='cuda:0') tensor(3.2486e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.004762
Average KL loss: 0.182393
Average total loss: 0.187155
tensor(-10.7621, device='cuda:0') tensor(6.6389, device='cuda:0') tensor(-8.3761e-11, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.005005
Average KL loss: 0.182143
Average total loss: 0.187148
tensor(-10.7690, device='cuda:0') tensor(6.6407, device='cuda:0') tensor(2.7180e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.004561
Average KL loss: 0.181888
Average total loss: 0.186449
tensor(-10.7759, device='cuda:0') tensor(6.6421, device='cuda:0') tensor(3.9377e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.004971
Average KL loss: 0.181602
Average total loss: 0.186573
tensor(-10.7827, device='cuda:0') tensor(6.6431, device='cuda:0') tensor(6.0474e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.005038
Average KL loss: 0.181348
Average total loss: 0.186387
tensor(-10.7894, device='cuda:0') tensor(6.6456, device='cuda:0') tensor(7.8672e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.004667
Average KL loss: 0.181112
Average total loss: 0.185779
tensor(-10.7961, device='cuda:0') tensor(6.6473, device='cuda:0') tensor(-1.0337e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.004498
Average KL loss: 0.180825
Average total loss: 0.185323
tensor(-10.8029, device='cuda:0') tensor(6.6477, device='cuda:0') tensor(4.7519e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.004506
Average KL loss: 0.180572
Average total loss: 0.185078
tensor(-10.8095, device='cuda:0') tensor(6.6493, device='cuda:0') tensor(3.1975e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.004317
Average KL loss: 0.180308
Average total loss: 0.184625
tensor(-10.8161, device='cuda:0') tensor(6.6500, device='cuda:0') tensor(3.6971e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.004815
Average KL loss: 0.180054
Average total loss: 0.184869
tensor(-10.8227, device='cuda:0') tensor(6.6520, device='cuda:0') tensor(5.1382e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.004351
Average KL loss: 0.179809
Average total loss: 0.184160
tensor(-10.8292, device='cuda:0') tensor(6.6530, device='cuda:0') tensor(3.0310e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.004469
Average KL loss: 0.179540
Average total loss: 0.184008
tensor(-10.8357, device='cuda:0') tensor(6.6538, device='cuda:0') tensor(3.0428e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.004726
Average KL loss: 0.179291
Average total loss: 0.184017
tensor(-10.8422, device='cuda:0') tensor(6.6554, device='cuda:0') tensor(9.2908e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.004633
Average KL loss: 0.179063
Average total loss: 0.183696
tensor(-10.8486, device='cuda:0') tensor(6.6577, device='cuda:0') tensor(1.9435e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.004399
Average KL loss: 0.178833
Average total loss: 0.183232
tensor(-10.8551, device='cuda:0') tensor(6.6582, device='cuda:0') tensor(4.0802e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.004199
Average KL loss: 0.178552
Average total loss: 0.182751
tensor(-10.8615, device='cuda:0') tensor(6.6568, device='cuda:0') tensor(3.1253e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.003965
Average KL loss: 0.178234
Average total loss: 0.182199
tensor(-10.8679, device='cuda:0') tensor(6.6566, device='cuda:0') tensor(3.7837e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.004457
Average KL loss: 0.177930
Average total loss: 0.182386
tensor(-10.8742, device='cuda:0') tensor(6.6562, device='cuda:0') tensor(3.4385e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.003949
Average KL loss: 0.177707
Average total loss: 0.181655
tensor(-10.8805, device='cuda:0') tensor(6.6565, device='cuda:0') tensor(3.2359e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.004148
Average KL loss: 0.177455
Average total loss: 0.181604
tensor(-10.8868, device='cuda:0') tensor(6.6563, device='cuda:0') tensor(5.2142e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.004077
Average KL loss: 0.177178
Average total loss: 0.181255
tensor(-10.8930, device='cuda:0') tensor(6.6571, device='cuda:0') tensor(3.4587e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.004319
Average KL loss: 0.176920
Average total loss: 0.181239
tensor(-10.8992, device='cuda:0') tensor(6.6576, device='cuda:0') tensor(5.4991e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.004266
Average KL loss: 0.176670
Average total loss: 0.180936
tensor(-10.9054, device='cuda:0') tensor(6.6584, device='cuda:0') tensor(4.0422e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.004259
Average KL loss: 0.176427
Average total loss: 0.180686
tensor(-10.9115, device='cuda:0') tensor(6.6586, device='cuda:0') tensor(7.8501e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.004150
Average KL loss: 0.176188
Average total loss: 0.180338
tensor(-10.9176, device='cuda:0') tensor(6.6593, device='cuda:0') tensor(3.7877e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.003868
Average KL loss: 0.175907
Average total loss: 0.179775
tensor(-10.9238, device='cuda:0') tensor(6.6583, device='cuda:0') tensor(5.0922e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.004137
Average KL loss: 0.175614
Average total loss: 0.179751
tensor(-10.9299, device='cuda:0') tensor(6.6575, device='cuda:0') tensor(-1.2070e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.004264
Average KL loss: 0.175384
Average total loss: 0.179649
tensor(-10.9359, device='cuda:0') tensor(6.6589, device='cuda:0') tensor(5.6819e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.003980
Average KL loss: 0.175133
Average total loss: 0.179114
tensor(-10.9419, device='cuda:0') tensor(6.6576, device='cuda:0') tensor(4.3188e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.004213
Average KL loss: 0.174830
Average total loss: 0.179044
tensor(-10.9479, device='cuda:0') tensor(6.6578, device='cuda:0') tensor(2.1150e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.004326
Average KL loss: 0.174602
Average total loss: 0.178928
tensor(-10.9539, device='cuda:0') tensor(6.6587, device='cuda:0') tensor(7.1271e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.004252
Average KL loss: 0.174372
Average total loss: 0.178624
tensor(-10.9598, device='cuda:0') tensor(6.6586, device='cuda:0') tensor(3.3689e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.003924
Average KL loss: 0.174127
Average total loss: 0.178050
tensor(-10.9657, device='cuda:0') tensor(6.6573, device='cuda:0') tensor(5.0229e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.003957
Average KL loss: 0.173851
Average total loss: 0.177809
tensor(-10.9717, device='cuda:0') tensor(6.6565, device='cuda:0') tensor(2.4595e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.003830
Average KL loss: 0.173592
Average total loss: 0.177422
tensor(-10.9775, device='cuda:0') tensor(6.6562, device='cuda:0') tensor(3.8435e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.003875
Average KL loss: 0.173326
Average total loss: 0.177201
tensor(-10.9833, device='cuda:0') tensor(6.6554, device='cuda:0') tensor(3.5370e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.003677
Average KL loss: 0.173076
Average total loss: 0.176752
tensor(-10.9890, device='cuda:0') tensor(6.6550, device='cuda:0') tensor(3.7761e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.003737
Average KL loss: 0.172830
Average total loss: 0.176567
tensor(-10.9948, device='cuda:0') tensor(6.6543, device='cuda:0') tensor(1.0178e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.003887
Average KL loss: 0.172565
Average total loss: 0.176451
tensor(-11.0006, device='cuda:0') tensor(6.6535, device='cuda:0') tensor(2.9095e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.003856
Average KL loss: 0.172325
Average total loss: 0.176180
tensor(-11.0063, device='cuda:0') tensor(6.6534, device='cuda:0') tensor(2.8569e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.003905
Average KL loss: 0.172059
Average total loss: 0.175964
tensor(-11.0120, device='cuda:0') tensor(6.6533, device='cuda:0') tensor(1.5799e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.003785
Average KL loss: 0.171817
Average total loss: 0.175602
tensor(-11.0177, device='cuda:0') tensor(6.6526, device='cuda:0') tensor(2.7901e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.003940
Average KL loss: 0.171563
Average total loss: 0.175502
tensor(-11.0234, device='cuda:0') tensor(6.6521, device='cuda:0') tensor(2.8953e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.003723
Average KL loss: 0.171344
Average total loss: 0.175067
tensor(-11.0290, device='cuda:0') tensor(6.6512, device='cuda:0') tensor(3.1230e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.003786
Average KL loss: 0.171071
Average total loss: 0.174857
tensor(-11.0346, device='cuda:0') tensor(6.6497, device='cuda:0') tensor(4.7500e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.003415
Average KL loss: 0.170800
Average total loss: 0.174214
tensor(-11.0403, device='cuda:0') tensor(6.6478, device='cuda:0') tensor(2.1487e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.003766
Average KL loss: 0.170537
Average total loss: 0.174303
tensor(-11.0458, device='cuda:0') tensor(6.6473, device='cuda:0') tensor(3.9232e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.003859
Average KL loss: 0.170345
Average total loss: 0.174203
tensor(-11.0513, device='cuda:0') tensor(6.6471, device='cuda:0') tensor(2.1012e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.003998
Average KL loss: 0.170120
Average total loss: 0.174118
tensor(-11.0569, device='cuda:0') tensor(6.6467, device='cuda:0') tensor(2.5988e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.003855
Average KL loss: 0.169908
Average total loss: 0.173763
tensor(-11.0624, device='cuda:0') tensor(6.6470, device='cuda:0') tensor(2.7911e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.003740
Average KL loss: 0.169671
Average total loss: 0.173411
tensor(-11.0679, device='cuda:0') tensor(6.6461, device='cuda:0') tensor(3.3498e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.003799
Average KL loss: 0.169447
Average total loss: 0.173246
tensor(-11.0734, device='cuda:0') tensor(6.6462, device='cuda:0') tensor(2.5157e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.003967
Average KL loss: 0.169262
Average total loss: 0.173229
tensor(-11.0788, device='cuda:0') tensor(6.6474, device='cuda:0') tensor(3.4986e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.003928
Average KL loss: 0.169052
Average total loss: 0.172980
tensor(-11.0842, device='cuda:0') tensor(6.6471, device='cuda:0') tensor(2.3935e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.004086
Average KL loss: 0.168846
Average total loss: 0.172932
tensor(-11.0896, device='cuda:0') tensor(6.6475, device='cuda:0') tensor(1.3406e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.003784
Average KL loss: 0.168639
Average total loss: 0.172423
tensor(-11.0949, device='cuda:0') tensor(6.6469, device='cuda:0') tensor(2.7278e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.003666
Average KL loss: 0.168402
Average total loss: 0.172069
tensor(-11.1003, device='cuda:0') tensor(6.6451, device='cuda:0') tensor(1.3331e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.003760
Average KL loss: 0.168150
Average total loss: 0.171910
tensor(-11.1057, device='cuda:0') tensor(6.6428, device='cuda:0') tensor(2.8972e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.003930
Average KL loss: 0.167912
Average total loss: 0.171842
tensor(-11.1110, device='cuda:0') tensor(6.6430, device='cuda:0') tensor(3.7342e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.003532
Average KL loss: 0.167727
Average total loss: 0.171259
tensor(-11.1163, device='cuda:0') tensor(6.6413, device='cuda:0') tensor(2.8059e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.004109
Average KL loss: 0.167485
Average total loss: 0.171594
tensor(-11.1216, device='cuda:0') tensor(6.6407, device='cuda:0') tensor(1.8398e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.003936
Average KL loss: 0.167280
Average total loss: 0.171216
tensor(-11.1269, device='cuda:0') tensor(6.6414, device='cuda:0') tensor(3.0380e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.004039
Average KL loss: 0.167072
Average total loss: 0.171111
tensor(-11.1322, device='cuda:0') tensor(6.6403, device='cuda:0') tensor(3.0118e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.004083
Average KL loss: 0.166916
Average total loss: 0.170999
tensor(-11.1374, device='cuda:0') tensor(6.6414, device='cuda:0') tensor(4.6642e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.004099
Average KL loss: 0.166708
Average total loss: 0.170807
tensor(-11.1425, device='cuda:0') tensor(6.6420, device='cuda:0') tensor(2.2472e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.003787
Average KL loss: 0.166534
Average total loss: 0.170321
tensor(-11.1477, device='cuda:0') tensor(6.6415, device='cuda:0') tensor(2.1117e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.003923
Average KL loss: 0.166333
Average total loss: 0.170255
tensor(-11.1529, device='cuda:0') tensor(6.6415, device='cuda:0') tensor(1.9029e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.004071
Average KL loss: 0.166186
Average total loss: 0.170258
tensor(-11.1580, device='cuda:0') tensor(6.6422, device='cuda:0') tensor(2.4009e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.004027
Average KL loss: 0.166021
Average total loss: 0.170048
tensor(-11.1630, device='cuda:0') tensor(6.6428, device='cuda:0') tensor(4.1534e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.003969
Average KL loss: 0.165865
Average total loss: 0.169834
tensor(-11.1681, device='cuda:0') tensor(6.6432, device='cuda:0') tensor(1.0239e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.003991
Average KL loss: 0.165688
Average total loss: 0.169679
tensor(-11.1732, device='cuda:0') tensor(6.6433, device='cuda:0') tensor(3.1535e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.003778
Average KL loss: 0.165509
Average total loss: 0.169287
tensor(-11.1782, device='cuda:0') tensor(6.6427, device='cuda:0') tensor(3.4064e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.003991
Average KL loss: 0.165347
Average total loss: 0.169338
tensor(-11.1833, device='cuda:0') tensor(6.6428, device='cuda:0') tensor(3.0311e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.004099
Average KL loss: 0.165176
Average total loss: 0.169274
tensor(-11.1882, device='cuda:0') tensor(6.6444, device='cuda:0') tensor(1.5989e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.003978
Average KL loss: 0.165033
Average total loss: 0.169011
tensor(-11.1932, device='cuda:0') tensor(6.6449, device='cuda:0') tensor(7.8139e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.003795
Average KL loss: 0.164856
Average total loss: 0.168651
tensor(-11.1982, device='cuda:0') tensor(6.6447, device='cuda:0') tensor(6.7480e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.003735
Average KL loss: 0.164668
Average total loss: 0.168403
tensor(-11.2031, device='cuda:0') tensor(6.6440, device='cuda:0') tensor(2.9530e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.003740
Average KL loss: 0.164456
Average total loss: 0.168196
tensor(-11.2081, device='cuda:0') tensor(6.6430, device='cuda:0') tensor(1.9604e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.003765
Average KL loss: 0.164244
Average total loss: 0.168009
tensor(-11.2130, device='cuda:0') tensor(6.6414, device='cuda:0') tensor(2.6650e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.003602
Average KL loss: 0.164068
Average total loss: 0.167670
tensor(-11.2179, device='cuda:0') tensor(6.6407, device='cuda:0') tensor(2.4849e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.003768
Average KL loss: 0.163869
Average total loss: 0.167638
tensor(-11.2228, device='cuda:0') tensor(6.6390, device='cuda:0') tensor(1.0192e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.003673
Average KL loss: 0.163682
Average total loss: 0.167354
tensor(-11.2277, device='cuda:0') tensor(6.6388, device='cuda:0') tensor(2.6286e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.003837
Average KL loss: 0.163495
Average total loss: 0.167332
tensor(-11.2325, device='cuda:0') tensor(6.6387, device='cuda:0') tensor(3.2956e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.003951
Average KL loss: 0.163328
Average total loss: 0.167278
tensor(-11.2373, device='cuda:0') tensor(6.6386, device='cuda:0') tensor(2.1773e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.003577
Average KL loss: 0.163160
Average total loss: 0.166736
tensor(-11.2422, device='cuda:0') tensor(6.6368, device='cuda:0') tensor(6.5879e-11, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.003930
Average KL loss: 0.162959
Average total loss: 0.166889
tensor(-11.2470, device='cuda:0') tensor(6.6362, device='cuda:0') tensor(2.6488e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.003765
Average KL loss: 0.162788
Average total loss: 0.166554
tensor(-11.2518, device='cuda:0') tensor(6.6360, device='cuda:0') tensor(1.3102e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.003484
Average KL loss: 0.162586
Average total loss: 0.166070
tensor(-11.2566, device='cuda:0') tensor(6.6340, device='cuda:0') tensor(5.5543e-12, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.003778
Average KL loss: 0.162358
Average total loss: 0.166136
tensor(-11.2613, device='cuda:0') tensor(6.6327, device='cuda:0') tensor(1.3765e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.003633
Average KL loss: 0.162184
Average total loss: 0.165817
tensor(-11.2660, device='cuda:0') tensor(6.6324, device='cuda:0') tensor(3.1584e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.003635
Average KL loss: 0.162007
Average total loss: 0.165643
tensor(-11.2707, device='cuda:0') tensor(6.6320, device='cuda:0') tensor(1.9290e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.003630
Average KL loss: 0.161811
Average total loss: 0.165441
tensor(-11.2755, device='cuda:0') tensor(6.6306, device='cuda:0') tensor(2.0102e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.003677
Average KL loss: 0.161625
Average total loss: 0.165302
tensor(-11.2801, device='cuda:0') tensor(6.6304, device='cuda:0') tensor(2.0247e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.003523
Average KL loss: 0.161450
Average total loss: 0.164974
tensor(-11.2848, device='cuda:0') tensor(6.6292, device='cuda:0') tensor(9.0503e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.003514
Average KL loss: 0.161300
Average total loss: 0.164813
tensor(-11.2895, device='cuda:0') tensor(6.6285, device='cuda:0') tensor(1.8907e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.003654
Average KL loss: 0.161137
Average total loss: 0.164791
 Percentile value: -7.1581066131591795
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =    1284 /    1728             ( 74.31%) | total_pruned =     444 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   12161 /   36864             ( 32.99%) | total_pruned =   24703 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   12684 /   36864             ( 34.41%) | total_pruned =   24180 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   11646 /   36864             ( 31.59%) | total_pruned =   25218 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   11745 /   36864             ( 31.86%) | total_pruned =   25119 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   22116 /   73728             ( 30.00%) | total_pruned =   51612 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   38232 /  147456             ( 25.93%) | total_pruned =  109224 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4610 /    8192             ( 56.27%) | total_pruned =    3582 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   30397 /  147456             ( 20.61%) | total_pruned =  117059 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   30194 /  147456             ( 20.48%) | total_pruned =  117262 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   70209 /  294912             ( 23.81%) | total_pruned =  224703 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  117896 /  589824             ( 19.99%) | total_pruned =  471928 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   14160 /   32768             ( 43.21%) | total_pruned =   18608 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   72137 /  589824             ( 12.23%) | total_pruned =  517687 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     176 /     256             ( 68.75%) | total_pruned =      80 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   69578 /  589824             ( 11.80%) | total_pruned =  520246 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  174499 / 1179648             ( 14.79%) | total_pruned = 1005149 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     487 /     512             ( 95.12%) | total_pruned =      25 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  176195 / 2359296             (  7.47%) | total_pruned = 2183101 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     307 /     512             ( 59.96%) | total_pruned =     205 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   24861 /  131072             ( 18.97%) | total_pruned =  106211 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     439 /     512             ( 85.74%) | total_pruned =      73 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     300 /     512             ( 58.59%) | total_pruned =     212 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   61592 / 2359296             (  2.61%) | total_pruned = 2297704 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   38636 / 2359296             (  1.64%) | total_pruned = 2320660 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
linear.weight        | nonzeros =    3979 /    5120             ( 77.71%) | total_pruned =    1141 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 23/200 Loss: 0.000370 Accuracy: 86.39 100.00 % Best test Accuracy: 86.54%
tensor(-11.2941, device='cuda:0') tensor(6.6277, device='cuda:0') tensor(-7.1403e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.067903
Average KL loss: 0.160330
Average total loss: 0.228233
tensor(-11.3123, device='cuda:0') tensor(6.4130, device='cuda:0') tensor(-6.3439e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.050710
Average KL loss: 0.159919
Average total loss: 0.210629
tensor(-11.3238, device='cuda:0') tensor(6.3117, device='cuda:0') tensor(-4.1673e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.041379
Average KL loss: 0.159647
Average total loss: 0.201026
tensor(-11.3333, device='cuda:0') tensor(6.2426, device='cuda:0') tensor(-3.2138e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.033774
Average KL loss: 0.159380
Average total loss: 0.193154
tensor(-11.3418, device='cuda:0') tensor(6.1896, device='cuda:0') tensor(4.9955e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.029568
Average KL loss: 0.159097
Average total loss: 0.188665
tensor(-11.3496, device='cuda:0') tensor(6.1472, device='cuda:0') tensor(-4.3391e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.026354
Average KL loss: 0.158791
Average total loss: 0.185145
tensor(-11.3569, device='cuda:0') tensor(6.1121, device='cuda:0') tensor(-8.7288e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.024390
Average KL loss: 0.158509
Average total loss: 0.182898
tensor(-11.3637, device='cuda:0') tensor(6.0835, device='cuda:0') tensor(1.0103e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.022914
Average KL loss: 0.158239
Average total loss: 0.181153
tensor(-11.3704, device='cuda:0') tensor(6.0589, device='cuda:0') tensor(8.4755e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.020932
Average KL loss: 0.157957
Average total loss: 0.178889
tensor(-11.3767, device='cuda:0') tensor(6.0372, device='cuda:0') tensor(-7.1601e-11, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.021262
Average KL loss: 0.157687
Average total loss: 0.178949
tensor(-11.3829, device='cuda:0') tensor(6.0179, device='cuda:0') tensor(1.4223e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.019447
Average KL loss: 0.157448
Average total loss: 0.176895
tensor(-11.3889, device='cuda:0') tensor(6.0028, device='cuda:0') tensor(-4.6713e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.018760
Average KL loss: 0.157246
Average total loss: 0.176006
tensor(-11.3947, device='cuda:0') tensor(5.9886, device='cuda:0') tensor(4.0067e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.017248
Average KL loss: 0.157022
Average total loss: 0.174270
tensor(-11.4003, device='cuda:0') tensor(5.9763, device='cuda:0') tensor(-5.6233e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.016932
Average KL loss: 0.156807
Average total loss: 0.173739
tensor(-11.4059, device='cuda:0') tensor(5.9658, device='cuda:0') tensor(-7.6614e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.016400
Average KL loss: 0.156619
Average total loss: 0.173019
tensor(-11.4113, device='cuda:0') tensor(5.9561, device='cuda:0') tensor(3.4681e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.015608
Average KL loss: 0.156410
Average total loss: 0.172018
tensor(-11.4166, device='cuda:0') tensor(5.9481, device='cuda:0') tensor(-5.8633e-11, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.014945
Average KL loss: 0.156201
Average total loss: 0.171146
tensor(-11.4219, device='cuda:0') tensor(5.9415, device='cuda:0') tensor(9.5771e-13, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.014531
Average KL loss: 0.156052
Average total loss: 0.170583
tensor(-11.4270, device='cuda:0') tensor(5.9360, device='cuda:0') tensor(-1.0872e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.014466
Average KL loss: 0.155868
Average total loss: 0.170334
tensor(-11.4321, device='cuda:0') tensor(5.9302, device='cuda:0') tensor(4.0575e-11, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.013286
Average KL loss: 0.155696
Average total loss: 0.168982
tensor(-11.4370, device='cuda:0') tensor(5.9255, device='cuda:0') tensor(-7.9170e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.013924
Average KL loss: 0.155526
Average total loss: 0.169450
tensor(-11.4420, device='cuda:0') tensor(5.9205, device='cuda:0') tensor(-2.5298e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.012685
Average KL loss: 0.155365
Average total loss: 0.168051
tensor(-11.4469, device='cuda:0') tensor(5.9166, device='cuda:0') tensor(-2.1596e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.013071
Average KL loss: 0.155191
Average total loss: 0.168262
tensor(-11.4517, device='cuda:0') tensor(5.9125, device='cuda:0') tensor(7.3255e-12, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.012008
Average KL loss: 0.155017
Average total loss: 0.167025
tensor(-11.4565, device='cuda:0') tensor(5.9100, device='cuda:0') tensor(2.9035e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.012074
Average KL loss: 0.154890
Average total loss: 0.166964
tensor(-11.4612, device='cuda:0') tensor(5.9075, device='cuda:0') tensor(-4.2420e-11, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.012435
Average KL loss: 0.154754
Average total loss: 0.167190
tensor(-11.4659, device='cuda:0') tensor(5.9050, device='cuda:0') tensor(2.3406e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.012008
Average KL loss: 0.154593
Average total loss: 0.166601
tensor(-11.4705, device='cuda:0') tensor(5.9031, device='cuda:0') tensor(1.5071e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.011190
Average KL loss: 0.154431
Average total loss: 0.165621
tensor(-11.4751, device='cuda:0') tensor(5.9009, device='cuda:0') tensor(-1.1518e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.010886
Average KL loss: 0.154303
Average total loss: 0.165189
tensor(-11.4796, device='cuda:0') tensor(5.8987, device='cuda:0') tensor(1.9937e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.011318
Average KL loss: 0.154124
Average total loss: 0.165442
tensor(-11.4842, device='cuda:0') tensor(5.8965, device='cuda:0') tensor(1.0348e-11, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.010421
Average KL loss: 0.153969
Average total loss: 0.164389
tensor(-11.4886, device='cuda:0') tensor(5.8955, device='cuda:0') tensor(4.4133e-11, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.010390
Average KL loss: 0.153851
Average total loss: 0.164241
tensor(-11.4930, device='cuda:0') tensor(5.8944, device='cuda:0') tensor(1.4762e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.009574
Average KL loss: 0.153712
Average total loss: 0.163286
tensor(-11.4975, device='cuda:0') tensor(5.8920, device='cuda:0') tensor(-7.3472e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.009944
Average KL loss: 0.153550
Average total loss: 0.163495
tensor(-11.5018, device='cuda:0') tensor(5.8905, device='cuda:0') tensor(6.3510e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.010146
Average KL loss: 0.153393
Average total loss: 0.163539
tensor(-11.5062, device='cuda:0') tensor(5.8892, device='cuda:0') tensor(3.2944e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.009036
Average KL loss: 0.153256
Average total loss: 0.162292
tensor(-11.5105, device='cuda:0') tensor(5.8874, device='cuda:0') tensor(-3.2137e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.009485
Average KL loss: 0.153113
Average total loss: 0.162598
tensor(-11.5148, device='cuda:0') tensor(5.8863, device='cuda:0') tensor(2.3912e-11, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.009164
Average KL loss: 0.152937
Average total loss: 0.162101
tensor(-11.5190, device='cuda:0') tensor(5.8850, device='cuda:0') tensor(1.8506e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.008964
Average KL loss: 0.152778
Average total loss: 0.161742
tensor(-11.5232, device='cuda:0') tensor(5.8846, device='cuda:0') tensor(4.5528e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.008596
Average KL loss: 0.152659
Average total loss: 0.161255
tensor(-11.5274, device='cuda:0') tensor(5.8843, device='cuda:0') tensor(1.2055e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.008834
Average KL loss: 0.152520
Average total loss: 0.161354
tensor(-11.5315, device='cuda:0') tensor(5.8841, device='cuda:0') tensor(1.9178e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.008564
Average KL loss: 0.152391
Average total loss: 0.160955
tensor(-11.5356, device='cuda:0') tensor(5.8839, device='cuda:0') tensor(-6.3907e-11, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.008085
Average KL loss: 0.152243
Average total loss: 0.160327
tensor(-11.5397, device='cuda:0') tensor(5.8836, device='cuda:0') tensor(2.1711e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.008190
Average KL loss: 0.152111
Average total loss: 0.160301
tensor(-11.5438, device='cuda:0') tensor(5.8834, device='cuda:0') tensor(-2.3873e-11, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.007861
Average KL loss: 0.151987
Average total loss: 0.159848
tensor(-11.5478, device='cuda:0') tensor(5.8834, device='cuda:0') tensor(-6.2983e-12, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.007118
Average KL loss: 0.151853
Average total loss: 0.158971
tensor(-11.5519, device='cuda:0') tensor(5.8825, device='cuda:0') tensor(3.8150e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.007516
Average KL loss: 0.151714
Average total loss: 0.159230
tensor(-11.5559, device='cuda:0') tensor(5.8814, device='cuda:0') tensor(3.4765e-11, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.007823
Average KL loss: 0.151571
Average total loss: 0.159393
tensor(-11.5599, device='cuda:0') tensor(5.8808, device='cuda:0') tensor(-9.7525e-11, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.007260
Average KL loss: 0.151426
Average total loss: 0.158687
tensor(-11.5638, device='cuda:0') tensor(5.8806, device='cuda:0') tensor(-1.1692e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.007463
Average KL loss: 0.151283
Average total loss: 0.158746
tensor(-11.5677, device='cuda:0') tensor(5.8801, device='cuda:0') tensor(-4.9333e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.007240
Average KL loss: 0.151162
Average total loss: 0.158402
tensor(-11.5716, device='cuda:0') tensor(5.8806, device='cuda:0') tensor(1.1708e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.006751
Average KL loss: 0.151021
Average total loss: 0.157772
tensor(-11.5755, device='cuda:0') tensor(5.8803, device='cuda:0') tensor(-1.0068e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.006521
Average KL loss: 0.150894
Average total loss: 0.157415
tensor(-11.5793, device='cuda:0') tensor(5.8808, device='cuda:0') tensor(3.9714e-11, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.006852
Average KL loss: 0.150741
Average total loss: 0.157593
tensor(-11.5832, device='cuda:0') tensor(5.8808, device='cuda:0') tensor(6.2274e-11, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.006538
Average KL loss: 0.150586
Average total loss: 0.157124
tensor(-11.5870, device='cuda:0') tensor(5.8803, device='cuda:0') tensor(2.0354e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.006648
Average KL loss: 0.150452
Average total loss: 0.157100
tensor(-11.5908, device='cuda:0') tensor(5.8808, device='cuda:0') tensor(4.4748e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.006437
Average KL loss: 0.150322
Average total loss: 0.156759
tensor(-11.5946, device='cuda:0') tensor(5.8807, device='cuda:0') tensor(1.6159e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.006365
Average KL loss: 0.150193
Average total loss: 0.156558
tensor(-11.5984, device='cuda:0') tensor(5.8810, device='cuda:0') tensor(-1.0039e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.006274
Average KL loss: 0.150060
Average total loss: 0.156334
tensor(-11.6021, device='cuda:0') tensor(5.8812, device='cuda:0') tensor(-9.6517e-11, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.006386
Average KL loss: 0.149939
Average total loss: 0.156324
tensor(-11.6059, device='cuda:0') tensor(5.8812, device='cuda:0') tensor(8.9087e-11, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.006457
Average KL loss: 0.149813
Average total loss: 0.156269
tensor(-11.6096, device='cuda:0') tensor(5.8812, device='cuda:0') tensor(-6.9544e-11, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.006459
Average KL loss: 0.149693
Average total loss: 0.156152
tensor(-11.6132, device='cuda:0') tensor(5.8824, device='cuda:0') tensor(1.0726e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.006274
Average KL loss: 0.149553
Average total loss: 0.155827
tensor(-11.6170, device='cuda:0') tensor(5.8823, device='cuda:0') tensor(1.5389e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.006182
Average KL loss: 0.149417
Average total loss: 0.155599
tensor(-11.6206, device='cuda:0') tensor(5.8829, device='cuda:0') tensor(8.5584e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.006148
Average KL loss: 0.149296
Average total loss: 0.155444
tensor(-11.6242, device='cuda:0') tensor(5.8838, device='cuda:0') tensor(-1.6975e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.005637
Average KL loss: 0.149166
Average total loss: 0.154803
tensor(-11.6279, device='cuda:0') tensor(5.8830, device='cuda:0') tensor(1.8808e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.005694
Average KL loss: 0.148997
Average total loss: 0.154691
tensor(-11.6316, device='cuda:0') tensor(5.8814, device='cuda:0') tensor(2.8543e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.005781
Average KL loss: 0.148853
Average total loss: 0.154634
tensor(-11.6352, device='cuda:0') tensor(5.8822, device='cuda:0') tensor(1.9118e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.005997
Average KL loss: 0.148733
Average total loss: 0.154730
tensor(-11.6387, device='cuda:0') tensor(5.8824, device='cuda:0') tensor(2.3567e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.005371
Average KL loss: 0.148610
Average total loss: 0.153982
tensor(-11.6423, device='cuda:0') tensor(5.8818, device='cuda:0') tensor(6.0558e-12, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.005572
Average KL loss: 0.148456
Average total loss: 0.154028
tensor(-11.6459, device='cuda:0') tensor(5.8822, device='cuda:0') tensor(5.8702e-11, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.005510
Average KL loss: 0.148318
Average total loss: 0.153828
tensor(-11.6494, device='cuda:0') tensor(5.8825, device='cuda:0') tensor(-5.6941e-11, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.005187
Average KL loss: 0.148167
Average total loss: 0.153355
tensor(-11.6529, device='cuda:0') tensor(5.8823, device='cuda:0') tensor(8.8161e-11, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.005690
Average KL loss: 0.148009
Average total loss: 0.153699
tensor(-11.6564, device='cuda:0') tensor(5.8828, device='cuda:0') tensor(2.6134e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.005474
Average KL loss: 0.147873
Average total loss: 0.153347
tensor(-11.6600, device='cuda:0') tensor(5.8819, device='cuda:0') tensor(8.7035e-11, device='cuda:0')
Epoch 76
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 77
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 78
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 79
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 80
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 81
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 82
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 83
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 84
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 85
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 86
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 87
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 88
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 89
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 90
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 91
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 92
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 93
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 94
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 95
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 96
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 97
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 98
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 99
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 100
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 101
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 102
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 103
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 104
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 105
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 106
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 107
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 108
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 109
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 110
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 111
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 112
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 113
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 114
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 115
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 116
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 117
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 118
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 119
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 120
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 121
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 122
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 123
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 124
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 125
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 126
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 127
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  170199 / 2359296             (  7.21%) | total_pruned = 2189097 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     307 /     512             ( 59.96%) | total_pruned =     205 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   24861 /  131072             ( 18.97%) | total_pruned =  106211 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     439 /     512             ( 85.74%) | total_pruned =      73 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     300 /     512             ( 58.59%) | total_pruned =     212 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   61592 / 2359296             (  2.61%) | total_pruned = 2297704 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   38636 / 2359296             (  1.64%) | total_pruned = 2320660 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
linear.weight        | nonzeros =    3979 /    5120             ( 77.71%) | total_pruned =    1141 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 34/200 Loss: 2.302588 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   46909 / 2359296             (  1.99%) | total_pruned = 2312387 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   38636 / 2359296             (  1.64%) | total_pruned = 2320660 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
linear.weight        | nonzeros =    3979 /    5120             ( 77.71%) | total_pruned =    1141 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 34/200 Loss: 2.302669 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   22475 / 2359296             (  0.95%) | total_pruned = 2336821 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
linear.weight        | nonzeros =    3979 /    5120             ( 77.71%) | total_pruned =    1141 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 34/200 Loss: 2.302621 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    3460 / 2359296             (  0.15%) | total_pruned = 2355836 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
linear.weight        | nonzeros =    3979 /    5120             ( 77.71%) | total_pruned =    1141 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 34/200 Loss: 2.302584 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
