Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1414e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.863382
Average KL loss: 0.248168
Average total loss: 2.111550
tensor(0.0001, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-9.4857e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.662708
Average KL loss: 0.335364
Average total loss: 1.998072
tensor(0.0001, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-1.4474e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.479582
Average KL loss: 0.326158
Average total loss: 1.805740
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-1.3861e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.370945
Average KL loss: 0.318334
Average total loss: 1.689278
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-8.9818e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.288931
Average KL loss: 0.311180
Average total loss: 1.600111
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-7.1547e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.226898
Average KL loss: 0.302768
Average total loss: 1.529666
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-6.5667e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.166820
Average KL loss: 0.304817
Average total loss: 1.471637
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-8.4537e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.117207
Average KL loss: 0.318679
Average total loss: 1.435886
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-7.9097e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.051817
Average KL loss: 0.312995
Average total loss: 1.364812
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-6.5091e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.025258
Average KL loss: 0.313763
Average total loss: 1.339020
tensor(0.0003, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-5.0152e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.001526
Average KL loss: 0.319036
Average total loss: 1.320561
tensor(0.0003, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-4.7458e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.961735
Average KL loss: 0.328446
Average total loss: 1.290181
tensor(0.0003, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-5.9220e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.930334
Average KL loss: 0.336973
Average total loss: 1.267307
tensor(0.0003, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-5.1898e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.910860
Average KL loss: 0.336544
Average total loss: 1.247404
tensor(0.0003, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-4.6197e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.890872
Average KL loss: 0.345567
Average total loss: 1.236440
tensor(0.0003, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-1.8142e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.853588
Average KL loss: 0.346746
Average total loss: 1.200334
tensor(0.0003, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-1.5623e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.825035
Average KL loss: 0.346078
Average total loss: 1.171113
tensor(0.0003, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-3.3395e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.836090
Average KL loss: 0.357573
Average total loss: 1.193662
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-5.8818e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.814994
Average KL loss: 0.365625
Average total loss: 1.180619
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-2.9539e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.792990
Average KL loss: 0.370938
Average total loss: 1.163928
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.1617e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.786346
Average KL loss: 0.374685
Average total loss: 1.161031
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-4.3522e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.771281
Average KL loss: 0.378353
Average total loss: 1.149633
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-4.5367e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.752924
Average KL loss: 0.381351
Average total loss: 1.134275
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.1164e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.751200
Average KL loss: 0.387576
Average total loss: 1.138776
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-2.3381e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.746299
Average KL loss: 0.390096
Average total loss: 1.136396
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(4.1635e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.719636
Average KL loss: 0.389810
Average total loss: 1.109445
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.1088e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.723444
Average KL loss: 0.398052
Average total loss: 1.121495
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(1.3782e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.716578
Average KL loss: 0.400694
Average total loss: 1.117272
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-2.7500e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.711071
Average KL loss: 0.403510
Average total loss: 1.114580
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-6.1931e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.697622
Average KL loss: 0.404487
Average total loss: 1.102109
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.4711e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.700976
Average KL loss: 0.405538
Average total loss: 1.106514
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.3598e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.691481
Average KL loss: 0.415634
Average total loss: 1.107115
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-2.4075e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.680919
Average KL loss: 0.413267
Average total loss: 1.094186
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.1577e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.675888
Average KL loss: 0.417779
Average total loss: 1.093668
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-8.8129e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.679954
Average KL loss: 0.417758
Average total loss: 1.097712
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(5.0160e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.669930
Average KL loss: 0.425233
Average total loss: 1.095163
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.3636e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.679164
Average KL loss: 0.427968
Average total loss: 1.107132
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.8860e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.669859
Average KL loss: 0.429992
Average total loss: 1.099851
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(2.3645e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.672882
Average KL loss: 0.432898
Average total loss: 1.105780
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.2574e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.661496
Average KL loss: 0.428632
Average total loss: 1.090128
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(3.9705e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.651848
Average KL loss: 0.430670
Average total loss: 1.082519
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-6.8486e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.639606
Average KL loss: 0.430902
Average total loss: 1.070508
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-2.5094e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.637779
Average KL loss: 0.435831
Average total loss: 1.073610
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-2.7369e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.665563
Average KL loss: 0.443505
Average total loss: 1.109068
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(2.8621e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.642692
Average KL loss: 0.444468
Average total loss: 1.087160
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-6.6493e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.639092
Average KL loss: 0.440045
Average total loss: 1.079137
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.4107e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.653800
Average KL loss: 0.444333
Average total loss: 1.098133
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.4828e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.639104
Average KL loss: 0.446691
Average total loss: 1.085795
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(7.2617e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.627961
Average KL loss: 0.448723
Average total loss: 1.076685
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-4.1284e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.626927
Average KL loss: 0.450212
Average total loss: 1.077139
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-9.3667e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.632340
Average KL loss: 0.451054
Average total loss: 1.083394
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.0852e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.621064
Average KL loss: 0.450924
Average total loss: 1.071988
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-9.3912e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.621190
Average KL loss: 0.449977
Average total loss: 1.071168
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.1166e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.627660
Average KL loss: 0.411102
Average total loss: 1.038762
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(5.9032e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.615233
Average KL loss: 0.372416
Average total loss: 0.987649
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-4.3991e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.617015
Average KL loss: 0.361749
Average total loss: 0.978763
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.2767e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.628017
Average KL loss: 0.356978
Average total loss: 0.984994
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-3.4992e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.623992
Average KL loss: 0.354533
Average total loss: 0.978525
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-5.5011e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.622344
Average KL loss: 0.352894
Average total loss: 0.975238
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(4.8445e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.625048
Average KL loss: 0.351449
Average total loss: 0.976497
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(1.3663e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.613856
Average KL loss: 0.350168
Average total loss: 0.964024
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.2398e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.617636
Average KL loss: 0.348906
Average total loss: 0.966542
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.1304e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.624949
Average KL loss: 0.348998
Average total loss: 0.973947
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(4.7985e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.621646
Average KL loss: 0.347872
Average total loss: 0.969517
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(3.5803e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.615219
Average KL loss: 0.347226
Average total loss: 0.962445
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-6.0581e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.638967
Average KL loss: 0.346891
Average total loss: 0.985858
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(1.2263e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.600517
Average KL loss: 0.346272
Average total loss: 0.946789
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.4983e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.625937
Average KL loss: 0.345896
Average total loss: 0.971833
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(7.5223e-11, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.619749
Average KL loss: 0.345301
Average total loss: 0.965050
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(6.6359e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.614302
Average KL loss: 0.344931
Average total loss: 0.959232
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(3.4558e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.626469
Average KL loss: 0.345095
Average total loss: 0.971565
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-2.3774e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.616876
Average KL loss: 0.344786
Average total loss: 0.961662
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(1.1157e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.621840
Average KL loss: 0.344697
Average total loss: 0.966537
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.5997e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.621486
Average KL loss: 0.344285
Average total loss: 0.965772
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(6.6774e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.614115
Average KL loss: 0.344165
Average total loss: 0.958280
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-8.3304e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.626833
Average KL loss: 0.344061
Average total loss: 0.970895
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-2.4446e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.617223
Average KL loss: 0.344084
Average total loss: 0.961307
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(4.2949e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.626546
Average KL loss: 0.343586
Average total loss: 0.970132
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(2.0330e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.617800
Average KL loss: 0.342683
Average total loss: 0.960483
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(2.8579e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.603676
Average KL loss: 0.340602
Average total loss: 0.944279
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.8404e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.616652
Average KL loss: 0.339286
Average total loss: 0.955937
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(5.4857e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.609232
Average KL loss: 0.338358
Average total loss: 0.947590
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(1.1645e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.620699
Average KL loss: 0.337655
Average total loss: 0.958354
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-9.8938e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.615256
Average KL loss: 0.337107
Average total loss: 0.952363
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-2.8985e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.609108
Average KL loss: 0.336660
Average total loss: 0.945768
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(3.6913e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.613237
Average KL loss: 0.336269
Average total loss: 0.949505
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-8.8906e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.623798
Average KL loss: 0.335960
Average total loss: 0.959758
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.1449e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.604968
Average KL loss: 0.335682
Average total loss: 0.940649
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-6.8605e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.611453
Average KL loss: 0.335412
Average total loss: 0.946865
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(7.3926e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.624577
Average KL loss: 0.335229
Average total loss: 0.959806
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-9.8442e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.607899
Average KL loss: 0.335030
Average total loss: 0.942929
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(1.3590e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.621020
Average KL loss: 0.334826
Average total loss: 0.955846
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(2.2730e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.620361
Average KL loss: 0.334679
Average total loss: 0.955040
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.2207e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.608698
Average KL loss: 0.334536
Average total loss: 0.943234
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(1.0875e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.623467
Average KL loss: 0.334399
Average total loss: 0.957866
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-5.5513e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.610238
Average KL loss: 0.334252
Average total loss: 0.944490
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(5.5454e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.607451
Average KL loss: 0.334127
Average total loss: 0.941578
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.2834e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.622440
Average KL loss: 0.333971
Average total loss: 0.956411
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.6547e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.615534
Average KL loss: 0.333868
Average total loss: 0.949402
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.4722e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.625997
Average KL loss: 0.333797
Average total loss: 0.959795
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(3.5858e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.619438
Average KL loss: 0.333746
Average total loss: 0.953184
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-6.0719e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.624871
Average KL loss: 0.333706
Average total loss: 0.958576
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(9.9476e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.618617
Average KL loss: 0.333671
Average total loss: 0.952288
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.6593e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.612928
Average KL loss: 0.333637
Average total loss: 0.946565
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.5407e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.617521
Average KL loss: 0.333600
Average total loss: 0.951121
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(1.8141e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.594095
Average KL loss: 0.333566
Average total loss: 0.927661
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-2.1790e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.611333
Average KL loss: 0.333532
Average total loss: 0.944866
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(8.4215e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.623383
Average KL loss: 0.333505
Average total loss: 0.956888
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(1.9561e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.619517
Average KL loss: 0.333479
Average total loss: 0.952996
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-4.4085e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.627615
Average KL loss: 0.333454
Average total loss: 0.961069
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(3.2582e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.623506
Average KL loss: 0.333430
Average total loss: 0.956936
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-9.3706e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.615979
Average KL loss: 0.333410
Average total loss: 0.949389
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-8.4268e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.611749
Average KL loss: 0.333388
Average total loss: 0.945137
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.4531e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.615482
Average KL loss: 0.333363
Average total loss: 0.948845
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.1498e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.621728
Average KL loss: 0.333342
Average total loss: 0.955070
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-7.4336e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.624217
Average KL loss: 0.333322
Average total loss: 0.957540
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(4.3304e-10, device='cuda:0')
 Percentile value: 0.0012807406252250066
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1246 /    1728             ( 72.11%) | total_pruned =     482 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   18753 /   36864             ( 50.87%) | total_pruned =   18111 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   18869 /   36864             ( 51.19%) | total_pruned =   17995 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   18493 /   36864             ( 50.17%) | total_pruned =   18371 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18232 /   36864             ( 49.46%) | total_pruned =   18632 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   36596 /   73728             ( 49.64%) | total_pruned =   37132 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   72058 /  147456             ( 48.87%) | total_pruned =   75398 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4851 /    8192             ( 59.22%) | total_pruned =    3341 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   67846 /  147456             ( 46.01%) | total_pruned =   79610 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   68074 /  147456             ( 46.17%) | total_pruned =   79382 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  140554 /  294912             ( 47.66%) | total_pruned =  154358 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  272207 /  589824             ( 46.15%) | total_pruned =  317617 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     132 /     256             ( 51.56%) | total_pruned =     124 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18115 /   32768             ( 55.28%) | total_pruned =   14653 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     133 /     256             ( 51.95%) | total_pruned =     123 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  224128 /  589824             ( 38.00%) | total_pruned =  365696 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     194 /     256             ( 75.78%) | total_pruned =      62 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     182 /     256             ( 71.09%) | total_pruned =      74 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  224430 /  589824             ( 38.05%) | total_pruned =  365394 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  497200 / 1179648             ( 42.15%) | total_pruned =  682448 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     308 /     512             ( 60.16%) | total_pruned =     204 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  764024 / 2359296             ( 32.38%) | total_pruned = 1595272 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     447 /     512             ( 87.30%) | total_pruned =      65 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     389 /     512             ( 75.98%) | total_pruned =     123 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   62945 /  131072             ( 48.02%) | total_pruned =   68127 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     430 /     512             ( 83.98%) | total_pruned =      82 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     370 /     512             ( 72.27%) | total_pruned =     142 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  505868 / 2359296             ( 21.44%) | total_pruned = 1853428 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     401 /     512             ( 78.32%) | total_pruned =     111 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     352 /     512             ( 68.75%) | total_pruned =     160 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  308272 / 2359296             ( 13.07%) | total_pruned = 2051024 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     281 /     512             ( 54.88%) | total_pruned =     231 | shape = torch.Size([512])
linear.weight        | nonzeros =    3564 /    5120             ( 69.61%) | total_pruned =    1556 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       5 /      10             ( 50.00%) | total_pruned =       5 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 50/200 Loss: 0.000104 Accuracy: 86.60 100.00 % Best test Accuracy: 86.64%
tensor(0.0004, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-3.8347e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.967853
Average KL loss: 0.428187
Average total loss: 1.396040
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-7.3906e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.925157
Average KL loss: 0.466636
Average total loss: 1.391793
tensor(0.0004, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-8.2330e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.893295
Average KL loss: 0.476489
Average total loss: 1.369784
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.0287e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.881483
Average KL loss: 0.482050
Average total loss: 1.363533
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.3100e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.887066
Average KL loss: 0.486429
Average total loss: 1.373495
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.8435e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.849872
Average KL loss: 0.489845
Average total loss: 1.339718
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(4.7250e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.837460
Average KL loss: 0.489370
Average total loss: 1.326830
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-9.9464e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.840929
Average KL loss: 0.498589
Average total loss: 1.339518
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.1153e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.827595
Average KL loss: 0.503000
Average total loss: 1.330596
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.9195e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.831229
Average KL loss: 0.501736
Average total loss: 1.332965
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.4554e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.821388
Average KL loss: 0.501987
Average total loss: 1.323376
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(4.1078e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.805432
Average KL loss: 0.504786
Average total loss: 1.310218
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-3.9085e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.797017
Average KL loss: 0.501310
Average total loss: 1.298328
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-7.1578e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.826003
Average KL loss: 0.511033
Average total loss: 1.337036
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-4.3710e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.811563
Average KL loss: 0.514016
Average total loss: 1.325579
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.3953e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.776927
Average KL loss: 0.509145
Average total loss: 1.286071
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(4.8876e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.798644
Average KL loss: 0.510518
Average total loss: 1.309163
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(3.2040e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.802307
Average KL loss: 0.511070
Average total loss: 1.313377
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-9.3795e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.782381
Average KL loss: 0.513562
Average total loss: 1.295943
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.9661e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.772899
Average KL loss: 0.510443
Average total loss: 1.283342
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.4922e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.801639
Average KL loss: 0.516298
Average total loss: 1.317937
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(9.6770e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.782378
Average KL loss: 0.517636
Average total loss: 1.300014
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.3811e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.801592
Average KL loss: 0.517556
Average total loss: 1.319148
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(5.3493e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.792805
Average KL loss: 0.522455
Average total loss: 1.315261
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.0496e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.788413
Average KL loss: 0.519723
Average total loss: 1.308136
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.4227e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.787396
Average KL loss: 0.517571
Average total loss: 1.304967
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.4784e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.790059
Average KL loss: 0.523150
Average total loss: 1.313209
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.9108e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.781761
Average KL loss: 0.526573
Average total loss: 1.308335
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.0896e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.782518
Average KL loss: 0.521573
Average total loss: 1.304091
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-7.1596e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.793479
Average KL loss: 0.525864
Average total loss: 1.319343
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.0278e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.783913
Average KL loss: 0.526518
Average total loss: 1.310432
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.7547e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.764570
Average KL loss: 0.501101
Average total loss: 1.265671
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(2.1288e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.778717
Average KL loss: 0.459313
Average total loss: 1.238029
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-4.1295e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.772518
Average KL loss: 0.442527
Average total loss: 1.215045
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-9.4056e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.764357
Average KL loss: 0.433194
Average total loss: 1.197551
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.2241e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.780867
Average KL loss: 0.427563
Average total loss: 1.208430
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.0513e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.782522
Average KL loss: 0.423943
Average total loss: 1.206465
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.0274e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.790407
Average KL loss: 0.421796
Average total loss: 1.212203
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-9.8045e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.754716
Average KL loss: 0.419499
Average total loss: 1.174215
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.2758e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.772258
Average KL loss: 0.417244
Average total loss: 1.189502
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(6.8564e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.767501
Average KL loss: 0.415970
Average total loss: 1.183471
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.3865e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.784525
Average KL loss: 0.415087
Average total loss: 1.199612
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(9.9315e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.784903
Average KL loss: 0.414511
Average total loss: 1.199413
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(2.0958e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.782395
Average KL loss: 0.414103
Average total loss: 1.196498
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.2605e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.773359
Average KL loss: 0.413753
Average total loss: 1.187111
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.7137e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.787409
Average KL loss: 0.412653
Average total loss: 1.200062
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.1078e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.782896
Average KL loss: 0.412241
Average total loss: 1.195137
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.0611e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.778945
Average KL loss: 0.412018
Average total loss: 1.190962
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(2.7431e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.760928
Average KL loss: 0.410908
Average total loss: 1.171836
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-3.7605e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.793511
Average KL loss: 0.410176
Average total loss: 1.203687
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.4570e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.786494
Average KL loss: 0.410842
Average total loss: 1.197336
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.0603e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.778584
Average KL loss: 0.410174
Average total loss: 1.188758
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.1246e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.772628
Average KL loss: 0.409563
Average total loss: 1.182191
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-3.0764e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.792706
Average KL loss: 0.409667
Average total loss: 1.202373
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.3752e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.765564
Average KL loss: 0.409605
Average total loss: 1.175170
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.4836e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.784782
Average KL loss: 0.409048
Average total loss: 1.193830
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.3078e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.779084
Average KL loss: 0.408694
Average total loss: 1.187778
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.9729e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.768520
Average KL loss: 0.408695
Average total loss: 1.177215
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(8.5327e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.779121
Average KL loss: 0.408286
Average total loss: 1.187408
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(8.4440e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.773517
Average KL loss: 0.407931
Average total loss: 1.181448
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(2.2353e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.790594
Average KL loss: 0.407229
Average total loss: 1.197823
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.2139e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.767064
Average KL loss: 0.406205
Average total loss: 1.173269
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.4626e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.764907
Average KL loss: 0.405274
Average total loss: 1.170181
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.4292e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.766292
Average KL loss: 0.404511
Average total loss: 1.170803
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-4.1590e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.758201
Average KL loss: 0.403836
Average total loss: 1.162037
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.7988e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.779970
Average KL loss: 0.403237
Average total loss: 1.183207
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(2.5269e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.765423
Average KL loss: 0.402752
Average total loss: 1.168174
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-6.0806e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.772059
Average KL loss: 0.402323
Average total loss: 1.174382
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.9260e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.783369
Average KL loss: 0.401939
Average total loss: 1.185308
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(3.0884e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.769230
Average KL loss: 0.401575
Average total loss: 1.170805
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(8.2279e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.775419
Average KL loss: 0.401251
Average total loss: 1.176670
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.8278e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.769137
Average KL loss: 0.400946
Average total loss: 1.170082
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-9.9748e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.763697
Average KL loss: 0.400658
Average total loss: 1.164355
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.4520e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.787572
Average KL loss: 0.400400
Average total loss: 1.187972
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(3.4562e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.794122
Average KL loss: 0.400183
Average total loss: 1.194305
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(9.1842e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.769031
Average KL loss: 0.399960
Average total loss: 1.168991
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.7157e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.783365
Average KL loss: 0.399817
Average total loss: 1.183182
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(6.7710e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.763594
Average KL loss: 0.399780
Average total loss: 1.163374
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-9.7779e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.783369
Average KL loss: 0.399744
Average total loss: 1.183113
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.2694e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.768177
Average KL loss: 0.399712
Average total loss: 1.167889
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(1.6635e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.770915
Average KL loss: 0.399681
Average total loss: 1.170595
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.7332e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.780780
Average KL loss: 0.399648
Average total loss: 1.180428
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.1883e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.792183
Average KL loss: 0.399619
Average total loss: 1.191801
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.0880e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.781470
Average KL loss: 0.399592
Average total loss: 1.181062
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(9.4739e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.767519
Average KL loss: 0.399559
Average total loss: 1.167078
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.0699e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.766275
Average KL loss: 0.399525
Average total loss: 1.165800
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.1149e-09, device='cuda:0')
 Percentile value: 0.005962699372321367
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =     965 /    1728             ( 55.84%) | total_pruned =     763 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    8945 /   36864             ( 24.26%) | total_pruned =   27919 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    9399 /   36864             ( 25.50%) | total_pruned =   27465 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    9075 /   36864             ( 24.62%) | total_pruned =   27789 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    8845 /   36864             ( 23.99%) | total_pruned =   28019 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   16821 /   73728             ( 22.81%) | total_pruned =   56907 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   31713 /  147456             ( 21.51%) | total_pruned =  115743 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2876 /    8192             ( 35.11%) | total_pruned =    5316 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   25081 /  147456             ( 17.01%) | total_pruned =  122375 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   25406 /  147456             ( 17.23%) | total_pruned =  122050 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   60474 /  294912             ( 20.51%) | total_pruned =  234438 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      89 /     256             ( 34.77%) | total_pruned =     167 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  111534 /  589824             ( 18.91%) | total_pruned =  478290 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    9363 /   32768             ( 28.57%) | total_pruned =   23405 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   59160 /  589824             ( 10.03%) | total_pruned =  530664 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     161 /     256             ( 62.89%) | total_pruned =      95 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      68 /     256             ( 26.56%) | total_pruned =     188 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   58532 /  589824             (  9.92%) | total_pruned =  531292 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      52 /     256             ( 20.31%) | total_pruned =     204 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  176584 / 1179648             ( 14.97%) | total_pruned = 1003064 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     467 /     512             ( 91.21%) | total_pruned =      45 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     165 /     512             ( 32.23%) | total_pruned =     347 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  200273 / 2359296             (  8.49%) | total_pruned = 2159023 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     407 /     512             ( 79.49%) | total_pruned =     105 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     288 /     512             ( 56.25%) | total_pruned =     224 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   23598 /  131072             ( 18.00%) | total_pruned =  107474 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     334 /     512             ( 65.23%) | total_pruned =     178 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     288 /     512             ( 56.25%) | total_pruned =     224 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  101852 / 2359296             (  4.32%) | total_pruned = 2257444 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     365 /     512             ( 71.29%) | total_pruned =     147 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     166 /     512             ( 32.42%) | total_pruned =     346 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   57443 / 2359296             (  2.43%) | total_pruned = 2301853 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     438 /     512             ( 85.55%) | total_pruned =      74 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     178 /     512             ( 34.77%) | total_pruned =     334 | shape = torch.Size([512])
linear.weight        | nonzeros =    2351 /    5120             ( 45.92%) | total_pruned =    2769 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 47/200 Loss: 0.000080 Accuracy: 86.59 100.00 % Best test Accuracy: 86.59%
tensor(0.0005, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.0591e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.451230
Average KL loss: 0.464213
Average total loss: 1.915443
tensor(0.0003, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-8.0653e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.339597
Average KL loss: 0.531738
Average total loss: 1.871335
tensor(0.0006, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.0353e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.317739
Average KL loss: 0.556356
Average total loss: 1.874095
tensor(0.0006, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.3460e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.290751
Average KL loss: 0.567025
Average total loss: 1.857776
tensor(0.0006, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.8981e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.236240
Average KL loss: 0.573183
Average total loss: 1.809423
tensor(0.0006, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-3.9901e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.270415
Average KL loss: 0.578297
Average total loss: 1.848712
tensor(0.0006, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.2676e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.228387
Average KL loss: 0.580279
Average total loss: 1.808665
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.9339e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.242976
Average KL loss: 0.582024
Average total loss: 1.825000
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.3950e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.221657
Average KL loss: 0.582357
Average total loss: 1.804014
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.5594e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.219504
Average KL loss: 0.591412
Average total loss: 1.810916
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-3.1016e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.213968
Average KL loss: 0.590935
Average total loss: 1.804904
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.1570e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.175200
Average KL loss: 0.591599
Average total loss: 1.766799
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(3.7456e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.197685
Average KL loss: 0.595685
Average total loss: 1.793369
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-6.9175e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.170502
Average KL loss: 0.593347
Average total loss: 1.763849
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-8.8521e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.189300
Average KL loss: 0.595106
Average total loss: 1.784405
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.1760e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.167956
Average KL loss: 0.600657
Average total loss: 1.768612
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-3.6311e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.192288
Average KL loss: 0.600719
Average total loss: 1.793007
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-6.2563e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.167563
Average KL loss: 0.604088
Average total loss: 1.771651
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-4.1245e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.163789
Average KL loss: 0.601022
Average total loss: 1.764811
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-3.3202e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.167157
Average KL loss: 0.604242
Average total loss: 1.771398
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-4.5009e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.173982
Average KL loss: 0.605737
Average total loss: 1.779718
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(8.7136e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.171120
Average KL loss: 0.610083
Average total loss: 1.781203
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(8.6867e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.154521
Average KL loss: 0.610367
Average total loss: 1.764888
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.1285e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.151419
Average KL loss: 0.606574
Average total loss: 1.757994
tensor(0.0007, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.9970e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.162527
Average KL loss: 0.611403
Average total loss: 1.773929
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.1402e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.154033
Average KL loss: 0.610757
Average total loss: 1.764789
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(8.0870e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.169743
Average KL loss: 0.610699
Average total loss: 1.780442
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.7827e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.159033
Average KL loss: 0.615542
Average total loss: 1.774576
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.2555e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.171457
Average KL loss: 0.618330
Average total loss: 1.789787
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(3.6602e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.151940
Average KL loss: 0.627961
Average total loss: 1.779902
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.3519e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.114358
Average KL loss: 0.613169
Average total loss: 1.727528
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.5228e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.132857
Average KL loss: 0.612032
Average total loss: 1.744889
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.9898e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.164976
Average KL loss: 0.618126
Average total loss: 1.783102
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-4.2316e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.133127
Average KL loss: 0.623942
Average total loss: 1.757070
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.0272e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.152046
Average KL loss: 0.617610
Average total loss: 1.769656
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-5.6039e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.149430
Average KL loss: 0.623724
Average total loss: 1.773154
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(4.8455e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.137232
Average KL loss: 0.623664
Average total loss: 1.760896
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.3093e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.122933
Average KL loss: 0.617169
Average total loss: 1.740103
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-3.8506e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.114770
Average KL loss: 0.617564
Average total loss: 1.732334
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.5785e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.143493
Average KL loss: 0.618527
Average total loss: 1.762021
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(3.8877e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.163026
Average KL loss: 0.621951
Average total loss: 1.784977
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.8840e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.157801
Average KL loss: 0.629530
Average total loss: 1.787331
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(3.0421e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.145930
Average KL loss: 0.616403
Average total loss: 1.762333
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.1613e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.122807
Average KL loss: 0.590984
Average total loss: 1.713791
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.4402e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.115417
Average KL loss: 0.574728
Average total loss: 1.690145
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.0261e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.129176
Average KL loss: 0.563233
Average total loss: 1.692410
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-4.4232e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.104576
Average KL loss: 0.554742
Average total loss: 1.659318
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-8.9033e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.141674
Average KL loss: 0.548478
Average total loss: 1.690152
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-7.6509e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.133806
Average KL loss: 0.543406
Average total loss: 1.677213
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(7.4023e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.082084
Average KL loss: 0.539262
Average total loss: 1.621346
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.7177e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.126325
Average KL loss: 0.536118
Average total loss: 1.662443
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-3.6219e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.153402
Average KL loss: 0.533603
Average total loss: 1.687005
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.5526e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.095240
Average KL loss: 0.531462
Average total loss: 1.626701
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.8376e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.123069
Average KL loss: 0.529647
Average total loss: 1.652716
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-9.7258e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.160656
Average KL loss: 0.528166
Average total loss: 1.688823
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.5180e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.131941
Average KL loss: 0.526992
Average total loss: 1.658933
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-4.9324e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.151174
Average KL loss: 0.526169
Average total loss: 1.677343
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(4.6074e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.122242
Average KL loss: 0.525118
Average total loss: 1.647360
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.7831e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.128828
Average KL loss: 0.523701
Average total loss: 1.652529
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.6454e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.113724
Average KL loss: 0.522995
Average total loss: 1.636719
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-4.0117e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.138093
Average KL loss: 0.522003
Average total loss: 1.660095
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(4.0637e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.147842
Average KL loss: 0.521587
Average total loss: 1.669429
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.0537e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.153135
Average KL loss: 0.521102
Average total loss: 1.674237
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(3.9227e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.143131
Average KL loss: 0.520681
Average total loss: 1.663812
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.6380e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.141699
Average KL loss: 0.520253
Average total loss: 1.661953
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-6.4705e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.115112
Average KL loss: 0.519874
Average total loss: 1.634985
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.8985e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.138712
Average KL loss: 0.519507
Average total loss: 1.658219
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-8.6930e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.111360
Average KL loss: 0.519171
Average total loss: 1.630531
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(8.6905e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.139507
Average KL loss: 0.518818
Average total loss: 1.658325
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.1232e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.142363
Average KL loss: 0.518495
Average total loss: 1.660858
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.0898e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.099338
Average KL loss: 0.518168
Average total loss: 1.617506
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.3132e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.124510
Average KL loss: 0.517855
Average total loss: 1.642366
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(8.2821e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.126861
Average KL loss: 0.517555
Average total loss: 1.644416
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.2136e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.150311
Average KL loss: 0.517289
Average total loss: 1.667600
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.0712e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.120995
Average KL loss: 0.517055
Average total loss: 1.638050
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.3333e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.109182
Average KL loss: 0.516768
Average total loss: 1.625950
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.7555e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.118616
Average KL loss: 0.516498
Average total loss: 1.635114
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.1002e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.132823
Average KL loss: 0.516274
Average total loss: 1.649097
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-3.2385e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.154196
Average KL loss: 0.516051
Average total loss: 1.670247
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.8233e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.109362
Average KL loss: 0.515844
Average total loss: 1.625206
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.2423e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.117674
Average KL loss: 0.515591
Average total loss: 1.633265
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.5354e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.120414
Average KL loss: 0.515353
Average total loss: 1.635767
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.1084e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.134309
Average KL loss: 0.515218
Average total loss: 1.649527
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-8.2118e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.139224
Average KL loss: 0.515196
Average total loss: 1.654420
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.0330e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.141494
Average KL loss: 0.515173
Average total loss: 1.656667
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.9800e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.102721
Average KL loss: 0.515149
Average total loss: 1.617870
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-4.8427e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.126293
Average KL loss: 0.515125
Average total loss: 1.641418
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(7.0399e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.140403
Average KL loss: 0.515099
Average total loss: 1.655502
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.1635e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.103144
Average KL loss: 0.515078
Average total loss: 1.618223
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.4614e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.135571
Average KL loss: 0.515055
Average total loss: 1.650626
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.0147e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.117944
Average KL loss: 0.515032
Average total loss: 1.632976
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(5.7488e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.116230
Average KL loss: 0.515006
Average total loss: 1.631236
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(5.3883e-09, device='cuda:0')
 Percentile value: 0.02210715413093567
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =     747 /    1728             ( 43.23%) | total_pruned =     981 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    3983 /   36864             ( 10.80%) | total_pruned =   32881 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4445 /   36864             ( 12.06%) | total_pruned =   32419 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4219 /   36864             ( 11.44%) | total_pruned =   32645 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4001 /   36864             ( 10.85%) | total_pruned =   32863 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    7658 /   73728             ( 10.39%) | total_pruned =   66070 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   13297 /  147456             (  9.02%) | total_pruned =  134159 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1576 /    8192             ( 19.24%) | total_pruned =    6616 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8078 /  147456             (  5.48%) | total_pruned =  139378 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    7904 /  147456             (  5.36%) | total_pruned =  139552 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   23521 /  294912             (  7.98%) | total_pruned =  271391 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   39109 /  589824             (  6.63%) | total_pruned =  550715 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3975 /   32768             ( 12.13%) | total_pruned =   28793 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     164 /     256             ( 64.06%) | total_pruned =      92 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   14311 /  589824             (  2.43%) | total_pruned =  575513 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     130 /     256             ( 50.78%) | total_pruned =     126 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   13473 /  589824             (  2.28%) | total_pruned =  576351 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     173 /     256             ( 67.58%) | total_pruned =      83 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   52059 / 1179648             (  4.41%) | total_pruned = 1127589 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     426 /     512             ( 83.20%) | total_pruned =      86 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      69 /     512             ( 13.48%) | total_pruned =     443 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   48008 / 2359296             (  2.03%) | total_pruned = 2311288 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     342 /     512             ( 66.80%) | total_pruned =     170 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     180 /     512             ( 35.16%) | total_pruned =     332 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    7385 /  131072             (  5.63%) | total_pruned =  123687 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     244 /     512             ( 47.66%) | total_pruned =     268 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     184 /     512             ( 35.94%) | total_pruned =     328 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   24871 / 2359296             (  1.05%) | total_pruned = 2334425 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     328 /     512             ( 64.06%) | total_pruned =     184 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   13354 / 2359296             (  0.57%) | total_pruned = 2345942 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     309 /     512             ( 60.35%) | total_pruned =     203 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
linear.weight        | nonzeros =    1422 /    5120             ( 27.77%) | total_pruned =    3698 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 41/200 Loss: 0.000228 Accuracy: 85.24 100.00 % Best test Accuracy: 85.48%
tensor(0.0005, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-9.9854e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.347530
Average KL loss: 0.512741
Average total loss: 2.860271
tensor(0.0003, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.7398e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.106746
Average KL loss: 0.585104
Average total loss: 2.691850
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.8346e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.985964
Average KL loss: 0.631293
Average total loss: 2.617258
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(6.5318e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.925918
Average KL loss: 0.657655
Average total loss: 2.583573
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.2327e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.913941
Average KL loss: 0.674933
Average total loss: 2.588874
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(5.4487e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.919388
Average KL loss: 0.686410
Average total loss: 2.605798
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.4783e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.887731
Average KL loss: 0.699796
Average total loss: 2.587526
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.4920e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.830278
Average KL loss: 0.703758
Average total loss: 2.534035
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.1367e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.832888
Average KL loss: 0.707637
Average total loss: 2.540526
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.2326e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.789039
Average KL loss: 0.712766
Average total loss: 2.501805
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.2825e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.797814
Average KL loss: 0.708153
Average total loss: 2.505967
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.1397e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.754739
Average KL loss: 0.706394
Average total loss: 2.461133
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(4.6848e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.828653
Average KL loss: 0.710486
Average total loss: 2.539139
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(6.1413e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.769356
Average KL loss: 0.718891
Average total loss: 2.488247
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-8.4443e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.764483
Average KL loss: 0.717068
Average total loss: 2.481551
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.1520e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.764585
Average KL loss: 0.715330
Average total loss: 2.479914
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.3176e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.752330
Average KL loss: 0.714676
Average total loss: 2.467007
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.3149e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.736864
Average KL loss: 0.712331
Average total loss: 2.449195
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-8.9168e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.735654
Average KL loss: 0.714099
Average total loss: 2.449753
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.0064e-07, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.773729
Average KL loss: 0.717517
Average total loss: 2.491245
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-6.7425e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.761791
Average KL loss: 0.717241
Average total loss: 2.479031
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.5165e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.701935
Average KL loss: 0.719107
Average total loss: 2.421042
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-4.9971e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.713478
Average KL loss: 0.711097
Average total loss: 2.424575
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-9.2434e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.695486
Average KL loss: 0.708717
Average total loss: 2.404203
tensor(0.0007, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(6.7000e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.776841
Average KL loss: 0.711919
Average total loss: 2.488760
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.1716e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.696946
Average KL loss: 0.712203
Average total loss: 2.409148
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(5.0696e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.705609
Average KL loss: 0.706189
Average total loss: 2.411797
tensor(0.0007, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(6.4851e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.704316
Average KL loss: 0.706695
Average total loss: 2.411011
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.8861e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.722213
Average KL loss: 0.712511
Average total loss: 2.434723
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(6.3967e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.732628
Average KL loss: 0.709537
Average total loss: 2.442165
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.2949e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.672343
Average KL loss: 0.710934
Average total loss: 2.383277
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.2095e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.716191
Average KL loss: 0.710447
Average total loss: 2.426638
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-8.9032e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.735290
Average KL loss: 0.711426
Average total loss: 2.446716
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.9332e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.730640
Average KL loss: 0.713362
Average total loss: 2.444002
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.0143e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.670877
Average KL loss: 0.714633
Average total loss: 2.385511
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-7.1282e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.678223
Average KL loss: 0.708485
Average total loss: 2.386708
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.6211e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.702651
Average KL loss: 0.704196
Average total loss: 2.406847
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.4929e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.674569
Average KL loss: 0.703224
Average total loss: 2.377793
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.0655e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.704921
Average KL loss: 0.704798
Average total loss: 2.409720
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(4.6421e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.661126
Average KL loss: 0.705469
Average total loss: 2.366595
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.9860e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.650324
Average KL loss: 0.701620
Average total loss: 2.351944
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.1371e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.671767
Average KL loss: 0.697415
Average total loss: 2.369182
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.8301e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.679623
Average KL loss: 0.697750
Average total loss: 2.377373
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-4.4406e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.639296
Average KL loss: 0.697244
Average total loss: 2.336539
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.5761e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.649245
Average KL loss: 0.696178
Average total loss: 2.345424
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.5701e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.655543
Average KL loss: 0.695478
Average total loss: 2.351021
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.7564e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.680793
Average KL loss: 0.696719
Average total loss: 2.377512
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.5357e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.634004
Average KL loss: 0.700534
Average total loss: 2.334538
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-9.3558e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.681530
Average KL loss: 0.702999
Average total loss: 2.384529
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.3673e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.615804
Average KL loss: 0.696316
Average total loss: 2.312121
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(4.6548e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.660027
Average KL loss: 0.697471
Average total loss: 2.357498
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-5.7023e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.676903
Average KL loss: 0.701756
Average total loss: 2.378658
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.8694e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.628854
Average KL loss: 0.697180
Average total loss: 2.326034
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.8898e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.602672
Average KL loss: 0.688202
Average total loss: 2.290874
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.0391e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.639428
Average KL loss: 0.687377
Average total loss: 2.326805
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.5640e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.655305
Average KL loss: 0.692032
Average total loss: 2.347337
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.7509e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.654734
Average KL loss: 0.695269
Average total loss: 2.350003
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.4523e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.647798
Average KL loss: 0.697645
Average total loss: 2.345443
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.7332e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.689980
Average KL loss: 0.698557
Average total loss: 2.388537
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.2628e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.648373
Average KL loss: 0.699432
Average total loss: 2.347806
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.8314e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.658495
Average KL loss: 0.693443
Average total loss: 2.351939
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.5864e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.675799
Average KL loss: 0.691663
Average total loss: 2.367462
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.2462e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.631379
Average KL loss: 0.693344
Average total loss: 2.324723
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.6620e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.640498
Average KL loss: 0.693853
Average total loss: 2.334351
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.7635e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.618283
Average KL loss: 0.689204
Average total loss: 2.307487
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.4938e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.655365
Average KL loss: 0.684874
Average total loss: 2.340239
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.3659e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.634767
Average KL loss: 0.676542
Average total loss: 2.311308
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-7.9252e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.666665
Average KL loss: 0.669805
Average total loss: 2.336471
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.7966e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.628124
Average KL loss: 0.663868
Average total loss: 2.291992
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.3768e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.628999
Average KL loss: 0.658606
Average total loss: 2.287605
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(8.4059e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.675000
Average KL loss: 0.654070
Average total loss: 2.329070
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(4.7972e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.620622
Average KL loss: 0.650464
Average total loss: 2.271086
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.9647e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.629989
Average KL loss: 0.647047
Average total loss: 2.277036
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.6848e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.700540
Average KL loss: 0.644339
Average total loss: 2.344880
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.2822e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.624400
Average KL loss: 0.641824
Average total loss: 2.266223
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.8598e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.669736
Average KL loss: 0.639288
Average total loss: 2.309024
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(6.7068e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.624329
Average KL loss: 0.637276
Average total loss: 2.261605
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.3042e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.643734
Average KL loss: 0.634838
Average total loss: 2.278573
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.9147e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.653109
Average KL loss: 0.632896
Average total loss: 2.286004
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.6427e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.647094
Average KL loss: 0.631847
Average total loss: 2.278941
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.4669e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.650173
Average KL loss: 0.630380
Average total loss: 2.280553
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.1933e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.666513
Average KL loss: 0.629308
Average total loss: 2.295821
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.9435e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.651397
Average KL loss: 0.628530
Average total loss: 2.279927
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.2198e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.644035
Average KL loss: 0.627469
Average total loss: 2.271504
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.8151e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.642335
Average KL loss: 0.626512
Average total loss: 2.268847
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(8.3545e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.630820
Average KL loss: 0.625593
Average total loss: 2.256413
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.0564e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.637362
Average KL loss: 0.624529
Average total loss: 2.261891
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.1876e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.638833
Average KL loss: 0.623514
Average total loss: 2.262347
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.6246e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.616215
Average KL loss: 0.622732
Average total loss: 2.238948
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.6456e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.626727
Average KL loss: 0.621953
Average total loss: 2.248680
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.5549e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.659608
Average KL loss: 0.621382
Average total loss: 2.280990
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(5.8241e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.635195
Average KL loss: 0.620703
Average total loss: 2.255898
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.4806e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.652658
Average KL loss: 0.619963
Average total loss: 2.272622
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(8.7464e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.665477
Average KL loss: 0.619417
Average total loss: 2.284894
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.6971e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.604049
Average KL loss: 0.618754
Average total loss: 2.222803
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.5701e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.618547
Average KL loss: 0.617662
Average total loss: 2.236209
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.4720e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.610260
Average KL loss: 0.616603
Average total loss: 2.226863
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.4412e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.649146
Average KL loss: 0.615993
Average total loss: 2.265139
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.7630e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.646497
Average KL loss: 0.615814
Average total loss: 2.262311
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.1103e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.622816
Average KL loss: 0.615784
Average total loss: 2.238600
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.7229e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.605044
Average KL loss: 0.615168
Average total loss: 2.220212
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.2118e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.624229
Average KL loss: 0.614435
Average total loss: 2.238663
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.0404e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.629946
Average KL loss: 0.613892
Average total loss: 2.243838
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.1486e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.652963
Average KL loss: 0.613415
Average total loss: 2.266378
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.1951e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.654947
Average KL loss: 0.613296
Average total loss: 2.268243
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.6804e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.634788
Average KL loss: 0.613141
Average total loss: 2.247929
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.3553e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.641039
Average KL loss: 0.612844
Average total loss: 2.253884
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.0443e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.668869
Average KL loss: 0.612178
Average total loss: 2.281046
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.4244e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.621480
Average KL loss: 0.612081
Average total loss: 2.233560
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.9098e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.630770
Average KL loss: 0.611827
Average total loss: 2.242597
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.1358e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.634229
Average KL loss: 0.611820
Average total loss: 2.246049
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.0854e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.643462
Average KL loss: 0.611877
Average total loss: 2.255339
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.2758e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.616129
Average KL loss: 0.611663
Average total loss: 2.227792
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(6.6343e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.595197
Average KL loss: 0.611526
Average total loss: 2.206723
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.6346e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.618341
Average KL loss: 0.611370
Average total loss: 2.229711
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.5218e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.653725
Average KL loss: 0.611197
Average total loss: 2.264922
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.1157e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.630069
Average KL loss: 0.611069
Average total loss: 2.241137
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.6252e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.641287
Average KL loss: 0.610979
Average total loss: 2.252267
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.5086e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.604110
Average KL loss: 0.610860
Average total loss: 2.214969
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.6735e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.600398
Average KL loss: 0.610698
Average total loss: 2.211096
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-4.0929e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.638979
Average KL loss: 0.610591
Average total loss: 2.249570
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.4323e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.620565
Average KL loss: 0.610501
Average total loss: 2.231066
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.4234e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.626762
Average KL loss: 0.610377
Average total loss: 2.237139
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(5.2188e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.636454
Average KL loss: 0.610237
Average total loss: 2.246691
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.5053e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.632487
Average KL loss: 0.610121
Average total loss: 2.242608
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(8.3663e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.604221
Average KL loss: 0.610050
Average total loss: 2.214271
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.3524e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.669193
Average KL loss: 0.610038
Average total loss: 2.279231
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.8190e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.660782
Average KL loss: 0.610029
Average total loss: 2.270811
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.3732e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.663081
Average KL loss: 0.610016
Average total loss: 2.273097
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.5488e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.644798
Average KL loss: 0.610004
Average total loss: 2.254802
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-5.6674e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.599856
Average KL loss: 0.609988
Average total loss: 2.209845
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.1336e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.647813
Average KL loss: 0.609973
Average total loss: 2.257786
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.0521e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.612832
Average KL loss: 0.609959
Average total loss: 2.222790
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.4104e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.647551
Average KL loss: 0.609940
Average total loss: 2.257492
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.6854e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.670086
Average KL loss: 0.609929
Average total loss: 2.280016
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.2069e-08, device='cuda:0')
 Percentile value: 0.06802431792020797
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =     542 /    1728             ( 31.37%) | total_pruned =    1186 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
bn1.bias             | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1688 /   36864             (  4.58%) | total_pruned =   35176 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2114 /   36864             (  5.73%) | total_pruned =   34750 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1939 /   36864             (  5.26%) | total_pruned =   34925 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1726 /   36864             (  4.68%) | total_pruned =   35138 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3497 /   73728             (  4.74%) | total_pruned =   70231 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5315 /  147456             (  3.60%) | total_pruned =  142141 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     802 /    8192             (  9.79%) | total_pruned =    7390 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2351 /  147456             (  1.59%) | total_pruned =  145105 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2053 /  147456             (  1.39%) | total_pruned =  145403 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8429 /  294912             (  2.86%) | total_pruned =  286483 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   12329 /  589824             (  2.09%) | total_pruned =  577495 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1542 /   32768             (  4.71%) | total_pruned =   31226 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     133 /     256             ( 51.95%) | total_pruned =     123 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2768 /  589824             (  0.47%) | total_pruned =  587056 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      89 /     256             ( 34.77%) | total_pruned =     167 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2613 /  589824             (  0.44%) | total_pruned =  587211 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      69 /     256             ( 26.95%) | total_pruned =     187 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   14108 / 1179648             (  1.20%) | total_pruned = 1165540 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     354 /     512             ( 69.14%) | total_pruned =     158 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   11479 / 2359296             (  0.49%) | total_pruned = 2347817 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     234 /     512             ( 45.70%) | total_pruned =     278 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2215 /  131072             (  1.69%) | total_pruned =  128857 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     163 /     512             ( 31.84%) | total_pruned =     349 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    6082 / 2359296             (  0.26%) | total_pruned = 2353214 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     259 /     512             ( 50.59%) | total_pruned =     253 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    3123 / 2359296             (  0.13%) | total_pruned = 2356173 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     138 /     512             ( 26.95%) | total_pruned =     374 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
linear.weight        | nonzeros =     707 /    5120             ( 13.81%) | total_pruned =    4413 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 56/200 Loss: 0.005060 Accuracy: 80.56 100.00 % Best test Accuracy: 82.35%
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(5.2951e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 3.940979
Average KL loss: 0.544814
Average total loss: 4.485793
tensor(0.0002, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-8.5599e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 3.654357
Average KL loss: 0.558405
Average total loss: 4.212762
tensor(0.0006, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.5701e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 3.374742
Average KL loss: 0.596480
Average total loss: 3.971222
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.5266e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 3.229447
Average KL loss: 0.628802
Average total loss: 3.858249
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-7.7618e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 3.309351
Average KL loss: 0.657701
Average total loss: 3.967052
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.0823e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 3.245644
Average KL loss: 0.682275
Average total loss: 3.927919
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.9839e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 3.125973
Average KL loss: 0.703151
Average total loss: 3.829124
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.0506e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.970755
Average KL loss: 0.719437
Average total loss: 3.690192
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.0916e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 3.056420
Average KL loss: 0.729756
Average total loss: 3.786176
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.4307e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.905133
Average KL loss: 0.740121
Average total loss: 3.645255
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.0679e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.958433
Average KL loss: 0.747728
Average total loss: 3.706161
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-3.0787e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.719577
Average KL loss: 0.753745
Average total loss: 3.473322
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.2089e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.784225
Average KL loss: 0.757911
Average total loss: 3.542136
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-3.4761e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.772055
Average KL loss: 0.765012
Average total loss: 3.537067
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.1367e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.757550
Average KL loss: 0.774024
Average total loss: 3.531575
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.4593e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.656272
Average KL loss: 0.779119
Average total loss: 3.435391
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.2664e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.689490
Average KL loss: 0.781242
Average total loss: 3.470732
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.8729e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.648462
Average KL loss: 0.787505
Average total loss: 3.435967
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(9.4751e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.646660
Average KL loss: 0.788528
Average total loss: 3.435188
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.1613e-07, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.625117
Average KL loss: 0.789413
Average total loss: 3.414530
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.0209e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.573447
Average KL loss: 0.790459
Average total loss: 3.363906
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.3616e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.531193
Average KL loss: 0.792267
Average total loss: 3.323460
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.3808e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.499683
Average KL loss: 0.790929
Average total loss: 3.290612
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.3384e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.508373
Average KL loss: 0.790808
Average total loss: 3.299181
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.1370e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.517935
Average KL loss: 0.792946
Average total loss: 3.310880
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.8183e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.530919
Average KL loss: 0.792162
Average total loss: 3.323081
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.9749e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.491725
Average KL loss: 0.793952
Average total loss: 3.285676
tensor(0.0006, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.6828e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.372009
Average KL loss: 0.793734
Average total loss: 3.165743
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.3619e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.371948
Average KL loss: 0.789825
Average total loss: 3.161773
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.8526e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.456725
Average KL loss: 0.787031
Average total loss: 3.243756
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.3756e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.371690
Average KL loss: 0.785090
Average total loss: 3.156781
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(9.5365e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.309511
Average KL loss: 0.781060
Average total loss: 3.090571
tensor(0.0007, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.9311e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 2.320698
Average KL loss: 0.778826
Average total loss: 3.099524
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.9905e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 2.416875
Average KL loss: 0.773923
Average total loss: 3.190799
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.6325e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 2.403000
Average KL loss: 0.773761
Average total loss: 3.176761
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(8.1422e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 2.358245
Average KL loss: 0.775478
Average total loss: 3.133723
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.3040e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 2.342184
Average KL loss: 0.772942
Average total loss: 3.115126
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-6.1507e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 2.381354
Average KL loss: 0.772779
Average total loss: 3.154133
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.9137e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 2.327008
Average KL loss: 0.773911
Average total loss: 3.100919
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.0844e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 2.280139
Average KL loss: 0.772040
Average total loss: 3.052180
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.0250e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 2.257813
Average KL loss: 0.766523
Average total loss: 3.024336
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-9.0754e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 2.305993
Average KL loss: 0.766315
Average total loss: 3.072308
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-9.0448e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 2.288139
Average KL loss: 0.765584
Average total loss: 3.053723
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-3.6564e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 2.266190
Average KL loss: 0.764312
Average total loss: 3.030502
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.0171e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 2.256095
Average KL loss: 0.760055
Average total loss: 3.016150
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(8.7053e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 2.240055
Average KL loss: 0.754790
Average total loss: 2.994845
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.2460e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 2.230322
Average KL loss: 0.754212
Average total loss: 2.984533
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.3645e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 2.212989
Average KL loss: 0.752401
Average total loss: 2.965390
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-3.1048e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 2.231694
Average KL loss: 0.752881
Average total loss: 2.984576
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.6430e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 2.246833
Average KL loss: 0.751855
Average total loss: 2.998688
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.4244e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 2.146640
Average KL loss: 0.747855
Average total loss: 2.894495
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.5126e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 2.159827
Average KL loss: 0.744227
Average total loss: 2.904055
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.6583e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 2.273109
Average KL loss: 0.740732
Average total loss: 3.013841
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.8231e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 2.141734
Average KL loss: 0.737058
Average total loss: 2.878792
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-5.7520e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 2.147488
Average KL loss: 0.734045
Average total loss: 2.881533
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.7395e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 2.174386
Average KL loss: 0.732876
Average total loss: 2.907262
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.9814e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 2.165446
Average KL loss: 0.731933
Average total loss: 2.897379
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-4.1883e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 2.188203
Average KL loss: 0.729876
Average total loss: 2.918079
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.4399e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 2.167190
Average KL loss: 0.729871
Average total loss: 2.897061
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.7788e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 2.169544
Average KL loss: 0.725298
Average total loss: 2.894842
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.7303e-07, device='cuda:0')
Epoch 61
Average batch original loss after noise: 2.232855
Average KL loss: 0.725852
Average total loss: 2.958707
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.7685e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 2.135263
Average KL loss: 0.727847
Average total loss: 2.863111
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.9386e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 2.112189
Average KL loss: 0.721535
Average total loss: 2.833724
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.1063e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 2.145791
Average KL loss: 0.717510
Average total loss: 2.863302
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.0129e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 2.093046
Average KL loss: 0.717821
Average total loss: 2.810867
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.1899e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 2.076896
Average KL loss: 0.713612
Average total loss: 2.790508
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.8967e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 2.106525
Average KL loss: 0.709683
Average total loss: 2.816209
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.3300e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 2.044700
Average KL loss: 0.708956
Average total loss: 2.753656
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.6746e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 2.095596
Average KL loss: 0.705460
Average total loss: 2.801056
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.6726e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 2.085176
Average KL loss: 0.705880
Average total loss: 2.791056
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.4171e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 2.051247
Average KL loss: 0.706172
Average total loss: 2.757420
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.4291e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 2.146392
Average KL loss: 0.702537
Average total loss: 2.848929
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.5635e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 2.069304
Average KL loss: 0.700860
Average total loss: 2.770164
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(7.4516e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 2.117979
Average KL loss: 0.697628
Average total loss: 2.815606
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.2152e-07, device='cuda:0')
Epoch 75
Average batch original loss after noise: 2.077268
Average KL loss: 0.695645
Average total loss: 2.772913
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(8.1776e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 2.083554
Average KL loss: 0.694451
Average total loss: 2.778005
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.1297e-07, device='cuda:0')
Epoch 77
Average batch original loss after noise: 2.081459
Average KL loss: 0.692881
Average total loss: 2.774341
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(9.1491e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 2.081424
Average KL loss: 0.689876
Average total loss: 2.771300
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-6.8930e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 2.065812
Average KL loss: 0.688089
Average total loss: 2.753901
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.8597e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 2.054305
Average KL loss: 0.686988
Average total loss: 2.741293
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.7952e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 2.024896
Average KL loss: 0.684611
Average total loss: 2.709507
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.4510e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 2.077412
Average KL loss: 0.682165
Average total loss: 2.759576
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.1678e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 2.022453
Average KL loss: 0.679980
Average total loss: 2.702433
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.5200e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 2.037981
Average KL loss: 0.677778
Average total loss: 2.715759
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.5976e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 2.024919
Average KL loss: 0.675499
Average total loss: 2.700418
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.0421e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 2.085888
Average KL loss: 0.673675
Average total loss: 2.759564
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.4080e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 2.023091
Average KL loss: 0.672212
Average total loss: 2.695303
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.2961e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 2.086473
Average KL loss: 0.670627
Average total loss: 2.757100
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-9.9372e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 2.054921
Average KL loss: 0.669291
Average total loss: 2.724212
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.5688e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 2.055554
Average KL loss: 0.668072
Average total loss: 2.723626
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.6202e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 2.079581
Average KL loss: 0.666540
Average total loss: 2.746121
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.0648e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 2.022728
Average KL loss: 0.665025
Average total loss: 2.687753
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.5598e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 2.083435
Average KL loss: 0.663264
Average total loss: 2.746699
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.6378e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 2.033950
Average KL loss: 0.662036
Average total loss: 2.695987
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-4.1615e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 2.059514
Average KL loss: 0.660822
Average total loss: 2.720336
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.6868e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 2.062519
Average KL loss: 0.659373
Average total loss: 2.721892
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.8786e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 2.035543
Average KL loss: 0.657942
Average total loss: 2.693485
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.3355e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 2.060525
Average KL loss: 0.656812
Average total loss: 2.717338
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.5123e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 2.003826
Average KL loss: 0.655885
Average total loss: 2.659711
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.1247e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.972478
Average KL loss: 0.654958
Average total loss: 2.627437
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.1677e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 2.060357
Average KL loss: 0.653954
Average total loss: 2.714311
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.8445e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.997139
Average KL loss: 0.652908
Average total loss: 2.650048
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.5685e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 2.032080
Average KL loss: 0.651835
Average total loss: 2.683915
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-7.5624e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 2.023471
Average KL loss: 0.650615
Average total loss: 2.674086
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-6.0834e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 2.028667
Average KL loss: 0.649658
Average total loss: 2.678325
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.2076e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 2.052522
Average KL loss: 0.649052
Average total loss: 2.701574
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.3341e-07, device='cuda:0')
Epoch 107
Average batch original loss after noise: 2.068300
Average KL loss: 0.648370
Average total loss: 2.716669
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.1073e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 2.010240
Average KL loss: 0.647545
Average total loss: 2.657785
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-4.2523e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 2.031091
Average KL loss: 0.646547
Average total loss: 2.677638
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.6941e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 2.083804
Average KL loss: 0.645587
Average total loss: 2.729391
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.2336e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 2.019884
Average KL loss: 0.644800
Average total loss: 2.664684
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.8086e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 2.027875
Average KL loss: 0.644534
Average total loss: 2.672409
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.8076e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 2.023914
Average KL loss: 0.644429
Average total loss: 2.668343
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(8.4594e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 2.052266
Average KL loss: 0.644319
Average total loss: 2.696585
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.7410e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 2.035632
Average KL loss: 0.644233
Average total loss: 2.679865
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.0517e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 2.045287
Average KL loss: 0.644157
Average total loss: 2.689444
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.0739e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 2.039103
Average KL loss: 0.644066
Average total loss: 2.683169
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(9.1782e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 2.056603
Average KL loss: 0.643941
Average total loss: 2.700544
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.0348e-07, device='cuda:0')
Epoch 119
Average batch original loss after noise: 2.047292
Average KL loss: 0.643838
Average total loss: 2.691130
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.4679e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 2.038864
Average KL loss: 0.643777
Average total loss: 2.682641
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.4889e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 2.052579
Average KL loss: 0.643682
Average total loss: 2.696260
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.9384e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 2.092508
Average KL loss: 0.643585
Average total loss: 2.736093
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-4.9013e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 2.078872
Average KL loss: 0.643536
Average total loss: 2.722408
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.5689e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 2.059066
Average KL loss: 0.643527
Average total loss: 2.702594
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.9688e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 2.078943
Average KL loss: 0.643518
Average total loss: 2.722461
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.0766e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 2.056013
Average KL loss: 0.643506
Average total loss: 2.699519
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(7.5411e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 2.031383
Average KL loss: 0.643494
Average total loss: 2.674877
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.8775e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 2.091504
Average KL loss: 0.643484
Average total loss: 2.734988
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.3044e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 2.038629
Average KL loss: 0.643475
Average total loss: 2.682103
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.4102e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 2.052745
Average KL loss: 0.643465
Average total loss: 2.696210
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-5.0766e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 2.065369
Average KL loss: 0.643455
Average total loss: 2.708824
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.1698e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 2.048086
Average KL loss: 0.643445
Average total loss: 2.691531
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.1446e-08, device='cuda:0')
 Percentile value: 0.1644836515188217
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     356 /    1728             ( 20.60%) | total_pruned =    1372 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
bn1.bias             | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     734 /   36864             (  1.99%) | total_pruned =   36130 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     956 /   36864             (  2.59%) | total_pruned =   35908 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     883 /   36864             (  2.40%) | total_pruned =   35981 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     830 /   36864             (  2.25%) | total_pruned =   36034 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1531 /   73728             (  2.08%) | total_pruned =   72197 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1995 /  147456             (  1.35%) | total_pruned =  145461 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     376 /    8192             (  4.59%) | total_pruned =    7816 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     742 /  147456             (  0.50%) | total_pruned =  146714 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     553 /  147456             (  0.38%) | total_pruned =  146903 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2888 /  294912             (  0.98%) | total_pruned =  292024 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     179 /     256             ( 69.92%) | total_pruned =      77 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3767 /  589824             (  0.64%) | total_pruned =  586057 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     175 /     256             ( 68.36%) | total_pruned =      81 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     571 /   32768             (  1.74%) | total_pruned =   32197 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      98 /     256             ( 38.28%) | total_pruned =     158 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     431 /  589824             (  0.07%) | total_pruned =  589393 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     291 /  589824             (  0.05%) | total_pruned =  589533 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    3637 / 1179648             (  0.31%) | total_pruned = 1176011 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     243 /     512             ( 47.46%) | total_pruned =     269 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2394 / 2359296             (  0.10%) | total_pruned = 2356902 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     128 /     512             ( 25.00%) | total_pruned =     384 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     587 /  131072             (  0.45%) | total_pruned =  130485 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      43 /     512             (  8.40%) | total_pruned =     469 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     996 / 2359296             (  0.04%) | total_pruned = 2358300 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     116 /     512             ( 22.66%) | total_pruned =     396 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     443 / 2359296             (  0.02%) | total_pruned = 2358853 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
linear.weight        | nonzeros =     253 /    5120             (  4.94%) | total_pruned =    4867 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 199/200 Loss: 0.109899 Accuracy: 74.23 98.42 % Best test Accuracy: 77.27%
tensor(0.0003, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(7.0203e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 7.814425
Average KL loss: 0.558265
Average total loss: 8.372690
tensor(0.0001, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.5372e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 7.015770
Average KL loss: 0.516427
Average total loss: 7.532197
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.3676e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 6.639617
Average KL loss: 0.516465
Average total loss: 7.156081
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.0951e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 6.532189
Average KL loss: 0.527381
Average total loss: 7.059570
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-7.9413e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 6.324879
Average KL loss: 0.544394
Average total loss: 6.869273
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-5.6789e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 6.094455
Average KL loss: 0.565396
Average total loss: 6.659850
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-7.4254e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 5.785204
Average KL loss: 0.585255
Average total loss: 6.370459
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(5.6027e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 5.616618
Average KL loss: 0.605392
Average total loss: 6.222010
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(4.8360e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 5.715533
Average KL loss: 0.625645
Average total loss: 6.341178
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(9.1989e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 5.614227
Average KL loss: 0.645752
Average total loss: 6.259979
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-5.1362e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 5.401165
Average KL loss: 0.663944
Average total loss: 6.065109
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-4.8163e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 5.337003
Average KL loss: 0.682263
Average total loss: 6.019266
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.2971e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 5.275092
Average KL loss: 0.699805
Average total loss: 5.974897
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.6114e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 5.070790
Average KL loss: 0.716115
Average total loss: 5.786904
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.0996e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 5.051599
Average KL loss: 0.732059
Average total loss: 5.783658
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.3366e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 5.252181
Average KL loss: 0.748070
Average total loss: 6.000251
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-6.9018e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 4.653529
Average KL loss: 0.763140
Average total loss: 5.416669
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(8.0611e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 5.016708
Average KL loss: 0.777029
Average total loss: 5.793737
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.5925e-07, device='cuda:0')
Epoch 19
Average batch original loss after noise: 4.687713
Average KL loss: 0.789565
Average total loss: 5.477278
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(5.1927e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 4.600586
Average KL loss: 0.800406
Average total loss: 5.400992
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.1573e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 4.519286
Average KL loss: 0.811171
Average total loss: 5.330456
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.8836e-07, device='cuda:0')
Epoch 22
Average batch original loss after noise: 4.669216
Average KL loss: 0.823101
Average total loss: 5.492317
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(3.0325e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 4.445684
Average KL loss: 0.836852
Average total loss: 5.282536
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.4476e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 4.463106
Average KL loss: 0.848353
Average total loss: 5.311460
tensor(0.0007, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.4288e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 4.442392
Average KL loss: 0.859307
Average total loss: 5.301699
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-4.1941e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 4.271615
Average KL loss: 0.868969
Average total loss: 5.140585
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(4.4046e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 4.183436
Average KL loss: 0.879161
Average total loss: 5.062597
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(7.4475e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 4.147286
Average KL loss: 0.888374
Average total loss: 5.035660
tensor(0.0005, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(5.3676e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 4.326001
Average KL loss: 0.896775
Average total loss: 5.222776
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.9908e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 4.024925
Average KL loss: 0.903138
Average total loss: 4.928063
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.3026e-07, device='cuda:0')
Epoch 31
Average batch original loss after noise: 4.017626
Average KL loss: 0.908306
Average total loss: 4.925933
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(6.1830e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 3.933750
Average KL loss: 0.916529
Average total loss: 4.850279
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.3305e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 4.051282
Average KL loss: 0.921969
Average total loss: 4.973250
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1209e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 3.879059
Average KL loss: 0.929291
Average total loss: 4.808350
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-9.2367e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 3.973649
Average KL loss: 0.936034
Average total loss: 4.909684
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.3869e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 3.773652
Average KL loss: 0.941370
Average total loss: 4.715023
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.3979e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 3.860524
Average KL loss: 0.946972
Average total loss: 4.807495
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.6821e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 3.888742
Average KL loss: 0.953476
Average total loss: 4.842218
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.2733e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 3.670993
Average KL loss: 0.962018
Average total loss: 4.633011
tensor(0.0005, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.7384e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 3.612322
Average KL loss: 0.967268
Average total loss: 4.579590
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.9754e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 3.759693
Average KL loss: 0.971903
Average total loss: 4.731596
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.2078e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 3.756037
Average KL loss: 0.975924
Average total loss: 4.731962
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.7704e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 3.569354
Average KL loss: 0.982195
Average total loss: 4.551549
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-2.0517e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 3.504856
Average KL loss: 0.987995
Average total loss: 4.492851
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(4.2369e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 3.588162
Average KL loss: 0.992587
Average total loss: 4.580749
tensor(0.0005, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-4.2788e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 3.545144
Average KL loss: 0.997000
Average total loss: 4.542144
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-6.3364e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 3.380051
Average KL loss: 0.998345
Average total loss: 4.378396
tensor(0.0005, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(9.3628e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 3.558293
Average KL loss: 1.004359
Average total loss: 4.562652
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.2352e-07, device='cuda:0')
Epoch 49
Average batch original loss after noise: 3.459729
Average KL loss: 1.007909
Average total loss: 4.467638
tensor(0.0005, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-2.8242e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 3.320690
Average KL loss: 1.009205
Average total loss: 4.329895
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(2.4411e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 3.398466
Average KL loss: 1.012995
Average total loss: 4.411461
tensor(0.0005, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.3405e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 3.539530
Average KL loss: 1.019564
Average total loss: 4.559094
tensor(0.0007, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.0604e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 3.386965
Average KL loss: 1.023421
Average total loss: 4.410386
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.6762e-07, device='cuda:0')
Epoch 54
Average batch original loss after noise: 3.325166
Average KL loss: 1.026255
Average total loss: 4.351421
tensor(0.0005, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.2517e-07, device='cuda:0')
Epoch 55
Average batch original loss after noise: 3.174414
Average KL loss: 1.026552
Average total loss: 4.200966
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.3526e-07, device='cuda:0')
Epoch 56
Average batch original loss after noise: 3.216645
Average KL loss: 1.026892
Average total loss: 4.243537
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(7.5088e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 3.179576
Average KL loss: 1.025921
Average total loss: 4.205497
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.6940e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 3.176511
Average KL loss: 1.027828
Average total loss: 4.204339
tensor(0.0002, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.9324e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 3.133927
Average KL loss: 1.028812
Average total loss: 4.162738
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.2795e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 3.092019
Average KL loss: 1.029325
Average total loss: 4.121344
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(3.1029e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 3.106432
Average KL loss: 1.031741
Average total loss: 4.138173
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.0123e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 3.023258
Average KL loss: 1.035688
Average total loss: 4.058946
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-3.3473e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 3.077828
Average KL loss: 1.038444
Average total loss: 4.116272
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(5.1450e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 2.998676
Average KL loss: 1.039731
Average total loss: 4.038407
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(1.0420e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 3.084896
Average KL loss: 1.041664
Average total loss: 4.126559
tensor(0.0003, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(4.9610e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 2.917935
Average KL loss: 1.045439
Average total loss: 3.963374
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-2.0469e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 2.995628
Average KL loss: 1.047610
Average total loss: 4.043238
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(1.8019e-07, device='cuda:0')
Epoch 68
Average batch original loss after noise: 2.859545
Average KL loss: 1.049033
Average total loss: 3.908578
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(1.0285e-07, device='cuda:0')
Epoch 69
Average batch original loss after noise: 2.867516
Average KL loss: 1.048862
Average total loss: 3.916377
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-2.5130e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 2.798526
Average KL loss: 1.049784
Average total loss: 3.848311
tensor(0.0006, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(4.1502e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 2.843646
Average KL loss: 1.050019
Average total loss: 3.893665
tensor(0.0003, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(1.9497e-07, device='cuda:0')
Epoch 72
Average batch original loss after noise: 2.875347
Average KL loss: 1.051303
Average total loss: 3.926650
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(3.1471e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 2.834871
Average KL loss: 1.052028
Average total loss: 3.886899
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(7.5187e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 2.891150
Average KL loss: 1.053439
Average total loss: 3.944589
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-2.8531e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 2.865998
Average KL loss: 1.052859
Average total loss: 3.918857
tensor(0.0003, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(4.8013e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 2.845627
Average KL loss: 1.053277
Average total loss: 3.898904
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(2.7011e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 2.834736
Average KL loss: 1.054653
Average total loss: 3.889389
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.6265e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 2.762207
Average KL loss: 1.055754
Average total loss: 3.817961
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-5.5004e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 2.880152
Average KL loss: 1.056660
Average total loss: 3.936812
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-6.4859e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 2.709429
Average KL loss: 1.056960
Average total loss: 3.766389
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.1856e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 2.716552
Average KL loss: 1.057816
Average total loss: 3.774368
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(7.0740e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 2.647582
Average KL loss: 1.058213
Average total loss: 3.705795
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(5.9131e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 2.649427
Average KL loss: 1.058324
Average total loss: 3.707751
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.6493e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 2.707587
Average KL loss: 1.060877
Average total loss: 3.768464
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(8.2727e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 2.560377
Average KL loss: 1.061771
Average total loss: 3.622147
tensor(0.0003, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.1456e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 2.655762
Average KL loss: 1.061471
Average total loss: 3.717233
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-8.8763e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 2.592559
Average KL loss: 1.061572
Average total loss: 3.654131
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.9256e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 2.622356
Average KL loss: 1.060914
Average total loss: 3.683270
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.5540e-07, device='cuda:0')
Epoch 89
Average batch original loss after noise: 2.669448
Average KL loss: 1.060520
Average total loss: 3.729969
tensor(0.0003, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.7945e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 2.601221
Average KL loss: 1.061983
Average total loss: 3.663204
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.3151e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 2.585844
Average KL loss: 1.062522
Average total loss: 3.648367
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(3.7619e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 2.524511
Average KL loss: 1.060585
Average total loss: 3.585096
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-5.4576e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 2.595844
Average KL loss: 1.061792
Average total loss: 3.657636
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(2.0587e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 2.578876
Average KL loss: 1.062220
Average total loss: 3.641096
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(1.4378e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 2.490958
Average KL loss: 1.062104
Average total loss: 3.553061
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.7749e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 2.504513
Average KL loss: 1.059537
Average total loss: 3.564050
tensor(0.0002, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.7414e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 2.513953
Average KL loss: 1.059861
Average total loss: 3.573813
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(3.5698e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 2.487869
Average KL loss: 1.061076
Average total loss: 3.548945
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.2324e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 2.422557
Average KL loss: 1.062002
Average total loss: 3.484558
tensor(0.0001, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.2318e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 2.478345
Average KL loss: 1.061945
Average total loss: 3.540290
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.6626e-07, device='cuda:0')
Epoch 101
Average batch original loss after noise: 2.470882
Average KL loss: 1.060852
Average total loss: 3.531734
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.5721e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 2.415508
Average KL loss: 1.062687
Average total loss: 3.478196
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.5424e-07, device='cuda:0')
Epoch 103
Average batch original loss after noise: 2.376546
Average KL loss: 1.061599
Average total loss: 3.438145
tensor(0.0003, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.4718e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 2.475110
Average KL loss: 1.062062
Average total loss: 3.537172
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(5.0488e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 2.445130
Average KL loss: 1.060581
Average total loss: 3.505711
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.0218e-07, device='cuda:0')
Epoch 106
Average batch original loss after noise: 2.446871
Average KL loss: 1.059652
Average total loss: 3.506523
tensor(0.0003, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.7400e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 2.406102
Average KL loss: 1.059911
Average total loss: 3.466013
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(3.1652e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 2.381362
Average KL loss: 1.060701
Average total loss: 3.442063
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(5.1565e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 2.361400
Average KL loss: 1.059064
Average total loss: 3.420464
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.1314e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 2.403879
Average KL loss: 1.057575
Average total loss: 3.461454
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(3.7199e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 2.416471
Average KL loss: 1.056657
Average total loss: 3.473128
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.2107e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 2.366467
Average KL loss: 1.059055
Average total loss: 3.425522
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(3.2998e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 2.304458
Average KL loss: 1.058606
Average total loss: 3.363064
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-7.6960e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 2.261407
Average KL loss: 1.056376
Average total loss: 3.317783
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.0186e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 2.376239
Average KL loss: 1.055682
Average total loss: 3.431921
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(3.6426e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 2.364790
Average KL loss: 1.054650
Average total loss: 3.419440
tensor(0.0003, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.1809e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 2.290407
Average KL loss: 1.052413
Average total loss: 3.342820
tensor(0.0003, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.0146e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 2.389677
Average KL loss: 1.051018
Average total loss: 3.440695
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.2793e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 2.364751
Average KL loss: 1.053814
Average total loss: 3.418566
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(4.4885e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 2.321762
Average KL loss: 1.054225
Average total loss: 3.375987
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.4714e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 2.301318
Average KL loss: 1.055525
Average total loss: 3.356843
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.3233e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 2.272719
Average KL loss: 1.056077
Average total loss: 3.328797
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(3.1180e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 2.258218
Average KL loss: 1.055178
Average total loss: 3.313396
tensor(0.0003, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(2.6481e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 2.203282
Average KL loss: 1.054497
Average total loss: 3.257779
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.6121e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 2.246105
Average KL loss: 1.053707
Average total loss: 3.299813
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(2.4082e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 2.253097
Average KL loss: 1.053617
Average total loss: 3.306714
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(3.2557e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 2.229072
Average KL loss: 1.052951
Average total loss: 3.282023
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(3.3168e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 2.313530
Average KL loss: 1.050767
Average total loss: 3.364298
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(5.8547e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 2.192800
Average KL loss: 1.049823
Average total loss: 3.242624
tensor(0.0003, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.2174e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 2.229182
Average KL loss: 1.050298
Average total loss: 3.279480
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.8157e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 2.266154
Average KL loss: 1.050514
Average total loss: 3.316667
tensor(0.0006, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(3.3389e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 2.212115
Average KL loss: 1.051427
Average total loss: 3.263542
tensor(0.0003, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.8308e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 2.193874
Average KL loss: 1.050148
Average total loss: 3.244022
tensor(0.0003, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.8101e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 2.197170
Average KL loss: 1.049028
Average total loss: 3.246198
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(8.4888e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 2.143626
Average KL loss: 1.048097
Average total loss: 3.191723
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(4.0448e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 2.194701
Average KL loss: 1.047090
Average total loss: 3.241791
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-6.6892e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 2.223468
Average KL loss: 1.046905
Average total loss: 3.270374
tensor(0.0001, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-8.1560e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 2.164678
Average KL loss: 1.047052
Average total loss: 3.211729
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(3.5385e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 2.231502
Average KL loss: 1.047888
Average total loss: 3.279390
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(4.9677e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 2.181640
Average KL loss: 1.046496
Average total loss: 3.228136
tensor(0.0003, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.1709e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 2.152717
Average KL loss: 1.045569
Average total loss: 3.198286
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-8.0840e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 2.130350
Average KL loss: 1.044946
Average total loss: 3.175296
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(4.4120e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 2.115948
Average KL loss: 1.043576
Average total loss: 3.159524
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(4.6518e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 2.095431
Average KL loss: 1.042226
Average total loss: 3.137658
tensor(-3.8605e-05, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.1397e-07, device='cuda:0')
Epoch 145
Average batch original loss after noise: 2.137143
Average KL loss: 1.040798
Average total loss: 3.177940
tensor(0.0006, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.6281e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 2.133446
Average KL loss: 1.040649
Average total loss: 3.174094
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.8660e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 2.129440
Average KL loss: 1.039990
Average total loss: 3.169430
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.8693e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 2.148997
Average KL loss: 1.040487
Average total loss: 3.189484
tensor(0.0003, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.1862e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 2.081149
Average KL loss: 1.040796
Average total loss: 3.121945
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(4.4770e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 2.134731
Average KL loss: 1.039106
Average total loss: 3.173837
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(2.1934e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 2.113251
Average KL loss: 1.038071
Average total loss: 3.151321
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.7872e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 2.092532
Average KL loss: 1.038112
Average total loss: 3.130643
tensor(0.0003, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(4.9163e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 2.060189
Average KL loss: 1.036522
Average total loss: 3.096711
tensor(0.0003, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.2033e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 2.092644
Average KL loss: 1.035464
Average total loss: 3.128108
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(4.1337e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 2.094758
Average KL loss: 1.034301
Average total loss: 3.129059
tensor(0.0006, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(6.2589e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 2.082148
Average KL loss: 1.034837
Average total loss: 3.116985
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(2.4721e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 2.061571
Average KL loss: 1.033681
Average total loss: 3.095253
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-6.5119e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 2.033728
Average KL loss: 1.031945
Average total loss: 3.065673
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(5.1190e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 2.083073
Average KL loss: 1.030606
Average total loss: 3.113680
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(5.3603e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 2.035464
Average KL loss: 1.031028
Average total loss: 3.066493
tensor(0.0003, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(7.5890e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 2.057240
Average KL loss: 1.029357
Average total loss: 3.086596
tensor(0.0003, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.8203e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 2.039608
Average KL loss: 1.028435
Average total loss: 3.068042
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(2.4992e-07, device='cuda:0')
Epoch 163
Average batch original loss after noise: 2.103243
Average KL loss: 1.028596
Average total loss: 3.131839
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.2793e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.991629
Average KL loss: 1.028737
Average total loss: 3.020365
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(3.9565e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 2.045660
Average KL loss: 1.027474
Average total loss: 3.073133
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-5.6851e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 2.010946
Average KL loss: 1.025505
Average total loss: 3.036452
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(3.0588e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 2.064475
Average KL loss: 1.023779
Average total loss: 3.088254
tensor(0.0003, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.7726e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 2.009758
Average KL loss: 1.020650
Average total loss: 3.030409
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(8.6790e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.988487
Average KL loss: 1.020665
Average total loss: 3.009152
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.3731e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 2.001645
Average KL loss: 1.021660
Average total loss: 3.023305
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.3444e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 2.001978
Average KL loss: 1.021235
Average total loss: 3.023214
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.8996e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 2.009378
Average KL loss: 1.019560
Average total loss: 3.028938
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(5.6752e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 1.965151
Average KL loss: 1.018958
Average total loss: 2.984108
tensor(0.0004, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(9.4560e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.990508
Average KL loss: 1.017996
Average total loss: 3.008504
tensor(0.0004, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.0296e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 2.037164
Average KL loss: 1.017659
Average total loss: 3.054823
tensor(0.0004, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(6.3011e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 2.021311
Average KL loss: 1.017632
Average total loss: 3.038943
tensor(0.0002, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.5244e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 2.020799
Average KL loss: 1.018705
Average total loss: 3.039504
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.0265e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 2.007728
Average KL loss: 1.019029
Average total loss: 3.026757
tensor(0.0002, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.5766e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 1.995223
Average KL loss: 1.017396
Average total loss: 3.012618
tensor(0.0003, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(3.7866e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 1.982562
Average KL loss: 1.016994
Average total loss: 2.999555
tensor(0.0003, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.4479e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 1.961673
Average KL loss: 1.015688
Average total loss: 2.977361
tensor(1.5707e-07, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.3856e-07, device='cuda:0')
Epoch 182
Average batch original loss after noise: 1.971956
Average KL loss: 1.014387
Average total loss: 2.986342
tensor(0.0003, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.2003e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 1.930025
Average KL loss: 1.012230
Average total loss: 2.942256
tensor(0.0004, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(7.3414e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 1.944259
Average KL loss: 1.011847
Average total loss: 2.956106
tensor(0.0004, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.6897e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 1.963295
Average KL loss: 1.010446
Average total loss: 2.973740
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(6.7683e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 1.948296
Average KL loss: 1.010286
Average total loss: 2.958582
tensor(0.0003, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.9045e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 1.937475
Average KL loss: 1.009389
Average total loss: 2.946864
tensor(0.0004, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.6007e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 1.995335
Average KL loss: 1.007578
Average total loss: 3.002913
tensor(0.0004, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.5874e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 1.937261
Average KL loss: 1.008482
Average total loss: 2.945743
tensor(0.0003, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.3565e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 1.996554
Average KL loss: 1.010438
Average total loss: 3.006992
tensor(0.0001, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.4200e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 2.009739
Average KL loss: 1.011306
Average total loss: 3.021045
tensor(0.0004, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(6.9805e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 1.926808
Average KL loss: 1.011740
Average total loss: 2.938548
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(4.6724e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 1.922265
Average KL loss: 1.011158
Average total loss: 2.933424
tensor(0.0002, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-5.2545e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 1.930256
Average KL loss: 1.009510
Average total loss: 2.939766
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(5.2696e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 1.920174
Average KL loss: 1.007535
Average total loss: 2.927710
tensor(0.0004, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.9660e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 1.907229
Average KL loss: 1.004851
Average total loss: 2.912079
tensor(0.0004, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.9748e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 1.942638
Average KL loss: 1.002809
Average total loss: 2.945447
tensor(0.0001, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.0264e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 1.923758
Average KL loss: 1.002400
Average total loss: 2.926158
tensor(0.0003, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.3712e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 1.910854
Average KL loss: 1.002402
Average total loss: 2.913256
tensor(0.0003, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-8.2598e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 1.912034
Average KL loss: 1.001264
Average total loss: 2.913298
 Percentile value: 0.5809497833251952
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =     233 /    1728             ( 13.48%) | total_pruned =    1495 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
bn1.bias             | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     331 /   36864             (  0.90%) | total_pruned =   36533 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     448 /   36864             (  1.22%) | total_pruned =   36416 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     428 /   36864             (  1.16%) | total_pruned =   36436 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     408 /   36864             (  1.11%) | total_pruned =   36456 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     681 /   73728             (  0.92%) | total_pruned =   73047 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     721 /  147456             (  0.49%) | total_pruned =  146735 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     159 /    8192             (  1.94%) | total_pruned =    8033 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     235 /  147456             (  0.16%) | total_pruned =  147221 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     131 /  147456             (  0.09%) | total_pruned =  147325 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     931 /  294912             (  0.32%) | total_pruned =  293981 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     118 /     256             ( 46.09%) | total_pruned =     138 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     995 /  589824             (  0.17%) | total_pruned =  588829 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     103 /     256             ( 40.23%) | total_pruned =     153 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     152 /   32768             (  0.46%) | total_pruned =   32616 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =      67 /  589824             (  0.01%) | total_pruned =  589757 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =      28 /  589824             (  0.00%) | total_pruned =  589796 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     750 / 1179648             (  0.06%) | total_pruned = 1178898 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      87 /     512             ( 16.99%) | total_pruned =     425 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     293 / 2359296             (  0.01%) | total_pruned = 2359003 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      28 /     512             (  5.47%) | total_pruned =     484 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     102 /  131072             (  0.08%) | total_pruned =  130970 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      25 / 2359296             (  0.00%) | total_pruned = 2359271 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =       5 / 2359296             (  0.00%) | total_pruned = 2359291 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =      66 /    5120             (  1.29%) | total_pruned =    5054 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 199/200 Loss: 0.648416 Accuracy: 68.33 77.14 % Best test Accuracy: 68.84%
