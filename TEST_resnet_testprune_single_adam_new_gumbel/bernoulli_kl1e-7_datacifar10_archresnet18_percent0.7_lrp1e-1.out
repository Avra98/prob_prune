Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1415e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.121474
Average KL loss: 0.024354
Average total loss: 1.145828
tensor(0.0068, device='cuda:0') tensor(0.3485, device='cuda:0') tensor(-5.8757e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.585114
Average KL loss: 0.054453
Average total loss: 0.639566
tensor(0.0123, device='cuda:0') tensor(0.5495, device='cuda:0') tensor(-4.2393e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.392714
Average KL loss: 0.071389
Average total loss: 0.464103
tensor(0.0172, device='cuda:0') tensor(0.7145, device='cuda:0') tensor(-2.7128e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.273919
Average KL loss: 0.083548
Average total loss: 0.357467
tensor(0.0219, device='cuda:0') tensor(0.8523, device='cuda:0') tensor(-3.0036e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.199626
Average KL loss: 0.092860
Average total loss: 0.292486
tensor(0.0255, device='cuda:0') tensor(0.9619, device='cuda:0') tensor(-2.4610e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.146184
Average KL loss: 0.099372
Average total loss: 0.245556
tensor(0.0284, device='cuda:0') tensor(1.0493, device='cuda:0') tensor(-1.9296e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.106852
Average KL loss: 0.103906
Average total loss: 0.210759
tensor(0.0308, device='cuda:0') tensor(1.1146, device='cuda:0') tensor(-1.8053e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.081093
Average KL loss: 0.106821
Average total loss: 0.187914
tensor(0.0328, device='cuda:0') tensor(1.1604, device='cuda:0') tensor(-1.3462e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.059863
Average KL loss: 0.107695
Average total loss: 0.167558
tensor(0.0343, device='cuda:0') tensor(1.1829, device='cuda:0') tensor(-8.8814e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.045970
Average KL loss: 0.107622
Average total loss: 0.153592
tensor(0.0355, device='cuda:0') tensor(1.1916, device='cuda:0') tensor(-7.1771e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.040953
Average KL loss: 0.106822
Average total loss: 0.147774
tensor(0.0365, device='cuda:0') tensor(1.2004, device='cuda:0') tensor(-6.8922e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.031532
Average KL loss: 0.106189
Average total loss: 0.137721
tensor(0.0371, device='cuda:0') tensor(1.1999, device='cuda:0') tensor(-3.2827e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.027629
Average KL loss: 0.104936
Average total loss: 0.132565
tensor(0.0378, device='cuda:0') tensor(1.1992, device='cuda:0') tensor(-7.0657e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.024667
Average KL loss: 0.103811
Average total loss: 0.128478
tensor(0.0382, device='cuda:0') tensor(1.1947, device='cuda:0') tensor(-4.3259e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.022128
Average KL loss: 0.102497
Average total loss: 0.124625
tensor(0.0387, device='cuda:0') tensor(1.1897, device='cuda:0') tensor(-3.5615e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.017214
Average KL loss: 0.101098
Average total loss: 0.118312
tensor(0.0391, device='cuda:0') tensor(1.1758, device='cuda:0') tensor(-1.8809e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.014653
Average KL loss: 0.098794
Average total loss: 0.113447
tensor(0.0392, device='cuda:0') tensor(1.1538, device='cuda:0') tensor(-1.2598e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.015289
Average KL loss: 0.096847
Average total loss: 0.112136
tensor(0.0397, device='cuda:0') tensor(1.1454, device='cuda:0') tensor(-2.5826e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.013892
Average KL loss: 0.096035
Average total loss: 0.109926
tensor(0.0398, device='cuda:0') tensor(1.1378, device='cuda:0') tensor(-1.2102e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.011134
Average KL loss: 0.094430
Average total loss: 0.105564
tensor(0.0400, device='cuda:0') tensor(1.1186, device='cuda:0') tensor(-1.4365e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.010157
Average KL loss: 0.092129
Average total loss: 0.102286
tensor(0.0400, device='cuda:0') tensor(1.0965, device='cuda:0') tensor(-1.6508e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.009802
Average KL loss: 0.090165
Average total loss: 0.099966
tensor(0.0400, device='cuda:0') tensor(1.0797, device='cuda:0') tensor(-6.4550e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.010061
Average KL loss: 0.088992
Average total loss: 0.099052
tensor(0.0401, device='cuda:0') tensor(1.0725, device='cuda:0') tensor(-2.4241e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.008419
Average KL loss: 0.088044
Average total loss: 0.096463
tensor(0.0400, device='cuda:0') tensor(1.0612, device='cuda:0') tensor(-1.5161e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.008548
Average KL loss: 0.086623
Average total loss: 0.095171
tensor(0.0402, device='cuda:0') tensor(1.0493, device='cuda:0') tensor(-9.1672e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.006629
Average KL loss: 0.084883
Average total loss: 0.091513
tensor(0.0400, device='cuda:0') tensor(1.0239, device='cuda:0') tensor(-1.9891e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.006969
Average KL loss: 0.083154
Average total loss: 0.090123
tensor(0.0399, device='cuda:0') tensor(1.0125, device='cuda:0') tensor(-1.1781e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.007224
Average KL loss: 0.082067
Average total loss: 0.089290
tensor(0.0396, device='cuda:0') tensor(1.0033, device='cuda:0') tensor(-1.1896e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.006441
Average KL loss: 0.081246
Average total loss: 0.087687
tensor(0.0397, device='cuda:0') tensor(0.9923, device='cuda:0') tensor(-6.7918e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.006718
Average KL loss: 0.080676
Average total loss: 0.087394
tensor(0.0398, device='cuda:0') tensor(0.9938, device='cuda:0') tensor(-6.6883e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.006192
Average KL loss: 0.080442
Average total loss: 0.086634
tensor(0.0398, device='cuda:0') tensor(0.9852, device='cuda:0') tensor(-7.4725e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.005656
Average KL loss: 0.079234
Average total loss: 0.084890
tensor(0.0400, device='cuda:0') tensor(0.9766, device='cuda:0') tensor(-1.0346e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.005508
Average KL loss: 0.078318
Average total loss: 0.083826
tensor(0.0400, device='cuda:0') tensor(0.9654, device='cuda:0') tensor(-6.6357e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.005391
Average KL loss: 0.077229
Average total loss: 0.082620
tensor(0.0399, device='cuda:0') tensor(0.9566, device='cuda:0') tensor(2.8472e-11, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.005633
Average KL loss: 0.076885
Average total loss: 0.082518
tensor(0.0398, device='cuda:0') tensor(0.9549, device='cuda:0') tensor(-2.0473e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.005893
Average KL loss: 0.076290
Average total loss: 0.082183
tensor(0.0401, device='cuda:0') tensor(0.9534, device='cuda:0') tensor(8.2128e-12, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.004673
Average KL loss: 0.076833
Average total loss: 0.081506
tensor(0.0403, device='cuda:0') tensor(0.9536, device='cuda:0') tensor(-2.6110e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.005349
Average KL loss: 0.076314
Average total loss: 0.081663
tensor(0.0405, device='cuda:0') tensor(0.9569, device='cuda:0') tensor(-6.1332e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.005029
Average KL loss: 0.076773
Average total loss: 0.081802
tensor(0.0407, device='cuda:0') tensor(0.9617, device='cuda:0') tensor(-1.0735e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.005204
Average KL loss: 0.076600
Average total loss: 0.081805
tensor(0.0406, device='cuda:0') tensor(0.9651, device='cuda:0') tensor(-1.0598e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.004455
Average KL loss: 0.076691
Average total loss: 0.081146
tensor(0.0408, device='cuda:0') tensor(0.9599, device='cuda:0') tensor(-6.9311e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.004896
Average KL loss: 0.075559
Average total loss: 0.080455
tensor(0.0407, device='cuda:0') tensor(0.9596, device='cuda:0') tensor(-8.7614e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.004430
Average KL loss: 0.076726
Average total loss: 0.081157
tensor(0.0410, device='cuda:0') tensor(0.9698, device='cuda:0') tensor(2.2212e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.004488
Average KL loss: 0.076295
Average total loss: 0.080782
tensor(0.0412, device='cuda:0') tensor(0.9735, device='cuda:0') tensor(-3.3062e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.004202
Average KL loss: 0.076139
Average total loss: 0.080340
tensor(0.0409, device='cuda:0') tensor(0.9689, device='cuda:0') tensor(-6.5584e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.004091
Average KL loss: 0.076028
Average total loss: 0.080119
tensor(0.0410, device='cuda:0') tensor(0.9691, device='cuda:0') tensor(-9.9185e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.003607
Average KL loss: 0.074864
Average total loss: 0.078471
tensor(0.0408, device='cuda:0') tensor(0.9550, device='cuda:0') tensor(-3.8785e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.003531
Average KL loss: 0.074263
Average total loss: 0.077794
tensor(0.0408, device='cuda:0') tensor(0.9559, device='cuda:0') tensor(-3.2742e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.003354
Average KL loss: 0.073224
Average total loss: 0.076577
tensor(0.0405, device='cuda:0') tensor(0.9385, device='cuda:0') tensor(-5.1071e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.003638
Average KL loss: 0.072366
Average total loss: 0.076004
tensor(0.0403, device='cuda:0') tensor(0.9459, device='cuda:0') tensor(2.9040e-11, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.003967
Average KL loss: 0.073422
Average total loss: 0.077389
tensor(0.0405, device='cuda:0') tensor(0.9558, device='cuda:0') tensor(-1.2977e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.003947
Average KL loss: 0.074630
Average total loss: 0.078577
tensor(0.0409, device='cuda:0') tensor(0.9738, device='cuda:0') tensor(-1.2360e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.003975
Average KL loss: 0.075367
Average total loss: 0.079342
tensor(0.0408, device='cuda:0') tensor(0.9863, device='cuda:0') tensor(-7.3726e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.004121
Average KL loss: 0.076847
Average total loss: 0.080968
tensor(0.0412, device='cuda:0') tensor(1.0092, device='cuda:0') tensor(-5.6250e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.003659
Average KL loss: 0.078269
Average total loss: 0.081929
tensor(0.0413, device='cuda:0') tensor(1.0179, device='cuda:0') tensor(1.8828e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.003393
Average KL loss: 0.077044
Average total loss: 0.080437
tensor(0.0415, device='cuda:0') tensor(1.0060, device='cuda:0') tensor(-1.5507e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.003098
Average KL loss: 0.075845
Average total loss: 0.078943
tensor(0.0413, device='cuda:0') tensor(1.0008, device='cuda:0') tensor(-7.0190e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.003448
Average KL loss: 0.076069
Average total loss: 0.079517
tensor(0.0417, device='cuda:0') tensor(1.0141, device='cuda:0') tensor(-1.1543e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.003274
Average KL loss: 0.077101
Average total loss: 0.080375
tensor(0.0417, device='cuda:0') tensor(1.0187, device='cuda:0') tensor(-9.2984e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.003102
Average KL loss: 0.076535
Average total loss: 0.079638
tensor(0.0417, device='cuda:0') tensor(1.0142, device='cuda:0') tensor(-4.0448e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.003567
Average KL loss: 0.076077
Average total loss: 0.079644
tensor(0.0417, device='cuda:0') tensor(1.0229, device='cuda:0') tensor(-3.2962e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.002797
Average KL loss: 0.076068
Average total loss: 0.078866
tensor(0.0417, device='cuda:0') tensor(1.0131, device='cuda:0') tensor(-7.8635e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.001948
Average KL loss: 0.074880
Average total loss: 0.076828
tensor(0.0416, device='cuda:0') tensor(1.0013, device='cuda:0') tensor(1.3403e-11, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.001780
Average KL loss: 0.073738
Average total loss: 0.075518
tensor(0.0415, device='cuda:0') tensor(0.9901, device='cuda:0') tensor(-7.4730e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.001548
Average KL loss: 0.072659
Average total loss: 0.074207
tensor(0.0414, device='cuda:0') tensor(0.9792, device='cuda:0') tensor(1.3475e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.001401
Average KL loss: 0.071633
Average total loss: 0.073034
tensor(0.0412, device='cuda:0') tensor(0.9688, device='cuda:0') tensor(1.9911e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.001545
Average KL loss: 0.070662
Average total loss: 0.072206
tensor(0.0411, device='cuda:0') tensor(0.9588, device='cuda:0') tensor(-1.0510e-12, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.001172
Average KL loss: 0.069737
Average total loss: 0.070909
tensor(0.0410, device='cuda:0') tensor(0.9490, device='cuda:0') tensor(-4.4813e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.001470
Average KL loss: 0.068839
Average total loss: 0.070309
tensor(0.0409, device='cuda:0') tensor(0.9396, device='cuda:0') tensor(-5.9863e-11, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.001287
Average KL loss: 0.067982
Average total loss: 0.069269
tensor(0.0408, device='cuda:0') tensor(0.9303, device='cuda:0') tensor(2.2009e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.001283
Average KL loss: 0.067144
Average total loss: 0.068427
tensor(0.0407, device='cuda:0') tensor(0.9212, device='cuda:0') tensor(-2.6243e-11, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.001177
Average KL loss: 0.066322
Average total loss: 0.067498
tensor(0.0405, device='cuda:0') tensor(0.9121, device='cuda:0') tensor(1.4101e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.001180
Average KL loss: 0.065525
Average total loss: 0.066705
tensor(0.0404, device='cuda:0') tensor(0.9033, device='cuda:0') tensor(-9.4752e-11, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.001322
Average KL loss: 0.064752
Average total loss: 0.066073
tensor(0.0403, device='cuda:0') tensor(0.8947, device='cuda:0') tensor(-5.4298e-11, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.000897
Average KL loss: 0.063998
Average total loss: 0.064895
tensor(0.0402, device='cuda:0') tensor(0.8861, device='cuda:0') tensor(2.2755e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.001110
Average KL loss: 0.063233
Average total loss: 0.064343
tensor(0.0400, device='cuda:0') tensor(0.8775, device='cuda:0') tensor(-3.9564e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.001054
Average KL loss: 0.062495
Average total loss: 0.063549
tensor(0.0399, device='cuda:0') tensor(0.8690, device='cuda:0') tensor(-2.4175e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.001276
Average KL loss: 0.061792
Average total loss: 0.063068
tensor(0.0398, device='cuda:0') tensor(0.8611, device='cuda:0') tensor(1.0176e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.001035
Average KL loss: 0.061105
Average total loss: 0.062140
tensor(0.0396, device='cuda:0') tensor(0.8528, device='cuda:0') tensor(-1.7855e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.001072
Average KL loss: 0.060413
Average total loss: 0.061485
tensor(0.0395, device='cuda:0') tensor(0.8447, device='cuda:0') tensor(1.2805e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.000885
Average KL loss: 0.059726
Average total loss: 0.060612
tensor(0.0394, device='cuda:0') tensor(0.8366, device='cuda:0') tensor(8.8474e-11, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.001268
Average KL loss: 0.059058
Average total loss: 0.060326
tensor(0.0392, device='cuda:0') tensor(0.8289, device='cuda:0') tensor(2.2313e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.000875
Average KL loss: 0.058421
Average total loss: 0.059296
tensor(0.0391, device='cuda:0') tensor(0.8210, device='cuda:0') tensor(-7.5234e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.000938
Average KL loss: 0.057757
Average total loss: 0.058696
tensor(0.0390, device='cuda:0') tensor(0.8131, device='cuda:0') tensor(1.9174e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.000987
Average KL loss: 0.057114
Average total loss: 0.058101
tensor(0.0388, device='cuda:0') tensor(0.8054, device='cuda:0') tensor(8.4404e-12, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.000924
Average KL loss: 0.056478
Average total loss: 0.057401
tensor(0.0387, device='cuda:0') tensor(0.7976, device='cuda:0') tensor(7.8071e-11, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.000982
Average KL loss: 0.055855
Average total loss: 0.056837
tensor(0.0385, device='cuda:0') tensor(0.7901, device='cuda:0') tensor(-2.3232e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.000847
Average KL loss: 0.055237
Average total loss: 0.056084
tensor(0.0384, device='cuda:0') tensor(0.7824, device='cuda:0') tensor(1.6870e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.000941
Average KL loss: 0.054620
Average total loss: 0.055561
tensor(0.0383, device='cuda:0') tensor(0.7748, device='cuda:0') tensor(-2.9838e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.001071
Average KL loss: 0.054019
Average total loss: 0.055090
tensor(0.0381, device='cuda:0') tensor(0.7674, device='cuda:0') tensor(2.1019e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.000830
Average KL loss: 0.053442
Average total loss: 0.054272
tensor(0.0380, device='cuda:0') tensor(0.7599, device='cuda:0') tensor(5.2798e-11, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.000793
Average KL loss: 0.052832
Average total loss: 0.053624
tensor(0.0379, device='cuda:0') tensor(0.7523, device='cuda:0') tensor(2.2754e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.000858
Average KL loss: 0.052244
Average total loss: 0.053102
tensor(0.0377, device='cuda:0') tensor(0.7450, device='cuda:0') tensor(1.1127e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.000877
Average KL loss: 0.051659
Average total loss: 0.052536
tensor(0.0375, device='cuda:0') tensor(0.7375, device='cuda:0') tensor(5.6639e-11, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.000928
Average KL loss: 0.051107
Average total loss: 0.052035
tensor(0.0374, device='cuda:0') tensor(0.7306, device='cuda:0') tensor(1.3963e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.000832
Average KL loss: 0.050558
Average total loss: 0.051390
tensor(0.0372, device='cuda:0') tensor(0.7233, device='cuda:0') tensor(-9.2787e-11, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.000934
Average KL loss: 0.049995
Average total loss: 0.050929
tensor(0.0371, device='cuda:0') tensor(0.7161, device='cuda:0') tensor(3.5279e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.000686
Average KL loss: 0.049439
Average total loss: 0.050126
tensor(0.0369, device='cuda:0') tensor(0.7087, device='cuda:0') tensor(1.2031e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.000850
Average KL loss: 0.048866
Average total loss: 0.049716
tensor(0.0368, device='cuda:0') tensor(0.7015, device='cuda:0') tensor(1.7864e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.000776
Average KL loss: 0.048315
Average total loss: 0.049091
tensor(0.0366, device='cuda:0') tensor(0.6942, device='cuda:0') tensor(-1.2362e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.000865
Average KL loss: 0.047773
Average total loss: 0.048639
tensor(0.0365, device='cuda:0') tensor(0.6872, device='cuda:0') tensor(9.0346e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.000840
Average KL loss: 0.047248
Average total loss: 0.048088
tensor(0.0363, device='cuda:0') tensor(0.6801, device='cuda:0') tensor(1.2103e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.000739
Average KL loss: 0.046715
Average total loss: 0.047454
tensor(0.0361, device='cuda:0') tensor(0.6731, device='cuda:0') tensor(1.6020e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.000741
Average KL loss: 0.046191
Average total loss: 0.046932
tensor(0.0360, device='cuda:0') tensor(0.6660, device='cuda:0') tensor(-6.8780e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.000745
Average KL loss: 0.045665
Average total loss: 0.046411
tensor(0.0358, device='cuda:0') tensor(0.6591, device='cuda:0') tensor(1.3849e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.000756
Average KL loss: 0.045148
Average total loss: 0.045904
tensor(0.0357, device='cuda:0') tensor(0.6521, device='cuda:0') tensor(1.7923e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.000730
Average KL loss: 0.044620
Average total loss: 0.045350
tensor(0.0355, device='cuda:0') tensor(0.6449, device='cuda:0') tensor(-1.0891e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.000859
Average KL loss: 0.044111
Average total loss: 0.044970
tensor(0.0353, device='cuda:0') tensor(0.6384, device='cuda:0') tensor(-2.0759e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.000828
Average KL loss: 0.043656
Average total loss: 0.044485
tensor(0.0352, device='cuda:0') tensor(0.6318, device='cuda:0') tensor(1.1286e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.000669
Average KL loss: 0.043136
Average total loss: 0.043805
tensor(0.0350, device='cuda:0') tensor(0.6245, device='cuda:0') tensor(4.5875e-11, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.000755
Average KL loss: 0.042619
Average total loss: 0.043374
tensor(0.0348, device='cuda:0') tensor(0.6178, device='cuda:0') tensor(2.2455e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.000610
Average KL loss: 0.042101
Average total loss: 0.042712
tensor(0.0347, device='cuda:0') tensor(0.6106, device='cuda:0') tensor(-3.0666e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.000757
Average KL loss: 0.041608
Average total loss: 0.042366
tensor(0.0345, device='cuda:0') tensor(0.6041, device='cuda:0') tensor(1.7129e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.000864
Average KL loss: 0.041148
Average total loss: 0.042011
tensor(0.0343, device='cuda:0') tensor(0.5977, device='cuda:0') tensor(1.8572e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.000887
Average KL loss: 0.040725
Average total loss: 0.041613
tensor(0.0342, device='cuda:0') tensor(0.5916, device='cuda:0') tensor(2.1783e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.000830
Average KL loss: 0.040311
Average total loss: 0.041141
tensor(0.0341, device='cuda:0') tensor(0.5853, device='cuda:0') tensor(1.5853e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.000959
Average KL loss: 0.039876
Average total loss: 0.040835
tensor(0.0339, device='cuda:0') tensor(0.5793, device='cuda:0') tensor(-1.7687e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.001114
Average KL loss: 0.039496
Average total loss: 0.040610
tensor(0.0337, device='cuda:0') tensor(0.5738, device='cuda:0') tensor(-8.4811e-11, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.000824
Average KL loss: 0.039146
Average total loss: 0.039971
tensor(0.0336, device='cuda:0') tensor(0.5677, device='cuda:0') tensor(7.7812e-11, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.000773
Average KL loss: 0.038686
Average total loss: 0.039460
tensor(0.0335, device='cuda:0') tensor(0.5613, device='cuda:0') tensor(1.5578e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.000941
Average KL loss: 0.038241
Average total loss: 0.039182
tensor(0.0333, device='cuda:0') tensor(0.5554, device='cuda:0') tensor(1.9508e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.000803
Average KL loss: 0.037841
Average total loss: 0.038643
tensor(0.0332, device='cuda:0') tensor(0.5493, device='cuda:0') tensor(1.5984e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.000822
Average KL loss: 0.037431
Average total loss: 0.038253
tensor(0.0330, device='cuda:0') tensor(0.5432, device='cuda:0') tensor(1.8271e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.000785
Average KL loss: 0.037033
Average total loss: 0.037818
tensor(0.0329, device='cuda:0') tensor(0.5376, device='cuda:0') tensor(4.0024e-12, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.000962
Average KL loss: 0.036696
Average total loss: 0.037657
tensor(0.0327, device='cuda:0') tensor(0.5326, device='cuda:0') tensor(-4.3044e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.000949
Average KL loss: 0.036352
Average total loss: 0.037302
tensor(0.0326, device='cuda:0') tensor(0.5270, device='cuda:0') tensor(8.8189e-12, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.000907
Average KL loss: 0.035996
Average total loss: 0.036904
tensor(0.0324, device='cuda:0') tensor(0.5216, device='cuda:0') tensor(-3.6836e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.000856
Average KL loss: 0.035597
Average total loss: 0.036454
tensor(0.0323, device='cuda:0') tensor(0.5155, device='cuda:0') tensor(4.7981e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.000945
Average KL loss: 0.035208
Average total loss: 0.036154
tensor(0.0321, device='cuda:0') tensor(0.5105, device='cuda:0') tensor(4.7889e-12, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.000721
Average KL loss: 0.034863
Average total loss: 0.035584
tensor(0.0320, device='cuda:0') tensor(0.5047, device='cuda:0') tensor(3.0843e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.000905
Average KL loss: 0.034497
Average total loss: 0.035401
tensor(0.0318, device='cuda:0') tensor(0.4994, device='cuda:0') tensor(4.5746e-11, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.000817
Average KL loss: 0.034092
Average total loss: 0.034909
tensor(0.0317, device='cuda:0') tensor(0.4937, device='cuda:0') tensor(6.0523e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.001019
Average KL loss: 0.033778
Average total loss: 0.034797
tensor(0.0315, device='cuda:0') tensor(0.4893, device='cuda:0') tensor(8.9450e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.000808
Average KL loss: 0.033524
Average total loss: 0.034332
tensor(0.0314, device='cuda:0') tensor(0.4842, device='cuda:0') tensor(1.6838e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.000912
Average KL loss: 0.033148
Average total loss: 0.034060
tensor(0.0312, device='cuda:0') tensor(0.4787, device='cuda:0') tensor(1.7849e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.000978
Average KL loss: 0.032827
Average total loss: 0.033805
tensor(0.0311, device='cuda:0') tensor(0.4741, device='cuda:0') tensor(1.1184e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.000875
Average KL loss: 0.032558
Average total loss: 0.033433
tensor(0.0310, device='cuda:0') tensor(0.4696, device='cuda:0') tensor(2.3120e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.000993
Average KL loss: 0.032272
Average total loss: 0.033265
tensor(0.0308, device='cuda:0') tensor(0.4650, device='cuda:0') tensor(9.9169e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.000719
Average KL loss: 0.031955
Average total loss: 0.032674
tensor(0.0306, device='cuda:0') tensor(0.4595, device='cuda:0') tensor(1.7976e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.000918
Average KL loss: 0.031572
Average total loss: 0.032490
tensor(0.0305, device='cuda:0') tensor(0.4549, device='cuda:0') tensor(-3.3349e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.000974
Average KL loss: 0.031301
Average total loss: 0.032276
tensor(0.0303, device='cuda:0') tensor(0.4502, device='cuda:0') tensor(-3.2678e-11, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.000801
Average KL loss: 0.031020
Average total loss: 0.031821
tensor(0.0302, device='cuda:0') tensor(0.4455, device='cuda:0') tensor(4.6656e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.000980
Average KL loss: 0.030691
Average total loss: 0.031672
tensor(0.0301, device='cuda:0') tensor(0.4409, device='cuda:0') tensor(-1.0486e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.001078
Average KL loss: 0.030453
Average total loss: 0.031531
tensor(0.0300, device='cuda:0') tensor(0.4371, device='cuda:0') tensor(-4.8536e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.001051
Average KL loss: 0.030244
Average total loss: 0.031295
tensor(0.0299, device='cuda:0') tensor(0.4335, device='cuda:0') tensor(-1.3962e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.000978
Average KL loss: 0.030030
Average total loss: 0.031008
tensor(0.0298, device='cuda:0') tensor(0.4295, device='cuda:0') tensor(2.2122e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.000951
Average KL loss: 0.029750
Average total loss: 0.030700
tensor(0.0297, device='cuda:0') tensor(0.4249, device='cuda:0') tensor(1.2140e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.000834
Average KL loss: 0.029449
Average total loss: 0.030283
tensor(0.0295, device='cuda:0') tensor(0.4202, device='cuda:0') tensor(2.2056e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.000844
Average KL loss: 0.029138
Average total loss: 0.029982
tensor(0.0294, device='cuda:0') tensor(0.4160, device='cuda:0') tensor(1.5948e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.000921
Average KL loss: 0.028879
Average total loss: 0.029800
tensor(0.0293, device='cuda:0') tensor(0.4121, device='cuda:0') tensor(6.6735e-11, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.000800
Average KL loss: 0.028616
Average total loss: 0.029416
tensor(0.0291, device='cuda:0') tensor(0.4075, device='cuda:0') tensor(1.2528e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.000990
Average KL loss: 0.028293
Average total loss: 0.029283
tensor(0.0290, device='cuda:0') tensor(0.4032, device='cuda:0') tensor(7.7756e-11, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.001159
Average KL loss: 0.028099
Average total loss: 0.029258
tensor(0.0289, device='cuda:0') tensor(0.4003, device='cuda:0') tensor(-3.7531e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.001059
Average KL loss: 0.028008
Average total loss: 0.029068
tensor(0.0288, device='cuda:0') tensor(0.3975, device='cuda:0') tensor(1.3763e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.001169
Average KL loss: 0.027837
Average total loss: 0.029006
tensor(0.0287, device='cuda:0') tensor(0.3940, device='cuda:0') tensor(-2.7684e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.000758
Average KL loss: 0.027625
Average total loss: 0.028383
tensor(0.0286, device='cuda:0') tensor(0.3903, device='cuda:0') tensor(1.0585e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.001004
Average KL loss: 0.027351
Average total loss: 0.028355
tensor(0.0285, device='cuda:0') tensor(0.3867, device='cuda:0') tensor(1.1995e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.001133
Average KL loss: 0.027195
Average total loss: 0.028328
tensor(0.0284, device='cuda:0') tensor(0.3837, device='cuda:0') tensor(-9.2344e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.000917
Average KL loss: 0.026966
Average total loss: 0.027883
tensor(0.0283, device='cuda:0') tensor(0.3797, device='cuda:0') tensor(-4.3622e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.000985
Average KL loss: 0.026746
Average total loss: 0.027731
tensor(0.0282, device='cuda:0') tensor(0.3764, device='cuda:0') tensor(6.8744e-11, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.000992
Average KL loss: 0.026476
Average total loss: 0.027468
tensor(0.0281, device='cuda:0') tensor(0.3725, device='cuda:0') tensor(1.8357e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.001276
Average KL loss: 0.026338
Average total loss: 0.027614
tensor(0.0280, device='cuda:0') tensor(0.3706, device='cuda:0') tensor(-2.3890e-12, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.000947
Average KL loss: 0.026199
Average total loss: 0.027146
tensor(0.0279, device='cuda:0') tensor(0.3672, device='cuda:0') tensor(-6.4738e-11, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.001062
Average KL loss: 0.026001
Average total loss: 0.027063
tensor(0.0278, device='cuda:0') tensor(0.3642, device='cuda:0') tensor(-1.9355e-11, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.000975
Average KL loss: 0.025869
Average total loss: 0.026844
tensor(0.0278, device='cuda:0') tensor(0.3616, device='cuda:0') tensor(4.2867e-11, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.001013
Average KL loss: 0.025670
Average total loss: 0.026683
tensor(0.0277, device='cuda:0') tensor(0.3583, device='cuda:0') tensor(-2.6409e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.001112
Average KL loss: 0.025487
Average total loss: 0.026598
tensor(0.0276, device='cuda:0') tensor(0.3555, device='cuda:0') tensor(2.4387e-11, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.001209
Average KL loss: 0.025362
Average total loss: 0.026571
tensor(0.0275, device='cuda:0') tensor(0.3533, device='cuda:0') tensor(-4.1206e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.001046
Average KL loss: 0.025229
Average total loss: 0.026275
tensor(0.0275, device='cuda:0') tensor(0.3505, device='cuda:0') tensor(-1.6923e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.000831
Average KL loss: 0.025023
Average total loss: 0.025854
tensor(0.0273, device='cuda:0') tensor(0.3471, device='cuda:0') tensor(1.3108e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.000990
Average KL loss: 0.024787
Average total loss: 0.025776
tensor(0.0273, device='cuda:0') tensor(0.3439, device='cuda:0') tensor(4.0658e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.001144
Average KL loss: 0.024589
Average total loss: 0.025733
tensor(0.0272, device='cuda:0') tensor(0.3410, device='cuda:0') tensor(-1.8477e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.001019
Average KL loss: 0.024439
Average total loss: 0.025458
tensor(0.0271, device='cuda:0') tensor(0.3385, device='cuda:0') tensor(2.6551e-11, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.000874
Average KL loss: 0.024248
Average total loss: 0.025122
tensor(0.0270, device='cuda:0') tensor(0.3354, device='cuda:0') tensor(1.3478e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.000894
Average KL loss: 0.024002
Average total loss: 0.024897
tensor(0.0269, device='cuda:0') tensor(0.3319, device='cuda:0') tensor(3.1128e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.000956
Average KL loss: 0.023740
Average total loss: 0.024696
tensor(0.0267, device='cuda:0') tensor(0.3286, device='cuda:0') tensor(-3.3313e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.000841
Average KL loss: 0.023560
Average total loss: 0.024401
tensor(0.0266, device='cuda:0') tensor(0.3257, device='cuda:0') tensor(1.6600e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.000759
Average KL loss: 0.023341
Average total loss: 0.024100
tensor(0.0265, device='cuda:0') tensor(0.3225, device='cuda:0') tensor(-4.2999e-11, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.000950
Average KL loss: 0.023122
Average total loss: 0.024071
tensor(0.0264, device='cuda:0') tensor(0.3198, device='cuda:0') tensor(4.1916e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.000880
Average KL loss: 0.022953
Average total loss: 0.023833
tensor(0.0264, device='cuda:0') tensor(0.3169, device='cuda:0') tensor(1.7509e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.000725
Average KL loss: 0.022760
Average total loss: 0.023485
tensor(0.0263, device='cuda:0') tensor(0.3138, device='cuda:0') tensor(-5.3902e-11, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.001074
Average KL loss: 0.022563
Average total loss: 0.023637
tensor(0.0262, device='cuda:0') tensor(0.3118, device='cuda:0') tensor(-1.2099e-11, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.000918
Average KL loss: 0.022491
Average total loss: 0.023408
tensor(0.0261, device='cuda:0') tensor(0.3098, device='cuda:0') tensor(-2.9917e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.000934
Average KL loss: 0.022403
Average total loss: 0.023337
tensor(0.0261, device='cuda:0') tensor(0.3074, device='cuda:0') tensor(2.8861e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.001159
Average KL loss: 0.022291
Average total loss: 0.023450
tensor(0.0260, device='cuda:0') tensor(0.3062, device='cuda:0') tensor(-8.1193e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.000949
Average KL loss: 0.022213
Average total loss: 0.023162
tensor(0.0259, device='cuda:0') tensor(0.3038, device='cuda:0') tensor(9.8101e-11, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.000916
Average KL loss: 0.022045
Average total loss: 0.022962
tensor(0.0258, device='cuda:0') tensor(0.3013, device='cuda:0') tensor(-1.1722e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.000968
Average KL loss: 0.021880
Average total loss: 0.022848
tensor(0.0257, device='cuda:0') tensor(0.2988, device='cuda:0') tensor(9.3031e-11, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.000968
Average KL loss: 0.021773
Average total loss: 0.022741
tensor(0.0257, device='cuda:0') tensor(0.2970, device='cuda:0') tensor(5.2036e-12, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.000908
Average KL loss: 0.021660
Average total loss: 0.022568
tensor(0.0257, device='cuda:0') tensor(0.2947, device='cuda:0') tensor(-6.0778e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.000793
Average KL loss: 0.021488
Average total loss: 0.022281
tensor(0.0256, device='cuda:0') tensor(0.2921, device='cuda:0') tensor(-3.4298e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.000940
Average KL loss: 0.021316
Average total loss: 0.022256
tensor(0.0255, device='cuda:0') tensor(0.2902, device='cuda:0') tensor(1.8868e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.000920
Average KL loss: 0.021211
Average total loss: 0.022131
tensor(0.0254, device='cuda:0') tensor(0.2878, device='cuda:0') tensor(-1.6306e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.000750
Average KL loss: 0.021030
Average total loss: 0.021780
tensor(0.0253, device='cuda:0') tensor(0.2851, device='cuda:0') tensor(7.1644e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.000994
Average KL loss: 0.020837
Average total loss: 0.021831
tensor(0.0252, device='cuda:0') tensor(0.2832, device='cuda:0') tensor(-2.0366e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.000983
Average KL loss: 0.020781
Average total loss: 0.021764
tensor(0.0252, device='cuda:0') tensor(0.2816, device='cuda:0') tensor(2.5316e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.000959
Average KL loss: 0.020704
Average total loss: 0.021662
tensor(0.0251, device='cuda:0') tensor(0.2800, device='cuda:0') tensor(1.5798e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.001041
Average KL loss: 0.020626
Average total loss: 0.021667
tensor(0.0250, device='cuda:0') tensor(0.2786, device='cuda:0') tensor(1.2762e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.000829
Average KL loss: 0.020481
Average total loss: 0.021311
tensor(0.0250, device='cuda:0') tensor(0.2759, device='cuda:0') tensor(-1.2472e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.000970
Average KL loss: 0.020334
Average total loss: 0.021304
 Percentile value: 0.2666624784469603
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1208 /    1728             ( 69.91%) | total_pruned =     520 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   18391 /   36864             ( 49.89%) | total_pruned =   18473 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   18818 /   36864             ( 51.05%) | total_pruned =   18046 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   18623 /   36864             ( 50.52%) | total_pruned =   18241 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18339 /   36864             ( 49.75%) | total_pruned =   18525 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   36399 /   73728             ( 49.37%) | total_pruned =   37329 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   70837 /  147456             ( 48.04%) | total_pruned =   76619 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4966 /    8192             ( 60.62%) | total_pruned =    3226 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   65855 /  147456             ( 44.66%) | total_pruned =   81601 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   65656 /  147456             ( 44.53%) | total_pruned =   81800 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  140323 /  294912             ( 47.58%) | total_pruned =  154589 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  271268 /  589824             ( 45.99%) | total_pruned =  318556 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18518 /   32768             ( 56.51%) | total_pruned =   14250 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  225934 /  589824             ( 38.31%) | total_pruned =  363890 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  222437 /  589824             ( 37.71%) | total_pruned =  367387 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  507901 / 1179648             ( 43.06%) | total_pruned =  671747 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  802167 / 2359296             ( 34.00%) | total_pruned = 1557129 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     353 /     512             ( 68.95%) | total_pruned =     159 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   60763 /  131072             ( 46.36%) | total_pruned =   70309 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     444 /     512             ( 86.72%) | total_pruned =      68 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     338 /     512             ( 66.02%) | total_pruned =     174 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  497196 / 2359296             ( 21.07%) | total_pruned = 1862100 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     366 /     512             ( 71.48%) | total_pruned =     146 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     419 /     512             ( 81.84%) | total_pruned =      93 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  275985 / 2359296             ( 11.70%) | total_pruned = 2083311 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
linear.weight        | nonzeros =    4269 /    5120             ( 83.38%) | total_pruned =     851 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 40/200 Loss: 0.000020 Accuracy: 86.75 100.00 % Best test Accuracy: 86.85%
tensor(0.0250, device='cuda:0') tensor(0.2740, device='cuda:0') tensor(-4.7374e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.021523
Average KL loss: 0.020658
Average total loss: 0.042180
tensor(0.0937, device='cuda:0') tensor(0.2630, device='cuda:0') tensor(-3.8247e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.013048
Average KL loss: 0.027472
Average total loss: 0.040520
tensor(0.0958, device='cuda:0') tensor(0.3251, device='cuda:0') tensor(-2.1211e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.011125
Average KL loss: 0.032099
Average total loss: 0.043225
tensor(0.0955, device='cuda:0') tensor(0.3814, device='cuda:0') tensor(-1.4166e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.008701
Average KL loss: 0.036061
Average total loss: 0.044762
tensor(0.0954, device='cuda:0') tensor(0.4313, device='cuda:0') tensor(-1.0358e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.008013
Average KL loss: 0.039004
Average total loss: 0.047017
tensor(0.0951, device='cuda:0') tensor(0.4750, device='cuda:0') tensor(-1.0734e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.008755
Average KL loss: 0.041794
Average total loss: 0.050548
tensor(0.0951, device='cuda:0') tensor(0.5223, device='cuda:0') tensor(-2.0612e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.007222
Average KL loss: 0.044589
Average total loss: 0.051811
tensor(0.0949, device='cuda:0') tensor(0.5629, device='cuda:0') tensor(-1.7917e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.006076
Average KL loss: 0.046186
Average total loss: 0.052262
tensor(0.0946, device='cuda:0') tensor(0.5884, device='cuda:0') tensor(-5.1710e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.004379
Average KL loss: 0.046976
Average total loss: 0.051354
tensor(0.0939, device='cuda:0') tensor(0.6015, device='cuda:0') tensor(-8.9280e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.004495
Average KL loss: 0.047082
Average total loss: 0.051577
tensor(0.0933, device='cuda:0') tensor(0.6141, device='cuda:0') tensor(-8.5118e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.003993
Average KL loss: 0.047579
Average total loss: 0.051572
tensor(0.0928, device='cuda:0') tensor(0.6288, device='cuda:0') tensor(-1.3826e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.003843
Average KL loss: 0.048126
Average total loss: 0.051969
tensor(0.0923, device='cuda:0') tensor(0.6421, device='cuda:0') tensor(-7.8879e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.003555
Average KL loss: 0.048277
Average total loss: 0.051832
tensor(0.0917, device='cuda:0') tensor(0.6520, device='cuda:0') tensor(-3.7034e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.002969
Average KL loss: 0.048348
Average total loss: 0.051317
tensor(0.0916, device='cuda:0') tensor(0.6490, device='cuda:0') tensor(1.7216e-11, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.002171
Average KL loss: 0.047993
Average total loss: 0.050164
tensor(0.0915, device='cuda:0') tensor(0.6447, device='cuda:0') tensor(6.3202e-11, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.001988
Average KL loss: 0.047619
Average total loss: 0.049607
tensor(0.0914, device='cuda:0') tensor(0.6404, device='cuda:0') tensor(3.2799e-11, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.002006
Average KL loss: 0.047249
Average total loss: 0.049255
tensor(0.0913, device='cuda:0') tensor(0.6361, device='cuda:0') tensor(2.0771e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.001878
Average KL loss: 0.046877
Average total loss: 0.048755
tensor(0.0912, device='cuda:0') tensor(0.6317, device='cuda:0') tensor(4.0206e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.001874
Average KL loss: 0.046505
Average total loss: 0.048379
tensor(0.0910, device='cuda:0') tensor(0.6273, device='cuda:0') tensor(-5.3261e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.001861
Average KL loss: 0.046140
Average total loss: 0.048001
tensor(0.0909, device='cuda:0') tensor(0.6231, device='cuda:0') tensor(4.1620e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.001342
Average KL loss: 0.045775
Average total loss: 0.047117
tensor(0.0907, device='cuda:0') tensor(0.6186, device='cuda:0') tensor(-3.6169e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.001519
Average KL loss: 0.045404
Average total loss: 0.046923
tensor(0.0906, device='cuda:0') tensor(0.6142, device='cuda:0') tensor(4.9638e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.001408
Average KL loss: 0.045035
Average total loss: 0.046443
tensor(0.0904, device='cuda:0') tensor(0.6098, device='cuda:0') tensor(2.5045e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.001318
Average KL loss: 0.044664
Average total loss: 0.045983
tensor(0.0902, device='cuda:0') tensor(0.6053, device='cuda:0') tensor(3.7112e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.001455
Average KL loss: 0.044455
Average total loss: 0.045910
tensor(0.0902, device='cuda:0') tensor(0.6048, device='cuda:0') tensor(2.8711e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.001491
Average KL loss: 0.044415
Average total loss: 0.045905
tensor(0.0902, device='cuda:0') tensor(0.6043, device='cuda:0') tensor(3.3012e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.001215
Average KL loss: 0.044374
Average total loss: 0.045588
tensor(0.0902, device='cuda:0') tensor(0.6038, device='cuda:0') tensor(3.2500e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.001400
Average KL loss: 0.044332
Average total loss: 0.045731
tensor(0.0902, device='cuda:0') tensor(0.6033, device='cuda:0') tensor(2.6735e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.001187
Average KL loss: 0.044289
Average total loss: 0.045476
tensor(0.0901, device='cuda:0') tensor(0.6027, device='cuda:0') tensor(5.0520e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.001145
Average KL loss: 0.044245
Average total loss: 0.045389
tensor(0.0901, device='cuda:0') tensor(0.6022, device='cuda:0') tensor(2.0469e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.001385
Average KL loss: 0.044200
Average total loss: 0.045585
tensor(0.0901, device='cuda:0') tensor(0.6017, device='cuda:0') tensor(2.0650e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.001328
Average KL loss: 0.044155
Average total loss: 0.045483
tensor(0.0901, device='cuda:0') tensor(0.6011, device='cuda:0') tensor(3.0269e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.001340
Average KL loss: 0.044109
Average total loss: 0.045448
tensor(0.0901, device='cuda:0') tensor(0.6005, device='cuda:0') tensor(-3.2220e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.001227
Average KL loss: 0.044062
Average total loss: 0.045289
tensor(0.0900, device='cuda:0') tensor(0.5999, device='cuda:0') tensor(4.5976e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.001224
Average KL loss: 0.044015
Average total loss: 0.045239
tensor(0.0900, device='cuda:0') tensor(0.5994, device='cuda:0') tensor(2.9969e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.001215
Average KL loss: 0.043988
Average total loss: 0.045203
tensor(0.0900, device='cuda:0') tensor(0.5993, device='cuda:0') tensor(2.1293e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.001344
Average KL loss: 0.043983
Average total loss: 0.045327
tensor(0.0900, device='cuda:0') tensor(0.5992, device='cuda:0') tensor(4.9353e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.000953
Average KL loss: 0.043978
Average total loss: 0.044931
tensor(0.0900, device='cuda:0') tensor(0.5992, device='cuda:0') tensor(4.4834e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.001041
Average KL loss: 0.043973
Average total loss: 0.045014
tensor(0.0900, device='cuda:0') tensor(0.5991, device='cuda:0') tensor(3.7546e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.001108
Average KL loss: 0.043968
Average total loss: 0.045075
tensor(0.0900, device='cuda:0') tensor(0.5990, device='cuda:0') tensor(2.1188e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.001261
Average KL loss: 0.043962
Average total loss: 0.045223
tensor(0.0900, device='cuda:0') tensor(0.5990, device='cuda:0') tensor(3.7619e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.001293
Average KL loss: 0.043957
Average total loss: 0.045250
tensor(0.0900, device='cuda:0') tensor(0.5989, device='cuda:0') tensor(8.5680e-11, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.001482
Average KL loss: 0.043951
Average total loss: 0.045433
tensor(0.0900, device='cuda:0') tensor(0.5988, device='cuda:0') tensor(-9.5600e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.001228
Average KL loss: 0.043946
Average total loss: 0.045174
tensor(0.0900, device='cuda:0') tensor(0.5988, device='cuda:0') tensor(-2.7817e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.001316
Average KL loss: 0.043940
Average total loss: 0.045256
tensor(0.0900, device='cuda:0') tensor(0.5987, device='cuda:0') tensor(1.6815e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.001269
Average KL loss: 0.043935
Average total loss: 0.045204
tensor(0.0900, device='cuda:0') tensor(0.5986, device='cuda:0') tensor(-1.2661e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.001177
Average KL loss: 0.043932
Average total loss: 0.045108
tensor(0.0900, device='cuda:0') tensor(0.5986, device='cuda:0') tensor(3.7279e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.001136
Average KL loss: 0.043931
Average total loss: 0.045067
tensor(0.0900, device='cuda:0') tensor(0.5986, device='cuda:0') tensor(2.7576e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.001175
Average KL loss: 0.043930
Average total loss: 0.045106
tensor(0.0900, device='cuda:0') tensor(0.5986, device='cuda:0') tensor(4.7944e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.001224
Average KL loss: 0.043930
Average total loss: 0.045154
tensor(0.0900, device='cuda:0') tensor(0.5986, device='cuda:0') tensor(4.1867e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.001242
Average KL loss: 0.043929
Average total loss: 0.045171
tensor(0.0900, device='cuda:0') tensor(0.5986, device='cuda:0') tensor(1.0130e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.001304
Average KL loss: 0.043929
Average total loss: 0.045232
tensor(0.0900, device='cuda:0') tensor(0.5986, device='cuda:0') tensor(1.1735e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.001512
Average KL loss: 0.043928
Average total loss: 0.045440
tensor(0.0900, device='cuda:0') tensor(0.5986, device='cuda:0') tensor(3.1800e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.000876
Average KL loss: 0.043927
Average total loss: 0.044804
tensor(0.0900, device='cuda:0') tensor(0.5986, device='cuda:0') tensor(5.4988e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.001411
Average KL loss: 0.043927
Average total loss: 0.045337
tensor(0.0900, device='cuda:0') tensor(0.5986, device='cuda:0') tensor(4.5729e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.001318
Average KL loss: 0.043926
Average total loss: 0.045244
tensor(0.0900, device='cuda:0') tensor(0.5986, device='cuda:0') tensor(-2.8042e-11, device='cuda:0')
 Percentile value: 2.2754844188690186
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =    1026 /    1728             ( 59.38%) | total_pruned =     702 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    9333 /   36864             ( 25.32%) | total_pruned =   27531 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    9853 /   36864             ( 26.73%) | total_pruned =   27011 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    9167 /   36864             ( 24.87%) | total_pruned =   27697 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9227 /   36864             ( 25.03%) | total_pruned =   27637 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   17753 /   73728             ( 24.08%) | total_pruned =   55975 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   33364 /  147456             ( 22.63%) | total_pruned =  114092 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3545 /    8192             ( 43.27%) | total_pruned =    4647 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   25945 /  147456             ( 17.60%) | total_pruned =  121511 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   26473 /  147456             ( 17.95%) | total_pruned =  120983 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   65221 /  294912             ( 22.12%) | total_pruned =  229691 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  116685 /  589824             ( 19.78%) | total_pruned =  473139 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     193 /     256             ( 75.39%) | total_pruned =      63 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   12049 /   32768             ( 36.77%) | total_pruned =   20719 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     191 /     256             ( 74.61%) | total_pruned =      65 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   67964 /  589824             ( 11.52%) | total_pruned =  521860 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     195 /     256             ( 76.17%) | total_pruned =      61 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   66716 /  589824             ( 11.31%) | total_pruned =  523108 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  190054 / 1179648             ( 16.11%) | total_pruned =  989594 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     445 /     512             ( 86.91%) | total_pruned =      67 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  194599 / 2359296             (  8.25%) | total_pruned = 2164697 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     264 /     512             ( 51.56%) | total_pruned =     248 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   24277 /  131072             ( 18.52%) | total_pruned =  106795 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     416 /     512             ( 81.25%) | total_pruned =      96 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     246 /     512             ( 48.05%) | total_pruned =     266 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   83875 / 2359296             (  3.56%) | total_pruned = 2275421 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     330 /     512             ( 64.45%) | total_pruned =     182 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     232 /     512             ( 45.31%) | total_pruned =     280 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   28390 / 2359296             (  1.20%) | total_pruned = 2330906 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
linear.weight        | nonzeros =    3495 /    5120             ( 68.26%) | total_pruned =    1625 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 30/200 Loss: 0.000026 Accuracy: 85.96 100.00 % Best test Accuracy: 86.04%
tensor(0.0900, device='cuda:0') tensor(0.5986, device='cuda:0') tensor(-1.2570e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.010576
Average KL loss: 0.028977
Average total loss: 0.039553
tensor(0.1487, device='cuda:0') tensor(0.3508, device='cuda:0') tensor(-9.7072e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.010378
Average KL loss: 0.025223
Average total loss: 0.035601
tensor(0.1445, device='cuda:0') tensor(0.3801, device='cuda:0') tensor(-2.8917e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.010718
Average KL loss: 0.025914
Average total loss: 0.036632
tensor(0.1431, device='cuda:0') tensor(0.4099, device='cuda:0') tensor(-7.7173e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.009800
Average KL loss: 0.026804
Average total loss: 0.036604
tensor(0.1422, device='cuda:0') tensor(0.4416, device='cuda:0') tensor(-1.6341e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.008767
Average KL loss: 0.027517
Average total loss: 0.036284
tensor(0.1415, device='cuda:0') tensor(0.4675, device='cuda:0') tensor(8.3359e-11, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.007321
Average KL loss: 0.028157
Average total loss: 0.035478
tensor(0.1407, device='cuda:0') tensor(0.4900, device='cuda:0') tensor(-1.6227e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.008036
Average KL loss: 0.028715
Average total loss: 0.036751
tensor(0.1400, device='cuda:0') tensor(0.5130, device='cuda:0') tensor(-9.6610e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.007162
Average KL loss: 0.029302
Average total loss: 0.036464
tensor(0.1394, device='cuda:0') tensor(0.5356, device='cuda:0') tensor(-9.2867e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.007326
Average KL loss: 0.029927
Average total loss: 0.037253
tensor(0.1390, device='cuda:0') tensor(0.5599, device='cuda:0') tensor(-1.4306e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.006179
Average KL loss: 0.030413
Average total loss: 0.036592
tensor(0.1384, device='cuda:0') tensor(0.5771, device='cuda:0') tensor(-2.2224e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.005212
Average KL loss: 0.030742
Average total loss: 0.035955
tensor(0.1378, device='cuda:0') tensor(0.5920, device='cuda:0') tensor(-8.2466e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.004726
Average KL loss: 0.030977
Average total loss: 0.035704
tensor(0.1372, device='cuda:0') tensor(0.6029, device='cuda:0') tensor(2.5074e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.003987
Average KL loss: 0.031130
Average total loss: 0.035117
tensor(0.1366, device='cuda:0') tensor(0.6127, device='cuda:0') tensor(-6.7115e-11, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.004847
Average KL loss: 0.031340
Average total loss: 0.036187
tensor(0.1360, device='cuda:0') tensor(0.6264, device='cuda:0') tensor(3.3594e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.005092
Average KL loss: 0.031753
Average total loss: 0.036845
tensor(0.1356, device='cuda:0') tensor(0.6452, device='cuda:0') tensor(-3.8156e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.003989
Average KL loss: 0.032046
Average total loss: 0.036036
tensor(0.1351, device='cuda:0') tensor(0.6563, device='cuda:0') tensor(8.5973e-11, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.003988
Average KL loss: 0.032271
Average total loss: 0.036259
tensor(0.1346, device='cuda:0') tensor(0.6690, device='cuda:0') tensor(-2.7893e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.003105
Average KL loss: 0.032455
Average total loss: 0.035560
tensor(0.1340, device='cuda:0') tensor(0.6775, device='cuda:0') tensor(7.7652e-11, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.003197
Average KL loss: 0.032504
Average total loss: 0.035701
tensor(0.1335, device='cuda:0') tensor(0.6856, device='cuda:0') tensor(-6.1195e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.003182
Average KL loss: 0.032630
Average total loss: 0.035812
tensor(0.1330, device='cuda:0') tensor(0.6942, device='cuda:0') tensor(-1.2151e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.003764
Average KL loss: 0.032878
Average total loss: 0.036642
tensor(0.1326, device='cuda:0') tensor(0.7094, device='cuda:0') tensor(-2.0105e-11, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.002920
Average KL loss: 0.033147
Average total loss: 0.036067
tensor(0.1322, device='cuda:0') tensor(0.7196, device='cuda:0') tensor(-1.4872e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.002525
Average KL loss: 0.033216
Average total loss: 0.035742
tensor(0.1316, device='cuda:0') tensor(0.7254, device='cuda:0') tensor(-3.6342e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.002299
Average KL loss: 0.033182
Average total loss: 0.035481
tensor(0.1310, device='cuda:0') tensor(0.7282, device='cuda:0') tensor(-1.5162e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.002131
Average KL loss: 0.033115
Average total loss: 0.035246
tensor(0.1310, device='cuda:0') tensor(0.7275, device='cuda:0') tensor(-3.2919e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.002129
Average KL loss: 0.033058
Average total loss: 0.035187
tensor(0.1309, device='cuda:0') tensor(0.7264, device='cuda:0') tensor(-5.7234e-11, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.001846
Average KL loss: 0.032997
Average total loss: 0.034843
tensor(0.1308, device='cuda:0') tensor(0.7253, device='cuda:0') tensor(-4.9519e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.001848
Average KL loss: 0.032935
Average total loss: 0.034783
tensor(0.1308, device='cuda:0') tensor(0.7242, device='cuda:0') tensor(-1.5909e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.001983
Average KL loss: 0.032876
Average total loss: 0.034859
tensor(0.1307, device='cuda:0') tensor(0.7231, device='cuda:0') tensor(-9.7697e-12, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.001964
Average KL loss: 0.032815
Average total loss: 0.034779
tensor(0.1306, device='cuda:0') tensor(0.7220, device='cuda:0') tensor(-4.1442e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.001801
Average KL loss: 0.032754
Average total loss: 0.034555
tensor(0.1305, device='cuda:0') tensor(0.7209, device='cuda:0') tensor(-1.2665e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.001763
Average KL loss: 0.032693
Average total loss: 0.034455
tensor(0.1304, device='cuda:0') tensor(0.7197, device='cuda:0') tensor(2.2848e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.001436
Average KL loss: 0.032630
Average total loss: 0.034065
tensor(0.1303, device='cuda:0') tensor(0.7185, device='cuda:0') tensor(2.6301e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.001383
Average KL loss: 0.032565
Average total loss: 0.033948
tensor(0.1302, device='cuda:0') tensor(0.7173, device='cuda:0') tensor(2.1006e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.001697
Average KL loss: 0.032500
Average total loss: 0.034197
tensor(0.1301, device='cuda:0') tensor(0.7161, device='cuda:0') tensor(-1.4348e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.001363
Average KL loss: 0.032436
Average total loss: 0.033799
tensor(0.1300, device='cuda:0') tensor(0.7148, device='cuda:0') tensor(2.5846e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.001365
Average KL loss: 0.032369
Average total loss: 0.033734
tensor(0.1299, device='cuda:0') tensor(0.7135, device='cuda:0') tensor(-6.7866e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.001233
Average KL loss: 0.032301
Average total loss: 0.033534
tensor(0.1298, device='cuda:0') tensor(0.7122, device='cuda:0') tensor(-9.5406e-11, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.001341
Average KL loss: 0.032233
Average total loss: 0.033574
tensor(0.1297, device='cuda:0') tensor(0.7108, device='cuda:0') tensor(1.0477e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.001481
Average KL loss: 0.032165
Average total loss: 0.033646
tensor(0.1296, device='cuda:0') tensor(0.7096, device='cuda:0') tensor(6.2209e-11, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.001391
Average KL loss: 0.032098
Average total loss: 0.033489
tensor(0.1295, device='cuda:0') tensor(0.7082, device='cuda:0') tensor(7.5751e-11, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.001203
Average KL loss: 0.032029
Average total loss: 0.033232
tensor(0.1294, device='cuda:0') tensor(0.7068, device='cuda:0') tensor(1.4670e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.001005
Average KL loss: 0.031956
Average total loss: 0.032961
tensor(0.1293, device='cuda:0') tensor(0.7054, device='cuda:0') tensor(2.7609e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.001355
Average KL loss: 0.031884
Average total loss: 0.033239
tensor(0.1292, device='cuda:0') tensor(0.7040, device='cuda:0') tensor(4.3559e-11, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.001166
Average KL loss: 0.031812
Average total loss: 0.032978
tensor(0.1290, device='cuda:0') tensor(0.7025, device='cuda:0') tensor(2.1937e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.001081
Average KL loss: 0.031738
Average total loss: 0.032819
tensor(0.1289, device='cuda:0') tensor(0.7010, device='cuda:0') tensor(-7.2651e-11, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.001048
Average KL loss: 0.031664
Average total loss: 0.032713
tensor(0.1288, device='cuda:0') tensor(0.6995, device='cuda:0') tensor(-5.3261e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.001157
Average KL loss: 0.031589
Average total loss: 0.032747
tensor(0.1286, device='cuda:0') tensor(0.6980, device='cuda:0') tensor(2.2092e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.001198
Average KL loss: 0.031515
Average total loss: 0.032713
tensor(0.1285, device='cuda:0') tensor(0.6966, device='cuda:0') tensor(1.1234e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.001062
Average KL loss: 0.031440
Average total loss: 0.032502
tensor(0.1284, device='cuda:0') tensor(0.6950, device='cuda:0') tensor(2.8687e-11, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.000980
Average KL loss: 0.031363
Average total loss: 0.032342
tensor(0.1282, device='cuda:0') tensor(0.6935, device='cuda:0') tensor(5.8384e-11, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.001139
Average KL loss: 0.031286
Average total loss: 0.032425
tensor(0.1281, device='cuda:0') tensor(0.6919, device='cuda:0') tensor(1.8907e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.000922
Average KL loss: 0.031208
Average total loss: 0.032131
tensor(0.1279, device='cuda:0') tensor(0.6903, device='cuda:0') tensor(-1.2664e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.000970
Average KL loss: 0.031128
Average total loss: 0.032098
tensor(0.1278, device='cuda:0') tensor(0.6886, device='cuda:0') tensor(2.6680e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.001084
Average KL loss: 0.031047
Average total loss: 0.032131
tensor(0.1276, device='cuda:0') tensor(0.6870, device='cuda:0') tensor(5.9454e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.001071
Average KL loss: 0.030967
Average total loss: 0.032038
tensor(0.1275, device='cuda:0') tensor(0.6854, device='cuda:0') tensor(2.8702e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.001049
Average KL loss: 0.030887
Average total loss: 0.031936
tensor(0.1273, device='cuda:0') tensor(0.6837, device='cuda:0') tensor(2.2892e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.001035
Average KL loss: 0.030808
Average total loss: 0.031843
tensor(0.1271, device='cuda:0') tensor(0.6821, device='cuda:0') tensor(1.0268e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.001054
Average KL loss: 0.030728
Average total loss: 0.031783
tensor(0.1270, device='cuda:0') tensor(0.6805, device='cuda:0') tensor(-1.4549e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.000862
Average KL loss: 0.030647
Average total loss: 0.031508
tensor(0.1268, device='cuda:0') tensor(0.6787, device='cuda:0') tensor(-8.5971e-11, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.000982
Average KL loss: 0.030563
Average total loss: 0.031545
tensor(0.1266, device='cuda:0') tensor(0.6770, device='cuda:0') tensor(2.9755e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.001025
Average KL loss: 0.030481
Average total loss: 0.031506
tensor(0.1265, device='cuda:0') tensor(0.6753, device='cuda:0') tensor(1.4924e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.001018
Average KL loss: 0.030398
Average total loss: 0.031415
tensor(0.1263, device='cuda:0') tensor(0.6735, device='cuda:0') tensor(1.2214e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.000882
Average KL loss: 0.030313
Average total loss: 0.031196
tensor(0.1261, device='cuda:0') tensor(0.6717, device='cuda:0') tensor(2.8078e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.000879
Average KL loss: 0.030225
Average total loss: 0.031104
tensor(0.1259, device='cuda:0') tensor(0.6698, device='cuda:0') tensor(7.6008e-11, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.000858
Average KL loss: 0.030135
Average total loss: 0.030992
tensor(0.1257, device='cuda:0') tensor(0.6680, device='cuda:0') tensor(3.5070e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.000926
Average KL loss: 0.030046
Average total loss: 0.030972
tensor(0.1255, device='cuda:0') tensor(0.6662, device='cuda:0') tensor(3.2956e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.000880
Average KL loss: 0.029958
Average total loss: 0.030838
tensor(0.1253, device='cuda:0') tensor(0.6643, device='cuda:0') tensor(2.7067e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.000974
Average KL loss: 0.029869
Average total loss: 0.030842
tensor(0.1251, device='cuda:0') tensor(0.6624, device='cuda:0') tensor(2.1191e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.000940
Average KL loss: 0.029779
Average total loss: 0.030720
tensor(0.1249, device='cuda:0') tensor(0.6605, device='cuda:0') tensor(-2.6608e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.000920
Average KL loss: 0.029691
Average total loss: 0.030612
tensor(0.1247, device='cuda:0') tensor(0.6586, device='cuda:0') tensor(2.0959e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.000872
Average KL loss: 0.029602
Average total loss: 0.030474
tensor(0.1245, device='cuda:0') tensor(0.6568, device='cuda:0') tensor(3.1182e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.000866
Average KL loss: 0.029512
Average total loss: 0.030377
tensor(0.1243, device='cuda:0') tensor(0.6548, device='cuda:0') tensor(3.1235e-11, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.000805
Average KL loss: 0.029420
Average total loss: 0.030225
tensor(0.1241, device='cuda:0') tensor(0.6529, device='cuda:0') tensor(2.4488e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.000913
Average KL loss: 0.029330
Average total loss: 0.030243
tensor(0.1239, device='cuda:0') tensor(0.6510, device='cuda:0') tensor(1.4676e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.000870
Average KL loss: 0.029240
Average total loss: 0.030111
tensor(0.1237, device='cuda:0') tensor(0.6491, device='cuda:0') tensor(2.9907e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.000729
Average KL loss: 0.029145
Average total loss: 0.029874
tensor(0.1235, device='cuda:0') tensor(0.6470, device='cuda:0') tensor(2.2906e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.000924
Average KL loss: 0.029050
Average total loss: 0.029974
tensor(0.1233, device='cuda:0') tensor(0.6450, device='cuda:0') tensor(2.8201e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.001016
Average KL loss: 0.028959
Average total loss: 0.029976
tensor(0.1231, device='cuda:0') tensor(0.6431, device='cuda:0') tensor(3.0899e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.000843
Average KL loss: 0.028870
Average total loss: 0.029713
tensor(0.1228, device='cuda:0') tensor(0.6412, device='cuda:0') tensor(3.0420e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.000866
Average KL loss: 0.028779
Average total loss: 0.029645
tensor(0.1226, device='cuda:0') tensor(0.6392, device='cuda:0') tensor(2.7273e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.000813
Average KL loss: 0.028685
Average total loss: 0.029498
tensor(0.1224, device='cuda:0') tensor(0.6372, device='cuda:0') tensor(3.5203e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.000801
Average KL loss: 0.028592
Average total loss: 0.029393
tensor(0.1222, device='cuda:0') tensor(0.6352, device='cuda:0') tensor(1.5099e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.000927
Average KL loss: 0.028498
Average total loss: 0.029425
tensor(0.1219, device='cuda:0') tensor(0.6332, device='cuda:0') tensor(-1.0436e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.001082
Average KL loss: 0.028410
Average total loss: 0.029491
tensor(0.1217, device='cuda:0') tensor(0.6313, device='cuda:0') tensor(3.3735e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.000826
Average KL loss: 0.028320
Average total loss: 0.029147
tensor(0.1215, device='cuda:0') tensor(0.6294, device='cuda:0') tensor(1.3959e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.000750
Average KL loss: 0.028228
Average total loss: 0.028977
tensor(0.1213, device='cuda:0') tensor(0.6273, device='cuda:0') tensor(1.6373e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.000756
Average KL loss: 0.028133
Average total loss: 0.028889
tensor(0.1210, device='cuda:0') tensor(0.6253, device='cuda:0') tensor(3.8474e-11, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.000871
Average KL loss: 0.028038
Average total loss: 0.028910
tensor(0.1208, device='cuda:0') tensor(0.6233, device='cuda:0') tensor(1.9593e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.000873
Average KL loss: 0.027948
Average total loss: 0.028821
tensor(0.1206, device='cuda:0') tensor(0.6213, device='cuda:0') tensor(3.2095e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.000740
Average KL loss: 0.027854
Average total loss: 0.028595
tensor(0.1203, device='cuda:0') tensor(0.6192, device='cuda:0') tensor(-3.2994e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.000865
Average KL loss: 0.027760
Average total loss: 0.028625
tensor(0.1201, device='cuda:0') tensor(0.6172, device='cuda:0') tensor(2.7119e-11, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.000820
Average KL loss: 0.027667
Average total loss: 0.028488
tensor(0.1198, device='cuda:0') tensor(0.6151, device='cuda:0') tensor(2.6039e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.000734
Average KL loss: 0.027576
Average total loss: 0.028311
tensor(0.1196, device='cuda:0') tensor(0.6131, device='cuda:0') tensor(2.6122e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.000851
Average KL loss: 0.027483
Average total loss: 0.028334
tensor(0.1193, device='cuda:0') tensor(0.6111, device='cuda:0') tensor(3.3855e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.000636
Average KL loss: 0.027389
Average total loss: 0.028025
tensor(0.1191, device='cuda:0') tensor(0.6089, device='cuda:0') tensor(2.7479e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.000873
Average KL loss: 0.027294
Average total loss: 0.028167
tensor(0.1188, device='cuda:0') tensor(0.6069, device='cuda:0') tensor(-7.5855e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.000732
Average KL loss: 0.027202
Average total loss: 0.027934
tensor(0.1186, device='cuda:0') tensor(0.6048, device='cuda:0') tensor(3.6013e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.000694
Average KL loss: 0.027108
Average total loss: 0.027802
tensor(0.1183, device='cuda:0') tensor(0.6028, device='cuda:0') tensor(2.0388e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.000756
Average KL loss: 0.027012
Average total loss: 0.027768
tensor(0.1181, device='cuda:0') tensor(0.6006, device='cuda:0') tensor(2.9052e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.000807
Average KL loss: 0.026916
Average total loss: 0.027724
tensor(0.1178, device='cuda:0') tensor(0.5985, device='cuda:0') tensor(3.2844e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.000721
Average KL loss: 0.026824
Average total loss: 0.027545
tensor(0.1176, device='cuda:0') tensor(0.5965, device='cuda:0') tensor(3.0430e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.000845
Average KL loss: 0.026731
Average total loss: 0.027576
tensor(0.1173, device='cuda:0') tensor(0.5944, device='cuda:0') tensor(3.3177e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.000698
Average KL loss: 0.026638
Average total loss: 0.027335
tensor(0.1170, device='cuda:0') tensor(0.5923, device='cuda:0') tensor(2.0878e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.000642
Average KL loss: 0.026543
Average total loss: 0.027185
tensor(0.1168, device='cuda:0') tensor(0.5902, device='cuda:0') tensor(2.5376e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.000770
Average KL loss: 0.026446
Average total loss: 0.027216
tensor(0.1165, device='cuda:0') tensor(0.5880, device='cuda:0') tensor(2.6147e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.000653
Average KL loss: 0.026352
Average total loss: 0.027006
tensor(0.1162, device='cuda:0') tensor(0.5859, device='cuda:0') tensor(3.2996e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.000777
Average KL loss: 0.026256
Average total loss: 0.027033
tensor(0.1160, device='cuda:0') tensor(0.5838, device='cuda:0') tensor(2.9355e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.000651
Average KL loss: 0.026162
Average total loss: 0.026813
tensor(0.1157, device='cuda:0') tensor(0.5817, device='cuda:0') tensor(2.7048e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.000846
Average KL loss: 0.026068
Average total loss: 0.026914
tensor(0.1154, device='cuda:0') tensor(0.5797, device='cuda:0') tensor(3.6011e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.000694
Average KL loss: 0.025977
Average total loss: 0.026670
tensor(0.1152, device='cuda:0') tensor(0.5776, device='cuda:0') tensor(3.2612e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.000725
Average KL loss: 0.025883
Average total loss: 0.026609
tensor(0.1149, device='cuda:0') tensor(0.5755, device='cuda:0') tensor(2.5363e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.000706
Average KL loss: 0.025788
Average total loss: 0.026495
tensor(0.1146, device='cuda:0') tensor(0.5733, device='cuda:0') tensor(3.2233e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.000884
Average KL loss: 0.025697
Average total loss: 0.026581
tensor(0.1143, device='cuda:0') tensor(0.5714, device='cuda:0') tensor(3.6382e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.000626
Average KL loss: 0.025609
Average total loss: 0.026235
tensor(0.1141, device='cuda:0') tensor(0.5693, device='cuda:0') tensor(3.6046e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.000616
Average KL loss: 0.025512
Average total loss: 0.026128
tensor(0.1138, device='cuda:0') tensor(0.5671, device='cuda:0') tensor(2.4287e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.000674
Average KL loss: 0.025417
Average total loss: 0.026091
tensor(0.1135, device='cuda:0') tensor(0.5651, device='cuda:0') tensor(3.6559e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.000712
Average KL loss: 0.025325
Average total loss: 0.026037
tensor(0.1133, device='cuda:0') tensor(0.5630, device='cuda:0') tensor(1.4967e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.000603
Average KL loss: 0.025231
Average total loss: 0.025834
tensor(0.1130, device='cuda:0') tensor(0.5608, device='cuda:0') tensor(3.0277e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.000621
Average KL loss: 0.025132
Average total loss: 0.025754
tensor(0.1127, device='cuda:0') tensor(0.5587, device='cuda:0') tensor(2.6284e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.000629
Average KL loss: 0.025041
Average total loss: 0.025670
tensor(0.1124, device='cuda:0') tensor(0.5566, device='cuda:0') tensor(8.2301e-11, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.000637
Average KL loss: 0.024946
Average total loss: 0.025583
tensor(0.1121, device='cuda:0') tensor(0.5544, device='cuda:0') tensor(4.0702e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.000776
Average KL loss: 0.024851
Average total loss: 0.025627
tensor(0.1119, device='cuda:0') tensor(0.5524, device='cuda:0') tensor(3.5577e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.000652
Average KL loss: 0.024762
Average total loss: 0.025414
tensor(0.1116, device='cuda:0') tensor(0.5503, device='cuda:0') tensor(2.0867e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.000693
Average KL loss: 0.024670
Average total loss: 0.025362
tensor(0.1113, device='cuda:0') tensor(0.5483, device='cuda:0') tensor(2.5790e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.000769
Average KL loss: 0.024579
Average total loss: 0.025348
tensor(0.1110, device='cuda:0') tensor(0.5463, device='cuda:0') tensor(3.9851e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.000598
Average KL loss: 0.024493
Average total loss: 0.025091
tensor(0.1107, device='cuda:0') tensor(0.5443, device='cuda:0') tensor(2.2611e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.000585
Average KL loss: 0.024401
Average total loss: 0.024986
tensor(0.1104, device='cuda:0') tensor(0.5422, device='cuda:0') tensor(1.8092e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.000825
Average KL loss: 0.024311
Average total loss: 0.025136
tensor(0.1102, device='cuda:0') tensor(0.5403, device='cuda:0') tensor(3.5182e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.000567
Average KL loss: 0.024222
Average total loss: 0.024788
tensor(0.1099, device='cuda:0') tensor(0.5381, device='cuda:0') tensor(3.2411e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.000730
Average KL loss: 0.024129
Average total loss: 0.024859
tensor(0.1096, device='cuda:0') tensor(0.5361, device='cuda:0') tensor(3.1994e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.000738
Average KL loss: 0.024043
Average total loss: 0.024781
tensor(0.1093, device='cuda:0') tensor(0.5341, device='cuda:0') tensor(4.2865e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.000699
Average KL loss: 0.023955
Average total loss: 0.024654
tensor(0.1090, device='cuda:0') tensor(0.5321, device='cuda:0') tensor(2.6460e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.000761
Average KL loss: 0.023869
Average total loss: 0.024630
tensor(0.1088, device='cuda:0') tensor(0.5302, device='cuda:0') tensor(2.5834e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.000523
Average KL loss: 0.023781
Average total loss: 0.024304
tensor(0.1085, device='cuda:0') tensor(0.5281, device='cuda:0') tensor(1.8364e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.000776
Average KL loss: 0.023689
Average total loss: 0.024465
tensor(0.1082, device='cuda:0') tensor(0.5261, device='cuda:0') tensor(3.5992e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.000668
Average KL loss: 0.023607
Average total loss: 0.024275
tensor(0.1079, device='cuda:0') tensor(0.5242, device='cuda:0') tensor(2.9724e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.000606
Average KL loss: 0.023520
Average total loss: 0.024126
tensor(0.1076, device='cuda:0') tensor(0.5222, device='cuda:0') tensor(3.5857e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.000557
Average KL loss: 0.023428
Average total loss: 0.023985
tensor(0.1074, device='cuda:0') tensor(0.5201, device='cuda:0') tensor(3.7044e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.000652
Average KL loss: 0.023337
Average total loss: 0.023989
tensor(0.1071, device='cuda:0') tensor(0.5181, device='cuda:0') tensor(3.4583e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.000583
Average KL loss: 0.023247
Average total loss: 0.023830
tensor(0.1068, device='cuda:0') tensor(0.5160, device='cuda:0') tensor(1.3624e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.000700
Average KL loss: 0.023158
Average total loss: 0.023858
tensor(0.1065, device='cuda:0') tensor(0.5141, device='cuda:0') tensor(-4.6709e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.000585
Average KL loss: 0.023073
Average total loss: 0.023657
tensor(0.1062, device='cuda:0') tensor(0.5121, device='cuda:0') tensor(3.3233e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.000625
Average KL loss: 0.022981
Average total loss: 0.023605
tensor(0.1059, device='cuda:0') tensor(0.5100, device='cuda:0') tensor(3.9095e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.000548
Average KL loss: 0.022893
Average total loss: 0.023441
tensor(0.1056, device='cuda:0') tensor(0.5080, device='cuda:0') tensor(9.6507e-12, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.000678
Average KL loss: 0.022804
Average total loss: 0.023481
tensor(0.1054, device='cuda:0') tensor(0.5061, device='cuda:0') tensor(3.4985e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.000658
Average KL loss: 0.022721
Average total loss: 0.023379
tensor(0.1051, device='cuda:0') tensor(0.5042, device='cuda:0') tensor(-3.0987e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.000897
Average KL loss: 0.022641
Average total loss: 0.023538
tensor(0.1048, device='cuda:0') tensor(0.5024, device='cuda:0') tensor(3.3462e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.000739
Average KL loss: 0.022566
Average total loss: 0.023305
tensor(0.1045, device='cuda:0') tensor(0.5007, device='cuda:0') tensor(-2.8550e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.000937
Average KL loss: 0.022499
Average total loss: 0.023436
tensor(0.1043, device='cuda:0') tensor(0.4992, device='cuda:0') tensor(3.6946e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.000792
Average KL loss: 0.022433
Average total loss: 0.023225
tensor(0.1040, device='cuda:0') tensor(0.4975, device='cuda:0') tensor(3.2605e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.000817
Average KL loss: 0.022364
Average total loss: 0.023180
tensor(0.1037, device='cuda:0') tensor(0.4959, device='cuda:0') tensor(3.2556e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.000599
Average KL loss: 0.022291
Average total loss: 0.022889
tensor(0.1035, device='cuda:0') tensor(0.4941, device='cuda:0') tensor(3.0635e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.000685
Average KL loss: 0.022213
Average total loss: 0.022898
tensor(0.1032, device='cuda:0') tensor(0.4923, device='cuda:0') tensor(3.0209e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.000711
Average KL loss: 0.022134
Average total loss: 0.022845
tensor(0.1030, device='cuda:0') tensor(0.4905, device='cuda:0') tensor(3.3317e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.000604
Average KL loss: 0.022061
Average total loss: 0.022665
tensor(0.1027, device='cuda:0') tensor(0.4889, device='cuda:0') tensor(3.0310e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.000621
Average KL loss: 0.021983
Average total loss: 0.022604
tensor(0.1024, device='cuda:0') tensor(0.4870, device='cuda:0') tensor(4.5780e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.000741
Average KL loss: 0.021906
Average total loss: 0.022647
tensor(0.1022, device='cuda:0') tensor(0.4854, device='cuda:0') tensor(3.8818e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.000790
Average KL loss: 0.021839
Average total loss: 0.022629
tensor(0.1019, device='cuda:0') tensor(0.4838, device='cuda:0') tensor(-2.2910e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.001064
Average KL loss: 0.021775
Average total loss: 0.022839
tensor(0.1017, device='cuda:0') tensor(0.4824, device='cuda:0') tensor(3.1258e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.000659
Average KL loss: 0.021718
Average total loss: 0.022376
tensor(0.1014, device='cuda:0') tensor(0.4808, device='cuda:0') tensor(1.7284e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.000737
Average KL loss: 0.021647
Average total loss: 0.022384
tensor(0.1012, device='cuda:0') tensor(0.4792, device='cuda:0') tensor(3.9266e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.000839
Average KL loss: 0.021582
Average total loss: 0.022421
tensor(0.1009, device='cuda:0') tensor(0.4777, device='cuda:0') tensor(2.9420e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.000820
Average KL loss: 0.021519
Average total loss: 0.022339
tensor(0.1007, device='cuda:0') tensor(0.4762, device='cuda:0') tensor(3.1322e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.000580
Average KL loss: 0.021455
Average total loss: 0.022035
tensor(0.1005, device='cuda:0') tensor(0.4746, device='cuda:0') tensor(2.1772e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.000776
Average KL loss: 0.021387
Average total loss: 0.022163
tensor(0.1002, device='cuda:0') tensor(0.4731, device='cuda:0') tensor(3.6246e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.000773
Average KL loss: 0.021322
Average total loss: 0.022095
tensor(0.1000, device='cuda:0') tensor(0.4716, device='cuda:0') tensor(3.7169e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.000839
Average KL loss: 0.021260
Average total loss: 0.022099
tensor(0.0998, device='cuda:0') tensor(0.4702, device='cuda:0') tensor(4.9744e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.000791
Average KL loss: 0.021200
Average total loss: 0.021992
tensor(0.0995, device='cuda:0') tensor(0.4688, device='cuda:0') tensor(3.0404e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.000691
Average KL loss: 0.021135
Average total loss: 0.021826
tensor(0.0993, device='cuda:0') tensor(0.4673, device='cuda:0') tensor(2.6330e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.000581
Average KL loss: 0.021071
Average total loss: 0.021651
tensor(0.0991, device='cuda:0') tensor(0.4657, device='cuda:0') tensor(3.3078e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.000790
Average KL loss: 0.021004
Average total loss: 0.021794
tensor(0.0988, device='cuda:0') tensor(0.4643, device='cuda:0') tensor(3.8482e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.000725
Average KL loss: 0.020944
Average total loss: 0.021670
tensor(0.0986, device='cuda:0') tensor(0.4628, device='cuda:0') tensor(3.5733e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.000700
Average KL loss: 0.020881
Average total loss: 0.021581
tensor(0.0984, device='cuda:0') tensor(0.4614, device='cuda:0') tensor(6.6130e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.001040
Average KL loss: 0.020821
Average total loss: 0.021861
tensor(0.0982, device='cuda:0') tensor(0.4601, device='cuda:0') tensor(2.5589e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.000775
Average KL loss: 0.020768
Average total loss: 0.021543
tensor(0.0980, device='cuda:0') tensor(0.4588, device='cuda:0') tensor(2.6048e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.000898
Average KL loss: 0.020713
Average total loss: 0.021611
tensor(0.0978, device='cuda:0') tensor(0.4576, device='cuda:0') tensor(1.9109e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.000783
Average KL loss: 0.020666
Average total loss: 0.021449
tensor(0.0975, device='cuda:0') tensor(0.4563, device='cuda:0') tensor(3.4728e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.000791
Average KL loss: 0.020606
Average total loss: 0.021398
tensor(0.0973, device='cuda:0') tensor(0.4549, device='cuda:0') tensor(1.4536e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.000707
Average KL loss: 0.020548
Average total loss: 0.021255
tensor(0.0971, device='cuda:0') tensor(0.4536, device='cuda:0') tensor(1.8071e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.000670
Average KL loss: 0.020490
Average total loss: 0.021160
tensor(0.0969, device='cuda:0') tensor(0.4522, device='cuda:0') tensor(2.4043e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.000718
Average KL loss: 0.020428
Average total loss: 0.021146
tensor(0.0967, device='cuda:0') tensor(0.4508, device='cuda:0') tensor(3.4895e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.000753
Average KL loss: 0.020369
Average total loss: 0.021122
tensor(0.0965, device='cuda:0') tensor(0.4495, device='cuda:0') tensor(3.4438e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.000873
Average KL loss: 0.020315
Average total loss: 0.021187
tensor(0.0963, device='cuda:0') tensor(0.4483, device='cuda:0') tensor(3.1510e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.000697
Average KL loss: 0.020266
Average total loss: 0.020963
tensor(0.0960, device='cuda:0') tensor(0.4470, device='cuda:0') tensor(7.6834e-11, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.000636
Average KL loss: 0.020206
Average total loss: 0.020843
tensor(0.0958, device='cuda:0') tensor(0.4457, device='cuda:0') tensor(-2.3425e-11, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.000750
Average KL loss: 0.020151
Average total loss: 0.020901
tensor(0.0956, device='cuda:0') tensor(0.4444, device='cuda:0') tensor(-1.2408e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.000680
Average KL loss: 0.020095
Average total loss: 0.020775
tensor(0.0954, device='cuda:0') tensor(0.4431, device='cuda:0') tensor(3.4931e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.000674
Average KL loss: 0.020036
Average total loss: 0.020710
tensor(0.0952, device='cuda:0') tensor(0.4418, device='cuda:0') tensor(5.8938e-11, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.000660
Average KL loss: 0.019980
Average total loss: 0.020640
tensor(0.0950, device='cuda:0') tensor(0.4405, device='cuda:0') tensor(3.0744e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.000656
Average KL loss: 0.019921
Average total loss: 0.020577
tensor(0.0948, device='cuda:0') tensor(0.4391, device='cuda:0') tensor(4.6240e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.000808
Average KL loss: 0.019863
Average total loss: 0.020671
tensor(0.0946, device='cuda:0') tensor(0.4378, device='cuda:0') tensor(2.6593e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.000802
Average KL loss: 0.019815
Average total loss: 0.020617
tensor(0.0944, device='cuda:0') tensor(0.4367, device='cuda:0') tensor(3.3466e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.000746
Average KL loss: 0.019765
Average total loss: 0.020510
tensor(0.0942, device='cuda:0') tensor(0.4355, device='cuda:0') tensor(1.4494e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.000752
Average KL loss: 0.019712
Average total loss: 0.020463
tensor(0.0940, device='cuda:0') tensor(0.4342, device='cuda:0') tensor(3.8129e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.000684
Average KL loss: 0.019661
Average total loss: 0.020345
tensor(0.0938, device='cuda:0') tensor(0.4330, device='cuda:0') tensor(3.1368e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.000771
Average KL loss: 0.019610
Average total loss: 0.020381
tensor(0.0936, device='cuda:0') tensor(0.4319, device='cuda:0') tensor(2.6422e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.000952
Average KL loss: 0.019566
Average total loss: 0.020518
tensor(0.0934, device='cuda:0') tensor(0.4309, device='cuda:0') tensor(1.3872e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.000636
Average KL loss: 0.019523
Average total loss: 0.020159
tensor(0.0932, device='cuda:0') tensor(0.4296, device='cuda:0') tensor(2.7044e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.000689
Average KL loss: 0.019469
Average total loss: 0.020158
 Percentile value: 4.156938743591307
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =     909 /    1728             ( 52.60%) | total_pruned =     819 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4353 /   36864             ( 11.81%) | total_pruned =   32511 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4812 /   36864             ( 13.05%) | total_pruned =   32052 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4366 /   36864             ( 11.84%) | total_pruned =   32498 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4582 /   36864             ( 12.43%) | total_pruned =   32282 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8041 /   73728             ( 10.91%) | total_pruned =   65687 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   14343 /  147456             (  9.73%) | total_pruned =  133113 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2545 /    8192             ( 31.07%) | total_pruned =    5647 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    9330 /  147456             (  6.33%) | total_pruned =  138126 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    9542 /  147456             (  6.47%) | total_pruned =  137914 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   27090 /  294912             (  9.19%) | total_pruned =  267822 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     185 /     256             ( 72.27%) | total_pruned =      71 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   42902 /  589824             (  7.27%) | total_pruned =  546922 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    7584 /   32768             ( 23.14%) | total_pruned =   25184 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   18143 /  589824             (  3.08%) | total_pruned =  571681 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   17254 /  589824             (  2.93%) | total_pruned =  572570 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     179 /     256             ( 69.92%) | total_pruned =      77 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   56211 / 1179648             (  4.77%) | total_pruned = 1123437 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     410 /     512             ( 80.08%) | total_pruned =     102 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   33800 / 2359296             (  1.43%) | total_pruned = 2325496 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     481 /     512             ( 93.95%) | total_pruned =      31 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     201 /     512             ( 39.26%) | total_pruned =     311 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    9253 /  131072             (  7.06%) | total_pruned =  121819 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     402 /     512             ( 78.52%) | total_pruned =     110 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     174 /     512             ( 33.98%) | total_pruned =     338 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   13380 / 2359296             (  0.57%) | total_pruned = 2345916 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     307 /     512             ( 59.96%) | total_pruned =     205 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     128 /     512             ( 25.00%) | total_pruned =     384 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    3827 / 2359296             (  0.16%) | total_pruned = 2355469 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
linear.weight        | nonzeros =    2998 /    5120             ( 58.55%) | total_pruned =    2122 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 23/200 Loss: 0.000177 Accuracy: 85.18 100.00 % Best test Accuracy: 85.32%
tensor(0.0930, device='cuda:0') tensor(0.4285, device='cuda:0') tensor(-2.1001e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.006967
Average KL loss: 0.015055
Average total loss: 0.022022
tensor(0.0838, device='cuda:0') tensor(0.3201, device='cuda:0') tensor(-1.5620e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.011237
Average KL loss: 0.013622
Average total loss: 0.024859
tensor(0.0833, device='cuda:0') tensor(0.3229, device='cuda:0') tensor(-1.8848e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.012037
Average KL loss: 0.013526
Average total loss: 0.025563
tensor(0.0835, device='cuda:0') tensor(0.3339, device='cuda:0') tensor(-7.6134e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.012841
Average KL loss: 0.013561
Average total loss: 0.026402
tensor(0.0839, device='cuda:0') tensor(0.3473, device='cuda:0') tensor(-1.1229e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.012963
Average KL loss: 0.013644
Average total loss: 0.026607
tensor(0.0844, device='cuda:0') tensor(0.3607, device='cuda:0') tensor(-2.6245e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.013171
Average KL loss: 0.013753
Average total loss: 0.026924
tensor(0.0849, device='cuda:0') tensor(0.3745, device='cuda:0') tensor(-4.0571e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.013828
Average KL loss: 0.013873
Average total loss: 0.027700
tensor(0.0854, device='cuda:0') tensor(0.3881, device='cuda:0') tensor(-1.6175e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.014232
Average KL loss: 0.013998
Average total loss: 0.028229
tensor(0.0860, device='cuda:0') tensor(0.4020, device='cuda:0') tensor(-1.1174e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.013139
Average KL loss: 0.014128
Average total loss: 0.027267
tensor(0.0864, device='cuda:0') tensor(0.4146, device='cuda:0') tensor(-1.8842e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.011874
Average KL loss: 0.014247
Average total loss: 0.026121
tensor(0.0869, device='cuda:0') tensor(0.4260, device='cuda:0') tensor(-2.2416e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.012818
Average KL loss: 0.014367
Average total loss: 0.027185
tensor(0.0874, device='cuda:0') tensor(0.4380, device='cuda:0') tensor(-1.1784e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.012393
Average KL loss: 0.014483
Average total loss: 0.026876
tensor(0.0878, device='cuda:0') tensor(0.4494, device='cuda:0') tensor(-1.4699e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.011109
Average KL loss: 0.014545
Average total loss: 0.025654
tensor(0.0878, device='cuda:0') tensor(0.4497, device='cuda:0') tensor(-1.1770e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.009175
Average KL loss: 0.014548
Average total loss: 0.023723
tensor(0.0878, device='cuda:0') tensor(0.4499, device='cuda:0') tensor(-1.6047e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.009628
Average KL loss: 0.014550
Average total loss: 0.024178
tensor(0.0879, device='cuda:0') tensor(0.4500, device='cuda:0') tensor(-1.3190e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.009956
Average KL loss: 0.014552
Average total loss: 0.024508
tensor(0.0879, device='cuda:0') tensor(0.4501, device='cuda:0') tensor(-1.0906e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.009877
Average KL loss: 0.014555
Average total loss: 0.024432
tensor(0.0879, device='cuda:0') tensor(0.4503, device='cuda:0') tensor(-1.0852e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.009116
Average KL loss: 0.014557
Average total loss: 0.023673
tensor(0.0880, device='cuda:0') tensor(0.4505, device='cuda:0') tensor(-1.8807e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.008778
Average KL loss: 0.014558
Average total loss: 0.023337
tensor(0.0880, device='cuda:0') tensor(0.4506, device='cuda:0') tensor(-6.0907e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.008109
Average KL loss: 0.014560
Average total loss: 0.022669
tensor(0.0880, device='cuda:0') tensor(0.4507, device='cuda:0') tensor(-1.1530e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.008193
Average KL loss: 0.014561
Average total loss: 0.022754
tensor(0.0880, device='cuda:0') tensor(0.4508, device='cuda:0') tensor(-1.6650e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.008230
Average KL loss: 0.014563
Average total loss: 0.022793
tensor(0.0881, device='cuda:0') tensor(0.4510, device='cuda:0') tensor(-2.0126e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.008199
Average KL loss: 0.014564
Average total loss: 0.022763
tensor(0.0881, device='cuda:0') tensor(0.4511, device='cuda:0') tensor(-1.5774e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.007762
Average KL loss: 0.014564
Average total loss: 0.022326
tensor(0.0881, device='cuda:0') tensor(0.4511, device='cuda:0') tensor(-2.0648e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.007937
Average KL loss: 0.014564
Average total loss: 0.022501
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-5.0854e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.007099
Average KL loss: 0.014565
Average total loss: 0.021663
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-1.5609e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.008671
Average KL loss: 0.014565
Average total loss: 0.023236
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-5.5208e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.008095
Average KL loss: 0.014565
Average total loss: 0.022660
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-1.6413e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.007369
Average KL loss: 0.014565
Average total loss: 0.021934
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-1.5015e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.008666
Average KL loss: 0.014565
Average total loss: 0.023231
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-2.1819e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.008318
Average KL loss: 0.014565
Average total loss: 0.022883
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-4.0923e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.007482
Average KL loss: 0.014565
Average total loss: 0.022047
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-5.2672e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.007839
Average KL loss: 0.014565
Average total loss: 0.022404
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-2.4776e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.007288
Average KL loss: 0.014565
Average total loss: 0.021854
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-2.6883e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.007269
Average KL loss: 0.014565
Average total loss: 0.021835
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-6.1639e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.007804
Average KL loss: 0.014566
Average total loss: 0.022370
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-1.5999e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.008321
Average KL loss: 0.014566
Average total loss: 0.022887
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-1.2749e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.007388
Average KL loss: 0.014566
Average total loss: 0.021954
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-9.3473e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.007877
Average KL loss: 0.014566
Average total loss: 0.022442
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-7.9048e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.007772
Average KL loss: 0.014566
Average total loss: 0.022337
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-8.9169e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.007517
Average KL loss: 0.014566
Average total loss: 0.022083
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-1.0517e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.007581
Average KL loss: 0.014566
Average total loss: 0.022146
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-8.4990e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.007200
Average KL loss: 0.014566
Average total loss: 0.021766
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-8.0460e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.007452
Average KL loss: 0.014566
Average total loss: 0.022018
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-1.5954e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.007681
Average KL loss: 0.014566
Average total loss: 0.022247
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-2.0418e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.007497
Average KL loss: 0.014566
Average total loss: 0.022063
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-7.5299e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.007250
Average KL loss: 0.014566
Average total loss: 0.021816
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-4.2227e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.007234
Average KL loss: 0.014566
Average total loss: 0.021799
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-1.0543e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.007218
Average KL loss: 0.014566
Average total loss: 0.021783
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-5.1551e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.007548
Average KL loss: 0.014566
Average total loss: 0.022114
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-2.6708e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.007508
Average KL loss: 0.014566
Average total loss: 0.022074
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-9.7483e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.007138
Average KL loss: 0.014566
Average total loss: 0.021704
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-9.9756e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.007886
Average KL loss: 0.014566
Average total loss: 0.022452
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-1.6982e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.007167
Average KL loss: 0.014566
Average total loss: 0.021733
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-6.6154e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.007513
Average KL loss: 0.014566
Average total loss: 0.022079
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-1.8331e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.007609
Average KL loss: 0.014566
Average total loss: 0.022175
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-9.6661e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.007835
Average KL loss: 0.014566
Average total loss: 0.022401
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-2.6479e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.007879
Average KL loss: 0.014566
Average total loss: 0.022445
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-5.9747e-10, device='cuda:0')
 Percentile value: 6.293415927886962
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =     652 /    1728             ( 37.73%) | total_pruned =    1076 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
bn1.bias             | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1475 /   36864             (  4.00%) | total_pruned =   35389 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1703 /   36864             (  4.62%) | total_pruned =   35161 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1472 /   36864             (  3.99%) | total_pruned =   35392 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1611 /   36864             (  4.37%) | total_pruned =   35253 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2767 /   73728             (  3.75%) | total_pruned =   70961 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4677 /  147456             (  3.17%) | total_pruned =  142779 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1207 /    8192             ( 14.73%) | total_pruned =    6985 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2749 /  147456             (  1.86%) | total_pruned =  144707 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2884 /  147456             (  1.96%) | total_pruned =  144572 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8624 /  294912             (  2.92%) | total_pruned =  286288 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   12621 /  589824             (  2.14%) | total_pruned =  577203 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      98 /     256             ( 38.28%) | total_pruned =     158 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3163 /   32768             (  9.65%) | total_pruned =   29605 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      91 /     256             ( 35.55%) | total_pruned =     165 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    4678 /  589824             (  0.79%) | total_pruned =  585146 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4449 /  589824             (  0.75%) | total_pruned =  585375 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     114 /     256             ( 44.53%) | total_pruned =     142 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   14994 / 1179648             (  1.27%) | total_pruned = 1164654 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     409 /     512             ( 79.88%) | total_pruned =     103 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     285 /     512             ( 55.66%) | total_pruned =     227 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    7568 / 2359296             (  0.32%) | total_pruned = 2351728 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     372 /     512             ( 72.66%) | total_pruned =     140 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      81 /     512             ( 15.82%) | total_pruned =     431 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2875 /  131072             (  2.19%) | total_pruned =  128197 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     275 /     512             ( 53.71%) | total_pruned =     237 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      71 /     512             ( 13.87%) | total_pruned =     441 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3001 / 2359296             (  0.13%) | total_pruned = 2356295 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     205 /     512             ( 40.04%) | total_pruned =     307 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     827 / 2359296             (  0.04%) | total_pruned = 2358469 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     396 /     512             ( 77.34%) | total_pruned =     116 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
linear.weight        | nonzeros =    1672 /    5120             ( 32.66%) | total_pruned =    3448 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 70/200 Loss: 0.040640 Accuracy: 77.05 100.00 % Best test Accuracy: 77.16%
tensor(0.0881, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-6.6932e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.016550
Average KL loss: 0.010712
Average total loss: 0.027262
tensor(0.0515, device='cuda:0') tensor(0.2620, device='cuda:0') tensor(-4.1302e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.029496
Average KL loss: 0.005937
Average total loss: 0.035433
tensor(0.0402, device='cuda:0') tensor(0.2294, device='cuda:0') tensor(-1.0965e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.037558
Average KL loss: 0.005270
Average total loss: 0.042828
tensor(0.0389, device='cuda:0') tensor(0.2243, device='cuda:0') tensor(-1.7751e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.042142
Average KL loss: 0.005092
Average total loss: 0.047234
tensor(0.0385, device='cuda:0') tensor(0.2250, device='cuda:0') tensor(-7.3408e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.044560
Average KL loss: 0.005006
Average total loss: 0.049567
tensor(0.0385, device='cuda:0') tensor(0.2279, device='cuda:0') tensor(-4.0932e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.044847
Average KL loss: 0.004959
Average total loss: 0.049805
tensor(0.0386, device='cuda:0') tensor(0.2320, device='cuda:0') tensor(-4.5177e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.043095
Average KL loss: 0.004930
Average total loss: 0.048026
tensor(0.0388, device='cuda:0') tensor(0.2365, device='cuda:0') tensor(-4.3949e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.038678
Average KL loss: 0.004915
Average total loss: 0.043593
tensor(0.0390, device='cuda:0') tensor(0.2407, device='cuda:0') tensor(-3.7385e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.030216
Average KL loss: 0.004908
Average total loss: 0.035124
tensor(0.0392, device='cuda:0') tensor(0.2450, device='cuda:0') tensor(-2.7815e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.027317
Average KL loss: 0.004903
Average total loss: 0.032221
tensor(0.0395, device='cuda:0') tensor(0.2491, device='cuda:0') tensor(-6.6227e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.029742
Average KL loss: 0.004905
Average total loss: 0.034647
tensor(0.0397, device='cuda:0') tensor(0.2532, device='cuda:0') tensor(-4.9236e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.026002
Average KL loss: 0.004907
Average total loss: 0.030908
tensor(0.0400, device='cuda:0') tensor(0.2572, device='cuda:0') tensor(-5.6480e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.025102
Average KL loss: 0.004908
Average total loss: 0.030011
tensor(0.0400, device='cuda:0') tensor(0.2574, device='cuda:0') tensor(-4.8465e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.022327
Average KL loss: 0.004910
Average total loss: 0.027237
tensor(0.0400, device='cuda:0') tensor(0.2576, device='cuda:0') tensor(-4.3823e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.021829
Average KL loss: 0.004911
Average total loss: 0.026741
tensor(0.0401, device='cuda:0') tensor(0.2578, device='cuda:0') tensor(-2.0677e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.020466
Average KL loss: 0.004913
Average total loss: 0.025379
tensor(0.0401, device='cuda:0') tensor(0.2580, device='cuda:0') tensor(-4.2594e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.019318
Average KL loss: 0.004914
Average total loss: 0.024232
tensor(0.0401, device='cuda:0') tensor(0.2581, device='cuda:0') tensor(-1.4866e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.018846
Average KL loss: 0.004915
Average total loss: 0.023761
tensor(0.0401, device='cuda:0') tensor(0.2583, device='cuda:0') tensor(-1.1629e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.019685
Average KL loss: 0.004916
Average total loss: 0.024602
tensor(0.0401, device='cuda:0') tensor(0.2585, device='cuda:0') tensor(-3.0333e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.017215
Average KL loss: 0.004917
Average total loss: 0.022132
tensor(0.0402, device='cuda:0') tensor(0.2587, device='cuda:0') tensor(-1.7715e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.017130
Average KL loss: 0.004918
Average total loss: 0.022048
tensor(0.0402, device='cuda:0') tensor(0.2588, device='cuda:0') tensor(-2.5901e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.018141
Average KL loss: 0.004919
Average total loss: 0.023060
tensor(0.0402, device='cuda:0') tensor(0.2590, device='cuda:0') tensor(-2.3224e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.018223
Average KL loss: 0.004920
Average total loss: 0.023143
tensor(0.0402, device='cuda:0') tensor(0.2592, device='cuda:0') tensor(-2.5301e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.016370
Average KL loss: 0.004921
Average total loss: 0.021291
tensor(0.0402, device='cuda:0') tensor(0.2594, device='cuda:0') tensor(-6.2691e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.018175
Average KL loss: 0.004922
Average total loss: 0.023097
tensor(0.0403, device='cuda:0') tensor(0.2596, device='cuda:0') tensor(-3.2093e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.016987
Average KL loss: 0.004923
Average total loss: 0.021910
tensor(0.0403, device='cuda:0') tensor(0.2598, device='cuda:0') tensor(-1.2842e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.016270
Average KL loss: 0.004924
Average total loss: 0.021194
tensor(0.0403, device='cuda:0') tensor(0.2599, device='cuda:0') tensor(-1.3132e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.015743
Average KL loss: 0.004925
Average total loss: 0.020668
tensor(0.0403, device='cuda:0') tensor(0.2601, device='cuda:0') tensor(-3.2312e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.015567
Average KL loss: 0.004926
Average total loss: 0.020493
tensor(0.0403, device='cuda:0') tensor(0.2603, device='cuda:0') tensor(-1.5592e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.014740
Average KL loss: 0.004927
Average total loss: 0.019667
tensor(0.0404, device='cuda:0') tensor(0.2605, device='cuda:0') tensor(-2.9206e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.015653
Average KL loss: 0.004928
Average total loss: 0.020580
tensor(0.0404, device='cuda:0') tensor(0.2607, device='cuda:0') tensor(-4.0900e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.014637
Average KL loss: 0.004929
Average total loss: 0.019566
tensor(0.0404, device='cuda:0') tensor(0.2609, device='cuda:0') tensor(-1.5675e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.013823
Average KL loss: 0.004930
Average total loss: 0.018753
tensor(0.0404, device='cuda:0') tensor(0.2611, device='cuda:0') tensor(-3.2510e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.014684
Average KL loss: 0.004930
Average total loss: 0.019614
tensor(0.0404, device='cuda:0') tensor(0.2613, device='cuda:0') tensor(-1.8498e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.013523
Average KL loss: 0.004931
Average total loss: 0.018454
tensor(0.0405, device='cuda:0') tensor(0.2615, device='cuda:0') tensor(-1.5540e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.012939
Average KL loss: 0.004932
Average total loss: 0.017872
tensor(0.0405, device='cuda:0') tensor(0.2617, device='cuda:0') tensor(-2.2158e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.011954
Average KL loss: 0.004933
Average total loss: 0.016888
tensor(0.0405, device='cuda:0') tensor(0.2619, device='cuda:0') tensor(-1.5568e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.012395
Average KL loss: 0.004934
Average total loss: 0.017329
tensor(0.0405, device='cuda:0') tensor(0.2620, device='cuda:0') tensor(-1.3847e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.014344
Average KL loss: 0.004935
Average total loss: 0.019279
tensor(0.0405, device='cuda:0') tensor(0.2622, device='cuda:0') tensor(-2.3609e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.011458
Average KL loss: 0.004936
Average total loss: 0.016394
tensor(0.0405, device='cuda:0') tensor(0.2624, device='cuda:0') tensor(-1.4253e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.011720
Average KL loss: 0.004937
Average total loss: 0.016656
tensor(0.0406, device='cuda:0') tensor(0.2626, device='cuda:0') tensor(-1.4166e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.011613
Average KL loss: 0.004938
Average total loss: 0.016551
tensor(0.0406, device='cuda:0') tensor(0.2628, device='cuda:0') tensor(-1.3438e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.012177
Average KL loss: 0.004938
Average total loss: 0.017115
tensor(0.0406, device='cuda:0') tensor(0.2629, device='cuda:0') tensor(-1.3545e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.011652
Average KL loss: 0.004939
Average total loss: 0.016591
tensor(0.0406, device='cuda:0') tensor(0.2631, device='cuda:0') tensor(-1.6437e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.010745
Average KL loss: 0.004939
Average total loss: 0.015684
tensor(0.0406, device='cuda:0') tensor(0.2633, device='cuda:0') tensor(-8.3131e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.011214
Average KL loss: 0.004940
Average total loss: 0.016154
tensor(0.0406, device='cuda:0') tensor(0.2635, device='cuda:0') tensor(-1.1257e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.010364
Average KL loss: 0.004941
Average total loss: 0.015304
tensor(0.0407, device='cuda:0') tensor(0.2637, device='cuda:0') tensor(-1.1724e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.011016
Average KL loss: 0.004941
Average total loss: 0.015958
tensor(0.0407, device='cuda:0') tensor(0.2639, device='cuda:0') tensor(-1.7623e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.011063
Average KL loss: 0.004942
Average total loss: 0.016005
tensor(0.0407, device='cuda:0') tensor(0.2641, device='cuda:0') tensor(-8.6352e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.009961
Average KL loss: 0.004943
Average total loss: 0.014903
tensor(0.0407, device='cuda:0') tensor(0.2642, device='cuda:0') tensor(-3.5076e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.009942
Average KL loss: 0.004944
Average total loss: 0.014886
tensor(0.0407, device='cuda:0') tensor(0.2644, device='cuda:0') tensor(-1.7783e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.011424
Average KL loss: 0.004944
Average total loss: 0.016368
tensor(0.0408, device='cuda:0') tensor(0.2647, device='cuda:0') tensor(-4.1368e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.008796
Average KL loss: 0.004945
Average total loss: 0.013742
tensor(0.0408, device='cuda:0') tensor(0.2648, device='cuda:0') tensor(-2.3028e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.008783
Average KL loss: 0.004946
Average total loss: 0.013728
tensor(0.0408, device='cuda:0') tensor(0.2650, device='cuda:0') tensor(-5.3932e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.010098
Average KL loss: 0.004947
Average total loss: 0.015044
tensor(0.0408, device='cuda:0') tensor(0.2652, device='cuda:0') tensor(-1.5352e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.009430
Average KL loss: 0.004947
Average total loss: 0.014378
tensor(0.0408, device='cuda:0') tensor(0.2654, device='cuda:0') tensor(-1.5674e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.009029
Average KL loss: 0.004948
Average total loss: 0.013977
tensor(0.0408, device='cuda:0') tensor(0.2656, device='cuda:0') tensor(-2.6152e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.009883
Average KL loss: 0.004949
Average total loss: 0.014831
tensor(0.0409, device='cuda:0') tensor(0.2658, device='cuda:0') tensor(-6.9986e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.008401
Average KL loss: 0.004949
Average total loss: 0.013351
tensor(0.0409, device='cuda:0') tensor(0.2660, device='cuda:0') tensor(-2.5052e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.008864
Average KL loss: 0.004950
Average total loss: 0.013814
tensor(0.0409, device='cuda:0') tensor(0.2662, device='cuda:0') tensor(-9.3171e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.008964
Average KL loss: 0.004951
Average total loss: 0.013914
tensor(0.0409, device='cuda:0') tensor(0.2664, device='cuda:0') tensor(-2.3363e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.008128
Average KL loss: 0.004951
Average total loss: 0.013079
tensor(0.0409, device='cuda:0') tensor(0.2665, device='cuda:0') tensor(-1.0432e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.007365
Average KL loss: 0.004952
Average total loss: 0.012317
tensor(0.0409, device='cuda:0') tensor(0.2667, device='cuda:0') tensor(-8.8042e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.008322
Average KL loss: 0.004953
Average total loss: 0.013274
tensor(0.0410, device='cuda:0') tensor(0.2669, device='cuda:0') tensor(-2.1642e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.008427
Average KL loss: 0.004953
Average total loss: 0.013380
tensor(0.0410, device='cuda:0') tensor(0.2671, device='cuda:0') tensor(-1.0285e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.007686
Average KL loss: 0.004954
Average total loss: 0.012640
tensor(0.0410, device='cuda:0') tensor(0.2672, device='cuda:0') tensor(-2.5750e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.007487
Average KL loss: 0.004954
Average total loss: 0.012441
tensor(0.0410, device='cuda:0') tensor(0.2674, device='cuda:0') tensor(-1.4780e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.007752
Average KL loss: 0.004955
Average total loss: 0.012707
tensor(0.0410, device='cuda:0') tensor(0.2676, device='cuda:0') tensor(-3.1328e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.007952
Average KL loss: 0.004955
Average total loss: 0.012908
tensor(0.0410, device='cuda:0') tensor(0.2678, device='cuda:0') tensor(-8.2145e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.007724
Average KL loss: 0.004956
Average total loss: 0.012680
tensor(0.0411, device='cuda:0') tensor(0.2680, device='cuda:0') tensor(-4.7450e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.007334
Average KL loss: 0.004957
Average total loss: 0.012290
tensor(0.0411, device='cuda:0') tensor(0.2681, device='cuda:0') tensor(-6.1043e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.007656
Average KL loss: 0.004957
Average total loss: 0.012613
tensor(0.0411, device='cuda:0') tensor(0.2683, device='cuda:0') tensor(-2.3462e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.006820
Average KL loss: 0.004957
Average total loss: 0.011777
tensor(0.0411, device='cuda:0') tensor(0.2685, device='cuda:0') tensor(-5.2031e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.007014
Average KL loss: 0.004958
Average total loss: 0.011972
tensor(0.0411, device='cuda:0') tensor(0.2687, device='cuda:0') tensor(-1.1685e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.007909
Average KL loss: 0.004958
Average total loss: 0.012867
tensor(0.0411, device='cuda:0') tensor(0.2689, device='cuda:0') tensor(-1.0685e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.007499
Average KL loss: 0.004959
Average total loss: 0.012458
tensor(0.0412, device='cuda:0') tensor(0.2690, device='cuda:0') tensor(-5.3180e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.007271
Average KL loss: 0.004959
Average total loss: 0.012231
tensor(0.0412, device='cuda:0') tensor(0.2692, device='cuda:0') tensor(-4.4422e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.007262
Average KL loss: 0.004960
Average total loss: 0.012222
tensor(0.0412, device='cuda:0') tensor(0.2694, device='cuda:0') tensor(-1.0926e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.006988
Average KL loss: 0.004961
Average total loss: 0.011949
tensor(0.0412, device='cuda:0') tensor(0.2696, device='cuda:0') tensor(-5.8393e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.006717
Average KL loss: 0.004961
Average total loss: 0.011678
tensor(0.0412, device='cuda:0') tensor(0.2698, device='cuda:0') tensor(-1.7293e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.008260
Average KL loss: 0.004962
Average total loss: 0.013221
tensor(0.0412, device='cuda:0') tensor(0.2700, device='cuda:0') tensor(-4.4708e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.006144
Average KL loss: 0.004962
Average total loss: 0.011106
tensor(0.0413, device='cuda:0') tensor(0.2702, device='cuda:0') tensor(-5.7384e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.006165
Average KL loss: 0.004962
Average total loss: 0.011127
tensor(0.0413, device='cuda:0') tensor(0.2704, device='cuda:0') tensor(-5.2792e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.005910
Average KL loss: 0.004963
Average total loss: 0.010873
tensor(0.0413, device='cuda:0') tensor(0.2705, device='cuda:0') tensor(-5.5150e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.007393
Average KL loss: 0.004963
Average total loss: 0.012356
tensor(0.0413, device='cuda:0') tensor(0.2707, device='cuda:0') tensor(-7.4911e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.006186
Average KL loss: 0.004963
Average total loss: 0.011149
tensor(0.0413, device='cuda:0') tensor(0.2709, device='cuda:0') tensor(-5.2416e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.006052
Average KL loss: 0.004964
Average total loss: 0.011016
tensor(0.0413, device='cuda:0') tensor(0.2711, device='cuda:0') tensor(-6.5801e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.007299
Average KL loss: 0.004964
Average total loss: 0.012263
tensor(0.0414, device='cuda:0') tensor(0.2713, device='cuda:0') tensor(-1.2109e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.006351
Average KL loss: 0.004965
Average total loss: 0.011316
tensor(0.0414, device='cuda:0') tensor(0.2715, device='cuda:0') tensor(-5.4840e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.006101
Average KL loss: 0.004965
Average total loss: 0.011067
tensor(0.0414, device='cuda:0') tensor(0.2717, device='cuda:0') tensor(-1.0872e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.005911
Average KL loss: 0.004966
Average total loss: 0.010877
tensor(0.0414, device='cuda:0') tensor(0.2719, device='cuda:0') tensor(-7.7832e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.005402
Average KL loss: 0.004966
Average total loss: 0.010368
tensor(0.0414, device='cuda:0') tensor(0.2721, device='cuda:0') tensor(-6.6386e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.005146
Average KL loss: 0.004967
Average total loss: 0.010112
tensor(0.0414, device='cuda:0') tensor(0.2722, device='cuda:0') tensor(-6.2392e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.006412
Average KL loss: 0.004967
Average total loss: 0.011379
tensor(0.0415, device='cuda:0') tensor(0.2724, device='cuda:0') tensor(-1.0366e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.006096
Average KL loss: 0.004967
Average total loss: 0.011063
tensor(0.0415, device='cuda:0') tensor(0.2726, device='cuda:0') tensor(-8.2925e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.005532
Average KL loss: 0.004968
Average total loss: 0.010500
tensor(0.0415, device='cuda:0') tensor(0.2728, device='cuda:0') tensor(-2.9963e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.005435
Average KL loss: 0.004968
Average total loss: 0.010403
tensor(0.0415, device='cuda:0') tensor(0.2729, device='cuda:0') tensor(-8.3170e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.006595
Average KL loss: 0.004969
Average total loss: 0.011564
tensor(0.0415, device='cuda:0') tensor(0.2731, device='cuda:0') tensor(-5.5974e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.005779
Average KL loss: 0.004969
Average total loss: 0.010748
tensor(0.0415, device='cuda:0') tensor(0.2733, device='cuda:0') tensor(-3.6361e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.005804
Average KL loss: 0.004970
Average total loss: 0.010774
tensor(0.0416, device='cuda:0') tensor(0.2735, device='cuda:0') tensor(-8.3270e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.006144
Average KL loss: 0.004970
Average total loss: 0.011114
tensor(0.0416, device='cuda:0') tensor(0.2737, device='cuda:0') tensor(-8.1575e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.005690
Average KL loss: 0.004971
Average total loss: 0.010661
tensor(0.0416, device='cuda:0') tensor(0.2739, device='cuda:0') tensor(-7.9930e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.005191
Average KL loss: 0.004971
Average total loss: 0.010162
tensor(0.0416, device='cuda:0') tensor(0.2741, device='cuda:0') tensor(-5.9714e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.006038
Average KL loss: 0.004971
Average total loss: 0.011010
tensor(0.0416, device='cuda:0') tensor(0.2742, device='cuda:0') tensor(-1.1041e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.006048
Average KL loss: 0.004972
Average total loss: 0.011020
tensor(0.0416, device='cuda:0') tensor(0.2743, device='cuda:0') tensor(-6.4990e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.005779
Average KL loss: 0.004972
Average total loss: 0.010751
tensor(0.0416, device='cuda:0') tensor(0.2743, device='cuda:0') tensor(-4.1698e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.004460
Average KL loss: 0.004972
Average total loss: 0.009432
tensor(0.0416, device='cuda:0') tensor(0.2743, device='cuda:0') tensor(-5.4286e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.005241
Average KL loss: 0.004972
Average total loss: 0.010212
tensor(0.0416, device='cuda:0') tensor(0.2743, device='cuda:0') tensor(-4.3088e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.005186
Average KL loss: 0.004972
Average total loss: 0.010158
tensor(0.0416, device='cuda:0') tensor(0.2743, device='cuda:0') tensor(-6.7912e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.005334
Average KL loss: 0.004972
Average total loss: 0.010305
tensor(0.0416, device='cuda:0') tensor(0.2743, device='cuda:0') tensor(-8.4240e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.005164
Average KL loss: 0.004972
Average total loss: 0.010136
tensor(0.0416, device='cuda:0') tensor(0.2744, device='cuda:0') tensor(-4.1696e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.004954
Average KL loss: 0.004972
Average total loss: 0.009926
tensor(0.0416, device='cuda:0') tensor(0.2744, device='cuda:0') tensor(-1.3093e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.005658
Average KL loss: 0.004972
Average total loss: 0.010630
tensor(0.0416, device='cuda:0') tensor(0.2744, device='cuda:0') tensor(-2.6799e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.005895
Average KL loss: 0.004972
Average total loss: 0.010867
tensor(0.0416, device='cuda:0') tensor(0.2744, device='cuda:0') tensor(-1.0201e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.005129
Average KL loss: 0.004972
Average total loss: 0.010101
tensor(0.0416, device='cuda:0') tensor(0.2744, device='cuda:0') tensor(-1.3324e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.005813
Average KL loss: 0.004972
Average total loss: 0.010785
tensor(0.0416, device='cuda:0') tensor(0.2744, device='cuda:0') tensor(-3.1981e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.004685
Average KL loss: 0.004972
Average total loss: 0.009657
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-3.7099e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.006203
Average KL loss: 0.004972
Average total loss: 0.011176
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-6.3407e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.005246
Average KL loss: 0.004972
Average total loss: 0.010218
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-1.5039e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.004487
Average KL loss: 0.004972
Average total loss: 0.009459
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-5.2619e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.005683
Average KL loss: 0.004972
Average total loss: 0.010655
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-5.4072e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.004690
Average KL loss: 0.004972
Average total loss: 0.009663
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-4.6123e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.004555
Average KL loss: 0.004972
Average total loss: 0.009528
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-4.6133e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.004624
Average KL loss: 0.004972
Average total loss: 0.009596
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-8.7805e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.005111
Average KL loss: 0.004972
Average total loss: 0.010083
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-3.8941e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.004686
Average KL loss: 0.004972
Average total loss: 0.009658
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-7.6630e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.006459
Average KL loss: 0.004972
Average total loss: 0.011431
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-8.0775e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.005041
Average KL loss: 0.004972
Average total loss: 0.010013
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-7.6363e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.005841
Average KL loss: 0.004972
Average total loss: 0.010814
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-7.4064e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.004800
Average KL loss: 0.004972
Average total loss: 0.009772
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-4.2623e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.005459
Average KL loss: 0.004972
Average total loss: 0.010431
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-3.9705e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.005169
Average KL loss: 0.004972
Average total loss: 0.010141
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-3.1221e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.004823
Average KL loss: 0.004972
Average total loss: 0.009796
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-8.5072e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.005085
Average KL loss: 0.004972
Average total loss: 0.010057
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-1.2901e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.005685
Average KL loss: 0.004972
Average total loss: 0.010658
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-1.4223e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.004943
Average KL loss: 0.004972
Average total loss: 0.009915
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-5.3792e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.005404
Average KL loss: 0.004972
Average total loss: 0.010377
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-1.5837e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.005386
Average KL loss: 0.004972
Average total loss: 0.010358
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-4.5384e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.005037
Average KL loss: 0.004972
Average total loss: 0.010009
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-4.7911e-10, device='cuda:0')
 Percentile value: 8.090087890625
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     471 /    1728             ( 27.26%) | total_pruned =    1257 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
bn1.bias             | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     571 /   36864             (  1.55%) | total_pruned =   36293 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     617 /   36864             (  1.67%) | total_pruned =   36247 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     593 /   36864             (  1.61%) | total_pruned =   36271 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     585 /   36864             (  1.59%) | total_pruned =   36279 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1038 /   73728             (  1.41%) | total_pruned =   72690 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1449 /  147456             (  0.98%) | total_pruned =  146007 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     521 /    8192             (  6.36%) | total_pruned =    7671 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     888 /  147456             (  0.60%) | total_pruned =  146568 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     823 /  147456             (  0.56%) | total_pruned =  146633 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2652 /  294912             (  0.90%) | total_pruned =  292260 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     202 /     256             ( 78.91%) | total_pruned =      54 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      69 /     256             ( 26.95%) | total_pruned =     187 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3355 /  589824             (  0.57%) | total_pruned =  586469 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1101 /   32768             (  3.36%) | total_pruned =   31667 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     178 /     256             ( 69.53%) | total_pruned =      78 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      43 /     256             ( 16.80%) | total_pruned =     213 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1178 /  589824             (  0.20%) | total_pruned =  588646 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     119 /     256             ( 46.48%) | total_pruned =     137 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      49 /     256             ( 19.14%) | total_pruned =     207 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     993 /  589824             (  0.17%) | total_pruned =  588831 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     167 /     256             ( 65.23%) | total_pruned =      89 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      50 /     256             ( 19.53%) | total_pruned =     206 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    3449 / 1179648             (  0.29%) | total_pruned = 1176199 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     126 /     512             ( 24.61%) | total_pruned =     386 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1466 / 2359296             (  0.06%) | total_pruned = 2357830 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     251 /     512             ( 49.02%) | total_pruned =     261 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     671 /  131072             (  0.51%) | total_pruned =  130401 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     159 /     512             ( 31.05%) | total_pruned =     353 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     640 / 2359296             (  0.03%) | total_pruned = 2358656 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      96 /     512             ( 18.75%) | total_pruned =     416 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     140 / 2359296             (  0.01%) | total_pruned = 2359156 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     192 /     512             ( 37.50%) | total_pruned =     320 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
linear.weight        | nonzeros =     766 /    5120             ( 14.96%) | total_pruned =    4354 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 199/200 Loss: 0.396455 Accuracy: 65.27 91.78 % Best test Accuracy: 66.89%
tensor(0.0416, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-4.3345e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.335693
Average KL loss: 0.004674
Average total loss: 0.340367
tensor(0.0352, device='cuda:0') tensor(0.2251, device='cuda:0') tensor(-3.4767e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.348037
Average KL loss: 0.003807
Average total loss: 0.351844
tensor(0.0277, device='cuda:0') tensor(0.1814, device='cuda:0') tensor(-6.9108e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.357481
Average KL loss: 0.002926
Average total loss: 0.360407
tensor(0.0220, device='cuda:0') tensor(0.1506, device='cuda:0') tensor(-8.1914e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.370805
Average KL loss: 0.002264
Average total loss: 0.373069
tensor(0.0183, device='cuda:0') tensor(0.1328, device='cuda:0') tensor(-5.5982e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.381509
Average KL loss: 0.001861
Average total loss: 0.383370
tensor(0.0168, device='cuda:0') tensor(0.1262, device='cuda:0') tensor(-4.2905e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.377091
Average KL loss: 0.001740
Average total loss: 0.378830
tensor(0.0163, device='cuda:0') tensor(0.1229, device='cuda:0') tensor(-4.4150e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.385974
Average KL loss: 0.001673
Average total loss: 0.387647
tensor(0.0159, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-1.1842e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.389476
Average KL loss: 0.001625
Average total loss: 0.391100
tensor(0.0156, device='cuda:0') tensor(0.1200, device='cuda:0') tensor(-4.0450e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.368661
Average KL loss: 0.001588
Average total loss: 0.370248
tensor(0.0154, device='cuda:0') tensor(0.1196, device='cuda:0') tensor(-6.6819e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.378342
Average KL loss: 0.001560
Average total loss: 0.379902
tensor(0.0153, device='cuda:0') tensor(0.1197, device='cuda:0') tensor(-7.5820e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.371627
Average KL loss: 0.001541
Average total loss: 0.373168
tensor(0.0152, device='cuda:0') tensor(0.1200, device='cuda:0') tensor(-9.0796e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.365256
Average KL loss: 0.001524
Average total loss: 0.366780
tensor(0.0152, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-1.0242e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.354957
Average KL loss: 0.001516
Average total loss: 0.356473
tensor(0.0152, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-6.2998e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.366063
Average KL loss: 0.001515
Average total loss: 0.367578
tensor(0.0152, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-2.8515e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.343819
Average KL loss: 0.001514
Average total loss: 0.345332
tensor(0.0152, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-2.7991e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.350897
Average KL loss: 0.001513
Average total loss: 0.352410
tensor(0.0152, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-3.5677e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.362822
Average KL loss: 0.001512
Average total loss: 0.364334
tensor(0.0152, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-7.9819e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.351825
Average KL loss: 0.001511
Average total loss: 0.353336
tensor(0.0152, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-2.7753e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.357062
Average KL loss: 0.001510
Average total loss: 0.358572
tensor(0.0152, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-4.1995e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.351277
Average KL loss: 0.001509
Average total loss: 0.352786
tensor(0.0152, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-1.6774e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.347713
Average KL loss: 0.001508
Average total loss: 0.349221
tensor(0.0152, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-2.7429e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.339641
Average KL loss: 0.001507
Average total loss: 0.341148
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-8.9973e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.354349
Average KL loss: 0.001506
Average total loss: 0.355855
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-2.2741e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.333818
Average KL loss: 0.001506
Average total loss: 0.335323
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-1.0580e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.334570
Average KL loss: 0.001506
Average total loss: 0.336076
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-3.0044e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.331875
Average KL loss: 0.001506
Average total loss: 0.333381
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-4.7411e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.334319
Average KL loss: 0.001506
Average total loss: 0.335824
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-1.9136e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.345066
Average KL loss: 0.001505
Average total loss: 0.346571
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-1.9550e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.338059
Average KL loss: 0.001505
Average total loss: 0.339565
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-2.2457e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.346735
Average KL loss: 0.001505
Average total loss: 0.348241
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-4.5973e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.346133
Average KL loss: 0.001505
Average total loss: 0.347638
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-3.2083e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.349320
Average KL loss: 0.001505
Average total loss: 0.350825
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-1.2723e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.350296
Average KL loss: 0.001505
Average total loss: 0.351801
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-1.0644e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.339897
Average KL loss: 0.001505
Average total loss: 0.341402
tensor(0.0151, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-3.1811e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.347040
Average KL loss: 0.001505
Average total loss: 0.348545
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-5.7658e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.337721
Average KL loss: 0.001505
Average total loss: 0.339226
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-2.9537e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.327126
Average KL loss: 0.001505
Average total loss: 0.328631
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-3.6546e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.346517
Average KL loss: 0.001505
Average total loss: 0.348021
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-4.7509e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.338991
Average KL loss: 0.001505
Average total loss: 0.340495
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-4.5347e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.336540
Average KL loss: 0.001505
Average total loss: 0.338045
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-4.0783e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.333135
Average KL loss: 0.001504
Average total loss: 0.334639
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-3.6212e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.343138
Average KL loss: 0.001504
Average total loss: 0.344642
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-4.6490e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.334142
Average KL loss: 0.001504
Average total loss: 0.335646
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-1.5492e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.325838
Average KL loss: 0.001504
Average total loss: 0.327342
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-2.2049e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.348558
Average KL loss: 0.001504
Average total loss: 0.350062
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-1.6306e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.345080
Average KL loss: 0.001504
Average total loss: 0.346584
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-7.2165e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.339009
Average KL loss: 0.001504
Average total loss: 0.340513
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-1.1561e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.344593
Average KL loss: 0.001504
Average total loss: 0.346097
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-3.2231e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.329540
Average KL loss: 0.001504
Average total loss: 0.331044
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-3.0927e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.344698
Average KL loss: 0.001504
Average total loss: 0.346202
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-4.6225e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.334928
Average KL loss: 0.001504
Average total loss: 0.336432
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-1.2434e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.323750
Average KL loss: 0.001504
Average total loss: 0.325254
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-2.1247e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.335852
Average KL loss: 0.001504
Average total loss: 0.337356
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-2.8359e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.334639
Average KL loss: 0.001504
Average total loss: 0.336142
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-5.9964e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.335911
Average KL loss: 0.001503
Average total loss: 0.337415
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-4.3120e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.338007
Average KL loss: 0.001503
Average total loss: 0.339510
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-4.8758e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.335010
Average KL loss: 0.001503
Average total loss: 0.336513
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-3.1556e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.335929
Average KL loss: 0.001503
Average total loss: 0.337432
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-5.2563e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.337224
Average KL loss: 0.001503
Average total loss: 0.338727
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-3.8482e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.343577
Average KL loss: 0.001503
Average total loss: 0.345080
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-2.9435e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.327870
Average KL loss: 0.001503
Average total loss: 0.329373
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-4.2927e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.336326
Average KL loss: 0.001503
Average total loss: 0.337829
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-8.6579e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.339445
Average KL loss: 0.001503
Average total loss: 0.340948
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-1.3414e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.325321
Average KL loss: 0.001503
Average total loss: 0.326824
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-2.3947e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.345383
Average KL loss: 0.001503
Average total loss: 0.346886
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-5.2200e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.339643
Average KL loss: 0.001503
Average total loss: 0.341146
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-4.2415e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.331293
Average KL loss: 0.001503
Average total loss: 0.332796
tensor(0.0151, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-5.5616e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.333217
Average KL loss: 0.001503
Average total loss: 0.334719
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-4.5048e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.335862
Average KL loss: 0.001503
Average total loss: 0.337365
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-3.9218e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.332554
Average KL loss: 0.001503
Average total loss: 0.334057
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-5.1961e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.339224
Average KL loss: 0.001503
Average total loss: 0.340727
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-7.0249e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.342850
Average KL loss: 0.001503
Average total loss: 0.344353
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-3.6612e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.347538
Average KL loss: 0.001503
Average total loss: 0.349041
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-1.0261e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.344243
Average KL loss: 0.001503
Average total loss: 0.345746
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-5.8793e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.337277
Average KL loss: 0.001503
Average total loss: 0.338780
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-5.6134e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.334124
Average KL loss: 0.001503
Average total loss: 0.335627
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-1.6731e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.330841
Average KL loss: 0.001503
Average total loss: 0.332343
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-4.7493e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.347183
Average KL loss: 0.001503
Average total loss: 0.348686
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-4.5543e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.347300
Average KL loss: 0.001503
Average total loss: 0.348802
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-3.0068e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.328667
Average KL loss: 0.001503
Average total loss: 0.330169
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-9.1715e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.328933
Average KL loss: 0.001503
Average total loss: 0.330435
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-2.6384e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.335829
Average KL loss: 0.001503
Average total loss: 0.337332
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-1.8009e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.331579
Average KL loss: 0.001503
Average total loss: 0.333081
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-4.3524e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.336162
Average KL loss: 0.001503
Average total loss: 0.337665
tensor(0.0151, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-3.3325e-09, device='cuda:0')
 Percentile value: 9.421549606323243
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =     259 /    1728             ( 14.99%) | total_pruned =    1469 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
bn1.bias             | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     235 /   36864             (  0.64%) | total_pruned =   36629 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     210 /   36864             (  0.57%) | total_pruned =   36654 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     227 /   36864             (  0.62%) | total_pruned =   36637 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     221 /   36864             (  0.60%) | total_pruned =   36643 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     367 /   73728             (  0.50%) | total_pruned =   73361 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     447 /  147456             (  0.30%) | total_pruned =  147009 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     202 /    8192             (  2.47%) | total_pruned =    7990 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     314 /  147456             (  0.21%) | total_pruned =  147142 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     250 /  147456             (  0.17%) | total_pruned =  147206 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     836 /  294912             (  0.28%) | total_pruned =  294076 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     114 /     256             ( 44.53%) | total_pruned =     142 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     835 /  589824             (  0.14%) | total_pruned =  588989 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     309 /   32768             (  0.94%) | total_pruned =   32459 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      87 /     256             ( 33.98%) | total_pruned =     169 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     278 /  589824             (  0.05%) | total_pruned =  589546 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     208 /  589824             (  0.04%) | total_pruned =  589616 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      79 /     256             ( 30.86%) | total_pruned =     177 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     704 / 1179648             (  0.06%) | total_pruned = 1178944 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     117 /     512             ( 22.85%) | total_pruned =     395 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     232 / 2359296             (  0.01%) | total_pruned = 2359064 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     121 /     512             ( 23.63%) | total_pruned =     391 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     133 /  131072             (  0.10%) | total_pruned =  130939 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      82 / 2359296             (  0.00%) | total_pruned = 2359214 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      15 / 2359296             (  0.00%) | total_pruned = 2359281 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
linear.weight        | nonzeros =     283 /    5120             (  5.53%) | total_pruned =    4837 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 181/200 Loss: 1.506302 Accuracy: 45.68 48.03 % Best test Accuracy: 45.86%
