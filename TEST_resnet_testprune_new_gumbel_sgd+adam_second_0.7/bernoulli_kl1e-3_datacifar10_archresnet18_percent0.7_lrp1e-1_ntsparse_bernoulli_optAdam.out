Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0.0002, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.296965
Average KL loss: 1764.186709
Average total loss: 1766.483756
tensor(-3.5260, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(2.7973e-05, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.321992
Average KL loss: 195.652514
Average total loss: 197.974513
tensor(-4.5001, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.0981e-05, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.308064
Average KL loss: 95.739142
Average total loss: 98.047210
tensor(-5.0314, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.5159e-06, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.304031
Average KL loss: 60.625229
Average total loss: 62.929263
tensor(-5.4222, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.4288e-06, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.302783
Average KL loss: 42.716547
Average total loss: 45.019332
tensor(-5.7339, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(3.2496e-06, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.302671
Average KL loss: 32.108875
Average total loss: 34.411547
tensor(-5.9939, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(2.5093e-06, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.302608
Average KL loss: 25.217076
Average total loss: 27.519685
tensor(-6.2173, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.0086e-06, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.302579
Average KL loss: 20.444231
Average total loss: 22.746811
tensor(-6.4135, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(1.6518e-06, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.302582
Average KL loss: 16.979316
Average total loss: 19.281899
tensor(-6.5886, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(1.3870e-06, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.302585
Average KL loss: 14.371089
Average total loss: 16.673675
tensor(-6.7469, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.1843e-06, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.302580
Average KL loss: 12.350476
Average total loss: 14.653056
tensor(-6.8915, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.0251e-06, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.302583
Average KL loss: 10.748059
Average total loss: 13.050642
tensor(-7.0247, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(8.9742e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.302591
Average KL loss: 9.452401
Average total loss: 11.754992
tensor(-7.1482, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(7.9321e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.302585
Average KL loss: 8.387502
Average total loss: 10.690087
tensor(-7.2636, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(7.0687e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.302594
Average KL loss: 7.499951
Average total loss: 9.802545
tensor(-7.3718, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(6.3442e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.302577
Average KL loss: 6.751221
Average total loss: 9.053798
tensor(-7.4738, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(5.7294e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.302585
Average KL loss: 6.112900
Average total loss: 8.415486
tensor(-7.5704, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(5.2025e-07, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.302584
Average KL loss: 5.563630
Average total loss: 7.866214
tensor(-7.6620, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(4.7470e-07, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.302587
Average KL loss: 5.087074
Average total loss: 7.389661
tensor(-7.7494, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(4.3502e-07, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.302588
Average KL loss: 4.670551
Average total loss: 6.973140
tensor(-7.8328, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(4.0021e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.302583
Average KL loss: 4.304080
Average total loss: 6.606664
tensor(-7.9127, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(3.6948e-07, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.302585
Average KL loss: 3.979712
Average total loss: 6.282297
tensor(-7.9895, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(3.4220e-07, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.302581
Average KL loss: 3.691046
Average total loss: 5.993628
tensor(-8.0633, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(3.1786e-07, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.302576
Average KL loss: 3.432877
Average total loss: 5.735452
tensor(-8.1344, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(2.9604e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.302585
Average KL loss: 3.200936
Average total loss: 5.503521
tensor(-8.2031, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(2.7639e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.302585
Average KL loss: 2.991692
Average total loss: 5.294277
tensor(-8.2696, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(2.5862e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.302585
Average KL loss: 2.802184
Average total loss: 5.104769
tensor(-8.3340, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(2.4250e-07, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.302585
Average KL loss: 2.629948
Average total loss: 4.932534
tensor(-8.3964, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(2.2782e-07, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.302585
Average KL loss: 2.472891
Average total loss: 4.775477
tensor(-8.4571, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(2.1442e-07, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.302585
Average KL loss: 2.329236
Average total loss: 4.631821
tensor(-8.5161, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(2.0213e-07, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.302585
Average KL loss: 2.197466
Average total loss: 4.500051
tensor(-8.5735, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.9085e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.302585
Average KL loss: 2.076272
Average total loss: 4.378857
tensor(-8.6295, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.8046e-07, device='cuda:0')
Epoch 33
Average batch original loss after noise: 2.302585
Average KL loss: 1.964525
Average total loss: 4.267110
tensor(-8.6841, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.7087e-07, device='cuda:0')
Epoch 34
Average batch original loss after noise: 2.302585
Average KL loss: 1.861249
Average total loss: 4.163834
tensor(-8.7375, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.6199e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 2.302585
Average KL loss: 1.765592
Average total loss: 4.068177
tensor(-8.7896, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.5376e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 2.302585
Average KL loss: 1.676809
Average total loss: 3.979394
tensor(-8.8407, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.4612e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 2.302589
Average KL loss: 1.594238
Average total loss: 3.896827
tensor(-8.8906, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.3900e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 2.302585
Average KL loss: 1.517307
Average total loss: 3.819892
tensor(-8.9396, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.3236e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 2.302590
Average KL loss: 1.445505
Average total loss: 3.748095
tensor(-8.9876, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.2616e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 2.302585
Average KL loss: 1.378377
Average total loss: 3.680962
tensor(-9.0346, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.2036e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 2.302585
Average KL loss: 1.315524
Average total loss: 3.618109
tensor(-9.0809, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.1492e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 2.302585
Average KL loss: 1.256583
Average total loss: 3.559168
tensor(-9.1263, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.0982e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 2.302591
Average KL loss: 1.201232
Average total loss: 3.503823
tensor(-9.1710, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.0502e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 2.302585
Average KL loss: 1.149183
Average total loss: 3.451768
tensor(-9.2149, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.0051e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 2.302569
Average KL loss: 1.100177
Average total loss: 3.402746
tensor(-9.2581, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(9.6257e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 2.302585
Average KL loss: 1.053979
Average total loss: 3.356563
tensor(-9.3007, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(9.2247e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 2.302585
Average KL loss: 1.010376
Average total loss: 3.312961
tensor(-9.3426, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(8.8460e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 2.302585
Average KL loss: 0.969178
Average total loss: 3.271763
tensor(-9.3839, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(8.4879e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 2.302585
Average KL loss: 0.930209
Average total loss: 3.232794
tensor(-9.4247, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(8.1491e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 2.302585
Average KL loss: 0.893312
Average total loss: 3.195897
tensor(-9.4648, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(7.8281e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 2.302585
Average KL loss: 0.858343
Average total loss: 3.160928
tensor(-9.5045, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(7.5237e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 2.302585
Average KL loss: 0.825169
Average total loss: 3.127754
tensor(-9.5437, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(7.2348e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 2.302585
Average KL loss: 0.793670
Average total loss: 3.096255
tensor(-9.5823, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(6.9604e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 2.302585
Average KL loss: 0.763737
Average total loss: 3.066322
tensor(-9.6205, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(6.6995e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 2.302585
Average KL loss: 0.735266
Average total loss: 3.037851
tensor(-9.6583, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(6.4512e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 2.302585
Average KL loss: 0.708166
Average total loss: 3.010751
tensor(-9.6956, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(6.2148e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 2.302585
Average KL loss: 0.682350
Average total loss: 2.984935
tensor(-9.7326, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(5.9895e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 2.302585
Average KL loss: 0.657739
Average total loss: 2.960324
tensor(-9.7691, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(5.7747e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 2.302585
Average KL loss: 0.634262
Average total loss: 2.936847
tensor(-9.8053, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(5.5696e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 2.302587
Average KL loss: 0.611849
Average total loss: 2.914437
tensor(-9.8410, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(5.3738e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 2.302585
Average KL loss: 0.590440
Average total loss: 2.893025
tensor(-9.8765, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(5.1867e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 2.302585
Average KL loss: 0.569976
Average total loss: 2.872561
tensor(-9.9116, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(5.0078e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 2.302585
Average KL loss: 0.550403
Average total loss: 2.852988
tensor(-9.9464, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(4.8367e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 2.302587
Average KL loss: 0.531672
Average total loss: 2.834259
tensor(-9.9808, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(4.6728e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 2.302585
Average KL loss: 0.513736
Average total loss: 2.816321
tensor(-10.0150, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(4.5159e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 2.302585
Average KL loss: 0.496553
Average total loss: 2.799138
tensor(-10.0489, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(4.3655e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 2.302585
Average KL loss: 0.480081
Average total loss: 2.782666
tensor(-10.0824, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(4.2213e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 2.302585
Average KL loss: 0.464284
Average total loss: 2.766869
tensor(-10.1158, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(4.0830e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 2.302585
Average KL loss: 0.449125
Average total loss: 2.751710
tensor(-10.1488, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.9502e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 2.302585
Average KL loss: 0.434573
Average total loss: 2.737158
tensor(-10.1816, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.8227e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 2.302585
Average KL loss: 0.420597
Average total loss: 2.723182
tensor(-10.2142, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.7002e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 2.302585
Average KL loss: 0.407168
Average total loss: 2.709753
tensor(-10.2465, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.5825e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 2.302585
Average KL loss: 0.394258
Average total loss: 2.696843
tensor(-10.2786, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.4693e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 2.302585
Average KL loss: 0.381843
Average total loss: 2.684428
tensor(-10.3105, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.3605e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 2.302585
Average KL loss: 0.369899
Average total loss: 2.672484
tensor(-10.3422, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.2557e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 2.302585
Average KL loss: 0.358404
Average total loss: 2.660989
tensor(-10.3736, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.1549e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 2.302585
Average KL loss: 0.347336
Average total loss: 2.649921
tensor(-10.4049, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.0578e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 2.302585
Average KL loss: 0.336676
Average total loss: 2.639260
tensor(-10.4360, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.9642e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 2.302585
Average KL loss: 0.326404
Average total loss: 2.628989
tensor(-10.4669, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.8740e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 2.302585
Average KL loss: 0.316504
Average total loss: 2.619089
tensor(-10.4976, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.7871e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 2.302585
Average KL loss: 0.306959
Average total loss: 2.609544
tensor(-10.5281, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.7033e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 2.302586
Average KL loss: 0.297753
Average total loss: 2.600339
tensor(-10.5585, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.6225e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 2.302585
Average KL loss: 0.288871
Average total loss: 2.591456
tensor(-10.5887, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.5445e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 2.302585
Average KL loss: 0.280299
Average total loss: 2.582884
tensor(-10.6187, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.4692e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 2.302585
Average KL loss: 0.272024
Average total loss: 2.574609
tensor(-10.6486, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.3965e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 2.302585
Average KL loss: 0.264034
Average total loss: 2.566619
tensor(-10.6783, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.3262e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 2.302585
Average KL loss: 0.256316
Average total loss: 2.558901
tensor(-10.7079, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.2584e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 2.302585
Average KL loss: 0.248859
Average total loss: 2.551444
tensor(-10.7374, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.1929e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 2.302585
Average KL loss: 0.241652
Average total loss: 2.544237
tensor(-10.7667, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.1295e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 2.302585
Average KL loss: 0.234685
Average total loss: 2.537270
tensor(-10.7959, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.0683e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 2.302585
Average KL loss: 0.227950
Average total loss: 2.530534
tensor(-10.8249, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.0090e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 2.302585
Average KL loss: 0.221435
Average total loss: 2.524020
tensor(-10.8539, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.9517e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 2.302585
Average KL loss: 0.215133
Average total loss: 2.517718
tensor(-10.8827, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.8963e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 2.302585
Average KL loss: 0.209035
Average total loss: 2.511620
tensor(-10.9114, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.8427e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 2.302585
Average KL loss: 0.203133
Average total loss: 2.505718
tensor(-10.9400, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.7907e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 2.302585
Average KL loss: 0.197421
Average total loss: 2.500006
tensor(-10.9684, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.7405e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 2.302585
Average KL loss: 0.191890
Average total loss: 2.494474
tensor(-10.9968, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.6918e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 2.302585
Average KL loss: 0.186533
Average total loss: 2.489118
tensor(-11.0250, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.6447e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 2.302585
Average KL loss: 0.181345
Average total loss: 2.483930
tensor(-11.0532, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.5990e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 2.302585
Average KL loss: 0.176319
Average total loss: 2.478904
tensor(-11.0813, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.5548e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 2.302585
Average KL loss: 0.171448
Average total loss: 2.474033
tensor(-11.1092, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.5119e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 2.302585
Average KL loss: 0.166728
Average total loss: 2.469313
tensor(-11.1371, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.4704e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 2.302585
Average KL loss: 0.162153
Average total loss: 2.464738
tensor(-11.1649, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.4301e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 2.302585
Average KL loss: 0.157718
Average total loss: 2.460303
tensor(-11.1926, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.3910e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 2.302585
Average KL loss: 0.153417
Average total loss: 2.456002
tensor(-11.2202, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.3531e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 2.302585
Average KL loss: 0.149246
Average total loss: 2.451831
tensor(-11.2477, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.3164e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 2.302585
Average KL loss: 0.145200
Average total loss: 2.447785
tensor(-11.2751, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.2808e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 2.302585
Average KL loss: 0.141276
Average total loss: 2.443861
tensor(-11.3025, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.2462e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 2.302585
Average KL loss: 0.137468
Average total loss: 2.440053
tensor(-11.3298, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.2127e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 2.302585
Average KL loss: 0.133773
Average total loss: 2.436358
tensor(-11.3570, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.1801e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 2.302585
Average KL loss: 0.130187
Average total loss: 2.432772
tensor(-11.3841, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.1485e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 2.302585
Average KL loss: 0.126706
Average total loss: 2.429291
tensor(-11.4112, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.1179e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 2.302585
Average KL loss: 0.123327
Average total loss: 2.425912
tensor(-11.4382, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.0881e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 2.302585
Average KL loss: 0.120046
Average total loss: 2.422631
tensor(-11.4651, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.0592e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 2.302585
Average KL loss: 0.116860
Average total loss: 2.419445
tensor(-11.4920, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.0311e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 2.302585
Average KL loss: 0.113766
Average total loss: 2.416351
tensor(-11.5188, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.0038e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 2.302585
Average KL loss: 0.110761
Average total loss: 2.413346
tensor(-11.5455, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(9.7735e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 2.302585
Average KL loss: 0.107842
Average total loss: 2.410426
tensor(-11.5722, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(9.5163e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 2.302585
Average KL loss: 0.105006
Average total loss: 2.407591
tensor(-11.5988, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(9.2663e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 2.302585
Average KL loss: 0.102250
Average total loss: 2.404835
tensor(-11.6253, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(9.0234e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 2.302585
Average KL loss: 0.099573
Average total loss: 2.402158
tensor(-11.6518, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(8.7874e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 2.302585
Average KL loss: 0.096971
Average total loss: 2.399556
tensor(-11.6783, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(8.5580e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 2.302585
Average KL loss: 0.094442
Average total loss: 2.397027
tensor(-11.7047, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(8.3350e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 2.302585
Average KL loss: 0.091984
Average total loss: 2.394569
tensor(-11.7310, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(8.1183e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 2.302585
Average KL loss: 0.089594
Average total loss: 2.392179
tensor(-11.7573, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(7.9076e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 2.302585
Average KL loss: 0.087271
Average total loss: 2.389856
tensor(-11.7836, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(7.7028e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 2.302585
Average KL loss: 0.085013
Average total loss: 2.387598
tensor(-11.8098, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(7.5036e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 2.302585
Average KL loss: 0.082816
Average total loss: 2.385401
tensor(-11.8359, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(7.3100e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 2.302588
Average KL loss: 0.080681
Average total loss: 2.383268
tensor(-11.8620, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(7.1216e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 2.302585
Average KL loss: 0.078603
Average total loss: 2.381188
tensor(-11.8881, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(6.9384e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 2.302585
Average KL loss: 0.076583
Average total loss: 2.379168
tensor(-11.9141, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(6.7602e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 2.302585
Average KL loss: 0.074618
Average total loss: 2.377203
tensor(-11.9401, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(6.5869e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 2.302585
Average KL loss: 0.072706
Average total loss: 2.375291
tensor(-11.9660, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(6.4183e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 2.302585
Average KL loss: 0.070847
Average total loss: 2.373431
tensor(-11.9919, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(6.2542e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 2.302585
Average KL loss: 0.069037
Average total loss: 2.371622
tensor(-12.0177, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(6.0946e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 2.302585
Average KL loss: 0.067277
Average total loss: 2.369862
tensor(-12.0436, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(5.9393e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 2.302585
Average KL loss: 0.065563
Average total loss: 2.368148
tensor(-12.0693, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(5.7882e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 2.302585
Average KL loss: 0.063896
Average total loss: 2.366481
tensor(-12.0951, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(5.6411e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 2.302585
Average KL loss: 0.062274
Average total loss: 2.364859
tensor(-12.1208, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(5.4980e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 2.302585
Average KL loss: 0.060695
Average total loss: 2.363280
tensor(-12.1464, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(5.3587e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 2.302585
Average KL loss: 0.059158
Average total loss: 2.361743
tensor(-12.1720, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(5.2231e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 2.302585
Average KL loss: 0.057662
Average total loss: 2.360247
tensor(-12.1976, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(5.0911e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 2.302585
Average KL loss: 0.056206
Average total loss: 2.358791
tensor(-12.2232, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(4.9626e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 2.302585
Average KL loss: 0.054788
Average total loss: 2.357373
tensor(-12.2487, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(4.8375e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 2.302585
Average KL loss: 0.053408
Average total loss: 2.355993
tensor(-12.2742, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(4.7157e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 2.302585
Average KL loss: 0.052064
Average total loss: 2.354649
tensor(-12.2997, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(4.5971e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 2.302585
Average KL loss: 0.050755
Average total loss: 2.353340
tensor(-12.3251, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(4.4817e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 2.302585
Average KL loss: 0.049481
Average total loss: 2.352066
tensor(-12.3505, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(4.3692e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 2.302585
Average KL loss: 0.048241
Average total loss: 2.350826
tensor(-12.3759, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(4.2598e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 2.302585
Average KL loss: 0.047033
Average total loss: 2.349617
tensor(-12.4013, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(4.1531e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 2.302585
Average KL loss: 0.045856
Average total loss: 2.348441
tensor(-12.4266, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(4.0493e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 2.302585
Average KL loss: 0.044710
Average total loss: 2.347295
tensor(-12.4519, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.9482e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 2.302585
Average KL loss: 0.043594
Average total loss: 2.346179
tensor(-12.4771, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.8497e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 2.302585
Average KL loss: 0.042507
Average total loss: 2.345092
tensor(-12.5024, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.7537e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 2.302585
Average KL loss: 0.041448
Average total loss: 2.344033
tensor(-12.5276, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.6603e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 2.302585
Average KL loss: 0.040417
Average total loss: 2.343002
tensor(-12.5528, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.5692e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 2.302585
Average KL loss: 0.039412
Average total loss: 2.341997
tensor(-12.5779, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.4805e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 2.302585
Average KL loss: 0.038433
Average total loss: 2.341018
tensor(-12.6031, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.3941e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 2.302585
Average KL loss: 0.037480
Average total loss: 2.340064
tensor(-12.6282, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.3100e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 2.302585
Average KL loss: 0.036551
Average total loss: 2.339135
tensor(-12.6533, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.2279e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 2.302585
Average KL loss: 0.035645
Average total loss: 2.338230
tensor(-12.6783, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(3.1481e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 2.302585
Average KL loss: 0.034763
Average total loss: 2.337348
tensor(-12.7034, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(3.0702e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 2.302585
Average KL loss: 0.033904
Average total loss: 2.336489
tensor(-12.7284, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.9944e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 2.302585
Average KL loss: 0.033067
Average total loss: 2.335652
tensor(-12.7534, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.9204e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 2.302585
Average KL loss: 0.032251
Average total loss: 2.334836
tensor(-12.7783, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.8484e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 2.302585
Average KL loss: 0.031456
Average total loss: 2.334041
tensor(-12.8033, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.7782e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 2.302585
Average KL loss: 0.030681
Average total loss: 2.333266
tensor(-12.8282, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.7098e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 2.302585
Average KL loss: 0.029926
Average total loss: 2.332511
tensor(-12.8531, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.6432e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 2.302585
Average KL loss: 0.029190
Average total loss: 2.331775
tensor(-12.8780, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.5782e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 2.302585
Average KL loss: 0.028473
Average total loss: 2.331058
tensor(-12.9029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.5149e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 2.302585
Average KL loss: 0.027774
Average total loss: 2.330359
tensor(-12.9277, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.4532e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 2.302585
Average KL loss: 0.027093
Average total loss: 2.329678
tensor(-12.9525, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.3930e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 2.302585
Average KL loss: 0.026429
Average total loss: 2.329013
tensor(-12.9773, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.3344e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 2.302585
Average KL loss: 0.025781
Average total loss: 2.328366
tensor(-13.0021, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.2773e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 2.302585
Average KL loss: 0.025151
Average total loss: 2.327735
tensor(-13.0269, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.2215e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 2.302585
Average KL loss: 0.024536
Average total loss: 2.327120
tensor(-13.0516, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.1673e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 2.302585
Average KL loss: 0.023936
Average total loss: 2.326521
tensor(-13.0763, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.1143e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 2.302585
Average KL loss: 0.023352
Average total loss: 2.325937
tensor(-13.1010, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.0627e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 2.302585
Average KL loss: 0.022782
Average total loss: 2.325367
tensor(-13.1257, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.0124e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 2.302585
Average KL loss: 0.022227
Average total loss: 2.324812
tensor(-13.1504, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.9634e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 2.302585
Average KL loss: 0.021686
Average total loss: 2.324270
tensor(-13.1750, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.9156e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 2.302585
Average KL loss: 0.021158
Average total loss: 2.323743
tensor(-13.1996, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.8690e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 2.302585
Average KL loss: 0.020643
Average total loss: 2.323228
tensor(-13.2242, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.8236e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 2.302585
Average KL loss: 0.020142
Average total loss: 2.322727
tensor(-13.2488, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.7793e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 2.302585
Average KL loss: 0.019652
Average total loss: 2.322237
tensor(-13.2734, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.7361e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 2.302585
Average KL loss: 0.019176
Average total loss: 2.321760
tensor(-13.2979, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.6940e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 2.302585
Average KL loss: 0.018711
Average total loss: 2.321296
tensor(-13.3225, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.6529e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 2.302585
Average KL loss: 0.018257
Average total loss: 2.320842
tensor(-13.3470, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.6129e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 2.302585
Average KL loss: 0.017815
Average total loss: 2.320400
tensor(-13.3715, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.5738e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 2.302585
Average KL loss: 0.017384
Average total loss: 2.319969
tensor(-13.3960, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.5358e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 2.302585
Average KL loss: 0.016964
Average total loss: 2.319549
tensor(-13.4204, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.4987e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 2.302585
Average KL loss: 0.016554
Average total loss: 2.319139
tensor(-13.4449, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.4625e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 2.302585
Average KL loss: 0.016155
Average total loss: 2.318740
tensor(-13.4693, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.4272e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 2.302585
Average KL loss: 0.015765
Average total loss: 2.318350
tensor(-13.4937, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.3928e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 2.302585
Average KL loss: 0.015385
Average total loss: 2.317970
tensor(-13.5181, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.3592e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 2.302585
Average KL loss: 0.015015
Average total loss: 2.317599
tensor(-13.5424, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.3265e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 2.302585
Average KL loss: 0.014653
Average total loss: 2.317238
tensor(-13.5668, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.2946e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 2.302585
Average KL loss: 0.014301
Average total loss: 2.316886
tensor(-13.5911, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.2635e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 2.302585
Average KL loss: 0.013957
Average total loss: 2.316542
tensor(-13.6154, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.2331e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 2.302585
Average KL loss: 0.013622
Average total loss: 2.316207
 Percentile value: -13.633804321289062
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1697 /    1728             ( 98.21%) | total_pruned =      31 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   27774 /   36864             ( 75.34%) | total_pruned =    9090 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   28085 /   36864             ( 76.19%) | total_pruned =    8779 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   27812 /   36864             ( 75.44%) | total_pruned =    9052 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   26251 /   36864             ( 71.21%) | total_pruned =   10613 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   54786 /   73728             ( 74.31%) | total_pruned =   18942 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   92379 /  147456             ( 62.65%) | total_pruned =   55077 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7264 /    8192             ( 88.67%) | total_pruned =     928 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   86385 /  147456             ( 58.58%) | total_pruned =   61071 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   77944 /  147456             ( 52.86%) | total_pruned =   69512 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  175959 /  294912             ( 59.66%) | total_pruned =  118953 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  275227 /  589824             ( 46.66%) | total_pruned =  314597 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   24982 /   32768             ( 76.24%) | total_pruned =    7786 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  236488 /  589824             ( 40.09%) | total_pruned =  353336 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  204392 /  589824             ( 34.65%) | total_pruned =  385432 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  509023 / 1179648             ( 43.15%) | total_pruned =  670625 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     483 /     512             ( 94.34%) | total_pruned =      29 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  626546 / 2359296             ( 26.56%) | total_pruned = 1732750 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   73583 /  131072             ( 56.14%) | total_pruned =   57489 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  508665 / 2359296             ( 21.56%) | total_pruned = 1850631 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     400 /     512             ( 78.12%) | total_pruned =     112 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  274131 / 2359296             ( 11.62%) | total_pruned = 2085165 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([512])
linear.weight        | nonzeros =    4941 /    5120             ( 96.50%) | total_pruned =     179 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 22/200 Loss: 0.000092 Accuracy: 86.93 100.00 % Best test Accuracy: 86.93%
tensor(-13.6397, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.2035e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302585
Average KL loss: 0.010700
Average total loss: 2.313285
tensor(-14.0867, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(7.6378e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.302585
Average KL loss: 0.007290
Average total loss: 2.309875
tensor(-14.3995, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(5.5811e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.302585
Average KL loss: 0.005542
Average total loss: 2.308127
tensor(-14.6360, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(4.4044e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.302585
Average KL loss: 0.004477
Average total loss: 2.307062
tensor(-14.8266, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(3.6394e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.302585
Average KL loss: 0.003758
Average total loss: 2.306343
tensor(-14.9865, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(3.1014e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.302585
Average KL loss: 0.003238
Average total loss: 2.305823
tensor(-15.1243, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(2.7019e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.302585
Average KL loss: 0.002845
Average total loss: 2.305430
tensor(-15.2455, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(2.3936e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.302585
Average KL loss: 0.002537
Average total loss: 2.305121
tensor(-15.3536, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(2.1483e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.302585
Average KL loss: 0.002289
Average total loss: 2.304873
tensor(-15.4511, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(1.9485e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.302585
Average KL loss: 0.002085
Average total loss: 2.304670
tensor(-15.5401, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(1.7826e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.302585
Average KL loss: 0.001914
Average total loss: 2.304499
tensor(-15.6219, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(1.6427e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.302585
Average KL loss: 0.001769
Average total loss: 2.304354
tensor(-15.6975, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(1.5230e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.302585
Average KL loss: 0.001645
Average total loss: 2.304229
tensor(-15.7678, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(1.4196e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.302585
Average KL loss: 0.001536
Average total loss: 2.304121
tensor(-15.8336, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(1.3292e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.302585
Average KL loss: 0.001441
Average total loss: 2.304026
tensor(-15.8953, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(1.2496e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.302585
Average KL loss: 0.001357
Average total loss: 2.303942
tensor(-15.9535, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(1.1790e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.302585
Average KL loss: 0.001283
Average total loss: 2.303868
tensor(-16.0085, device='cuda:0') tensor(9.8083e-05, device='cuda:0') tensor(1.1158e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.302585
Average KL loss: 0.001216
Average total loss: 2.303801
tensor(-16.0607, device='cuda:0') tensor(9.0804e-05, device='cuda:0') tensor(1.0591e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.302585
Average KL loss: 0.001155
Average total loss: 2.303740
tensor(-16.1103, device='cuda:0') tensor(8.4390e-05, device='cuda:0') tensor(1.0078e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.302585
Average KL loss: 0.001101
Average total loss: 2.303686
tensor(-16.1576, device='cuda:0') tensor(7.8702e-05, device='cuda:0') tensor(9.6126e-11, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 55
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 56
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 57
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 58
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 59
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 60
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 61
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 62
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 63
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 64
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 65
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 66
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 67
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 68
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 69
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 70
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 71
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 72
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 73
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 74
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  140889 / 2359296             (  5.97%) | total_pruned = 2218407 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   73583 /  131072             ( 56.14%) | total_pruned =   57489 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  508665 / 2359296             ( 21.56%) | total_pruned = 1850631 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     400 /     512             ( 78.12%) | total_pruned =     112 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  274131 / 2359296             ( 11.62%) | total_pruned = 2085165 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([512])
linear.weight        | nonzeros =    4941 /    5120             ( 96.50%) | total_pruned =     179 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 34/200 Loss: 2.302650 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   20897 / 2359296             (  0.89%) | total_pruned = 2338399 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     400 /     512             ( 78.12%) | total_pruned =     112 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  274131 / 2359296             ( 11.62%) | total_pruned = 2085165 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([512])
linear.weight        | nonzeros =    4941 /    5120             ( 96.50%) | total_pruned =     179 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 34/200 Loss: 2.302481 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   84655 / 2359296             (  3.59%) | total_pruned = 2274641 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([512])
linear.weight        | nonzeros =    4941 /    5120             ( 96.50%) | total_pruned =     179 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 34/200 Loss: 2.302543 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   21271 / 2359296             (  0.90%) | total_pruned = 2338025 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([512])
linear.weight        | nonzeros =    4941 /    5120             ( 96.50%) | total_pruned =     179 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 34/200 Loss: 2.302546 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2256 / 2359296             (  0.10%) | total_pruned = 2357040 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([512])
linear.weight        | nonzeros =    4941 /    5120             ( 96.50%) | total_pruned =     179 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 34/200 Loss: 2.302465 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
