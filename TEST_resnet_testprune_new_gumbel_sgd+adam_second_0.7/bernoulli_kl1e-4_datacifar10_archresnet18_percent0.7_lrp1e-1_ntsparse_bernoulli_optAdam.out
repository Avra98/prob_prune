Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(2.4786e-05, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.905239
Average KL loss: 189.331430
Average total loss: 191.236664
tensor(-3.3396, device='cuda:0') tensor(0.2401, device='cuda:0') tensor(3.6076e-06, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.906319
Average KL loss: 28.880134
Average total loss: 30.786452
tensor(-4.2937, device='cuda:0') tensor(0.2904, device='cuda:0') tensor(1.5993e-06, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.875756
Average KL loss: 15.407740
Average total loss: 17.283495
tensor(-4.8153, device='cuda:0') tensor(0.3157, device='cuda:0') tensor(9.7388e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.834596
Average KL loss: 10.406014
Average total loss: 12.240610
tensor(-5.1971, device='cuda:0') tensor(0.3381, device='cuda:0') tensor(7.1412e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.796720
Average KL loss: 7.758653
Average total loss: 9.555373
tensor(-5.5010, device='cuda:0') tensor(0.3556, device='cuda:0') tensor(5.1645e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.767840
Average KL loss: 6.135651
Average total loss: 7.903491
tensor(-5.7541, device='cuda:0') tensor(0.3707, device='cuda:0') tensor(4.1795e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.734271
Average KL loss: 5.053933
Average total loss: 6.788204
tensor(-5.9716, device='cuda:0') tensor(0.3841, device='cuda:0') tensor(3.5295e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.703514
Average KL loss: 4.283913
Average total loss: 5.987427
tensor(-6.1625, device='cuda:0') tensor(0.3949, device='cuda:0') tensor(3.0917e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.663220
Average KL loss: 3.704771
Average total loss: 5.367990
tensor(-6.3330, device='cuda:0') tensor(0.4028, device='cuda:0') tensor(2.5516e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.636119
Average KL loss: 3.253947
Average total loss: 4.890066
tensor(-6.4872, device='cuda:0') tensor(0.4088, device='cuda:0') tensor(2.2096e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.599933
Average KL loss: 2.895501
Average total loss: 4.495434
tensor(-6.6280, device='cuda:0') tensor(0.4138, device='cuda:0') tensor(1.8756e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.580764
Average KL loss: 2.602141
Average total loss: 4.182904
tensor(-6.7578, device='cuda:0') tensor(0.4181, device='cuda:0') tensor(1.7559e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.556254
Average KL loss: 2.361804
Average total loss: 3.918057
tensor(-6.8782, device='cuda:0') tensor(0.4216, device='cuda:0') tensor(1.5672e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.520404
Average KL loss: 2.157747
Average total loss: 3.678151
tensor(-6.9907, device='cuda:0') tensor(0.4237, device='cuda:0') tensor(1.4767e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.512979
Average KL loss: 1.981513
Average total loss: 3.494492
tensor(-7.0962, device='cuda:0') tensor(0.4257, device='cuda:0') tensor(1.3272e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.480897
Average KL loss: 1.831991
Average total loss: 3.312887
tensor(-7.1957, device='cuda:0') tensor(0.4275, device='cuda:0') tensor(1.2362e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.462960
Average KL loss: 1.703001
Average total loss: 3.165961
tensor(-7.2898, device='cuda:0') tensor(0.4293, device='cuda:0') tensor(1.0072e-07, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.438812
Average KL loss: 1.592720
Average total loss: 3.031531
tensor(-7.3793, device='cuda:0') tensor(0.4311, device='cuda:0') tensor(9.8864e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.414288
Average KL loss: 1.497437
Average total loss: 2.911725
tensor(-7.4645, device='cuda:0') tensor(0.4326, device='cuda:0') tensor(8.8620e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.391189
Average KL loss: 1.411750
Average total loss: 2.802938
tensor(-7.5460, device='cuda:0') tensor(0.4339, device='cuda:0') tensor(8.2914e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.369097
Average KL loss: 1.334004
Average total loss: 2.703100
tensor(-7.6240, device='cuda:0') tensor(0.4349, device='cuda:0') tensor(7.7982e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.360217
Average KL loss: 1.265794
Average total loss: 2.626011
tensor(-7.6989, device='cuda:0') tensor(0.4361, device='cuda:0') tensor(7.1318e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.345131
Average KL loss: 1.204095
Average total loss: 2.549226
tensor(-7.7710, device='cuda:0') tensor(0.4372, device='cuda:0') tensor(7.1008e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.323609
Average KL loss: 1.148666
Average total loss: 2.472275
tensor(-7.8405, device='cuda:0') tensor(0.4380, device='cuda:0') tensor(6.0047e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.309541
Average KL loss: 1.098052
Average total loss: 2.407594
tensor(-7.9076, device='cuda:0') tensor(0.4389, device='cuda:0') tensor(5.8231e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.299030
Average KL loss: 1.052464
Average total loss: 2.351493
tensor(-7.9726, device='cuda:0') tensor(0.4400, device='cuda:0') tensor(5.3360e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.292202
Average KL loss: 1.010510
Average total loss: 2.302712
tensor(-8.0355, device='cuda:0') tensor(0.4409, device='cuda:0') tensor(4.9848e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.278181
Average KL loss: 0.971740
Average total loss: 2.249921
tensor(-8.0966, device='cuda:0') tensor(0.4419, device='cuda:0') tensor(4.8038e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.267267
Average KL loss: 0.936404
Average total loss: 2.203671
tensor(-8.1559, device='cuda:0') tensor(0.4428, device='cuda:0') tensor(4.4107e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.260538
Average KL loss: 0.903762
Average total loss: 2.164300
tensor(-8.2136, device='cuda:0') tensor(0.4440, device='cuda:0') tensor(4.3807e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.247968
Average KL loss: 0.875323
Average total loss: 2.123291
tensor(-8.2698, device='cuda:0') tensor(0.4451, device='cuda:0') tensor(4.0583e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.241842
Average KL loss: 0.848154
Average total loss: 2.089996
tensor(-8.3246, device='cuda:0') tensor(0.4462, device='cuda:0') tensor(3.9273e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.235607
Average KL loss: 0.823300
Average total loss: 2.058907
tensor(-8.3781, device='cuda:0') tensor(0.4473, device='cuda:0') tensor(3.6287e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.226160
Average KL loss: 0.801431
Average total loss: 2.027591
tensor(-8.4304, device='cuda:0') tensor(0.4486, device='cuda:0') tensor(3.3821e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.218069
Average KL loss: 0.780755
Average total loss: 1.998824
tensor(-8.4814, device='cuda:0') tensor(0.4498, device='cuda:0') tensor(3.1824e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.210077
Average KL loss: 0.761179
Average total loss: 1.971256
tensor(-8.5314, device='cuda:0') tensor(0.4510, device='cuda:0') tensor(3.1082e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.205840
Average KL loss: 0.742803
Average total loss: 1.948642
tensor(-8.5803, device='cuda:0') tensor(0.4523, device='cuda:0') tensor(2.9352e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.202312
Average KL loss: 0.726348
Average total loss: 1.928660
tensor(-8.6283, device='cuda:0') tensor(0.4536, device='cuda:0') tensor(2.7026e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.190494
Average KL loss: 0.711228
Average total loss: 1.901721
tensor(-8.6753, device='cuda:0') tensor(0.4550, device='cuda:0') tensor(2.7217e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.187695
Average KL loss: 0.697303
Average total loss: 1.884998
tensor(-8.7215, device='cuda:0') tensor(0.4562, device='cuda:0') tensor(2.5512e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.176686
Average KL loss: 0.683506
Average total loss: 1.860192
tensor(-8.7668, device='cuda:0') tensor(0.4575, device='cuda:0') tensor(2.5107e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.175481
Average KL loss: 0.670325
Average total loss: 1.845806
tensor(-8.8114, device='cuda:0') tensor(0.4587, device='cuda:0') tensor(2.4139e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.169041
Average KL loss: 0.657579
Average total loss: 1.826620
tensor(-8.8552, device='cuda:0') tensor(0.4599, device='cuda:0') tensor(2.5251e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.166719
Average KL loss: 0.645707
Average total loss: 1.812425
tensor(-8.8983, device='cuda:0') tensor(0.4612, device='cuda:0') tensor(2.0481e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.162909
Average KL loss: 0.634179
Average total loss: 1.797089
tensor(-8.9408, device='cuda:0') tensor(0.4624, device='cuda:0') tensor(2.1502e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.157473
Average KL loss: 0.623746
Average total loss: 1.781220
tensor(-8.9826, device='cuda:0') tensor(0.4637, device='cuda:0') tensor(2.2530e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.151998
Average KL loss: 0.614027
Average total loss: 1.766024
tensor(-9.0237, device='cuda:0') tensor(0.4650, device='cuda:0') tensor(2.0659e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.147020
Average KL loss: 0.605092
Average total loss: 1.752113
tensor(-9.0643, device='cuda:0') tensor(0.4663, device='cuda:0') tensor(1.9019e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.143225
Average KL loss: 0.596415
Average total loss: 1.739641
tensor(-9.1043, device='cuda:0') tensor(0.4676, device='cuda:0') tensor(2.0317e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.139519
Average KL loss: 0.588072
Average total loss: 1.727591
tensor(-9.1438, device='cuda:0') tensor(0.4689, device='cuda:0') tensor(1.7467e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.139539
Average KL loss: 0.580142
Average total loss: 1.719681
tensor(-9.1828, device='cuda:0') tensor(0.4702, device='cuda:0') tensor(1.4488e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.131051
Average KL loss: 0.573383
Average total loss: 1.704434
tensor(-9.2213, device='cuda:0') tensor(0.4714, device='cuda:0') tensor(1.8155e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.128553
Average KL loss: 0.567020
Average total loss: 1.695574
tensor(-9.2593, device='cuda:0') tensor(0.4727, device='cuda:0') tensor(1.5739e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.121612
Average KL loss: 0.561255
Average total loss: 1.682867
tensor(-9.2969, device='cuda:0') tensor(0.4739, device='cuda:0') tensor(1.4513e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.120550
Average KL loss: 0.555186
Average total loss: 1.675736
tensor(-9.3340, device='cuda:0') tensor(0.4752, device='cuda:0') tensor(1.4488e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.116764
Average KL loss: 0.548780
Average total loss: 1.665544
tensor(-9.3707, device='cuda:0') tensor(0.4764, device='cuda:0') tensor(1.3049e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.116112
Average KL loss: 0.543171
Average total loss: 1.659283
tensor(-9.4070, device='cuda:0') tensor(0.4777, device='cuda:0') tensor(1.1638e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.112064
Average KL loss: 0.537787
Average total loss: 1.649851
tensor(-9.4429, device='cuda:0') tensor(0.4789, device='cuda:0') tensor(1.4058e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.108308
Average KL loss: 0.532371
Average total loss: 1.640680
tensor(-9.4785, device='cuda:0') tensor(0.4801, device='cuda:0') tensor(1.3717e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.106107
Average KL loss: 0.527647
Average total loss: 1.633754
tensor(-9.5137, device='cuda:0') tensor(0.4814, device='cuda:0') tensor(1.2600e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.103122
Average KL loss: 0.523105
Average total loss: 1.626227
tensor(-9.5485, device='cuda:0') tensor(0.4824, device='cuda:0') tensor(1.2294e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.100168
Average KL loss: 0.518438
Average total loss: 1.618606
tensor(-9.5831, device='cuda:0') tensor(0.4834, device='cuda:0') tensor(1.1236e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.099282
Average KL loss: 0.513640
Average total loss: 1.612922
tensor(-9.6173, device='cuda:0') tensor(0.4846, device='cuda:0') tensor(1.0525e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.094907
Average KL loss: 0.509408
Average total loss: 1.604315
tensor(-9.6512, device='cuda:0') tensor(0.4857, device='cuda:0') tensor(1.0138e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.094286
Average KL loss: 0.505380
Average total loss: 1.599666
tensor(-9.6848, device='cuda:0') tensor(0.4869, device='cuda:0') tensor(9.0908e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.092716
Average KL loss: 0.501988
Average total loss: 1.594704
tensor(-9.7181, device='cuda:0') tensor(0.4882, device='cuda:0') tensor(1.1811e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.090381
Average KL loss: 0.498232
Average total loss: 1.588613
tensor(-9.7512, device='cuda:0') tensor(0.4893, device='cuda:0') tensor(1.0695e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.087773
Average KL loss: 0.494525
Average total loss: 1.582298
tensor(-9.7840, device='cuda:0') tensor(0.4905, device='cuda:0') tensor(8.5783e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.087616
Average KL loss: 0.491198
Average total loss: 1.578815
tensor(-9.8165, device='cuda:0') tensor(0.4917, device='cuda:0') tensor(9.4086e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.086917
Average KL loss: 0.488088
Average total loss: 1.575005
tensor(-9.8488, device='cuda:0') tensor(0.4929, device='cuda:0') tensor(9.2713e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.082743
Average KL loss: 0.485300
Average total loss: 1.568044
tensor(-9.8808, device='cuda:0') tensor(0.4941, device='cuda:0') tensor(9.0796e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.082419
Average KL loss: 0.482125
Average total loss: 1.564545
tensor(-9.9126, device='cuda:0') tensor(0.4952, device='cuda:0') tensor(8.7036e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.078949
Average KL loss: 0.479280
Average total loss: 1.558229
tensor(-9.9442, device='cuda:0') tensor(0.4963, device='cuda:0') tensor(7.1669e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.081620
Average KL loss: 0.476589
Average total loss: 1.558209
tensor(-9.9755, device='cuda:0') tensor(0.4976, device='cuda:0') tensor(6.9326e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.076239
Average KL loss: 0.473918
Average total loss: 1.550157
tensor(-10.0067, device='cuda:0') tensor(0.4986, device='cuda:0') tensor(8.3913e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.076299
Average KL loss: 0.471227
Average total loss: 1.547526
tensor(-10.0377, device='cuda:0') tensor(0.4996, device='cuda:0') tensor(7.7261e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.075245
Average KL loss: 0.468588
Average total loss: 1.543833
tensor(-10.0685, device='cuda:0') tensor(0.5006, device='cuda:0') tensor(6.9791e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.076281
Average KL loss: 0.466361
Average total loss: 1.542642
tensor(-10.0990, device='cuda:0') tensor(0.5018, device='cuda:0') tensor(7.6386e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.071039
Average KL loss: 0.464538
Average total loss: 1.535577
tensor(-10.1294, device='cuda:0') tensor(0.5029, device='cuda:0') tensor(6.8800e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.070867
Average KL loss: 0.462638
Average total loss: 1.533505
tensor(-10.1596, device='cuda:0') tensor(0.5040, device='cuda:0') tensor(4.9692e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.070120
Average KL loss: 0.460455
Average total loss: 1.530575
tensor(-10.1896, device='cuda:0') tensor(0.5050, device='cuda:0') tensor(6.1108e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.068878
Average KL loss: 0.458357
Average total loss: 1.527235
tensor(-10.2195, device='cuda:0') tensor(0.5061, device='cuda:0') tensor(5.0128e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.067324
Average KL loss: 0.456818
Average total loss: 1.524142
tensor(-10.2492, device='cuda:0') tensor(0.5073, device='cuda:0') tensor(6.3282e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.068275
Average KL loss: 0.455022
Average total loss: 1.523297
tensor(-10.2787, device='cuda:0') tensor(0.5083, device='cuda:0') tensor(5.8110e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.065490
Average KL loss: 0.452920
Average total loss: 1.518410
tensor(-10.3081, device='cuda:0') tensor(0.5093, device='cuda:0') tensor(5.0168e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.064127
Average KL loss: 0.451487
Average total loss: 1.515614
tensor(-10.3374, device='cuda:0') tensor(0.5104, device='cuda:0') tensor(6.0328e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.063623
Average KL loss: 0.450057
Average total loss: 1.513679
tensor(-10.3664, device='cuda:0') tensor(0.5114, device='cuda:0') tensor(4.6406e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.063823
Average KL loss: 0.448125
Average total loss: 1.511948
tensor(-10.3954, device='cuda:0') tensor(0.5123, device='cuda:0') tensor(4.5926e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.063043
Average KL loss: 0.446522
Average total loss: 1.509566
tensor(-10.4242, device='cuda:0') tensor(0.5134, device='cuda:0') tensor(5.6199e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.063632
Average KL loss: 0.445125
Average total loss: 1.508757
tensor(-10.4529, device='cuda:0') tensor(0.5144, device='cuda:0') tensor(5.3193e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.062288
Average KL loss: 0.443691
Average total loss: 1.505979
tensor(-10.4814, device='cuda:0') tensor(0.5154, device='cuda:0') tensor(4.2641e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.060590
Average KL loss: 0.442162
Average total loss: 1.502752
tensor(-10.5099, device='cuda:0') tensor(0.5163, device='cuda:0') tensor(5.0645e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.060876
Average KL loss: 0.440570
Average total loss: 1.501446
tensor(-10.5382, device='cuda:0') tensor(0.5172, device='cuda:0') tensor(4.2420e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.060219
Average KL loss: 0.439301
Average total loss: 1.499521
tensor(-10.5663, device='cuda:0') tensor(0.5181, device='cuda:0') tensor(4.2629e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.061352
Average KL loss: 0.437854
Average total loss: 1.499206
tensor(-10.5944, device='cuda:0') tensor(0.5190, device='cuda:0') tensor(4.3432e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.057720
Average KL loss: 0.436682
Average total loss: 1.494402
tensor(-10.6223, device='cuda:0') tensor(0.5201, device='cuda:0') tensor(4.2599e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.056891
Average KL loss: 0.435627
Average total loss: 1.492518
tensor(-10.6502, device='cuda:0') tensor(0.5211, device='cuda:0') tensor(3.5742e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.057933
Average KL loss: 0.434622
Average total loss: 1.492555
tensor(-10.6779, device='cuda:0') tensor(0.5221, device='cuda:0') tensor(4.2761e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.055967
Average KL loss: 0.433501
Average total loss: 1.489468
tensor(-10.7055, device='cuda:0') tensor(0.5230, device='cuda:0') tensor(3.5409e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.055582
Average KL loss: 0.432171
Average total loss: 1.487753
tensor(-10.7330, device='cuda:0') tensor(0.5239, device='cuda:0') tensor(3.0769e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.055270
Average KL loss: 0.431170
Average total loss: 1.486440
tensor(-10.7605, device='cuda:0') tensor(0.5249, device='cuda:0') tensor(3.7011e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.052141
Average KL loss: 0.430314
Average total loss: 1.482455
tensor(-10.7878, device='cuda:0') tensor(0.5258, device='cuda:0') tensor(3.6547e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.053500
Average KL loss: 0.429254
Average total loss: 1.482754
tensor(-10.8150, device='cuda:0') tensor(0.5266, device='cuda:0') tensor(3.5376e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.053806
Average KL loss: 0.428051
Average total loss: 1.481856
tensor(-10.8421, device='cuda:0') tensor(0.5276, device='cuda:0') tensor(3.3751e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.051190
Average KL loss: 0.427300
Average total loss: 1.478490
tensor(-10.8692, device='cuda:0') tensor(0.5286, device='cuda:0') tensor(2.5132e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.050930
Average KL loss: 0.426718
Average total loss: 1.477648
tensor(-10.8961, device='cuda:0') tensor(0.5295, device='cuda:0') tensor(3.1659e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.050129
Average KL loss: 0.426029
Average total loss: 1.476158
tensor(-10.9230, device='cuda:0') tensor(0.5305, device='cuda:0') tensor(3.0828e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.050647
Average KL loss: 0.425554
Average total loss: 1.476201
tensor(-10.9498, device='cuda:0') tensor(0.5314, device='cuda:0') tensor(1.8653e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.047567
Average KL loss: 0.425029
Average total loss: 1.472596
tensor(-10.9765, device='cuda:0') tensor(0.5322, device='cuda:0') tensor(5.8119e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.048377
Average KL loss: 0.424530
Average total loss: 1.472907
tensor(-11.0031, device='cuda:0') tensor(0.5331, device='cuda:0') tensor(2.5868e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.046549
Average KL loss: 0.423997
Average total loss: 1.470546
tensor(-11.0296, device='cuda:0') tensor(0.5339, device='cuda:0') tensor(2.5954e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.045846
Average KL loss: 0.423038
Average total loss: 1.468884
tensor(-11.0561, device='cuda:0') tensor(0.5346, device='cuda:0') tensor(2.6205e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.046526
Average KL loss: 0.422013
Average total loss: 1.468539
tensor(-11.0825, device='cuda:0') tensor(0.5353, device='cuda:0') tensor(2.9620e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.044416
Average KL loss: 0.421204
Average total loss: 1.465619
tensor(-11.1088, device='cuda:0') tensor(0.5361, device='cuda:0') tensor(1.9853e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.044308
Average KL loss: 0.420564
Average total loss: 1.464872
tensor(-11.1350, device='cuda:0') tensor(0.5369, device='cuda:0') tensor(2.4632e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.044869
Average KL loss: 0.419553
Average total loss: 1.464422
tensor(-11.1612, device='cuda:0') tensor(0.5377, device='cuda:0') tensor(2.0789e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.042668
Average KL loss: 0.419134
Average total loss: 1.461802
tensor(-11.1873, device='cuda:0') tensor(0.5386, device='cuda:0') tensor(2.2892e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.041838
Average KL loss: 0.418775
Average total loss: 1.460613
tensor(-11.2133, device='cuda:0') tensor(0.5394, device='cuda:0') tensor(1.8025e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.041407
Average KL loss: 0.418409
Average total loss: 1.459816
tensor(-11.2392, device='cuda:0') tensor(0.5403, device='cuda:0') tensor(1.9205e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.040035
Average KL loss: 0.417980
Average total loss: 1.458015
tensor(-11.2651, device='cuda:0') tensor(0.5410, device='cuda:0') tensor(1.7916e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.039853
Average KL loss: 0.417312
Average total loss: 1.457166
tensor(-11.2909, device='cuda:0') tensor(0.5419, device='cuda:0') tensor(1.9275e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.040144
Average KL loss: 0.416776
Average total loss: 1.456920
tensor(-11.3167, device='cuda:0') tensor(0.5427, device='cuda:0') tensor(2.6036e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.040800
Average KL loss: 0.415999
Average total loss: 1.456799
tensor(-11.3424, device='cuda:0') tensor(0.5434, device='cuda:0') tensor(1.9593e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.038888
Average KL loss: 0.415349
Average total loss: 1.454237
tensor(-11.3680, device='cuda:0') tensor(0.5441, device='cuda:0') tensor(1.3772e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.038790
Average KL loss: 0.414895
Average total loss: 1.453685
tensor(-11.3936, device='cuda:0') tensor(0.5448, device='cuda:0') tensor(2.6596e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.039956
Average KL loss: 0.414109
Average total loss: 1.454065
tensor(-11.4191, device='cuda:0') tensor(0.5455, device='cuda:0') tensor(1.8209e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.038347
Average KL loss: 0.413385
Average total loss: 1.451732
tensor(-11.4445, device='cuda:0') tensor(0.5462, device='cuda:0') tensor(2.0521e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.036704
Average KL loss: 0.413092
Average total loss: 1.449795
tensor(-11.4699, device='cuda:0') tensor(0.5469, device='cuda:0') tensor(2.2865e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.036345
Average KL loss: 0.412652
Average total loss: 1.448997
tensor(-11.4952, device='cuda:0') tensor(0.5476, device='cuda:0') tensor(1.9592e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.036420
Average KL loss: 0.412246
Average total loss: 1.448666
tensor(-11.5205, device='cuda:0') tensor(0.5482, device='cuda:0') tensor(1.5419e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.034974
Average KL loss: 0.412027
Average total loss: 1.447000
tensor(-11.5457, device='cuda:0') tensor(0.5488, device='cuda:0') tensor(1.4373e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.034925
Average KL loss: 0.411853
Average total loss: 1.446778
tensor(-11.5709, device='cuda:0') tensor(0.5495, device='cuda:0') tensor(1.6886e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.034272
Average KL loss: 0.411284
Average total loss: 1.445556
tensor(-11.5960, device='cuda:0') tensor(0.5500, device='cuda:0') tensor(2.1093e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.034978
Average KL loss: 0.410631
Average total loss: 1.445609
tensor(-11.6210, device='cuda:0') tensor(0.5506, device='cuda:0') tensor(2.1073e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.034580
Average KL loss: 0.409917
Average total loss: 1.444497
tensor(-11.6460, device='cuda:0') tensor(0.5512, device='cuda:0') tensor(1.4734e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.035459
Average KL loss: 0.409489
Average total loss: 1.444947
tensor(-11.6710, device='cuda:0') tensor(0.5519, device='cuda:0') tensor(1.0616e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.035419
Average KL loss: 0.409047
Average total loss: 1.444466
tensor(-11.6958, device='cuda:0') tensor(0.5526, device='cuda:0') tensor(1.4686e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.033370
Average KL loss: 0.408752
Average total loss: 1.442122
tensor(-11.7207, device='cuda:0') tensor(0.5533, device='cuda:0') tensor(1.6681e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.032545
Average KL loss: 0.408616
Average total loss: 1.441160
tensor(-11.7454, device='cuda:0') tensor(0.5541, device='cuda:0') tensor(4.0670e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.033754
Average KL loss: 0.408339
Average total loss: 1.442093
tensor(-11.7702, device='cuda:0') tensor(0.5546, device='cuda:0') tensor(4.9982e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.033229
Average KL loss: 0.407702
Average total loss: 1.440931
tensor(-11.7948, device='cuda:0') tensor(0.5552, device='cuda:0') tensor(1.1489e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.033212
Average KL loss: 0.407034
Average total loss: 1.440246
tensor(-11.8195, device='cuda:0') tensor(0.5558, device='cuda:0') tensor(1.0543e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.032621
Average KL loss: 0.406371
Average total loss: 1.438991
tensor(-11.8440, device='cuda:0') tensor(0.5564, device='cuda:0') tensor(8.1067e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.033187
Average KL loss: 0.405940
Average total loss: 1.439128
tensor(-11.8686, device='cuda:0') tensor(0.5568, device='cuda:0') tensor(1.3986e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.033065
Average KL loss: 0.405515
Average total loss: 1.438581
tensor(-11.8930, device='cuda:0') tensor(0.5573, device='cuda:0') tensor(1.1513e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.032888
Average KL loss: 0.405101
Average total loss: 1.437989
tensor(-11.9175, device='cuda:0') tensor(0.5578, device='cuda:0') tensor(1.6574e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.032007
Average KL loss: 0.404528
Average total loss: 1.436535
tensor(-11.9418, device='cuda:0') tensor(0.5583, device='cuda:0') tensor(8.2446e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.033074
Average KL loss: 0.404073
Average total loss: 1.437147
tensor(-11.9662, device='cuda:0') tensor(0.5589, device='cuda:0') tensor(1.8221e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.031765
Average KL loss: 0.403960
Average total loss: 1.435725
tensor(-11.9904, device='cuda:0') tensor(0.5593, device='cuda:0') tensor(9.2553e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.031738
Average KL loss: 0.403734
Average total loss: 1.435472
tensor(-12.0147, device='cuda:0') tensor(0.5597, device='cuda:0') tensor(1.5093e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.030265
Average KL loss: 0.403442
Average total loss: 1.433707
tensor(-12.0388, device='cuda:0') tensor(0.5600, device='cuda:0') tensor(1.3466e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.030325
Average KL loss: 0.403076
Average total loss: 1.433401
tensor(-12.0630, device='cuda:0') tensor(0.5603, device='cuda:0') tensor(1.4704e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.030306
Average KL loss: 0.402628
Average total loss: 1.432933
tensor(-12.0871, device='cuda:0') tensor(0.5607, device='cuda:0') tensor(1.3707e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.030536
Average KL loss: 0.402482
Average total loss: 1.433018
tensor(-12.1111, device='cuda:0') tensor(0.5611, device='cuda:0') tensor(7.3354e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.028938
Average KL loss: 0.402429
Average total loss: 1.431366
tensor(-12.1351, device='cuda:0') tensor(0.5616, device='cuda:0') tensor(7.7466e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.028100
Average KL loss: 0.402249
Average total loss: 1.430350
tensor(-12.1590, device='cuda:0') tensor(0.5619, device='cuda:0') tensor(9.7508e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.028564
Average KL loss: 0.401964
Average total loss: 1.430528
tensor(-12.1829, device='cuda:0') tensor(0.5623, device='cuda:0') tensor(-3.3007e-11, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.028211
Average KL loss: 0.401980
Average total loss: 1.430190
tensor(-12.2067, device='cuda:0') tensor(0.5627, device='cuda:0') tensor(9.8812e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.028621
Average KL loss: 0.401896
Average total loss: 1.430517
tensor(-12.2305, device='cuda:0') tensor(0.5631, device='cuda:0') tensor(3.2133e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.027582
Average KL loss: 0.401895
Average total loss: 1.429477
tensor(-12.2542, device='cuda:0') tensor(0.5635, device='cuda:0') tensor(1.1552e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.026939
Average KL loss: 0.401784
Average total loss: 1.428723
tensor(-12.2779, device='cuda:0') tensor(0.5639, device='cuda:0') tensor(1.3678e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.027327
Average KL loss: 0.401408
Average total loss: 1.428735
tensor(-12.3015, device='cuda:0') tensor(0.5642, device='cuda:0') tensor(7.4183e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.025836
Average KL loss: 0.401097
Average total loss: 1.426933
tensor(-12.3251, device='cuda:0') tensor(0.5645, device='cuda:0') tensor(9.9611e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.027662
Average KL loss: 0.401140
Average total loss: 1.428802
tensor(-12.3486, device='cuda:0') tensor(0.5648, device='cuda:0') tensor(3.6563e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.026355
Average KL loss: 0.401131
Average total loss: 1.427487
tensor(-12.3721, device='cuda:0') tensor(0.5651, device='cuda:0') tensor(9.6991e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.026456
Average KL loss: 0.400664
Average total loss: 1.427120
tensor(-12.3956, device='cuda:0') tensor(0.5652, device='cuda:0') tensor(1.0987e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.026492
Average KL loss: 0.400596
Average total loss: 1.427088
tensor(-12.4189, device='cuda:0') tensor(0.5655, device='cuda:0') tensor(-1.3096e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.024842
Average KL loss: 0.400529
Average total loss: 1.425371
tensor(-12.4423, device='cuda:0') tensor(0.5656, device='cuda:0') tensor(5.0535e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.024540
Average KL loss: 0.400201
Average total loss: 1.424742
tensor(-12.4655, device='cuda:0') tensor(0.5658, device='cuda:0') tensor(1.1435e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 1.026659
Average KL loss: 0.399867
Average total loss: 1.426526
tensor(-12.4888, device='cuda:0') tensor(0.5658, device='cuda:0') tensor(8.1391e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.024433
Average KL loss: 0.399589
Average total loss: 1.424022
tensor(-12.5120, device='cuda:0') tensor(0.5659, device='cuda:0') tensor(3.4614e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 1.025087
Average KL loss: 0.399240
Average total loss: 1.424327
tensor(-12.5351, device='cuda:0') tensor(0.5659, device='cuda:0') tensor(9.1280e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 1.024620
Average KL loss: 0.399029
Average total loss: 1.423649
tensor(-12.5582, device='cuda:0') tensor(0.5660, device='cuda:0') tensor(7.7137e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.024932
Average KL loss: 0.398581
Average total loss: 1.423514
tensor(-12.5812, device='cuda:0') tensor(0.5661, device='cuda:0') tensor(1.0737e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 1.025728
Average KL loss: 0.398274
Average total loss: 1.424003
tensor(-12.6041, device='cuda:0') tensor(0.5660, device='cuda:0') tensor(6.6978e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 1.024904
Average KL loss: 0.397777
Average total loss: 1.422681
tensor(-12.6270, device='cuda:0') tensor(0.5661, device='cuda:0') tensor(5.8585e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 1.026234
Average KL loss: 0.397377
Average total loss: 1.423611
tensor(-12.6499, device='cuda:0') tensor(0.5662, device='cuda:0') tensor(5.3168e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 1.026014
Average KL loss: 0.397348
Average total loss: 1.423362
tensor(-12.6727, device='cuda:0') tensor(0.5663, device='cuda:0') tensor(7.2697e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 1.026585
Average KL loss: 0.397235
Average total loss: 1.423819
tensor(-12.6954, device='cuda:0') tensor(0.5663, device='cuda:0') tensor(4.4797e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 1.024805
Average KL loss: 0.396999
Average total loss: 1.421804
tensor(-12.7181, device='cuda:0') tensor(0.5663, device='cuda:0') tensor(7.1507e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 1.024530
Average KL loss: 0.396966
Average total loss: 1.421496
tensor(-12.7408, device='cuda:0') tensor(0.5662, device='cuda:0') tensor(7.2094e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 1.025707
Average KL loss: 0.396757
Average total loss: 1.422464
tensor(-12.7633, device='cuda:0') tensor(0.5662, device='cuda:0') tensor(7.5941e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 1.026520
Average KL loss: 0.396555
Average total loss: 1.423075
tensor(-12.7859, device='cuda:0') tensor(0.5661, device='cuda:0') tensor(3.5469e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 1.024413
Average KL loss: 0.396350
Average total loss: 1.420763
tensor(-12.8083, device='cuda:0') tensor(0.5661, device='cuda:0') tensor(2.5803e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 1.024887
Average KL loss: 0.396262
Average total loss: 1.421149
tensor(-12.8307, device='cuda:0') tensor(0.5659, device='cuda:0') tensor(1.3641e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 1.025437
Average KL loss: 0.396286
Average total loss: 1.421723
tensor(-12.8531, device='cuda:0') tensor(0.5658, device='cuda:0') tensor(3.1525e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 1.024418
Average KL loss: 0.396236
Average total loss: 1.420653
tensor(-12.8753, device='cuda:0') tensor(0.5657, device='cuda:0') tensor(3.9494e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 1.025135
Average KL loss: 0.395995
Average total loss: 1.421130
tensor(-12.8976, device='cuda:0') tensor(0.5655, device='cuda:0') tensor(3.1674e-11, device='cuda:0')
Epoch 189
Average batch original loss after noise: 1.024948
Average KL loss: 0.395710
Average total loss: 1.420658
tensor(-12.9197, device='cuda:0') tensor(0.5653, device='cuda:0') tensor(7.8570e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 1.024555
Average KL loss: 0.395733
Average total loss: 1.420287
tensor(-12.9418, device='cuda:0') tensor(0.5652, device='cuda:0') tensor(4.1121e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 1.023229
Average KL loss: 0.395465
Average total loss: 1.418694
tensor(-12.9639, device='cuda:0') tensor(0.5650, device='cuda:0') tensor(5.1370e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 1.023501
Average KL loss: 0.395384
Average total loss: 1.418885
tensor(-12.9858, device='cuda:0') tensor(0.5648, device='cuda:0') tensor(-1.6232e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 1.024440
Average KL loss: 0.395432
Average total loss: 1.419871
tensor(-13.0078, device='cuda:0') tensor(0.5646, device='cuda:0') tensor(4.2628e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 1.022791
Average KL loss: 0.395329
Average total loss: 1.418120
tensor(-13.0296, device='cuda:0') tensor(0.5643, device='cuda:0') tensor(4.8285e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 1.023692
Average KL loss: 0.395203
Average total loss: 1.418895
tensor(-13.0514, device='cuda:0') tensor(0.5639, device='cuda:0') tensor(4.8902e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 1.023369
Average KL loss: 0.395155
Average total loss: 1.418524
tensor(-13.0731, device='cuda:0') tensor(0.5636, device='cuda:0') tensor(1.8995e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 1.022258
Average KL loss: 0.394885
Average total loss: 1.417144
tensor(-13.0948, device='cuda:0') tensor(0.5635, device='cuda:0') tensor(7.6229e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 1.023517
Average KL loss: 0.394877
Average total loss: 1.418394
tensor(-13.1164, device='cuda:0') tensor(0.5630, device='cuda:0') tensor(2.5166e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 1.022715
Average KL loss: 0.394636
Average total loss: 1.417351
tensor(-13.1379, device='cuda:0') tensor(0.5627, device='cuda:0') tensor(2.7065e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 1.021550
Average KL loss: 0.394395
Average total loss: 1.415945
 Percentile value: -12.327040100097657
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1704 /    1728             ( 98.61%) | total_pruned =      24 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   30721 /   36864             ( 83.34%) | total_pruned =    6143 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   31154 /   36864             ( 84.51%) | total_pruned =    5710 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   29501 /   36864             ( 80.03%) | total_pruned =    7363 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   28096 /   36864             ( 76.22%) | total_pruned =    8768 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   59337 /   73728             ( 80.48%) | total_pruned =   14391 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  101411 /  147456             ( 68.77%) | total_pruned =   46045 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7699 /    8192             ( 93.98%) | total_pruned =     493 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   94710 /  147456             ( 64.23%) | total_pruned =   52746 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   87869 /  147456             ( 59.59%) | total_pruned =   59587 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  193654 /  294912             ( 65.67%) | total_pruned =  101258 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  301721 /  589824             ( 51.15%) | total_pruned =  288103 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   27565 /   32768             ( 84.12%) | total_pruned =    5203 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  221094 /  589824             ( 37.48%) | total_pruned =  368730 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  199586 /  589824             ( 33.84%) | total_pruned =  390238 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  506924 / 1179648             ( 42.97%) | total_pruned =  672724 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  556459 / 2359296             ( 23.59%) | total_pruned = 1802837 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   86542 /  131072             ( 66.03%) | total_pruned =   44530 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  445432 / 2359296             ( 18.88%) | total_pruned = 1913864 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     478 /     512             ( 93.36%) | total_pruned =      34 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  327845 / 2359296             ( 13.90%) | total_pruned = 2031451 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
linear.weight        | nonzeros =    5051 /    5120             ( 98.65%) | total_pruned =      69 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 38/200 Loss: 0.000112 Accuracy: 86.39 100.00 % Best test Accuracy: 86.54%
tensor(-13.1594, device='cuda:0') tensor(0.5623, device='cuda:0') tensor(1.6531e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.095924
Average KL loss: 0.389944
Average total loss: 1.485867
tensor(-13.2719, device='cuda:0') tensor(0.3769, device='cuda:0') tensor(-3.5336e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.166430
Average KL loss: 0.370502
Average total loss: 1.536933
tensor(-13.3643, device='cuda:0') tensor(0.2944, device='cuda:0') tensor(-1.0684e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.184363
Average KL loss: 0.359240
Average total loss: 1.543604
tensor(-13.4452, device='cuda:0') tensor(0.2533, device='cuda:0') tensor(-7.8267e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.164269
Average KL loss: 0.356629
Average total loss: 1.520898
tensor(-13.5182, device='cuda:0') tensor(0.2274, device='cuda:0') tensor(-6.8304e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.151468
Average KL loss: 0.355753
Average total loss: 1.507221
tensor(-13.5852, device='cuda:0') tensor(0.2095, device='cuda:0') tensor(-3.9587e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.127204
Average KL loss: 0.355397
Average total loss: 1.482601
tensor(-13.6474, device='cuda:0') tensor(0.1965, device='cuda:0') tensor(-3.1053e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.117342
Average KL loss: 0.355025
Average total loss: 1.472367
tensor(-13.7054, device='cuda:0') tensor(0.1866, device='cuda:0') tensor(-5.8151e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.112619
Average KL loss: 0.354581
Average total loss: 1.467200
tensor(-13.7599, device='cuda:0') tensor(0.1792, device='cuda:0') tensor(5.5122e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.107126
Average KL loss: 0.353581
Average total loss: 1.460707
tensor(-13.8113, device='cuda:0') tensor(0.1734, device='cuda:0') tensor(-1.9464e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.099302
Average KL loss: 0.353102
Average total loss: 1.452405
tensor(-13.8601, device='cuda:0') tensor(0.1688, device='cuda:0') tensor(-1.2094e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.091958
Average KL loss: 0.352635
Average total loss: 1.444593
tensor(-13.9064, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-1.1875e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.087879
Average KL loss: 0.352130
Average total loss: 1.440009
tensor(-13.9506, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(-3.0173e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.087302
Average KL loss: 0.351674
Average total loss: 1.438976
tensor(-13.9928, device='cuda:0') tensor(0.1595, device='cuda:0') tensor(-1.6884e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.084353
Average KL loss: 0.350944
Average total loss: 1.435296
tensor(-14.0332, device='cuda:0') tensor(0.1575, device='cuda:0') tensor(-6.6049e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.079344
Average KL loss: 0.350256
Average total loss: 1.429600
tensor(-14.0720, device='cuda:0') tensor(0.1560, device='cuda:0') tensor(-2.3497e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.075541
Average KL loss: 0.349864
Average total loss: 1.425404
tensor(-14.1093, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(-1.5534e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.073396
Average KL loss: 0.349517
Average total loss: 1.422914
tensor(-14.1452, device='cuda:0') tensor(0.1539, device='cuda:0') tensor(-1.8675e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.072431
Average KL loss: 0.348968
Average total loss: 1.421399
tensor(-14.1798, device='cuda:0') tensor(0.1531, device='cuda:0') tensor(6.5354e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.071052
Average KL loss: 0.348368
Average total loss: 1.419420
tensor(-14.2132, device='cuda:0') tensor(0.1527, device='cuda:0') tensor(-3.1073e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.068127
Average KL loss: 0.347913
Average total loss: 1.416039
tensor(-14.2456, device='cuda:0') tensor(0.1522, device='cuda:0') tensor(-4.5365e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.068682
Average KL loss: 0.347654
Average total loss: 1.416337
tensor(-14.2769, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(-2.8222e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.065136
Average KL loss: 0.347298
Average total loss: 1.412434
tensor(-14.3072, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(3.4605e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.066854
Average KL loss: 0.346794
Average total loss: 1.413648
tensor(-14.3366, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(-1.0461e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.064172
Average KL loss: 0.346397
Average total loss: 1.410569
tensor(-14.3652, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(-1.7877e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.062948
Average KL loss: 0.346061
Average total loss: 1.409009
tensor(-14.3929, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(1.0095e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.062211
Average KL loss: 0.345725
Average total loss: 1.407937
tensor(-14.4199, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(-2.0967e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.062616
Average KL loss: 0.345505
Average total loss: 1.408121
tensor(-14.4462, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(3.8820e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.062399
Average KL loss: 0.345401
Average total loss: 1.407801
tensor(-14.4718, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(-3.5730e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.059309
Average KL loss: 0.345387
Average total loss: 1.404695
tensor(-14.4967, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(5.0835e-11, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.059643
Average KL loss: 0.345387
Average total loss: 1.405030
tensor(-14.5211, device='cuda:0') tensor(0.1523, device='cuda:0') tensor(1.8192e-11, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.057963
Average KL loss: 0.345319
Average total loss: 1.403283
tensor(-14.5448, device='cuda:0') tensor(0.1526, device='cuda:0') tensor(-4.9906e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.057305
Average KL loss: 0.345221
Average total loss: 1.402526
tensor(-14.5680, device='cuda:0') tensor(0.1530, device='cuda:0') tensor(-1.3522e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.056379
Average KL loss: 0.345271
Average total loss: 1.401651
tensor(-14.5907, device='cuda:0') tensor(0.1533, device='cuda:0') tensor(-7.8986e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.057047
Average KL loss: 0.345239
Average total loss: 1.402286
tensor(-14.6128, device='cuda:0') tensor(0.1536, device='cuda:0') tensor(-5.2669e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.055851
Average KL loss: 0.344992
Average total loss: 1.400842
tensor(-14.6345, device='cuda:0') tensor(0.1540, device='cuda:0') tensor(-2.0061e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.055419
Average KL loss: 0.344940
Average total loss: 1.400359
tensor(-14.6557, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(1.2637e-11, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.054690
Average KL loss: 0.344721
Average total loss: 1.399411
tensor(-14.6765, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(-1.4819e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.052872
Average KL loss: 0.344670
Average total loss: 1.397542
tensor(-14.6968, device='cuda:0') tensor(0.1552, device='cuda:0') tensor(-3.5226e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.054176
Average KL loss: 0.344451
Average total loss: 1.398627
tensor(-14.7168, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(8.0677e-11, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.055313
Average KL loss: 0.344338
Average total loss: 1.399652
tensor(-14.7363, device='cuda:0') tensor(0.1560, device='cuda:0') tensor(-9.0341e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.052669
Average KL loss: 0.344160
Average total loss: 1.396829
tensor(-14.7555, device='cuda:0') tensor(0.1565, device='cuda:0') tensor(-5.7648e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.052417
Average KL loss: 0.343940
Average total loss: 1.396357
tensor(-14.7743, device='cuda:0') tensor(0.1569, device='cuda:0') tensor(-1.5876e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.050617
Average KL loss: 0.343912
Average total loss: 1.394529
tensor(-14.7927, device='cuda:0') tensor(0.1573, device='cuda:0') tensor(-4.2641e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.051652
Average KL loss: 0.343789
Average total loss: 1.395441
tensor(-14.8109, device='cuda:0') tensor(0.1576, device='cuda:0') tensor(2.5970e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.052930
Average KL loss: 0.343628
Average total loss: 1.396558
tensor(-14.8287, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(-1.0335e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.050539
Average KL loss: 0.343518
Average total loss: 1.394057
tensor(-14.8461, device='cuda:0') tensor(0.1583, device='cuda:0') tensor(1.6201e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.052314
Average KL loss: 0.343409
Average total loss: 1.395722
tensor(-14.8633, device='cuda:0') tensor(0.1589, device='cuda:0') tensor(-3.3333e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.050826
Average KL loss: 0.343546
Average total loss: 1.394372
tensor(-14.8802, device='cuda:0') tensor(0.1594, device='cuda:0') tensor(-1.3408e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.051676
Average KL loss: 0.343637
Average total loss: 1.395313
tensor(-14.8968, device='cuda:0') tensor(0.1598, device='cuda:0') tensor(5.6801e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.051929
Average KL loss: 0.343380
Average total loss: 1.395309
tensor(-14.9132, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-5.2094e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.049772
Average KL loss: 0.343248
Average total loss: 1.393021
tensor(-14.9292, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(8.7878e-11, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.049794
Average KL loss: 0.343287
Average total loss: 1.393081
tensor(-14.9451, device='cuda:0') tensor(0.1611, device='cuda:0') tensor(-6.8657e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.050196
Average KL loss: 0.343032
Average total loss: 1.393229
tensor(-14.9606, device='cuda:0') tensor(0.1614, device='cuda:0') tensor(1.1819e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.048756
Average KL loss: 0.342704
Average total loss: 1.391461
tensor(-14.9760, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-9.5945e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.051102
Average KL loss: 0.342398
Average total loss: 1.393500
tensor(-14.9911, device='cuda:0') tensor(0.1621, device='cuda:0') tensor(-9.2382e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.050582
Average KL loss: 0.342115
Average total loss: 1.392698
tensor(-15.0060, device='cuda:0') tensor(0.1625, device='cuda:0') tensor(-4.1339e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.051173
Average KL loss: 0.341897
Average total loss: 1.393070
tensor(-15.0206, device='cuda:0') tensor(0.1630, device='cuda:0') tensor(-1.5887e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.049978
Average KL loss: 0.341735
Average total loss: 1.391714
tensor(-15.0351, device='cuda:0') tensor(0.1635, device='cuda:0') tensor(-2.8115e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.049885
Average KL loss: 0.341560
Average total loss: 1.391444
tensor(-15.0493, device='cuda:0') tensor(0.1639, device='cuda:0') tensor(-7.0803e-11, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.050018
Average KL loss: 0.341277
Average total loss: 1.391295
tensor(-15.0634, device='cuda:0') tensor(0.1643, device='cuda:0') tensor(-3.0228e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.052211
Average KL loss: 0.341028
Average total loss: 1.393239
tensor(-15.0772, device='cuda:0') tensor(0.1647, device='cuda:0') tensor(-1.4794e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.050220
Average KL loss: 0.341007
Average total loss: 1.391227
tensor(-15.0909, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-9.6922e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.050809
Average KL loss: 0.340903
Average total loss: 1.391713
tensor(-15.1043, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(-3.9726e-11, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.049287
Average KL loss: 0.340784
Average total loss: 1.390070
tensor(-15.1176, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(-1.5843e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.049455
Average KL loss: 0.340616
Average total loss: 1.390071
tensor(-15.1307, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-3.0292e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.050302
Average KL loss: 0.340409
Average total loss: 1.390710
tensor(-15.1437, device='cuda:0') tensor(0.1669, device='cuda:0') tensor(-9.6730e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.050177
Average KL loss: 0.340268
Average total loss: 1.390445
tensor(-15.1565, device='cuda:0') tensor(0.1674, device='cuda:0') tensor(-2.4230e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.050272
Average KL loss: 0.340053
Average total loss: 1.390325
tensor(-15.1691, device='cuda:0') tensor(0.1679, device='cuda:0') tensor(-1.9795e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.049618
Average KL loss: 0.339987
Average total loss: 1.389605
tensor(-15.1816, device='cuda:0') tensor(0.1684, device='cuda:0') tensor(5.5672e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.050302
Average KL loss: 0.339814
Average total loss: 1.390117
tensor(-15.1939, device='cuda:0') tensor(0.1687, device='cuda:0') tensor(4.3994e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.050656
Average KL loss: 0.339638
Average total loss: 1.390294
tensor(-15.2060, device='cuda:0') tensor(0.1691, device='cuda:0') tensor(6.0708e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.049601
Average KL loss: 0.339607
Average total loss: 1.389208
tensor(-15.2181, device='cuda:0') tensor(0.1695, device='cuda:0') tensor(2.0606e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.050915
Average KL loss: 0.339260
Average total loss: 1.390175
tensor(-15.2299, device='cuda:0') tensor(0.1700, device='cuda:0') tensor(3.4479e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.051320
Average KL loss: 0.339084
Average total loss: 1.390404
tensor(-15.2417, device='cuda:0') tensor(0.1703, device='cuda:0') tensor(2.9604e-11, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.049955
Average KL loss: 0.338938
Average total loss: 1.388893
tensor(-15.2533, device='cuda:0') tensor(0.1707, device='cuda:0') tensor(-1.5704e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.048696
Average KL loss: 0.338841
Average total loss: 1.387537
tensor(-15.2647, device='cuda:0') tensor(0.1709, device='cuda:0') tensor(2.0059e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.050383
Average KL loss: 0.338787
Average total loss: 1.389170
tensor(-15.2761, device='cuda:0') tensor(0.1712, device='cuda:0') tensor(4.9736e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.049010
Average KL loss: 0.338852
Average total loss: 1.387862
tensor(-15.2873, device='cuda:0') tensor(0.1715, device='cuda:0') tensor(-7.8298e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.048855
Average KL loss: 0.338668
Average total loss: 1.387523
tensor(-15.2984, device='cuda:0') tensor(0.1719, device='cuda:0') tensor(-6.1447e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.048571
Average KL loss: 0.338433
Average total loss: 1.387004
tensor(-15.3093, device='cuda:0') tensor(0.1722, device='cuda:0') tensor(3.8252e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.049488
Average KL loss: 0.338372
Average total loss: 1.387859
tensor(-15.3202, device='cuda:0') tensor(0.1727, device='cuda:0') tensor(1.1428e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.048587
Average KL loss: 0.338218
Average total loss: 1.386804
tensor(-15.3309, device='cuda:0') tensor(0.1730, device='cuda:0') tensor(1.2760e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.049875
Average KL loss: 0.338172
Average total loss: 1.388048
tensor(-15.3415, device='cuda:0') tensor(0.1734, device='cuda:0') tensor(-3.1546e-12, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.049260
Average KL loss: 0.338020
Average total loss: 1.387279
tensor(-15.3520, device='cuda:0') tensor(0.1738, device='cuda:0') tensor(1.0363e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.049411
Average KL loss: 0.338037
Average total loss: 1.387448
tensor(-15.3624, device='cuda:0') tensor(0.1744, device='cuda:0') tensor(3.5316e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.048162
Average KL loss: 0.338101
Average total loss: 1.386263
tensor(-15.3727, device='cuda:0') tensor(0.1746, device='cuda:0') tensor(-4.9778e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.048563
Average KL loss: 0.338044
Average total loss: 1.386607
tensor(-15.3829, device='cuda:0') tensor(0.1749, device='cuda:0') tensor(-1.1101e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.049275
Average KL loss: 0.338014
Average total loss: 1.387289
tensor(-15.3930, device='cuda:0') tensor(0.1753, device='cuda:0') tensor(-1.3359e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.049006
Average KL loss: 0.337969
Average total loss: 1.386976
tensor(-15.4029, device='cuda:0') tensor(0.1756, device='cuda:0') tensor(1.1416e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.047752
Average KL loss: 0.337829
Average total loss: 1.385581
tensor(-15.4128, device='cuda:0') tensor(0.1759, device='cuda:0') tensor(1.3357e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.049657
Average KL loss: 0.337688
Average total loss: 1.387345
tensor(-15.4226, device='cuda:0') tensor(0.1763, device='cuda:0') tensor(-8.4910e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.048338
Average KL loss: 0.337622
Average total loss: 1.385960
tensor(-15.4323, device='cuda:0') tensor(0.1766, device='cuda:0') tensor(-1.9597e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.049360
Average KL loss: 0.337346
Average total loss: 1.386707
tensor(-15.4419, device='cuda:0') tensor(0.1769, device='cuda:0') tensor(-1.7574e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.049499
Average KL loss: 0.337131
Average total loss: 1.386630
tensor(-15.4514, device='cuda:0') tensor(0.1774, device='cuda:0') tensor(3.6916e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.048913
Average KL loss: 0.336957
Average total loss: 1.385871
tensor(-15.4608, device='cuda:0') tensor(0.1778, device='cuda:0') tensor(4.0644e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.048092
Average KL loss: 0.336810
Average total loss: 1.384903
tensor(-15.4701, device='cuda:0') tensor(0.1781, device='cuda:0') tensor(-1.9452e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.049061
Average KL loss: 0.336729
Average total loss: 1.385790
tensor(-15.4794, device='cuda:0') tensor(0.1785, device='cuda:0') tensor(2.3392e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.049093
Average KL loss: 0.336754
Average total loss: 1.385847
tensor(-15.4885, device='cuda:0') tensor(0.1789, device='cuda:0') tensor(3.2099e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.048953
Average KL loss: 0.336850
Average total loss: 1.385804
tensor(-15.4976, device='cuda:0') tensor(0.1792, device='cuda:0') tensor(9.2264e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.048241
Average KL loss: 0.336800
Average total loss: 1.385041
tensor(-15.5066, device='cuda:0') tensor(0.1795, device='cuda:0') tensor(-5.5611e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.048840
Average KL loss: 0.336691
Average total loss: 1.385532
tensor(-15.5155, device='cuda:0') tensor(0.1797, device='cuda:0') tensor(-4.2039e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.049584
Average KL loss: 0.336740
Average total loss: 1.386324
tensor(-15.5243, device='cuda:0') tensor(0.1801, device='cuda:0') tensor(-3.4954e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.050492
Average KL loss: 0.336743
Average total loss: 1.387235
tensor(-15.5331, device='cuda:0') tensor(0.1804, device='cuda:0') tensor(-2.3798e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.048962
Average KL loss: 0.336674
Average total loss: 1.385636
tensor(-15.5418, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-5.9394e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.048510
Average KL loss: 0.336532
Average total loss: 1.385041
tensor(-15.5504, device='cuda:0') tensor(0.1811, device='cuda:0') tensor(1.8044e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.048544
Average KL loss: 0.336292
Average total loss: 1.384836
tensor(-15.5589, device='cuda:0') tensor(0.1814, device='cuda:0') tensor(-1.3797e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.047172
Average KL loss: 0.336242
Average total loss: 1.383414
tensor(-15.5674, device='cuda:0') tensor(0.1817, device='cuda:0') tensor(1.1773e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.047274
Average KL loss: 0.336071
Average total loss: 1.383345
tensor(-15.5758, device='cuda:0') tensor(0.1820, device='cuda:0') tensor(2.0057e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.049135
Average KL loss: 0.335909
Average total loss: 1.385045
tensor(-15.5841, device='cuda:0') tensor(0.1822, device='cuda:0') tensor(1.1165e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.048271
Average KL loss: 0.335691
Average total loss: 1.383961
tensor(-15.5923, device='cuda:0') tensor(0.1825, device='cuda:0') tensor(1.3184e-14, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.049402
Average KL loss: 0.335692
Average total loss: 1.385093
tensor(-15.6005, device='cuda:0') tensor(0.1828, device='cuda:0') tensor(-2.1409e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.049090
Average KL loss: 0.335736
Average total loss: 1.384826
tensor(-15.6086, device='cuda:0') tensor(0.1831, device='cuda:0') tensor(-1.3333e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.049055
Average KL loss: 0.335649
Average total loss: 1.384704
tensor(-15.6167, device='cuda:0') tensor(0.1834, device='cuda:0') tensor(-1.1467e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.048816
Average KL loss: 0.335665
Average total loss: 1.384482
tensor(-15.6247, device='cuda:0') tensor(0.1837, device='cuda:0') tensor(5.8619e-11, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.048550
Average KL loss: 0.335602
Average total loss: 1.384152
tensor(-15.6326, device='cuda:0') tensor(0.1840, device='cuda:0') tensor(-1.3002e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.047862
Average KL loss: 0.335574
Average total loss: 1.383436
tensor(-15.6404, device='cuda:0') tensor(0.1843, device='cuda:0') tensor(-4.6743e-11, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.048908
Average KL loss: 0.335543
Average total loss: 1.384451
tensor(-15.6482, device='cuda:0') tensor(0.1849, device='cuda:0') tensor(-2.3703e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.049096
Average KL loss: 0.335355
Average total loss: 1.384451
tensor(-15.6560, device='cuda:0') tensor(0.1851, device='cuda:0') tensor(-2.6654e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.048511
Average KL loss: 0.335286
Average total loss: 1.383797
tensor(-15.6567, device='cuda:0') tensor(0.1851, device='cuda:0') tensor(-5.7368e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.048368
Average KL loss: 0.335280
Average total loss: 1.383648
tensor(-15.6575, device='cuda:0') tensor(0.1852, device='cuda:0') tensor(-6.5637e-12, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.047625
Average KL loss: 0.335272
Average total loss: 1.382898
tensor(-15.6583, device='cuda:0') tensor(0.1852, device='cuda:0') tensor(-8.2218e-11, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.048121
Average KL loss: 0.335277
Average total loss: 1.383398
tensor(-15.6590, device='cuda:0') tensor(0.1852, device='cuda:0') tensor(1.6011e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.048387
Average KL loss: 0.335270
Average total loss: 1.383657
tensor(-15.6598, device='cuda:0') tensor(0.1852, device='cuda:0') tensor(-1.1039e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.048045
Average KL loss: 0.335276
Average total loss: 1.383321
tensor(-15.6606, device='cuda:0') tensor(0.1852, device='cuda:0') tensor(2.8727e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.048202
Average KL loss: 0.335278
Average total loss: 1.383480
tensor(-15.6613, device='cuda:0') tensor(0.1853, device='cuda:0') tensor(-2.0356e-11, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.048130
Average KL loss: 0.335280
Average total loss: 1.383410
tensor(-15.6621, device='cuda:0') tensor(0.1853, device='cuda:0') tensor(1.0737e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.048155
Average KL loss: 0.335274
Average total loss: 1.383428
tensor(-15.6629, device='cuda:0') tensor(0.1853, device='cuda:0') tensor(4.3991e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.047451
Average KL loss: 0.335258
Average total loss: 1.382709
tensor(-15.6636, device='cuda:0') tensor(0.1853, device='cuda:0') tensor(-2.2459e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.047722
Average KL loss: 0.335259
Average total loss: 1.382981
tensor(-15.6644, device='cuda:0') tensor(0.1853, device='cuda:0') tensor(8.9562e-11, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.048246
Average KL loss: 0.335250
Average total loss: 1.383497
tensor(-15.6651, device='cuda:0') tensor(0.1853, device='cuda:0') tensor(3.9544e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.048950
Average KL loss: 0.335242
Average total loss: 1.384192
tensor(-15.6659, device='cuda:0') tensor(0.1854, device='cuda:0') tensor(-3.6277e-11, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.047827
Average KL loss: 0.335240
Average total loss: 1.383067
tensor(-15.6667, device='cuda:0') tensor(0.1854, device='cuda:0') tensor(1.3328e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.048383
Average KL loss: 0.335238
Average total loss: 1.383621
tensor(-15.6674, device='cuda:0') tensor(0.1854, device='cuda:0') tensor(1.4559e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.047412
Average KL loss: 0.335237
Average total loss: 1.382649
tensor(-15.6682, device='cuda:0') tensor(0.1854, device='cuda:0') tensor(2.5093e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.048768
Average KL loss: 0.335240
Average total loss: 1.384008
tensor(-15.6690, device='cuda:0') tensor(0.1854, device='cuda:0') tensor(-2.2016e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.047841
Average KL loss: 0.335216
Average total loss: 1.383058
tensor(-15.6697, device='cuda:0') tensor(0.1854, device='cuda:0') tensor(1.0596e-13, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.048768
Average KL loss: 0.335168
Average total loss: 1.383936
tensor(-15.6705, device='cuda:0') tensor(0.1854, device='cuda:0') tensor(-3.4178e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.048703
Average KL loss: 0.335140
Average total loss: 1.383844
tensor(-15.6712, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(1.9635e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.048002
Average KL loss: 0.335131
Average total loss: 1.383133
tensor(-15.6720, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(2.4742e-12, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.048094
Average KL loss: 0.335130
Average total loss: 1.383224
tensor(-15.6721, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(3.6203e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.048020
Average KL loss: 0.335130
Average total loss: 1.383149
tensor(-15.6722, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(1.1338e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.048362
Average KL loss: 0.335130
Average total loss: 1.383492
tensor(-15.6723, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(4.5012e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.049025
Average KL loss: 0.335128
Average total loss: 1.384152
tensor(-15.6724, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(2.5459e-11, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.048879
Average KL loss: 0.335128
Average total loss: 1.384007
tensor(-15.6725, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(1.9558e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.048469
Average KL loss: 0.335126
Average total loss: 1.383595
tensor(-15.6726, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-7.8690e-11, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.048129
Average KL loss: 0.335125
Average total loss: 1.383254
tensor(-15.6727, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(2.4613e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.048259
Average KL loss: 0.335124
Average total loss: 1.383383
tensor(-15.6727, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-5.7971e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.048079
Average KL loss: 0.335123
Average total loss: 1.383202
tensor(-15.6728, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(2.1889e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.047501
Average KL loss: 0.335120
Average total loss: 1.382622
tensor(-15.6729, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-4.9677e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.048601
Average KL loss: 0.335120
Average total loss: 1.383721
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(1.5599e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.048129
Average KL loss: 0.335120
Average total loss: 1.383249
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-1.6253e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.048803
Average KL loss: 0.335120
Average total loss: 1.383923
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(9.0098e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.047454
Average KL loss: 0.335120
Average total loss: 1.382574
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-4.6934e-11, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.048586
Average KL loss: 0.335120
Average total loss: 1.383705
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(2.0302e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.048225
Average KL loss: 0.335120
Average total loss: 1.383345
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-6.4450e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.048017
Average KL loss: 0.335119
Average total loss: 1.383136
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-8.4678e-11, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.048663
Average KL loss: 0.335120
Average total loss: 1.383783
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(4.0268e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.049188
Average KL loss: 0.335120
Average total loss: 1.384307
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(1.5524e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.048784
Average KL loss: 0.335120
Average total loss: 1.383903
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(3.6513e-11, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.048330
Average KL loss: 0.335120
Average total loss: 1.383450
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(1.1255e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.048197
Average KL loss: 0.335119
Average total loss: 1.383317
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(7.7794e-11, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.049044
Average KL loss: 0.335119
Average total loss: 1.384164
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-3.6090e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.047918
Average KL loss: 0.335119
Average total loss: 1.383038
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(1.4444e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.048660
Average KL loss: 0.335119
Average total loss: 1.383780
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(1.2042e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.047917
Average KL loss: 0.335119
Average total loss: 1.383036
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(2.1103e-11, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.049105
Average KL loss: 0.335119
Average total loss: 1.384225
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(5.9969e-11, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.047706
Average KL loss: 0.335119
Average total loss: 1.382825
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-1.0076e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.048656
Average KL loss: 0.335119
Average total loss: 1.383775
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-2.8102e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.048304
Average KL loss: 0.335119
Average total loss: 1.383423
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-2.6350e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 1.048446
Average KL loss: 0.335119
Average total loss: 1.383566
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-2.9119e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.048038
Average KL loss: 0.335119
Average total loss: 1.383157
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(2.7111e-11, device='cuda:0')
 Percentile value: -15.593095779418945
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =    1644 /    1728             ( 95.14%) | total_pruned =      84 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   22478 /   36864             ( 60.98%) | total_pruned =   14386 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   22742 /   36864             ( 61.69%) | total_pruned =   14122 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   19571 /   36864             ( 53.09%) | total_pruned =   17293 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   17845 /   36864             ( 48.41%) | total_pruned =   19019 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   37409 /   73728             ( 50.74%) | total_pruned =   36319 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   53400 /  147456             ( 36.21%) | total_pruned =   94056 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    6672 /    8192             ( 81.45%) | total_pruned =    1520 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   40960 /  147456             ( 27.78%) | total_pruned =  106496 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   37417 /  147456             ( 25.38%) | total_pruned =  110039 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   82057 /  294912             ( 27.82%) | total_pruned =  212855 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  102146 /  589824             ( 17.32%) | total_pruned =  487678 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19015 /   32768             ( 58.03%) | total_pruned =   13753 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   47466 /  589824             (  8.05%) | total_pruned =  542358 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   45577 /  589824             (  7.73%) | total_pruned =  544247 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  114752 / 1179648             (  9.73%) | total_pruned = 1064896 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  110277 / 2359296             (  4.67%) | total_pruned = 2249019 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   41260 /  131072             ( 31.48%) | total_pruned =   89812 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   84686 / 2359296             (  3.59%) | total_pruned = 2274610 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     328 /     512             ( 64.06%) | total_pruned =     184 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   84514 / 2359296             (  3.58%) | total_pruned = 2274782 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([512])
linear.weight        | nonzeros =    4882 /    5120             ( 95.35%) | total_pruned =     238 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 29/200 Loss: 0.000033 Accuracy: 86.14 100.00 % Best test Accuracy: 86.23%
tensor(-15.6730, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-3.8811e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.139000
Average KL loss: 0.332117
Average total loss: 1.471116
tensor(-15.6817, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(-1.5306e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.221525
Average KL loss: 0.314836
Average total loss: 1.536361
tensor(-15.6897, device='cuda:0') tensor(0.1233, device='cuda:0') tensor(-8.5723e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.238287
Average KL loss: 0.307672
Average total loss: 1.545959
tensor(-15.6972, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-4.3230e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.209861
Average KL loss: 0.307309
Average total loss: 1.517170
tensor(-15.7046, device='cuda:0') tensor(0.1211, device='cuda:0') tensor(-7.5121e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.183758
Average KL loss: 0.307330
Average total loss: 1.491088
tensor(-15.7119, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-4.5424e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.163935
Average KL loss: 0.307629
Average total loss: 1.471563
tensor(-15.7192, device='cuda:0') tensor(0.1227, device='cuda:0') tensor(-3.0868e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.148289
Average KL loss: 0.307445
Average total loss: 1.455734
tensor(-15.7264, device='cuda:0') tensor(0.1237, device='cuda:0') tensor(-8.5267e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.141554
Average KL loss: 0.307512
Average total loss: 1.449067
tensor(-15.7336, device='cuda:0') tensor(0.1248, device='cuda:0') tensor(-3.8122e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.133644
Average KL loss: 0.307540
Average total loss: 1.441184
tensor(-15.7407, device='cuda:0') tensor(0.1259, device='cuda:0') tensor(-9.8909e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.124990
Average KL loss: 0.307480
Average total loss: 1.432469
tensor(-15.7478, device='cuda:0') tensor(0.1269, device='cuda:0') tensor(-1.7275e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.117953
Average KL loss: 0.307600
Average total loss: 1.425553
tensor(-15.7548, device='cuda:0') tensor(0.1278, device='cuda:0') tensor(-5.9584e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.114777
Average KL loss: 0.307714
Average total loss: 1.422491
tensor(-15.7618, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-9.7838e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.106356
Average KL loss: 0.307812
Average total loss: 1.414167
tensor(-15.7687, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-2.2869e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.108211
Average KL loss: 0.307585
Average total loss: 1.415797
tensor(-15.7756, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-1.4515e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.102997
Average KL loss: 0.307268
Average total loss: 1.410265
tensor(-15.7824, device='cuda:0') tensor(0.1312, device='cuda:0') tensor(-1.7724e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.105407
Average KL loss: 0.307089
Average total loss: 1.412496
tensor(-15.7892, device='cuda:0') tensor(0.1320, device='cuda:0') tensor(-9.2945e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.099925
Average KL loss: 0.306875
Average total loss: 1.406800
tensor(-15.7959, device='cuda:0') tensor(0.1329, device='cuda:0') tensor(-1.0331e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.099456
Average KL loss: 0.306756
Average total loss: 1.406212
tensor(-15.8026, device='cuda:0') tensor(0.1337, device='cuda:0') tensor(-1.4507e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.093597
Average KL loss: 0.306745
Average total loss: 1.400342
tensor(-15.8092, device='cuda:0') tensor(0.1344, device='cuda:0') tensor(5.3824e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.092969
Average KL loss: 0.306537
Average total loss: 1.399506
tensor(-15.8158, device='cuda:0') tensor(0.1351, device='cuda:0') tensor(-7.0291e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.093419
Average KL loss: 0.306348
Average total loss: 1.399767
tensor(-15.8224, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-8.4908e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.093098
Average KL loss: 0.306229
Average total loss: 1.399328
tensor(-15.8289, device='cuda:0') tensor(0.1365, device='cuda:0') tensor(-1.4046e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.085489
Average KL loss: 0.306035
Average total loss: 1.391524
tensor(-15.8354, device='cuda:0') tensor(0.1372, device='cuda:0') tensor(-2.3986e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.087640
Average KL loss: 0.305624
Average total loss: 1.393264
tensor(-15.8418, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(-8.9684e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.089302
Average KL loss: 0.305313
Average total loss: 1.394615
tensor(-15.8482, device='cuda:0') tensor(0.1383, device='cuda:0') tensor(-9.3157e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.088062
Average KL loss: 0.305040
Average total loss: 1.393102
tensor(-15.8545, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(-3.8995e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 55
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 56
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 57
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 58
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 59
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 60
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 61
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 62
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 63
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 64
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 65
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 66
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 67
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 68
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 69
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 70
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 71
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 72
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 73
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 74
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 75
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 76
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 77
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   82598 / 2359296             (  3.50%) | total_pruned = 2276698 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   41260 /  131072             ( 31.48%) | total_pruned =   89812 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   84686 / 2359296             (  3.59%) | total_pruned = 2274610 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     328 /     512             ( 64.06%) | total_pruned =     184 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   84514 / 2359296             (  3.58%) | total_pruned = 2274782 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([512])
linear.weight        | nonzeros =    4882 /    5120             ( 95.35%) | total_pruned =     238 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 34/200 Loss: 2.302601 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     142 /     512             ( 27.73%) | total_pruned =     370 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   84514 / 2359296             (  3.58%) | total_pruned = 2274782 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([512])
linear.weight        | nonzeros =    4882 /    5120             ( 95.35%) | total_pruned =     238 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 34/200 Loss: 2.302739 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   21272 / 2359296             (  0.90%) | total_pruned = 2338024 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([512])
linear.weight        | nonzeros =    4882 /    5120             ( 95.35%) | total_pruned =     238 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 34/200 Loss: 2.302737 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2257 / 2359296             (  0.10%) | total_pruned = 2357039 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([512])
linear.weight        | nonzeros =    4882 /    5120             ( 95.35%) | total_pruned =     238 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 34/200 Loss: 2.302606 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
