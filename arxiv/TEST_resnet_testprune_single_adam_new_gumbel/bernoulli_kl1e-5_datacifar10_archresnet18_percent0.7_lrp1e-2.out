Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1415e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.781581
Average KL loss: 0.022915
Average total loss: 1.804496
tensor(0.0006, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.1547e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.479979
Average KL loss: 0.058272
Average total loss: 1.538250
tensor(0.0007, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.5852e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.272481
Average KL loss: 0.076328
Average total loss: 1.348809
tensor(0.0008, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.5496e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.138971
Average KL loss: 0.085166
Average total loss: 1.224137
tensor(0.0009, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.1944e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.051031
Average KL loss: 0.091656
Average total loss: 1.142688
tensor(0.0012, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.5875e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.969904
Average KL loss: 0.095247
Average total loss: 1.065151
tensor(0.0013, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.8225e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.903427
Average KL loss: 0.097790
Average total loss: 1.001218
tensor(0.0016, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.0753e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.849244
Average KL loss: 0.100548
Average total loss: 0.949792
tensor(0.0017, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-8.4542e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.777373
Average KL loss: 0.102282
Average total loss: 0.879656
tensor(0.0019, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-8.8526e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.748213
Average KL loss: 0.102905
Average total loss: 0.851118
tensor(0.0021, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-7.4957e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.712748
Average KL loss: 0.103284
Average total loss: 0.816031
tensor(0.0022, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.9964e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.671457
Average KL loss: 0.104221
Average total loss: 0.775679
tensor(0.0023, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.9778e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.630842
Average KL loss: 0.104695
Average total loss: 0.735537
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.1762e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.616385
Average KL loss: 0.105258
Average total loss: 0.721643
tensor(0.0026, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.4231e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.584807
Average KL loss: 0.105320
Average total loss: 0.690127
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.3865e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.548047
Average KL loss: 0.105806
Average total loss: 0.653853
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.6530e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.513818
Average KL loss: 0.104849
Average total loss: 0.618667
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.6244e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.504959
Average KL loss: 0.104445
Average total loss: 0.609404
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.8013e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.482208
Average KL loss: 0.104828
Average total loss: 0.587036
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.4251e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.467576
Average KL loss: 0.105407
Average total loss: 0.572983
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.8204e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.444845
Average KL loss: 0.105237
Average total loss: 0.550082
tensor(0.0033, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.2903e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.423391
Average KL loss: 0.105376
Average total loss: 0.528767
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.9380e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.409753
Average KL loss: 0.104885
Average total loss: 0.514638
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.0351e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.394528
Average KL loss: 0.105057
Average total loss: 0.499585
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.8894e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.377975
Average KL loss: 0.104943
Average total loss: 0.482918
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.6020e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.358811
Average KL loss: 0.104575
Average total loss: 0.463386
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.6157e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.351345
Average KL loss: 0.104555
Average total loss: 0.455900
tensor(0.0038, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.2522e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.336375
Average KL loss: 0.104652
Average total loss: 0.441027
tensor(0.0039, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.7072e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.326326
Average KL loss: 0.104912
Average total loss: 0.431239
tensor(0.0039, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.0123e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.311376
Average KL loss: 0.104743
Average total loss: 0.416119
tensor(0.0039, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.7136e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.311340
Average KL loss: 0.104169
Average total loss: 0.415509
tensor(0.0040, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.6583e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.292288
Average KL loss: 0.104393
Average total loss: 0.396681
tensor(0.0040, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.3398e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.277253
Average KL loss: 0.103879
Average total loss: 0.381131
tensor(0.0041, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.8263e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.274874
Average KL loss: 0.103563
Average total loss: 0.378437
tensor(0.0042, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.7256e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.272781
Average KL loss: 0.103917
Average total loss: 0.376698
tensor(0.0042, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.9162e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.257492
Average KL loss: 0.104074
Average total loss: 0.361566
tensor(0.0042, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.8884e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.255833
Average KL loss: 0.104825
Average total loss: 0.360657
tensor(0.0043, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6402e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.246381
Average KL loss: 0.105121
Average total loss: 0.351502
tensor(0.0043, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.6849e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.237651
Average KL loss: 0.105181
Average total loss: 0.342831
tensor(0.0043, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.8439e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.222925
Average KL loss: 0.104162
Average total loss: 0.327087
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.2318e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.217473
Average KL loss: 0.103188
Average total loss: 0.320661
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.0235e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.212115
Average KL loss: 0.103340
Average total loss: 0.315454
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4346e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.201699
Average KL loss: 0.102807
Average total loss: 0.304506
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.3994e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.210353
Average KL loss: 0.103091
Average total loss: 0.313444
tensor(0.0045, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.9570e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.196199
Average KL loss: 0.103497
Average total loss: 0.299696
tensor(0.0045, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8627e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.187141
Average KL loss: 0.102746
Average total loss: 0.289887
tensor(0.0045, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.6980e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.193485
Average KL loss: 0.102552
Average total loss: 0.296037
tensor(0.0045, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.7766e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.180178
Average KL loss: 0.103224
Average total loss: 0.283402
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.6197e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.165564
Average KL loss: 0.102694
Average total loss: 0.268258
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.0271e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.170761
Average KL loss: 0.102141
Average total loss: 0.272901
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4624e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.165021
Average KL loss: 0.102143
Average total loss: 0.267164
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7684e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.158368
Average KL loss: 0.102216
Average total loss: 0.260584
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8231e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.155569
Average KL loss: 0.101831
Average total loss: 0.257400
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4833e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.153638
Average KL loss: 0.101074
Average total loss: 0.254712
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.2993e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.148839
Average KL loss: 0.101029
Average total loss: 0.249868
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5768e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.145185
Average KL loss: 0.100715
Average total loss: 0.245901
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5557e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.140930
Average KL loss: 0.100427
Average total loss: 0.241357
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5318e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.140946
Average KL loss: 0.100946
Average total loss: 0.241892
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.7981e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.135439
Average KL loss: 0.100745
Average total loss: 0.236184
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5378e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.127886
Average KL loss: 0.100556
Average total loss: 0.228442
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.7945e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.124548
Average KL loss: 0.099436
Average total loss: 0.223984
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0687e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.122970
Average KL loss: 0.098844
Average total loss: 0.221815
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3015e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.125966
Average KL loss: 0.099451
Average total loss: 0.225417
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.6158e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.116570
Average KL loss: 0.099011
Average total loss: 0.215582
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.4844e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.113034
Average KL loss: 0.098034
Average total loss: 0.211068
tensor(0.0047, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1456e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.120709
Average KL loss: 0.097709
Average total loss: 0.218418
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3005e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.108732
Average KL loss: 0.098420
Average total loss: 0.207151
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5837e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.111783
Average KL loss: 0.098414
Average total loss: 0.210197
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.9634e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.113613
Average KL loss: 0.098283
Average total loss: 0.211896
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.6512e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.108252
Average KL loss: 0.098988
Average total loss: 0.207240
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.0617e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.104926
Average KL loss: 0.098901
Average total loss: 0.203827
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.5565e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.101908
Average KL loss: 0.098127
Average total loss: 0.200035
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.9785e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.096727
Average KL loss: 0.097325
Average total loss: 0.194052
tensor(0.0048, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.5567e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.101155
Average KL loss: 0.097302
Average total loss: 0.198458
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.1604e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.092656
Average KL loss: 0.097257
Average total loss: 0.189914
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.8732e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.098571
Average KL loss: 0.097537
Average total loss: 0.196107
tensor(0.0048, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.9620e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.094356
Average KL loss: 0.098037
Average total loss: 0.192393
tensor(0.0048, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.8142e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.092114
Average KL loss: 0.097569
Average total loss: 0.189683
tensor(0.0048, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.6523e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.089041
Average KL loss: 0.097587
Average total loss: 0.186628
tensor(0.0048, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.9336e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.087515
Average KL loss: 0.096662
Average total loss: 0.184176
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.6550e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.081658
Average KL loss: 0.095857
Average total loss: 0.177515
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.0571e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.085028
Average KL loss: 0.095018
Average total loss: 0.180046
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.2132e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.081676
Average KL loss: 0.094469
Average total loss: 0.176146
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0701e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.082045
Average KL loss: 0.095047
Average total loss: 0.177092
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.9775e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.081214
Average KL loss: 0.095063
Average total loss: 0.176278
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.6232e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.082661
Average KL loss: 0.095654
Average total loss: 0.178316
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.8928e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.078849
Average KL loss: 0.095893
Average total loss: 0.174741
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.6612e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.073816
Average KL loss: 0.095176
Average total loss: 0.168992
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.4495e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.073589
Average KL loss: 0.093897
Average total loss: 0.167486
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.3313e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.074293
Average KL loss: 0.094082
Average total loss: 0.168376
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.4775e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.071842
Average KL loss: 0.093958
Average total loss: 0.165800
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.0131e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.070900
Average KL loss: 0.094063
Average total loss: 0.164963
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.0265e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.071145
Average KL loss: 0.093464
Average total loss: 0.164609
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.7075e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.065632
Average KL loss: 0.093602
Average total loss: 0.159234
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.8177e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.069612
Average KL loss: 0.093171
Average total loss: 0.162784
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.9970e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.066480
Average KL loss: 0.093743
Average total loss: 0.160223
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2373e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.063725
Average KL loss: 0.092671
Average total loss: 0.156395
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3134e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.066125
Average KL loss: 0.092557
Average total loss: 0.158682
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.5158e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.062936
Average KL loss: 0.092801
Average total loss: 0.155737
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.9893e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.065525
Average KL loss: 0.092323
Average total loss: 0.157848
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.4077e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.060252
Average KL loss: 0.092750
Average total loss: 0.153002
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.4921e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.062894
Average KL loss: 0.091779
Average total loss: 0.154673
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.5107e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.059602
Average KL loss: 0.092448
Average total loss: 0.152049
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.7977e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.059708
Average KL loss: 0.091818
Average total loss: 0.151526
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.3837e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.058585
Average KL loss: 0.091326
Average total loss: 0.149911
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.4487e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.056023
Average KL loss: 0.090879
Average total loss: 0.146902
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2990e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.057102
Average KL loss: 0.090827
Average total loss: 0.147930
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.7662e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.057153
Average KL loss: 0.091195
Average total loss: 0.148348
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.2678e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.055326
Average KL loss: 0.090385
Average total loss: 0.145711
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.4728e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.056119
Average KL loss: 0.090345
Average total loss: 0.146465
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.5202e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.057698
Average KL loss: 0.091418
Average total loss: 0.149115
tensor(0.0046, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.6245e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.052311
Average KL loss: 0.091136
Average total loss: 0.143447
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.5827e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.052438
Average KL loss: 0.089820
Average total loss: 0.142259
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.1456e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.054580
Average KL loss: 0.090505
Average total loss: 0.145085
tensor(0.0046, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.5763e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.052857
Average KL loss: 0.090166
Average total loss: 0.143023
tensor(0.0046, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.1179e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.053456
Average KL loss: 0.090487
Average total loss: 0.143943
tensor(0.0046, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.8786e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.052757
Average KL loss: 0.090816
Average total loss: 0.143573
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.6519e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.053488
Average KL loss: 0.091435
Average total loss: 0.144922
tensor(0.0046, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.9328e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.050291
Average KL loss: 0.091249
Average total loss: 0.141540
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.0470e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.049077
Average KL loss: 0.090464
Average total loss: 0.139540
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.1736e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.046923
Average KL loss: 0.089705
Average total loss: 0.136628
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.1624e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.049107
Average KL loss: 0.089156
Average total loss: 0.138263
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.5521e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.047763
Average KL loss: 0.089396
Average total loss: 0.137159
tensor(0.0045, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.8167e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.048201
Average KL loss: 0.089247
Average total loss: 0.137447
tensor(0.0045, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.0370e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.046576
Average KL loss: 0.088985
Average total loss: 0.135561
tensor(0.0045, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.3068e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.048412
Average KL loss: 0.089484
Average total loss: 0.137896
tensor(0.0045, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.9681e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.047136
Average KL loss: 0.089814
Average total loss: 0.136950
tensor(0.0045, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.2743e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.049656
Average KL loss: 0.090647
Average total loss: 0.140304
tensor(0.0046, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.0727e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.045735
Average KL loss: 0.090068
Average total loss: 0.135803
tensor(0.0045, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.6646e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.046527
Average KL loss: 0.089819
Average total loss: 0.136345
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.8894e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.047779
Average KL loss: 0.090378
Average total loss: 0.138156
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-3.7242e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.047264
Average KL loss: 0.090736
Average total loss: 0.138000
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.7832e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.041933
Average KL loss: 0.090234
Average total loss: 0.132167
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.9440e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.043738
Average KL loss: 0.088916
Average total loss: 0.132654
tensor(0.0045, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.6805e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.043254
Average KL loss: 0.088537
Average total loss: 0.131791
tensor(0.0045, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.1088e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.044819
Average KL loss: 0.089170
Average total loss: 0.133989
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-4.3789e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.041414
Average KL loss: 0.089241
Average total loss: 0.130654
tensor(0.0045, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.2013e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.042764
Average KL loss: 0.087902
Average total loss: 0.130666
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(1.1491e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.041680
Average KL loss: 0.088009
Average total loss: 0.129689
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-7.1874e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.043757
Average KL loss: 0.088383
Average total loss: 0.132140
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(2.8715e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.042742
Average KL loss: 0.088940
Average total loss: 0.131682
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.4149e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.044301
Average KL loss: 0.089883
Average total loss: 0.134184
tensor(0.0045, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.8524e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.040750
Average KL loss: 0.089466
Average total loss: 0.130216
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(4.6232e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.039786
Average KL loss: 0.088334
Average total loss: 0.128120
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.7855e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.041448
Average KL loss: 0.088480
Average total loss: 0.129928
tensor(0.0045, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.5424e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.043358
Average KL loss: 0.089325
Average total loss: 0.132682
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.2629e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.040836
Average KL loss: 0.089177
Average total loss: 0.130013
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.8643e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.039042
Average KL loss: 0.089081
Average total loss: 0.128123
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-5.9492e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.038748
Average KL loss: 0.088687
Average total loss: 0.127435
tensor(0.0045, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.9755e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.041376
Average KL loss: 0.088984
Average total loss: 0.130360
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.8205e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.040140
Average KL loss: 0.088582
Average total loss: 0.128722
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.0065e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.040259
Average KL loss: 0.088583
Average total loss: 0.128842
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.0140e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.038836
Average KL loss: 0.088600
Average total loss: 0.127435
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.3856e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.039882
Average KL loss: 0.089406
Average total loss: 0.129288
tensor(0.0045, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.7375e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.038408
Average KL loss: 0.088766
Average total loss: 0.127175
tensor(0.0045, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.7966e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.032984
Average KL loss: 0.087530
Average total loss: 0.120513
tensor(0.0045, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.2096e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.036259
Average KL loss: 0.085906
Average total loss: 0.122165
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(1.2021e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.035665
Average KL loss: 0.086317
Average total loss: 0.121982
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.4226e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.036045
Average KL loss: 0.086438
Average total loss: 0.122483
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-3.9945e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.035302
Average KL loss: 0.085956
Average total loss: 0.121258
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.8041e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.034719
Average KL loss: 0.085262
Average total loss: 0.119982
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-9.3639e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.037679
Average KL loss: 0.086229
Average total loss: 0.123907
tensor(0.0044, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.3571e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.036059
Average KL loss: 0.086865
Average total loss: 0.122924
tensor(0.0044, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.3867e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.035157
Average KL loss: 0.085882
Average total loss: 0.121038
tensor(0.0044, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.5324e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.037641
Average KL loss: 0.086798
Average total loss: 0.124439
tensor(0.0045, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(3.0664e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.035381
Average KL loss: 0.087355
Average total loss: 0.122736
tensor(0.0044, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-3.4048e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.037332
Average KL loss: 0.086788
Average total loss: 0.124120
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(9.4284e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.034512
Average KL loss: 0.087080
Average total loss: 0.121592
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-3.2373e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.035520
Average KL loss: 0.086905
Average total loss: 0.122426
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-2.2830e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.036134
Average KL loss: 0.086511
Average total loss: 0.122645
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(3.8677e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.036416
Average KL loss: 0.087141
Average total loss: 0.123557
tensor(0.0044, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-5.7775e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.035434
Average KL loss: 0.087543
Average total loss: 0.122977
tensor(0.0044, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(5.1394e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.033761
Average KL loss: 0.086280
Average total loss: 0.120041
tensor(0.0044, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-3.9168e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.033557
Average KL loss: 0.083246
Average total loss: 0.116802
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(8.2886e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.031424
Average KL loss: 0.080896
Average total loss: 0.112320
tensor(0.0044, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.8207e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.033323
Average KL loss: 0.079004
Average total loss: 0.112326
tensor(0.0044, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.4673e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.034102
Average KL loss: 0.077424
Average total loss: 0.111526
tensor(0.0044, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-6.5342e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.032729
Average KL loss: 0.076047
Average total loss: 0.108776
tensor(0.0044, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.3489e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.033317
Average KL loss: 0.074836
Average total loss: 0.108153
tensor(0.0044, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.6407e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.032364
Average KL loss: 0.073755
Average total loss: 0.106118
tensor(0.0044, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.8960e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.034329
Average KL loss: 0.072766
Average total loss: 0.107095
tensor(0.0044, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.7675e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.033883
Average KL loss: 0.071885
Average total loss: 0.105768
tensor(0.0044, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.7903e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.031774
Average KL loss: 0.071040
Average total loss: 0.102814
tensor(0.0044, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.9508e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.031828
Average KL loss: 0.070265
Average total loss: 0.102093
tensor(0.0044, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.9237e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.032551
Average KL loss: 0.069531
Average total loss: 0.102082
tensor(0.0044, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.5946e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.033539
Average KL loss: 0.068879
Average total loss: 0.102418
tensor(0.0044, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2749e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.031630
Average KL loss: 0.068257
Average total loss: 0.099887
tensor(0.0044, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.0416e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.030774
Average KL loss: 0.067615
Average total loss: 0.098389
tensor(0.0044, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3234e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.031561
Average KL loss: 0.067028
Average total loss: 0.098589
tensor(0.0044, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.1571e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.032840
Average KL loss: 0.066525
Average total loss: 0.099365
tensor(0.0044, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.2323e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.029156
Average KL loss: 0.066016
Average total loss: 0.095172
tensor(0.0044, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.5949e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.032747
Average KL loss: 0.065535
Average total loss: 0.098282
tensor(0.0044, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(8.8404e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.031068
Average KL loss: 0.065124
Average total loss: 0.096192
tensor(0.0044, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.1214e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.031571
Average KL loss: 0.064700
Average total loss: 0.096270
tensor(0.0044, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.4386e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.032889
Average KL loss: 0.064316
Average total loss: 0.097205
tensor(0.0044, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(7.7628e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.033784
Average KL loss: 0.063977
Average total loss: 0.097761
tensor(0.0044, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0554e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.031319
Average KL loss: 0.063638
Average total loss: 0.094957
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.3839e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.031455
Average KL loss: 0.063284
Average total loss: 0.094739
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4471e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.030939
Average KL loss: 0.062966
Average total loss: 0.093904
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.6683e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.032241
Average KL loss: 0.062652
Average total loss: 0.094893
 Percentile value: 0.025203790515661236
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1320 /    1728             ( 76.39%) | total_pruned =     408 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   18753 /   36864             ( 50.87%) | total_pruned =   18111 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   19428 /   36864             ( 52.70%) | total_pruned =   17436 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   18908 /   36864             ( 51.29%) | total_pruned =   17956 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18953 /   36864             ( 51.41%) | total_pruned =   17911 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   36524 /   73728             ( 49.54%) | total_pruned =   37204 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   71475 /  147456             ( 48.47%) | total_pruned =   75981 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5397 /    8192             ( 65.88%) | total_pruned =    2795 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   65237 /  147456             ( 44.24%) | total_pruned =   82219 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   65770 /  147456             ( 44.60%) | total_pruned =   81686 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  139831 /  294912             ( 47.41%) | total_pruned =  155081 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  269291 /  589824             ( 45.66%) | total_pruned =  320533 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19271 /   32768             ( 58.81%) | total_pruned =   13497 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  221484 /  589824             ( 37.55%) | total_pruned =  368340 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  220453 /  589824             ( 37.38%) | total_pruned =  369371 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  501362 / 1179648             ( 42.50%) | total_pruned =  678286 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  770716 / 2359296             ( 32.67%) | total_pruned = 1588580 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     453 /     512             ( 88.48%) | total_pruned =      59 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   62014 /  131072             ( 47.31%) | total_pruned =   69058 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     448 /     512             ( 87.50%) | total_pruned =      64 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  511575 / 2359296             ( 21.68%) | total_pruned = 1847721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     415 /     512             ( 81.05%) | total_pruned =      97 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     395 /     512             ( 77.15%) | total_pruned =     117 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  303007 / 2359296             ( 12.84%) | total_pruned = 2056289 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     130 /     512             ( 25.39%) | total_pruned =     382 | shape = torch.Size([512])
linear.weight        | nonzeros =    4322 /    5120             ( 84.41%) | total_pruned =     798 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       8 /      10             ( 80.00%) | total_pruned =       2 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 33/200 Loss: 0.000019 Accuracy: 87.10 100.00 % Best test Accuracy: 87.25%
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4896e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.139754
Average KL loss: 0.060691
Average total loss: 0.200445
tensor(0.0087, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.2103e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.117407
Average KL loss: 0.070228
Average total loss: 0.187635
tensor(0.0086, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.8608e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.110129
Average KL loss: 0.077357
Average total loss: 0.187486
tensor(0.0084, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-9.6090e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.105608
Average KL loss: 0.082585
Average total loss: 0.188193
tensor(0.0083, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.9914e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.096380
Average KL loss: 0.086534
Average total loss: 0.182914
tensor(0.0083, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(6.5422e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.091751
Average KL loss: 0.089448
Average total loss: 0.181199
tensor(0.0082, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.0928e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.085382
Average KL loss: 0.091671
Average total loss: 0.177052
tensor(0.0081, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-7.3753e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.080930
Average KL loss: 0.093390
Average total loss: 0.174320
tensor(0.0081, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(4.1717e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.080146
Average KL loss: 0.094585
Average total loss: 0.174731
tensor(0.0080, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-6.1015e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.082671
Average KL loss: 0.096081
Average total loss: 0.178752
tensor(0.0079, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-8.1754e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.078003
Average KL loss: 0.097614
Average total loss: 0.175617
tensor(0.0078, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-4.8385e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.079267
Average KL loss: 0.098625
Average total loss: 0.177892
tensor(0.0078, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.2845e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.069998
Average KL loss: 0.099487
Average total loss: 0.169485
tensor(0.0077, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-7.9147e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.073370
Average KL loss: 0.099729
Average total loss: 0.173099
tensor(0.0077, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.8197e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.072575
Average KL loss: 0.100588
Average total loss: 0.173163
tensor(0.0076, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.5038e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.065704
Average KL loss: 0.100914
Average total loss: 0.166618
tensor(0.0075, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-4.0605e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.070035
Average KL loss: 0.101088
Average total loss: 0.171122
tensor(0.0075, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(4.9890e-11, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.068675
Average KL loss: 0.101880
Average total loss: 0.170556
tensor(0.0075, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-4.8297e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.069254
Average KL loss: 0.102688
Average total loss: 0.171943
tensor(0.0074, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(2.4535e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.066091
Average KL loss: 0.102787
Average total loss: 0.168878
tensor(0.0074, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-4.9015e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.063605
Average KL loss: 0.102855
Average total loss: 0.166460
tensor(0.0073, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(8.6084e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.062821
Average KL loss: 0.103112
Average total loss: 0.165932
tensor(0.0073, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.7853e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.061441
Average KL loss: 0.102980
Average total loss: 0.164421
tensor(0.0073, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.6840e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.060683
Average KL loss: 0.103131
Average total loss: 0.163815
tensor(0.0072, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(5.2549e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.063073
Average KL loss: 0.103191
Average total loss: 0.166263
tensor(0.0072, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(2.4743e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.060686
Average KL loss: 0.103290
Average total loss: 0.163976
tensor(0.0072, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-6.3068e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.061311
Average KL loss: 0.103812
Average total loss: 0.165123
tensor(0.0072, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(1.3340e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.060116
Average KL loss: 0.104297
Average total loss: 0.164413
tensor(0.0072, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(3.7735e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.060379
Average KL loss: 0.104781
Average total loss: 0.165160
tensor(0.0071, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(8.4488e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.057609
Average KL loss: 0.104698
Average total loss: 0.162307
tensor(0.0071, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(4.9637e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.057367
Average KL loss: 0.104259
Average total loss: 0.161626
tensor(0.0071, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(6.4896e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.056671
Average KL loss: 0.104268
Average total loss: 0.160939
tensor(0.0071, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.4266e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.059192
Average KL loss: 0.104645
Average total loss: 0.163837
tensor(0.0071, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.4976e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.053199
Average KL loss: 0.104950
Average total loss: 0.158149
tensor(0.0070, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.0839e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.057857
Average KL loss: 0.104327
Average total loss: 0.162184
tensor(0.0070, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(6.5256e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.054601
Average KL loss: 0.104789
Average total loss: 0.159391
tensor(0.0070, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.6235e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.051719
Average KL loss: 0.104054
Average total loss: 0.155773
tensor(0.0069, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.5094e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.054527
Average KL loss: 0.103958
Average total loss: 0.158485
tensor(0.0069, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.0857e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.051968
Average KL loss: 0.104145
Average total loss: 0.156114
tensor(0.0069, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.1947e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.056590
Average KL loss: 0.104416
Average total loss: 0.161005
tensor(0.0069, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.6049e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.053117
Average KL loss: 0.105066
Average total loss: 0.158182
tensor(0.0069, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.2398e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.054308
Average KL loss: 0.105122
Average total loss: 0.159430
tensor(0.0068, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-8.9251e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.052674
Average KL loss: 0.104985
Average total loss: 0.157659
tensor(0.0068, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(7.6684e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.054452
Average KL loss: 0.105003
Average total loss: 0.159455
tensor(0.0068, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.6041e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.052407
Average KL loss: 0.105104
Average total loss: 0.157511
tensor(0.0068, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.5458e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.056426
Average KL loss: 0.105402
Average total loss: 0.161828
tensor(0.0068, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.6908e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.051365
Average KL loss: 0.106309
Average total loss: 0.157674
tensor(0.0068, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.0400e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.052485
Average KL loss: 0.105962
Average total loss: 0.158447
tensor(0.0068, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.7262e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.052256
Average KL loss: 0.105448
Average total loss: 0.157704
tensor(0.0068, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.0305e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.049496
Average KL loss: 0.104146
Average total loss: 0.153642
tensor(0.0068, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.0396e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.052699
Average KL loss: 0.102935
Average total loss: 0.155634
tensor(0.0068, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.4352e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.050659
Average KL loss: 0.101836
Average total loss: 0.152495
tensor(0.0068, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.1995e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.049413
Average KL loss: 0.100809
Average total loss: 0.150223
tensor(0.0068, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.0537e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.048499
Average KL loss: 0.099848
Average total loss: 0.148347
tensor(0.0068, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.8955e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.050272
Average KL loss: 0.098942
Average total loss: 0.149213
tensor(0.0068, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.7162e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.051526
Average KL loss: 0.098101
Average total loss: 0.149626
tensor(0.0068, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.1186e-11, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.051264
Average KL loss: 0.097316
Average total loss: 0.148580
tensor(0.0068, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.7637e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.051639
Average KL loss: 0.096568
Average total loss: 0.148207
tensor(0.0068, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-6.3244e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.052013
Average KL loss: 0.095846
Average total loss: 0.147859
tensor(0.0068, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.9305e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.049157
Average KL loss: 0.095154
Average total loss: 0.144311
tensor(0.0068, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(6.6465e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.047584
Average KL loss: 0.094487
Average total loss: 0.142072
tensor(0.0068, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(7.6163e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.048928
Average KL loss: 0.093866
Average total loss: 0.142794
tensor(0.0068, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(2.7914e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.048353
Average KL loss: 0.093255
Average total loss: 0.141608
tensor(0.0068, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.5203e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.046862
Average KL loss: 0.092661
Average total loss: 0.139523
tensor(0.0068, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.1419e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.045526
Average KL loss: 0.092083
Average total loss: 0.137609
tensor(0.0068, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.3319e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.046908
Average KL loss: 0.091514
Average total loss: 0.138421
tensor(0.0068, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.9722e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.048030
Average KL loss: 0.090985
Average total loss: 0.139015
tensor(0.0068, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.9249e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.049014
Average KL loss: 0.090492
Average total loss: 0.139506
tensor(0.0068, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.7367e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.049379
Average KL loss: 0.090009
Average total loss: 0.139388
tensor(0.0068, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.4268e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.046970
Average KL loss: 0.089532
Average total loss: 0.136502
tensor(0.0068, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.3460e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.047892
Average KL loss: 0.089061
Average total loss: 0.136953
tensor(0.0067, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.7714e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.049565
Average KL loss: 0.088627
Average total loss: 0.138193
tensor(0.0067, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.3187e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.048973
Average KL loss: 0.088212
Average total loss: 0.137185
tensor(0.0067, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.8831e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.048441
Average KL loss: 0.087792
Average total loss: 0.136233
tensor(0.0067, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(3.9514e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.046911
Average KL loss: 0.087380
Average total loss: 0.134292
tensor(0.0067, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.8005e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.049031
Average KL loss: 0.086993
Average total loss: 0.136024
tensor(0.0067, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-4.9691e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.047495
Average KL loss: 0.086624
Average total loss: 0.134119
tensor(0.0067, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-2.0558e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.047953
Average KL loss: 0.086258
Average total loss: 0.134212
tensor(0.0067, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.5883e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.047932
Average KL loss: 0.085894
Average total loss: 0.133826
tensor(0.0067, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-2.9646e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.050763
Average KL loss: 0.085549
Average total loss: 0.136312
tensor(0.0067, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-8.1583e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.047659
Average KL loss: 0.085226
Average total loss: 0.132885
tensor(0.0067, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.2612e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.050430
Average KL loss: 0.084888
Average total loss: 0.135318
tensor(0.0067, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-7.8689e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.048168
Average KL loss: 0.084583
Average total loss: 0.132750
tensor(0.0067, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.6300e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.046993
Average KL loss: 0.084271
Average total loss: 0.131264
tensor(0.0067, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.6702e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.049892
Average KL loss: 0.083973
Average total loss: 0.133866
tensor(0.0067, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-4.5553e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.048525
Average KL loss: 0.083695
Average total loss: 0.132219
tensor(0.0067, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-3.4253e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.049136
Average KL loss: 0.083425
Average total loss: 0.132561
tensor(0.0067, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-4.5256e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.049785
Average KL loss: 0.083160
Average total loss: 0.132945
tensor(0.0067, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(1.4710e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.047182
Average KL loss: 0.082898
Average total loss: 0.130079
tensor(0.0067, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-3.4591e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.050118
Average KL loss: 0.082639
Average total loss: 0.132757
tensor(0.0067, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(4.2030e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.049014
Average KL loss: 0.082400
Average total loss: 0.131413
tensor(0.0067, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(1.3796e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.047438
Average KL loss: 0.082156
Average total loss: 0.129594
tensor(0.0067, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.5295e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.048261
Average KL loss: 0.081919
Average total loss: 0.130180
tensor(0.0067, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.5344e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.046537
Average KL loss: 0.081687
Average total loss: 0.128224
tensor(0.0067, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-7.9005e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.047611
Average KL loss: 0.081437
Average total loss: 0.129048
tensor(0.0067, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-8.7875e-11, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.047936
Average KL loss: 0.081213
Average total loss: 0.129149
tensor(0.0067, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.8401e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.047460
Average KL loss: 0.080986
Average total loss: 0.128447
tensor(0.0067, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-8.5161e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.046853
Average KL loss: 0.080785
Average total loss: 0.127637
tensor(0.0067, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(3.1637e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.049527
Average KL loss: 0.080579
Average total loss: 0.130106
tensor(0.0067, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-4.0090e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.047481
Average KL loss: 0.080397
Average total loss: 0.127878
tensor(0.0067, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(7.8767e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.049106
Average KL loss: 0.080208
Average total loss: 0.129314
tensor(0.0067, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(1.8535e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.047400
Average KL loss: 0.080025
Average total loss: 0.127426
tensor(0.0067, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(1.2886e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.048081
Average KL loss: 0.079836
Average total loss: 0.127918
tensor(0.0067, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.3875e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.049856
Average KL loss: 0.079660
Average total loss: 0.129516
tensor(0.0067, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-4.4841e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.046654
Average KL loss: 0.079479
Average total loss: 0.126133
tensor(0.0067, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-4.0685e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.047624
Average KL loss: 0.079301
Average total loss: 0.126924
tensor(0.0067, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(1.4307e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.048711
Average KL loss: 0.079137
Average total loss: 0.127848
tensor(0.0067, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.7704e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.048563
Average KL loss: 0.078962
Average total loss: 0.127526
tensor(0.0067, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(3.0395e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.048223
Average KL loss: 0.078801
Average total loss: 0.127025
tensor(0.0067, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-5.5746e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.047967
Average KL loss: 0.078638
Average total loss: 0.126604
tensor(0.0067, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(7.2793e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.048472
Average KL loss: 0.078479
Average total loss: 0.126951
tensor(0.0067, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-3.5866e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.048160
Average KL loss: 0.078325
Average total loss: 0.126485
tensor(0.0067, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(3.0967e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.047162
Average KL loss: 0.078166
Average total loss: 0.125329
tensor(0.0067, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(3.6960e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.046137
Average KL loss: 0.078009
Average total loss: 0.124146
tensor(0.0066, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-2.0701e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.050394
Average KL loss: 0.077873
Average total loss: 0.128267
tensor(0.0066, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-3.5665e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.048480
Average KL loss: 0.077735
Average total loss: 0.126215
tensor(0.0066, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-9.1232e-11, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.048798
Average KL loss: 0.077605
Average total loss: 0.126402
tensor(0.0066, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-4.9293e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.047662
Average KL loss: 0.077479
Average total loss: 0.125141
tensor(0.0066, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-3.5998e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.047868
Average KL loss: 0.077351
Average total loss: 0.125219
tensor(0.0066, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-2.1646e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.047234
Average KL loss: 0.077220
Average total loss: 0.124453
tensor(0.0066, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(2.2888e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.046849
Average KL loss: 0.077095
Average total loss: 0.123944
tensor(0.0066, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-7.3901e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.048966
Average KL loss: 0.076981
Average total loss: 0.125948
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.5925e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.048271
Average KL loss: 0.076867
Average total loss: 0.125139
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.2133e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.048113
Average KL loss: 0.076756
Average total loss: 0.124869
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.2281e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.046677
Average KL loss: 0.076651
Average total loss: 0.123328
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-2.3771e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.048478
Average KL loss: 0.076540
Average total loss: 0.125018
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-3.6030e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.047356
Average KL loss: 0.076437
Average total loss: 0.123793
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(2.9375e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.047062
Average KL loss: 0.076313
Average total loss: 0.123376
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-8.4248e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.048966
Average KL loss: 0.076210
Average total loss: 0.125176
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(4.5999e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.046835
Average KL loss: 0.076100
Average total loss: 0.122936
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-2.3873e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.047842
Average KL loss: 0.075984
Average total loss: 0.123826
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(1.4916e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.045705
Average KL loss: 0.075876
Average total loss: 0.121580
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(1.9826e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.049124
Average KL loss: 0.075768
Average total loss: 0.124892
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(9.8228e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.047909
Average KL loss: 0.075673
Average total loss: 0.123583
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(3.2484e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.046062
Average KL loss: 0.075574
Average total loss: 0.121635
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(1.8531e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.050475
Average KL loss: 0.075472
Average total loss: 0.125947
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-8.7106e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.046640
Average KL loss: 0.075390
Average total loss: 0.122030
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(1.3105e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.045901
Average KL loss: 0.075287
Average total loss: 0.121188
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(2.6574e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.046300
Average KL loss: 0.075198
Average total loss: 0.121498
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-2.2761e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.046537
Average KL loss: 0.075096
Average total loss: 0.121633
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.0038e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.047191
Average KL loss: 0.074997
Average total loss: 0.122188
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(3.2912e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.044857
Average KL loss: 0.074903
Average total loss: 0.119760
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(4.6815e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.045948
Average KL loss: 0.074798
Average total loss: 0.120746
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(1.3372e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.045893
Average KL loss: 0.074716
Average total loss: 0.120609
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-9.8929e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.047644
Average KL loss: 0.074626
Average total loss: 0.122270
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.1286e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.046626
Average KL loss: 0.074539
Average total loss: 0.121164
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(6.8009e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.046215
Average KL loss: 0.074453
Average total loss: 0.120668
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.3225e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.047647
Average KL loss: 0.074375
Average total loss: 0.122022
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.8543e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.045062
Average KL loss: 0.074302
Average total loss: 0.119364
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(2.3659e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.045697
Average KL loss: 0.074195
Average total loss: 0.119891
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-6.5706e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.049003
Average KL loss: 0.074111
Average total loss: 0.123114
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-7.8591e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.046561
Average KL loss: 0.074034
Average total loss: 0.120595
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.0282e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.042817
Average KL loss: 0.073953
Average total loss: 0.116770
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(9.2754e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.047081
Average KL loss: 0.073862
Average total loss: 0.120943
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(7.4609e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.046988
Average KL loss: 0.073792
Average total loss: 0.120780
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.5487e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.046676
Average KL loss: 0.073721
Average total loss: 0.120397
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.7926e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.047926
Average KL loss: 0.073654
Average total loss: 0.121581
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.0768e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.044988
Average KL loss: 0.073604
Average total loss: 0.118592
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.0453e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.046017
Average KL loss: 0.073518
Average total loss: 0.119535
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-4.9418e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.047038
Average KL loss: 0.073449
Average total loss: 0.120487
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(4.7091e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.044244
Average KL loss: 0.073384
Average total loss: 0.117628
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-9.7957e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.048146
Average KL loss: 0.073301
Average total loss: 0.121447
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.4787e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.046606
Average KL loss: 0.073256
Average total loss: 0.119862
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-5.3977e-12, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.046817
Average KL loss: 0.073200
Average total loss: 0.120017
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-4.1456e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.048785
Average KL loss: 0.073159
Average total loss: 0.121944
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(3.3489e-11, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.045618
Average KL loss: 0.073138
Average total loss: 0.118756
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(2.7023e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.049418
Average KL loss: 0.073116
Average total loss: 0.122534
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.5871e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.046503
Average KL loss: 0.073095
Average total loss: 0.119598
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.3398e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.048362
Average KL loss: 0.073074
Average total loss: 0.121436
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.7594e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.047572
Average KL loss: 0.073054
Average total loss: 0.120626
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.1119e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.046495
Average KL loss: 0.073033
Average total loss: 0.119528
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.8138e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.046760
Average KL loss: 0.073012
Average total loss: 0.119772
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.0263e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.045603
Average KL loss: 0.072992
Average total loss: 0.118595
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-6.1481e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.047674
Average KL loss: 0.072972
Average total loss: 0.120647
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.6271e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.047372
Average KL loss: 0.072953
Average total loss: 0.120325
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.5186e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.047863
Average KL loss: 0.072942
Average total loss: 0.120804
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.0451e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.047354
Average KL loss: 0.072939
Average total loss: 0.120294
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(7.9273e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.047560
Average KL loss: 0.072937
Average total loss: 0.120498
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.2426e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.044847
Average KL loss: 0.072935
Average total loss: 0.117782
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.6657e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.046147
Average KL loss: 0.072933
Average total loss: 0.119080
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-8.9084e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.048595
Average KL loss: 0.072931
Average total loss: 0.121526
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.5192e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.048121
Average KL loss: 0.072929
Average total loss: 0.121050
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-8.6588e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.046946
Average KL loss: 0.072927
Average total loss: 0.119873
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(4.7152e-11, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.046134
Average KL loss: 0.072924
Average total loss: 0.119058
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(2.4000e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.046573
Average KL loss: 0.072922
Average total loss: 0.119495
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(3.2520e-09, device='cuda:0')
 Percentile value: 0.08800256848335267
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =    1194 /    1728             ( 69.10%) | total_pruned =     534 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    9620 /   36864             ( 26.10%) | total_pruned =   27244 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   10354 /   36864             ( 28.09%) | total_pruned =   26510 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    9681 /   36864             ( 26.26%) | total_pruned =   27183 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9976 /   36864             ( 27.06%) | total_pruned =   26888 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   18049 /   73728             ( 24.48%) | total_pruned =   55679 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   33133 /  147456             ( 22.47%) | total_pruned =  114323 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3913 /    8192             ( 47.77%) | total_pruned =    4279 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   25713 /  147456             ( 17.44%) | total_pruned =  121743 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   26177 /  147456             ( 17.75%) | total_pruned =  121279 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   62987 /  294912             ( 21.36%) | total_pruned =  231925 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  112107 /  589824             ( 19.01%) | total_pruned =  477717 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   12292 /   32768             ( 37.51%) | total_pruned =   20476 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   68162 /  589824             ( 11.56%) | total_pruned =  521662 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   67123 /  589824             ( 11.38%) | total_pruned =  522701 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     214 /     256             ( 83.59%) | total_pruned =      42 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  185008 / 1179648             ( 15.68%) | total_pruned =  994640 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  191576 / 2359296             (  8.12%) | total_pruned = 2167720 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   27069 /  131072             ( 20.65%) | total_pruned =  104003 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     418 /     512             ( 81.64%) | total_pruned =      94 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   84709 / 2359296             (  3.59%) | total_pruned = 2274587 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     411 /     512             ( 80.27%) | total_pruned =     101 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     249 /     512             ( 48.63%) | total_pruned =     263 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   35430 / 2359296             (  1.50%) | total_pruned = 2323866 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
linear.weight        | nonzeros =    3721 /    5120             ( 72.68%) | total_pruned =    1399 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 25/200 Loss: 0.000063 Accuracy: 86.75 100.00 % Best test Accuracy: 86.82%
tensor(0.0066, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.7938e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.229144
Average KL loss: 0.067922
Average total loss: 0.297065
tensor(0.0094, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-2.3205e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.204754
Average KL loss: 0.072294
Average total loss: 0.277048
tensor(0.0095, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.3376e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.190162
Average KL loss: 0.077180
Average total loss: 0.267342
tensor(0.0095, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-8.7231e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.175476
Average KL loss: 0.081438
Average total loss: 0.256914
tensor(0.0095, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.6014e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.164215
Average KL loss: 0.085007
Average total loss: 0.249222
tensor(0.0095, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-8.1405e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.154336
Average KL loss: 0.088084
Average total loss: 0.242420
tensor(0.0096, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.1663e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.153365
Average KL loss: 0.090825
Average total loss: 0.244190
tensor(0.0096, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.9003e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.154486
Average KL loss: 0.093573
Average total loss: 0.248059
tensor(0.0096, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(5.3158e-11, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.148729
Average KL loss: 0.096218
Average total loss: 0.244947
tensor(0.0096, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.0634e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.136358
Average KL loss: 0.098359
Average total loss: 0.234717
tensor(0.0096, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.0228e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.135114
Average KL loss: 0.100115
Average total loss: 0.235229
tensor(0.0096, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-7.0288e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.136272
Average KL loss: 0.101808
Average total loss: 0.238080
tensor(0.0096, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.5007e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.131428
Average KL loss: 0.103423
Average total loss: 0.234851
tensor(0.0096, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-7.8237e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.127591
Average KL loss: 0.104991
Average total loss: 0.232582
tensor(0.0096, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(5.9604e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.121883
Average KL loss: 0.106192
Average total loss: 0.228075
tensor(0.0096, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.1974e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.122381
Average KL loss: 0.107372
Average total loss: 0.229752
tensor(0.0096, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-4.2103e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.118922
Average KL loss: 0.108631
Average total loss: 0.227553
tensor(0.0096, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.0299e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.117082
Average KL loss: 0.109619
Average total loss: 0.226701
tensor(0.0096, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-3.0573e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.118486
Average KL loss: 0.110588
Average total loss: 0.229075
tensor(0.0096, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.5171e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.114694
Average KL loss: 0.111595
Average total loss: 0.226289
tensor(0.0096, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.4638e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.113196
Average KL loss: 0.112523
Average total loss: 0.225719
tensor(0.0096, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-7.8459e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.115058
Average KL loss: 0.113441
Average total loss: 0.228499
tensor(0.0096, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(9.2060e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.108904
Average KL loss: 0.114400
Average total loss: 0.223304
tensor(0.0096, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-8.3349e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.108150
Average KL loss: 0.115128
Average total loss: 0.223278
tensor(0.0096, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-5.0090e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.107134
Average KL loss: 0.116001
Average total loss: 0.223135
tensor(0.0096, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.6765e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.106113
Average KL loss: 0.116529
Average total loss: 0.222642
tensor(0.0096, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-4.7341e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.103539
Average KL loss: 0.117001
Average total loss: 0.220540
tensor(0.0096, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.0145e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.103637
Average KL loss: 0.117429
Average total loss: 0.221066
tensor(0.0096, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.5176e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.105266
Average KL loss: 0.118227
Average total loss: 0.223493
tensor(0.0096, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.9285e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.103394
Average KL loss: 0.118863
Average total loss: 0.222257
tensor(0.0096, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.1640e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.096934
Average KL loss: 0.119446
Average total loss: 0.216380
tensor(0.0096, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.0955e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.099517
Average KL loss: 0.119747
Average total loss: 0.219264
tensor(0.0096, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.3965e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.095762
Average KL loss: 0.120124
Average total loss: 0.215886
tensor(0.0096, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.3799e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.094484
Average KL loss: 0.120303
Average total loss: 0.214787
tensor(0.0096, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-9.3242e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.100509
Average KL loss: 0.120746
Average total loss: 0.221255
tensor(0.0096, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.4036e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.100591
Average KL loss: 0.121267
Average total loss: 0.221858
tensor(0.0096, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-9.2890e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.095924
Average KL loss: 0.121869
Average total loss: 0.217793
tensor(0.0096, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.9029e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.095763
Average KL loss: 0.122192
Average total loss: 0.217955
tensor(0.0096, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.9872e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.096352
Average KL loss: 0.122543
Average total loss: 0.218895
tensor(0.0096, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.9902e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.093897
Average KL loss: 0.122928
Average total loss: 0.216825
tensor(0.0095, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-9.5188e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.096556
Average KL loss: 0.123332
Average total loss: 0.219888
tensor(0.0095, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(1.4773e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.097905
Average KL loss: 0.123997
Average total loss: 0.221902
tensor(0.0095, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-2.1144e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.091499
Average KL loss: 0.124340
Average total loss: 0.215839
tensor(0.0095, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.7469e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.096056
Average KL loss: 0.124728
Average total loss: 0.220783
tensor(0.0096, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-5.4910e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.091445
Average KL loss: 0.125189
Average total loss: 0.216634
tensor(0.0096, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-6.4650e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.092504
Average KL loss: 0.125073
Average total loss: 0.217577
tensor(0.0096, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-4.5774e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.087755
Average KL loss: 0.124683
Average total loss: 0.212438
tensor(0.0096, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(2.9021e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.086656
Average KL loss: 0.124284
Average total loss: 0.210940
tensor(0.0095, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.2325e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.086908
Average KL loss: 0.123890
Average total loss: 0.210797
tensor(0.0095, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-5.1400e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.086056
Average KL loss: 0.123499
Average total loss: 0.209555
tensor(0.0095, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(1.6241e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.087591
Average KL loss: 0.123127
Average total loss: 0.210718
tensor(0.0095, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(1.9062e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.088183
Average KL loss: 0.122766
Average total loss: 0.210949
tensor(0.0095, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-5.8719e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.089298
Average KL loss: 0.122408
Average total loss: 0.211706
tensor(0.0095, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(4.2589e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.089168
Average KL loss: 0.122076
Average total loss: 0.211244
tensor(0.0095, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(1.1505e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.087286
Average KL loss: 0.121752
Average total loss: 0.209038
tensor(0.0095, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-8.4451e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.087158
Average KL loss: 0.121420
Average total loss: 0.208577
tensor(0.0095, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-1.1087e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.086089
Average KL loss: 0.121097
Average total loss: 0.207186
tensor(0.0095, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-1.5110e-11, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.085710
Average KL loss: 0.120777
Average total loss: 0.206487
tensor(0.0095, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(4.9115e-11, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.088239
Average KL loss: 0.120454
Average total loss: 0.208694
tensor(0.0095, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(2.5769e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.084209
Average KL loss: 0.120141
Average total loss: 0.204350
tensor(0.0095, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-4.7444e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.087498
Average KL loss: 0.119836
Average total loss: 0.207334
tensor(0.0095, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-4.7368e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.086040
Average KL loss: 0.119543
Average total loss: 0.205583
tensor(0.0095, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.4650e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.086750
Average KL loss: 0.119252
Average total loss: 0.206002
tensor(0.0095, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.1500e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.087993
Average KL loss: 0.118973
Average total loss: 0.206966
tensor(0.0095, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-7.2932e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.090591
Average KL loss: 0.118700
Average total loss: 0.209291
tensor(0.0095, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(4.1480e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.087358
Average KL loss: 0.118430
Average total loss: 0.205789
tensor(0.0095, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-4.6205e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.083335
Average KL loss: 0.118161
Average total loss: 0.201496
tensor(0.0095, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.6512e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.084955
Average KL loss: 0.117888
Average total loss: 0.202843
tensor(0.0095, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(7.8902e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.084693
Average KL loss: 0.117616
Average total loss: 0.202309
tensor(0.0095, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-5.6367e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.087146
Average KL loss: 0.117356
Average total loss: 0.204502
tensor(0.0095, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.9279e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.090395
Average KL loss: 0.117116
Average total loss: 0.207512
tensor(0.0095, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(2.4467e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.085400
Average KL loss: 0.116880
Average total loss: 0.202280
tensor(0.0095, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.0217e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.087587
Average KL loss: 0.116635
Average total loss: 0.204222
tensor(0.0095, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-7.2159e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.084953
Average KL loss: 0.116409
Average total loss: 0.201361
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-5.3984e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.086911
Average KL loss: 0.116178
Average total loss: 0.203089
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(5.6564e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.089849
Average KL loss: 0.115943
Average total loss: 0.205793
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.9997e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.086843
Average KL loss: 0.115721
Average total loss: 0.202564
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(2.4584e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.087667
Average KL loss: 0.115495
Average total loss: 0.203162
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-5.7415e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.088590
Average KL loss: 0.115279
Average total loss: 0.203868
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(3.0289e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.082240
Average KL loss: 0.115065
Average total loss: 0.197305
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-7.9537e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.087872
Average KL loss: 0.114846
Average total loss: 0.202718
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.9347e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.085480
Average KL loss: 0.114645
Average total loss: 0.200126
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(3.5652e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.089051
Average KL loss: 0.114443
Average total loss: 0.203495
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.5345e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.087739
Average KL loss: 0.114243
Average total loss: 0.201981
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.0890e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.087483
Average KL loss: 0.114043
Average total loss: 0.201527
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(9.0851e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.082933
Average KL loss: 0.113844
Average total loss: 0.196776
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-9.0726e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.088438
Average KL loss: 0.113640
Average total loss: 0.202078
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.2557e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.085040
Average KL loss: 0.113457
Average total loss: 0.198497
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.3869e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.087224
Average KL loss: 0.113262
Average total loss: 0.200487
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.5503e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.085041
Average KL loss: 0.113079
Average total loss: 0.198120
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-4.5643e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.089678
Average KL loss: 0.112900
Average total loss: 0.202578
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.1314e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.083066
Average KL loss: 0.112718
Average total loss: 0.195784
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-7.0517e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.083103
Average KL loss: 0.112533
Average total loss: 0.195636
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(8.1531e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.084056
Average KL loss: 0.112353
Average total loss: 0.196408
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.0060e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.085249
Average KL loss: 0.112190
Average total loss: 0.197440
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-3.7021e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.087172
Average KL loss: 0.112028
Average total loss: 0.199200
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-5.6532e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.086652
Average KL loss: 0.111868
Average total loss: 0.198520
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.2844e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.087751
Average KL loss: 0.111709
Average total loss: 0.199460
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.2226e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.082699
Average KL loss: 0.111550
Average total loss: 0.194249
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(3.0077e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.082433
Average KL loss: 0.111383
Average total loss: 0.193815
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-6.0300e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.085595
Average KL loss: 0.111212
Average total loss: 0.196807
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-4.1185e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.085324
Average KL loss: 0.111057
Average total loss: 0.196381
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.5987e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.087807
Average KL loss: 0.110915
Average total loss: 0.198722
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.2156e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.084308
Average KL loss: 0.110776
Average total loss: 0.195084
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.3282e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.085970
Average KL loss: 0.110629
Average total loss: 0.196599
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-4.2027e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.083595
Average KL loss: 0.110486
Average total loss: 0.194081
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(4.0205e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.081926
Average KL loss: 0.110337
Average total loss: 0.192263
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.9891e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.086287
Average KL loss: 0.110186
Average total loss: 0.196473
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.1418e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.087153
Average KL loss: 0.110041
Average total loss: 0.197194
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.6821e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.083176
Average KL loss: 0.109899
Average total loss: 0.193076
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-7.4770e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.082017
Average KL loss: 0.109759
Average total loss: 0.191776
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(7.3359e-11, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.085994
Average KL loss: 0.109604
Average total loss: 0.195598
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.4235e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.084402
Average KL loss: 0.109477
Average total loss: 0.193880
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(5.5094e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.084176
Average KL loss: 0.109350
Average total loss: 0.193527
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.5604e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.082432
Average KL loss: 0.109217
Average total loss: 0.191649
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.3239e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.080933
Average KL loss: 0.109076
Average total loss: 0.190009
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.9992e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.084363
Average KL loss: 0.108936
Average total loss: 0.193298
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-7.4974e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.085493
Average KL loss: 0.108810
Average total loss: 0.194303
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(1.0788e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.082651
Average KL loss: 0.108675
Average total loss: 0.191325
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-4.5862e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.085951
Average KL loss: 0.108552
Average total loss: 0.194503
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.9741e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.081864
Average KL loss: 0.108441
Average total loss: 0.190304
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(2.1031e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.081438
Average KL loss: 0.108319
Average total loss: 0.189757
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.6359e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.083220
Average KL loss: 0.108191
Average total loss: 0.191411
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-4.6733e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.081386
Average KL loss: 0.108070
Average total loss: 0.189455
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(1.6036e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.081845
Average KL loss: 0.107944
Average total loss: 0.189788
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.9145e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.082566
Average KL loss: 0.107826
Average total loss: 0.190392
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(2.3362e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.082724
Average KL loss: 0.107703
Average total loss: 0.190427
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-3.7457e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.085264
Average KL loss: 0.107592
Average total loss: 0.192856
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-3.5943e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.081903
Average KL loss: 0.107493
Average total loss: 0.189396
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(4.3408e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.085664
Average KL loss: 0.107382
Average total loss: 0.193047
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-4.7462e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.083608
Average KL loss: 0.107289
Average total loss: 0.190897
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(2.7084e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.086929
Average KL loss: 0.107180
Average total loss: 0.194109
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-3.3012e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.088347
Average KL loss: 0.107087
Average total loss: 0.195434
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.4306e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.083067
Average KL loss: 0.107002
Average total loss: 0.190068
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-5.7100e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.082982
Average KL loss: 0.106890
Average total loss: 0.189871
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-4.5293e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.084568
Average KL loss: 0.106789
Average total loss: 0.191358
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(1.2350e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.084488
Average KL loss: 0.106692
Average total loss: 0.191179
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.1757e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.079626
Average KL loss: 0.106588
Average total loss: 0.186213
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(5.7588e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.078760
Average KL loss: 0.106483
Average total loss: 0.185243
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.7286e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.084653
Average KL loss: 0.106372
Average total loss: 0.191025
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.2060e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.084341
Average KL loss: 0.106292
Average total loss: 0.190633
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.2628e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.081732
Average KL loss: 0.106206
Average total loss: 0.187938
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-5.8574e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.083803
Average KL loss: 0.106114
Average total loss: 0.189916
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.0324e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.083502
Average KL loss: 0.106026
Average total loss: 0.189528
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.8645e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.082017
Average KL loss: 0.105933
Average total loss: 0.187950
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.0795e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.084902
Average KL loss: 0.105845
Average total loss: 0.190746
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(6.4036e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.084631
Average KL loss: 0.105759
Average total loss: 0.190391
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.9934e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.081352
Average KL loss: 0.105660
Average total loss: 0.187012
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-9.4960e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.079595
Average KL loss: 0.105568
Average total loss: 0.185163
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.0184e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.085389
Average KL loss: 0.105486
Average total loss: 0.190875
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.0092e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.082633
Average KL loss: 0.105422
Average total loss: 0.188055
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.0759e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.085090
Average KL loss: 0.105342
Average total loss: 0.190432
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.5779e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.088320
Average KL loss: 0.105271
Average total loss: 0.193590
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.8884e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.077966
Average KL loss: 0.105193
Average total loss: 0.183159
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(3.8384e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.078128
Average KL loss: 0.105092
Average total loss: 0.183220
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.7658e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.078856
Average KL loss: 0.104995
Average total loss: 0.183851
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.8991e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.085214
Average KL loss: 0.104912
Average total loss: 0.190126
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(2.9706e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.083365
Average KL loss: 0.104840
Average total loss: 0.188205
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.4506e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.080948
Average KL loss: 0.104760
Average total loss: 0.185708
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.1210e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.081194
Average KL loss: 0.104682
Average total loss: 0.185876
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.2066e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.084875
Average KL loss: 0.104612
Average total loss: 0.189487
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.8217e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.080240
Average KL loss: 0.104552
Average total loss: 0.184791
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(5.2329e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.083000
Average KL loss: 0.104481
Average total loss: 0.187481
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(9.8854e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.080740
Average KL loss: 0.104409
Average total loss: 0.185149
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.5896e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.079168
Average KL loss: 0.104332
Average total loss: 0.183500
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.8118e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.080682
Average KL loss: 0.104285
Average total loss: 0.184968
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-9.0284e-11, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.080084
Average KL loss: 0.104272
Average total loss: 0.184356
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.3048e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.080659
Average KL loss: 0.104260
Average total loss: 0.184919
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(3.3171e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.083520
Average KL loss: 0.104247
Average total loss: 0.187767
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-5.6267e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.080286
Average KL loss: 0.104234
Average total loss: 0.184520
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.0715e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.084120
Average KL loss: 0.104221
Average total loss: 0.188342
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.8561e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.080141
Average KL loss: 0.104209
Average total loss: 0.184350
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(3.7628e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.083508
Average KL loss: 0.104196
Average total loss: 0.187704
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.4807e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.079395
Average KL loss: 0.104185
Average total loss: 0.183580
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.0079e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.078012
Average KL loss: 0.104172
Average total loss: 0.182184
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.8403e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.083141
Average KL loss: 0.104159
Average total loss: 0.187301
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.8500e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.079556
Average KL loss: 0.104147
Average total loss: 0.183704
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.3371e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.081208
Average KL loss: 0.104136
Average total loss: 0.185344
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-6.2427e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.086455
Average KL loss: 0.104124
Average total loss: 0.190580
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(5.2171e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.081475
Average KL loss: 0.104114
Average total loss: 0.185589
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.4966e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.082622
Average KL loss: 0.104102
Average total loss: 0.186724
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.3742e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.078327
Average KL loss: 0.104090
Average total loss: 0.182417
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(2.0523e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.080395
Average KL loss: 0.104078
Average total loss: 0.184473
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.6397e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.080093
Average KL loss: 0.104067
Average total loss: 0.184160
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.4509e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.082222
Average KL loss: 0.104055
Average total loss: 0.186277
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.2749e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.082274
Average KL loss: 0.104043
Average total loss: 0.186317
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.2743e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.085511
Average KL loss: 0.104037
Average total loss: 0.189548
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-9.5449e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.087493
Average KL loss: 0.104036
Average total loss: 0.191530
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.6916e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.081603
Average KL loss: 0.104035
Average total loss: 0.185638
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.1315e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.083084
Average KL loss: 0.104034
Average total loss: 0.187118
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.8213e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.081443
Average KL loss: 0.104033
Average total loss: 0.185476
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(4.2345e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.078011
Average KL loss: 0.104031
Average total loss: 0.182043
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(3.9408e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.077098
Average KL loss: 0.104030
Average total loss: 0.181128
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.6063e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.079002
Average KL loss: 0.104029
Average total loss: 0.183031
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.0947e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.085323
Average KL loss: 0.104028
Average total loss: 0.189350
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(2.2502e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.081392
Average KL loss: 0.104027
Average total loss: 0.185419
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.7068e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.087961
Average KL loss: 0.104025
Average total loss: 0.191986
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.5038e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.082732
Average KL loss: 0.104024
Average total loss: 0.186756
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.5715e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.083069
Average KL loss: 0.104023
Average total loss: 0.187092
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(9.4931e-11, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.081270
Average KL loss: 0.104022
Average total loss: 0.185292
 Percentile value: 0.35852513313293455
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =    1104 /    1728             ( 63.89%) | total_pruned =     624 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4610 /   36864             ( 12.51%) | total_pruned =   32254 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5238 /   36864             ( 14.21%) | total_pruned =   31626 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4815 /   36864             ( 13.06%) | total_pruned =   32049 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4840 /   36864             ( 13.13%) | total_pruned =   32024 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8323 /   73728             ( 11.29%) | total_pruned =   65405 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   13813 /  147456             (  9.37%) | total_pruned =  133643 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2918 /    8192             ( 35.62%) | total_pruned =    5274 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8689 /  147456             (  5.89%) | total_pruned =  138767 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    8792 /  147456             (  5.96%) | total_pruned =  138664 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   24943 /  294912             (  8.46%) | total_pruned =  269969 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   37899 /  589824             (  6.43%) | total_pruned =  551925 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    7868 /   32768             ( 24.01%) | total_pruned =   24900 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   17911 /  589824             (  3.04%) | total_pruned =  571913 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   17410 /  589824             (  2.95%) | total_pruned =  572414 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     198 /     256             ( 77.34%) | total_pruned =      58 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   51916 / 1179648             (  4.40%) | total_pruned = 1127732 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   36349 / 2359296             (  1.54%) | total_pruned = 2322947 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     388 /     512             ( 75.78%) | total_pruned =     124 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   10267 /  131072             (  7.83%) | total_pruned =  120805 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     393 /     512             ( 76.76%) | total_pruned =     119 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   16102 / 2359296             (  0.68%) | total_pruned = 2343194 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     396 /     512             ( 77.34%) | total_pruned =     116 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     166 /     512             ( 32.42%) | total_pruned =     346 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    7102 / 2359296             (  0.30%) | total_pruned = 2352194 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      50 /     512             (  9.77%) | total_pruned =     462 | shape = torch.Size([512])
linear.weight        | nonzeros =    3150 /    5120             ( 61.52%) | total_pruned =    1970 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 24/200 Loss: 0.000113 Accuracy: 86.47 100.00 % Best test Accuracy: 86.65%
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.7135e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.368692
Average KL loss: 0.096050
Average total loss: 0.464742
tensor(0.0105, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.8032e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.345148
Average KL loss: 0.096963
Average total loss: 0.442111
tensor(0.0107, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-3.4218e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.316643
Average KL loss: 0.099915
Average total loss: 0.416558
tensor(0.0108, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.1074e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.292849
Average KL loss: 0.102612
Average total loss: 0.395461
tensor(0.0109, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.6272e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.283432
Average KL loss: 0.105097
Average total loss: 0.388529
tensor(0.0110, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.9141e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.266284
Average KL loss: 0.107383
Average total loss: 0.373667
tensor(0.0110, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.1453e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.269507
Average KL loss: 0.109503
Average total loss: 0.379010
tensor(0.0111, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.7744e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.273915
Average KL loss: 0.111773
Average total loss: 0.385688
tensor(0.0112, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.2332e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.249459
Average KL loss: 0.113980
Average total loss: 0.363439
tensor(0.0112, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.6451e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.237023
Average KL loss: 0.115759
Average total loss: 0.352781
tensor(0.0113, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.9763e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.242715
Average KL loss: 0.117456
Average total loss: 0.360172
tensor(0.0113, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-1.4257e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.220408
Average KL loss: 0.119190
Average total loss: 0.339598
tensor(0.0114, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.1518e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.230581
Average KL loss: 0.120748
Average total loss: 0.351329
tensor(0.0114, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.0386e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.222622
Average KL loss: 0.122320
Average total loss: 0.344942
tensor(0.0114, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-2.5379e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.218138
Average KL loss: 0.123818
Average total loss: 0.341956
tensor(0.0115, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-1.5303e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.204921
Average KL loss: 0.125194
Average total loss: 0.330115
tensor(0.0115, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.0223e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.213339
Average KL loss: 0.126527
Average total loss: 0.339866
tensor(0.0116, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-1.2346e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.207989
Average KL loss: 0.127948
Average total loss: 0.335937
tensor(0.0116, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-1.7627e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.208316
Average KL loss: 0.129296
Average total loss: 0.337612
tensor(0.0116, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.2230e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.206215
Average KL loss: 0.130675
Average total loss: 0.336890
tensor(0.0117, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.5097e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.198710
Average KL loss: 0.131971
Average total loss: 0.330681
tensor(0.0117, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-6.5834e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.193252
Average KL loss: 0.133057
Average total loss: 0.326309
tensor(0.0117, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-7.6614e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.190154
Average KL loss: 0.134114
Average total loss: 0.324268
tensor(0.0117, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-8.7944e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.194814
Average KL loss: 0.135181
Average total loss: 0.329995
tensor(0.0118, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.2832e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.190847
Average KL loss: 0.136284
Average total loss: 0.327131
tensor(0.0118, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.2948e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.192318
Average KL loss: 0.137288
Average total loss: 0.329606
tensor(0.0118, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-9.0608e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.182553
Average KL loss: 0.138315
Average total loss: 0.320867
tensor(0.0118, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-1.8144e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.182676
Average KL loss: 0.139259
Average total loss: 0.321936
tensor(0.0118, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-8.7792e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.173585
Average KL loss: 0.140195
Average total loss: 0.313781
tensor(0.0119, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.0041e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.176724
Average KL loss: 0.141021
Average total loss: 0.317745
tensor(0.0119, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-6.5844e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.178812
Average KL loss: 0.141872
Average total loss: 0.320684
tensor(0.0119, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-9.6187e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.170963
Average KL loss: 0.142734
Average total loss: 0.313697
tensor(0.0119, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.8623e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.177712
Average KL loss: 0.143553
Average total loss: 0.321265
tensor(0.0119, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.4671e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.176383
Average KL loss: 0.144420
Average total loss: 0.320803
tensor(0.0120, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-1.8785e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.168626
Average KL loss: 0.145339
Average total loss: 0.313965
tensor(0.0120, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(2.4518e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.163475
Average KL loss: 0.146028
Average total loss: 0.309503
tensor(0.0120, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-3.6449e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.163707
Average KL loss: 0.146651
Average total loss: 0.310358
tensor(0.0120, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.3559e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.169771
Average KL loss: 0.147294
Average total loss: 0.317065
tensor(0.0120, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.0102e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.161013
Average KL loss: 0.147977
Average total loss: 0.308990
tensor(0.0120, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.1225e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.164926
Average KL loss: 0.148715
Average total loss: 0.313641
tensor(0.0120, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-2.7470e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.156023
Average KL loss: 0.149378
Average total loss: 0.305401
tensor(0.0120, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-8.8850e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.156145
Average KL loss: 0.149979
Average total loss: 0.306124
tensor(0.0120, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.2580e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.159280
Average KL loss: 0.150473
Average total loss: 0.309753
tensor(0.0120, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.2286e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.159291
Average KL loss: 0.150988
Average total loss: 0.310279
tensor(0.0120, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(3.2559e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.156456
Average KL loss: 0.151571
Average total loss: 0.308027
tensor(0.0121, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-9.7487e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.153951
Average KL loss: 0.152124
Average total loss: 0.306075
tensor(0.0121, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.4604e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.156813
Average KL loss: 0.152616
Average total loss: 0.309429
tensor(0.0121, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-4.9324e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.154794
Average KL loss: 0.153214
Average total loss: 0.308008
tensor(0.0121, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-5.4951e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.154038
Average KL loss: 0.153789
Average total loss: 0.307827
tensor(0.0121, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-1.0056e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.146225
Average KL loss: 0.154367
Average total loss: 0.300592
tensor(0.0121, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.1869e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.149280
Average KL loss: 0.154899
Average total loss: 0.304179
tensor(0.0121, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-1.2752e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.151179
Average KL loss: 0.155466
Average total loss: 0.306645
tensor(0.0121, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-9.1274e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.150314
Average KL loss: 0.156047
Average total loss: 0.306362
tensor(0.0121, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-3.3532e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.147941
Average KL loss: 0.156706
Average total loss: 0.304647
tensor(0.0121, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-2.4008e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.151094
Average KL loss: 0.157304
Average total loss: 0.308398
tensor(0.0121, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-1.3671e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.143707
Average KL loss: 0.157823
Average total loss: 0.301531
tensor(0.0121, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-3.8393e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.144996
Average KL loss: 0.158275
Average total loss: 0.303271
tensor(0.0122, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-8.5506e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.140674
Average KL loss: 0.158646
Average total loss: 0.299320
tensor(0.0122, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-4.0182e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.142744
Average KL loss: 0.159041
Average total loss: 0.301784
tensor(0.0122, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-6.3310e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.137880
Average KL loss: 0.159403
Average total loss: 0.297282
tensor(0.0122, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-3.3619e-11, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.141312
Average KL loss: 0.159744
Average total loss: 0.301057
tensor(0.0122, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-5.9853e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.135788
Average KL loss: 0.160128
Average total loss: 0.295916
tensor(0.0122, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-9.6267e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.138862
Average KL loss: 0.160488
Average total loss: 0.299349
tensor(0.0122, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(7.5616e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.136074
Average KL loss: 0.160864
Average total loss: 0.296938
tensor(0.0122, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-4.9894e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.137768
Average KL loss: 0.161183
Average total loss: 0.298951
tensor(0.0122, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(1.4063e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.138050
Average KL loss: 0.161504
Average total loss: 0.299554
tensor(0.0122, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.1632e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.135056
Average KL loss: 0.161910
Average total loss: 0.296967
tensor(0.0122, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-5.6074e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.137887
Average KL loss: 0.162326
Average total loss: 0.300213
tensor(0.0122, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-8.0945e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.135486
Average KL loss: 0.162705
Average total loss: 0.298191
tensor(0.0122, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(1.9305e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.134184
Average KL loss: 0.163020
Average total loss: 0.297205
tensor(0.0122, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-7.6597e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.133942
Average KL loss: 0.163327
Average total loss: 0.297269
tensor(0.0122, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(3.6658e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.133705
Average KL loss: 0.163642
Average total loss: 0.297347
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-7.2064e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.132947
Average KL loss: 0.163891
Average total loss: 0.296838
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-7.4702e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.129725
Average KL loss: 0.163970
Average total loss: 0.293695
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-4.5768e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.131499
Average KL loss: 0.163894
Average total loss: 0.295393
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-8.3579e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.133357
Average KL loss: 0.163826
Average total loss: 0.297183
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-4.8465e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.128753
Average KL loss: 0.163756
Average total loss: 0.292509
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-4.9892e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.128209
Average KL loss: 0.163678
Average total loss: 0.291887
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(1.0050e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.128570
Average KL loss: 0.163599
Average total loss: 0.292169
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.1949e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.122856
Average KL loss: 0.163528
Average total loss: 0.286384
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(2.4990e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.126847
Average KL loss: 0.163434
Average total loss: 0.290281
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-4.5284e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.132852
Average KL loss: 0.163351
Average total loss: 0.296203
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-8.6388e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.127208
Average KL loss: 0.163277
Average total loss: 0.290485
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-6.2564e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.129102
Average KL loss: 0.163190
Average total loss: 0.292292
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.0839e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.126928
Average KL loss: 0.163105
Average total loss: 0.290033
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(6.2687e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.130369
Average KL loss: 0.163026
Average total loss: 0.293395
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(5.0370e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.123181
Average KL loss: 0.162946
Average total loss: 0.286127
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.9703e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.130267
Average KL loss: 0.162860
Average total loss: 0.293127
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-3.0353e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.125489
Average KL loss: 0.162783
Average total loss: 0.288272
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(4.8713e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.127033
Average KL loss: 0.162704
Average total loss: 0.289738
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-5.6475e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.128439
Average KL loss: 0.162628
Average total loss: 0.291067
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.4958e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.126858
Average KL loss: 0.162555
Average total loss: 0.289413
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-3.3048e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.126769
Average KL loss: 0.162477
Average total loss: 0.289246
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(1.2190e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.126534
Average KL loss: 0.162412
Average total loss: 0.288946
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-5.2735e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.126890
Average KL loss: 0.162334
Average total loss: 0.289223
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-7.4926e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.127109
Average KL loss: 0.162263
Average total loss: 0.289371
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.0089e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.136172
Average KL loss: 0.162202
Average total loss: 0.298374
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-5.9299e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.130560
Average KL loss: 0.162143
Average total loss: 0.292702
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.1566e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.126216
Average KL loss: 0.162103
Average total loss: 0.288318
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-3.8329e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.134926
Average KL loss: 0.162095
Average total loss: 0.297021
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-2.2178e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.126846
Average KL loss: 0.162088
Average total loss: 0.288934
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-2.5703e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.126642
Average KL loss: 0.162080
Average total loss: 0.288722
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.8869e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.125603
Average KL loss: 0.162072
Average total loss: 0.287675
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(4.5385e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.128670
Average KL loss: 0.162064
Average total loss: 0.290734
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.7710e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.124914
Average KL loss: 0.162056
Average total loss: 0.286970
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-7.7292e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.122458
Average KL loss: 0.162048
Average total loss: 0.284505
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-2.0165e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.124089
Average KL loss: 0.162039
Average total loss: 0.286128
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-5.6398e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.128564
Average KL loss: 0.162030
Average total loss: 0.290594
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-2.7126e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.125536
Average KL loss: 0.162021
Average total loss: 0.287557
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.1083e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.128338
Average KL loss: 0.162014
Average total loss: 0.290352
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(7.8091e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.128318
Average KL loss: 0.162006
Average total loss: 0.290324
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-5.3281e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.125677
Average KL loss: 0.161999
Average total loss: 0.287675
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-4.8734e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.123993
Average KL loss: 0.161990
Average total loss: 0.285983
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-5.6072e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.126673
Average KL loss: 0.161983
Average total loss: 0.288656
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(1.3131e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.127169
Average KL loss: 0.161975
Average total loss: 0.289144
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-7.9436e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.125926
Average KL loss: 0.161967
Average total loss: 0.287894
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(2.9740e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.127578
Average KL loss: 0.161959
Average total loss: 0.289537
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-8.0378e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.129436
Average KL loss: 0.161954
Average total loss: 0.291390
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(1.0586e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.134770
Average KL loss: 0.161954
Average total loss: 0.296724
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.1361e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.129475
Average KL loss: 0.161953
Average total loss: 0.291427
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.1491e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.129501
Average KL loss: 0.161952
Average total loss: 0.291453
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-2.3657e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.125999
Average KL loss: 0.161951
Average total loss: 0.287951
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-6.6657e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.126658
Average KL loss: 0.161950
Average total loss: 0.288608
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-5.5367e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.133650
Average KL loss: 0.161950
Average total loss: 0.295600
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(1.5783e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.123994
Average KL loss: 0.161949
Average total loss: 0.285942
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.3447e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.124013
Average KL loss: 0.161948
Average total loss: 0.285961
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-2.5877e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.128678
Average KL loss: 0.161947
Average total loss: 0.290625
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-8.4809e-10, device='cuda:0')
 Percentile value: 1.207376527786255
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =     991 /    1728             ( 57.35%) | total_pruned =     737 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1889 /   36864             (  5.12%) | total_pruned =   34975 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2217 /   36864             (  6.01%) | total_pruned =   34647 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1997 /   36864             (  5.42%) | total_pruned =   34867 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2035 /   36864             (  5.52%) | total_pruned =   34829 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3193 /   73728             (  4.33%) | total_pruned =   70535 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4699 /  147456             (  3.19%) | total_pruned =  142757 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1985 /    8192             ( 24.23%) | total_pruned =    6207 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2666 /  147456             (  1.81%) | total_pruned =  144790 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2517 /  147456             (  1.71%) | total_pruned =  144939 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8155 /  294912             (  2.77%) | total_pruned =  286757 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   10297 /  589824             (  1.75%) | total_pruned =  579527 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     182 /     256             ( 71.09%) | total_pruned =      74 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4094 /   32768             ( 12.49%) | total_pruned =   28674 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     185 /     256             ( 72.27%) | total_pruned =      71 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    4114 /  589824             (  0.70%) | total_pruned =  585710 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     166 /     256             ( 64.84%) | total_pruned =      90 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3927 /  589824             (  0.67%) | total_pruned =  585897 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     144 /     256             ( 56.25%) | total_pruned =     112 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   11468 / 1179648             (  0.97%) | total_pruned = 1168180 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     455 /     512             ( 88.87%) | total_pruned =      57 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    7011 / 2359296             (  0.30%) | total_pruned = 2352285 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     315 /     512             ( 61.52%) | total_pruned =     197 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3113 /  131072             (  2.38%) | total_pruned =  127959 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     474 /     512             ( 92.58%) | total_pruned =      38 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     316 /     512             ( 61.72%) | total_pruned =     196 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3551 / 2359296             (  0.15%) | total_pruned = 2355745 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     325 /     512             ( 63.48%) | total_pruned =     187 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      58 /     512             ( 11.33%) | total_pruned =     454 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1325 / 2359296             (  0.06%) | total_pruned = 2357971 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
linear.weight        | nonzeros =    2302 /    5120             ( 44.96%) | total_pruned =    2818 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 25/200 Loss: 0.002737 Accuracy: 84.84 100.00 % Best test Accuracy: 85.08%
tensor(0.0122, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-7.4396e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.722253
Average KL loss: 0.145085
Average total loss: 0.867338
tensor(0.0100, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-7.0833e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.696213
Average KL loss: 0.139198
Average total loss: 0.835411
tensor(0.0100, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-6.9119e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.642957
Average KL loss: 0.140622
Average total loss: 0.783579
tensor(0.0100, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-8.7719e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.638938
Average KL loss: 0.142214
Average total loss: 0.781152
tensor(0.0101, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-6.5061e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.600431
Average KL loss: 0.143845
Average total loss: 0.744276
tensor(0.0102, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-4.9525e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.562740
Average KL loss: 0.145433
Average total loss: 0.708173
tensor(0.0102, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-5.7049e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.551583
Average KL loss: 0.146874
Average total loss: 0.698458
tensor(0.0103, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-4.6959e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.553368
Average KL loss: 0.148311
Average total loss: 0.701679
tensor(0.0103, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-3.6070e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.535846
Average KL loss: 0.149754
Average total loss: 0.685600
tensor(0.0104, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-5.7449e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.520444
Average KL loss: 0.151128
Average total loss: 0.671572
tensor(0.0105, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-2.9362e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.492891
Average KL loss: 0.152484
Average total loss: 0.645375
tensor(0.0105, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-3.1159e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.485744
Average KL loss: 0.153748
Average total loss: 0.639492
tensor(0.0106, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.6272e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.486288
Average KL loss: 0.154935
Average total loss: 0.641223
tensor(0.0106, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-3.6920e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.469850
Average KL loss: 0.156143
Average total loss: 0.625993
tensor(0.0106, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-2.5279e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.483523
Average KL loss: 0.157344
Average total loss: 0.640867
tensor(0.0107, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-3.5474e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.457704
Average KL loss: 0.158549
Average total loss: 0.616253
tensor(0.0107, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-4.0969e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.430325
Average KL loss: 0.159679
Average total loss: 0.590004
tensor(0.0108, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-1.9211e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.448202
Average KL loss: 0.160789
Average total loss: 0.608991
tensor(0.0108, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-2.9277e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.420388
Average KL loss: 0.161905
Average total loss: 0.582293
tensor(0.0109, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-3.4430e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.434217
Average KL loss: 0.162986
Average total loss: 0.597204
tensor(0.0109, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-4.2954e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.421535
Average KL loss: 0.164092
Average total loss: 0.585627
tensor(0.0109, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-3.7491e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.423977
Average KL loss: 0.165192
Average total loss: 0.589169
tensor(0.0110, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-2.0362e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.410076
Average KL loss: 0.166219
Average total loss: 0.576295
tensor(0.0110, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-2.6791e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.414267
Average KL loss: 0.167232
Average total loss: 0.581499
tensor(0.0111, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-2.7262e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.401410
Average KL loss: 0.168246
Average total loss: 0.569656
tensor(0.0111, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.7680e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.388346
Average KL loss: 0.169214
Average total loss: 0.557560
tensor(0.0111, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.8986e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.391063
Average KL loss: 0.170119
Average total loss: 0.561182
tensor(0.0112, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-2.5240e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.392426
Average KL loss: 0.171022
Average total loss: 0.563447
tensor(0.0112, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-2.6990e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.378970
Average KL loss: 0.171954
Average total loss: 0.550924
tensor(0.0112, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-4.5568e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.392150
Average KL loss: 0.172933
Average total loss: 0.565083
tensor(0.0113, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-2.7826e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.374217
Average KL loss: 0.173897
Average total loss: 0.548114
tensor(0.0113, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-3.5076e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.387300
Average KL loss: 0.174842
Average total loss: 0.562142
tensor(0.0114, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-3.4360e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.361113
Average KL loss: 0.175745
Average total loss: 0.536857
tensor(0.0114, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-1.7732e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.352418
Average KL loss: 0.176589
Average total loss: 0.529007
tensor(0.0114, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-2.1607e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.358309
Average KL loss: 0.177381
Average total loss: 0.535690
tensor(0.0114, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-1.3252e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.355585
Average KL loss: 0.178198
Average total loss: 0.533783
tensor(0.0115, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.8739e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.339550
Average KL loss: 0.179016
Average total loss: 0.518566
tensor(0.0115, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.1564e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.354390
Average KL loss: 0.179865
Average total loss: 0.534255
tensor(0.0115, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-2.1331e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.354583
Average KL loss: 0.180737
Average total loss: 0.535320
tensor(0.0116, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-2.4733e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.342092
Average KL loss: 0.181563
Average total loss: 0.523655
tensor(0.0116, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-2.3029e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.343746
Average KL loss: 0.182347
Average total loss: 0.526093
tensor(0.0116, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.2626e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.329681
Average KL loss: 0.183156
Average total loss: 0.512837
tensor(0.0117, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-3.7756e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.326209
Average KL loss: 0.183905
Average total loss: 0.510114
tensor(0.0117, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-2.8299e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.324789
Average KL loss: 0.184684
Average total loss: 0.509473
tensor(0.0117, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.9391e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.338015
Average KL loss: 0.185469
Average total loss: 0.523484
tensor(0.0118, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-1.7379e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.321539
Average KL loss: 0.186257
Average total loss: 0.507796
tensor(0.0118, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-1.9915e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.319663
Average KL loss: 0.187000
Average total loss: 0.506663
tensor(0.0118, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.9483e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.304808
Average KL loss: 0.187735
Average total loss: 0.492544
tensor(0.0119, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-1.5188e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.311333
Average KL loss: 0.188475
Average total loss: 0.499808
tensor(0.0119, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-1.0686e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.309605
Average KL loss: 0.189216
Average total loss: 0.498821
tensor(0.0119, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-1.3682e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.303259
Average KL loss: 0.189906
Average total loss: 0.493164
tensor(0.0119, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-2.0306e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.295145
Average KL loss: 0.190621
Average total loss: 0.485766
tensor(0.0120, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.2524e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.301098
Average KL loss: 0.191289
Average total loss: 0.492387
tensor(0.0120, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-1.6069e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.288132
Average KL loss: 0.191961
Average total loss: 0.480092
tensor(0.0120, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.2000e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.296438
Average KL loss: 0.192645
Average total loss: 0.489083
tensor(0.0120, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-1.5367e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.290638
Average KL loss: 0.193357
Average total loss: 0.483995
tensor(0.0121, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.7090e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.289527
Average KL loss: 0.193963
Average total loss: 0.483490
tensor(0.0121, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-1.4665e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.290826
Average KL loss: 0.194581
Average total loss: 0.485406
tensor(0.0121, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-1.1971e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.286575
Average KL loss: 0.195203
Average total loss: 0.481777
tensor(0.0122, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-2.0811e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.275642
Average KL loss: 0.195836
Average total loss: 0.471478
tensor(0.0122, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-1.1085e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.270005
Average KL loss: 0.196438
Average total loss: 0.466442
tensor(0.0122, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.2875e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.268356
Average KL loss: 0.197030
Average total loss: 0.465386
tensor(0.0122, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.2235e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.277375
Average KL loss: 0.197620
Average total loss: 0.474995
tensor(0.0123, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.6868e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.264880
Average KL loss: 0.198223
Average total loss: 0.463103
tensor(0.0123, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.1244e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.271980
Average KL loss: 0.198806
Average total loss: 0.470786
tensor(0.0123, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-1.0300e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.265941
Average KL loss: 0.199419
Average total loss: 0.465360
tensor(0.0123, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-1.4455e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.280839
Average KL loss: 0.200092
Average total loss: 0.480931
tensor(0.0124, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-9.1108e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.265567
Average KL loss: 0.200768
Average total loss: 0.466335
tensor(0.0124, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-1.7743e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.257894
Average KL loss: 0.201322
Average total loss: 0.459216
tensor(0.0124, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-1.1201e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.258735
Average KL loss: 0.201873
Average total loss: 0.460609
tensor(0.0124, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-1.6878e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.260082
Average KL loss: 0.202492
Average total loss: 0.462573
tensor(0.0125, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.1356e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.255405
Average KL loss: 0.203065
Average total loss: 0.458470
tensor(0.0125, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-8.6717e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.256905
Average KL loss: 0.203609
Average total loss: 0.460514
tensor(0.0125, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-1.7500e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.250161
Average KL loss: 0.204169
Average total loss: 0.454330
tensor(0.0125, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-1.3408e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.255147
Average KL loss: 0.204719
Average total loss: 0.459866
tensor(0.0125, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-1.7339e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.242387
Average KL loss: 0.205268
Average total loss: 0.447655
tensor(0.0126, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-1.2469e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.245453
Average KL loss: 0.205821
Average total loss: 0.451274
tensor(0.0126, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-1.0331e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.236917
Average KL loss: 0.206356
Average total loss: 0.443273
tensor(0.0126, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-9.9793e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.236696
Average KL loss: 0.206850
Average total loss: 0.443547
tensor(0.0126, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-4.6084e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.242966
Average KL loss: 0.207334
Average total loss: 0.450300
tensor(0.0127, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-1.0124e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.230883
Average KL loss: 0.207830
Average total loss: 0.438713
tensor(0.0127, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-1.8870e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.233370
Average KL loss: 0.208321
Average total loss: 0.441691
tensor(0.0127, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-1.1110e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.229250
Average KL loss: 0.208748
Average total loss: 0.437999
tensor(0.0127, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-1.4645e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.225273
Average KL loss: 0.209179
Average total loss: 0.434452
tensor(0.0127, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-6.9548e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.226071
Average KL loss: 0.209648
Average total loss: 0.435719
tensor(0.0128, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.5054e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.234800
Average KL loss: 0.210113
Average total loss: 0.444913
tensor(0.0128, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-8.4374e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.218937
Average KL loss: 0.210631
Average total loss: 0.429568
tensor(0.0128, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-9.1173e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.238851
Average KL loss: 0.211083
Average total loss: 0.449934
tensor(0.0128, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-8.7988e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.228795
Average KL loss: 0.211575
Average total loss: 0.440370
tensor(0.0129, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-1.5519e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.217069
Average KL loss: 0.212113
Average total loss: 0.429182
tensor(0.0129, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-2.7987e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.215419
Average KL loss: 0.212612
Average total loss: 0.428031
tensor(0.0129, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-2.0032e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.216800
Average KL loss: 0.213100
Average total loss: 0.429900
tensor(0.0129, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-6.7659e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.217978
Average KL loss: 0.213518
Average total loss: 0.431496
tensor(0.0129, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-1.4617e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.212864
Average KL loss: 0.213972
Average total loss: 0.426836
tensor(0.0130, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-2.0388e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.209176
Average KL loss: 0.214423
Average total loss: 0.423598
tensor(0.0130, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-7.4786e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.216092
Average KL loss: 0.214829
Average total loss: 0.430921
tensor(0.0130, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-8.3260e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.204634
Average KL loss: 0.215240
Average total loss: 0.419874
tensor(0.0130, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-1.1197e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.212268
Average KL loss: 0.215621
Average total loss: 0.427889
tensor(0.0130, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-6.0995e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.208526
Average KL loss: 0.216064
Average total loss: 0.424589
tensor(0.0131, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-6.6540e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.210470
Average KL loss: 0.216518
Average total loss: 0.426988
tensor(0.0131, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-1.2618e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.204023
Average KL loss: 0.216985
Average total loss: 0.421008
tensor(0.0131, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-2.2460e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.204219
Average KL loss: 0.217386
Average total loss: 0.421605
tensor(0.0131, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.4033e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.204734
Average KL loss: 0.217753
Average total loss: 0.422487
tensor(0.0131, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.8331e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.203312
Average KL loss: 0.218135
Average total loss: 0.421447
tensor(0.0131, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-6.5978e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.199259
Average KL loss: 0.218526
Average total loss: 0.417785
tensor(0.0132, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-1.0006e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.201401
Average KL loss: 0.218916
Average total loss: 0.420317
tensor(0.0132, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-6.4847e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.195826
Average KL loss: 0.219286
Average total loss: 0.415112
tensor(0.0132, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-1.4112e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.194062
Average KL loss: 0.219642
Average total loss: 0.413703
tensor(0.0132, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-3.5287e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.193802
Average KL loss: 0.220041
Average total loss: 0.413844
tensor(0.0132, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-1.7557e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.193973
Average KL loss: 0.220423
Average total loss: 0.414396
tensor(0.0133, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-8.0477e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.188534
Average KL loss: 0.220775
Average total loss: 0.409309
tensor(0.0133, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-3.8273e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.190091
Average KL loss: 0.221177
Average total loss: 0.411267
tensor(0.0133, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-2.3114e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.193332
Average KL loss: 0.221568
Average total loss: 0.414901
tensor(0.0133, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-1.0219e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.195183
Average KL loss: 0.221913
Average total loss: 0.417096
tensor(0.0133, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-1.4493e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.192075
Average KL loss: 0.222290
Average total loss: 0.414365
tensor(0.0134, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-1.7962e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.191609
Average KL loss: 0.222667
Average total loss: 0.414277
tensor(0.0134, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-2.1564e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.188255
Average KL loss: 0.223038
Average total loss: 0.411293
tensor(0.0134, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-1.1969e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.184833
Average KL loss: 0.223398
Average total loss: 0.408231
tensor(0.0134, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-1.2830e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.182610
Average KL loss: 0.223726
Average total loss: 0.406336
tensor(0.0134, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-1.3571e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.182906
Average KL loss: 0.224036
Average total loss: 0.406942
tensor(0.0134, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-1.2899e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.182786
Average KL loss: 0.224348
Average total loss: 0.407134
tensor(0.0135, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-1.5687e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.176449
Average KL loss: 0.224629
Average total loss: 0.401078
tensor(0.0135, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-1.3346e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.183417
Average KL loss: 0.224942
Average total loss: 0.408359
tensor(0.0135, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-2.0922e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.181592
Average KL loss: 0.225297
Average total loss: 0.406889
tensor(0.0135, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-7.3468e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.184575
Average KL loss: 0.225601
Average total loss: 0.410176
tensor(0.0135, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-5.2921e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.180061
Average KL loss: 0.225935
Average total loss: 0.405996
tensor(0.0135, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-1.3030e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.171684
Average KL loss: 0.226238
Average total loss: 0.397922
tensor(0.0136, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-3.3876e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.176750
Average KL loss: 0.226512
Average total loss: 0.403262
tensor(0.0136, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-9.2454e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.173027
Average KL loss: 0.226853
Average total loss: 0.399880
tensor(0.0136, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-9.8591e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.170678
Average KL loss: 0.227172
Average total loss: 0.397849
tensor(0.0136, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-7.3586e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.169446
Average KL loss: 0.227484
Average total loss: 0.396929
tensor(0.0136, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(1.6027e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.167495
Average KL loss: 0.227730
Average total loss: 0.395225
tensor(0.0136, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(1.8667e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.163564
Average KL loss: 0.228009
Average total loss: 0.391573
tensor(0.0136, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-2.2277e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.171200
Average KL loss: 0.228276
Average total loss: 0.399475
tensor(0.0137, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-7.6761e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.166615
Average KL loss: 0.228559
Average total loss: 0.395174
tensor(0.0137, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-8.0162e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.170938
Average KL loss: 0.228869
Average total loss: 0.399807
tensor(0.0137, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-7.6587e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.165805
Average KL loss: 0.229176
Average total loss: 0.394981
tensor(0.0137, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-1.1131e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.166856
Average KL loss: 0.229477
Average total loss: 0.396333
tensor(0.0137, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-6.5690e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.159920
Average KL loss: 0.229737
Average total loss: 0.389657
tensor(0.0137, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-7.8884e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.162879
Average KL loss: 0.229966
Average total loss: 0.392845
tensor(0.0137, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-4.7722e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.166152
Average KL loss: 0.230238
Average total loss: 0.396390
tensor(0.0138, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-1.2161e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.165339
Average KL loss: 0.230526
Average total loss: 0.395865
tensor(0.0138, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-5.6087e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.165062
Average KL loss: 0.230812
Average total loss: 0.395875
tensor(0.0138, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-1.0627e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.161437
Average KL loss: 0.231098
Average total loss: 0.392536
tensor(0.0138, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-8.7828e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.157733
Average KL loss: 0.231379
Average total loss: 0.389112
tensor(0.0138, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-6.8519e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.158512
Average KL loss: 0.231659
Average total loss: 0.390171
tensor(0.0138, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-7.7636e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.154844
Average KL loss: 0.231939
Average total loss: 0.386783
tensor(0.0139, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-5.7819e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.159767
Average KL loss: 0.232192
Average total loss: 0.391959
tensor(0.0139, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-4.4778e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.156245
Average KL loss: 0.232406
Average total loss: 0.388650
tensor(0.0139, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(-6.8943e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.159906
Average KL loss: 0.232682
Average total loss: 0.392589
tensor(0.0139, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-2.1166e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.156782
Average KL loss: 0.232985
Average total loss: 0.389766
tensor(0.0139, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-5.5756e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.153035
Average KL loss: 0.233243
Average total loss: 0.386278
tensor(0.0139, device='cuda:0') tensor(0.0408, device='cuda:0') tensor(-4.9191e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.152945
Average KL loss: 0.233446
Average total loss: 0.386391
tensor(0.0139, device='cuda:0') tensor(0.0409, device='cuda:0') tensor(-9.8316e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.155944
Average KL loss: 0.233663
Average total loss: 0.389608
tensor(0.0140, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(-7.8401e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.152373
Average KL loss: 0.233854
Average total loss: 0.386227
tensor(0.0140, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(-7.9112e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.144413
Average KL loss: 0.234081
Average total loss: 0.378493
tensor(0.0140, device='cuda:0') tensor(0.0412, device='cuda:0') tensor(-1.6913e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.150632
Average KL loss: 0.234276
Average total loss: 0.384909
tensor(0.0140, device='cuda:0') tensor(0.0413, device='cuda:0') tensor(-4.6737e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.146085
Average KL loss: 0.234479
Average total loss: 0.380564
tensor(0.0140, device='cuda:0') tensor(0.0414, device='cuda:0') tensor(-7.8511e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.146513
Average KL loss: 0.234708
Average total loss: 0.381220
tensor(0.0140, device='cuda:0') tensor(0.0415, device='cuda:0') tensor(-1.1277e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.143588
Average KL loss: 0.234900
Average total loss: 0.378489
tensor(0.0140, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(-4.5932e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.149564
Average KL loss: 0.235128
Average total loss: 0.384692
tensor(0.0140, device='cuda:0') tensor(0.0417, device='cuda:0') tensor(-5.4095e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.144481
Average KL loss: 0.235384
Average total loss: 0.379865
tensor(0.0141, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-1.8989e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.146097
Average KL loss: 0.235599
Average total loss: 0.381696
tensor(0.0141, device='cuda:0') tensor(0.0420, device='cuda:0') tensor(7.6098e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.143110
Average KL loss: 0.235826
Average total loss: 0.378937
tensor(0.0141, device='cuda:0') tensor(0.0421, device='cuda:0') tensor(-1.0190e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.143216
Average KL loss: 0.236075
Average total loss: 0.379291
tensor(0.0141, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-1.0812e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.147407
Average KL loss: 0.236305
Average total loss: 0.383711
tensor(0.0141, device='cuda:0') tensor(0.0423, device='cuda:0') tensor(-6.8402e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.144998
Average KL loss: 0.236523
Average total loss: 0.381521
tensor(0.0141, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-4.7528e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.138443
Average KL loss: 0.236635
Average total loss: 0.375079
tensor(0.0141, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-3.8507e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.141791
Average KL loss: 0.236645
Average total loss: 0.378436
tensor(0.0141, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-4.2886e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.141221
Average KL loss: 0.236657
Average total loss: 0.377878
tensor(0.0141, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-6.5275e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.145012
Average KL loss: 0.236673
Average total loss: 0.381685
tensor(0.0141, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-4.1864e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.145262
Average KL loss: 0.236687
Average total loss: 0.381948
tensor(0.0141, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-4.1751e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.138355
Average KL loss: 0.236698
Average total loss: 0.375053
tensor(0.0141, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-1.3227e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.147521
Average KL loss: 0.236712
Average total loss: 0.384233
tensor(0.0141, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-8.8402e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.142443
Average KL loss: 0.236730
Average total loss: 0.379172
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-1.9875e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.140417
Average KL loss: 0.236741
Average total loss: 0.377158
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-7.6950e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.141275
Average KL loss: 0.236753
Average total loss: 0.378027
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-4.1609e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.139007
Average KL loss: 0.236763
Average total loss: 0.375770
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-8.7149e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.141172
Average KL loss: 0.236774
Average total loss: 0.377947
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(2.0018e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.142254
Average KL loss: 0.236783
Average total loss: 0.379037
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-1.3843e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.142896
Average KL loss: 0.236784
Average total loss: 0.379680
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-2.7782e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.136133
Average KL loss: 0.236785
Average total loss: 0.372918
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-8.8103e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.140896
Average KL loss: 0.236786
Average total loss: 0.377682
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-9.7291e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.142244
Average KL loss: 0.236787
Average total loss: 0.379031
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-6.2454e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.139944
Average KL loss: 0.236788
Average total loss: 0.376731
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-9.0381e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.140110
Average KL loss: 0.236789
Average total loss: 0.376898
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-9.1161e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.139013
Average KL loss: 0.236790
Average total loss: 0.375802
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-1.0751e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.139818
Average KL loss: 0.236791
Average total loss: 0.376609
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-5.1581e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.148698
Average KL loss: 0.236792
Average total loss: 0.385490
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-1.2431e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.138989
Average KL loss: 0.236794
Average total loss: 0.375782
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-7.1288e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.145065
Average KL loss: 0.236795
Average total loss: 0.381859
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-6.2733e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.134227
Average KL loss: 0.236796
Average total loss: 0.371022
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-9.7635e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.139756
Average KL loss: 0.236797
Average total loss: 0.376553
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-4.2841e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.142137
Average KL loss: 0.236798
Average total loss: 0.378935
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-4.4722e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.143551
Average KL loss: 0.236799
Average total loss: 0.380350
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-7.6099e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.140155
Average KL loss: 0.236800
Average total loss: 0.376955
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-1.0411e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.145201
Average KL loss: 0.236801
Average total loss: 0.382002
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-2.4313e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.144434
Average KL loss: 0.236802
Average total loss: 0.381236
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-6.8252e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.142581
Average KL loss: 0.236804
Average total loss: 0.379385
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-7.2779e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.141676
Average KL loss: 0.236805
Average total loss: 0.378480
 Percentile value: 3.6837861537933345
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     859 /    1728             ( 49.71%) | total_pruned =     869 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     699 /   36864             (  1.90%) | total_pruned =   36165 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     787 /   36864             (  2.13%) | total_pruned =   36077 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     717 /   36864             (  1.94%) | total_pruned =   36147 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     715 /   36864             (  1.94%) | total_pruned =   36149 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     989 /   73728             (  1.34%) | total_pruned =   72739 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1316 /  147456             (  0.89%) | total_pruned =  146140 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1048 /    8192             ( 12.79%) | total_pruned =    7144 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     736 /  147456             (  0.50%) | total_pruned =  146720 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     670 /  147456             (  0.45%) | total_pruned =  146786 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2032 /  294912             (  0.69%) | total_pruned =  292880 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     191 /     256             ( 74.61%) | total_pruned =      65 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2250 /  589824             (  0.38%) | total_pruned =  587574 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      62 /     256             ( 24.22%) | total_pruned =     194 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1378 /   32768             (  4.21%) | total_pruned =   31390 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     893 /  589824             (  0.15%) | total_pruned =  588931 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      63 /     256             ( 24.61%) | total_pruned =     193 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     815 /  589824             (  0.14%) | total_pruned =  589009 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2086 / 1179648             (  0.18%) | total_pruned = 1177562 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     266 /     512             ( 51.95%) | total_pruned =     246 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1306 / 2359296             (  0.06%) | total_pruned = 2357990 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     451 /     512             ( 88.09%) | total_pruned =      61 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     648 /  131072             (  0.49%) | total_pruned =  130424 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     355 /     512             ( 69.34%) | total_pruned =     157 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      54 /     512             ( 10.55%) | total_pruned =     458 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     664 / 2359296             (  0.03%) | total_pruned = 2358632 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     216 /     512             ( 42.19%) | total_pruned =     296 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     192 / 2359296             (  0.01%) | total_pruned = 2359104 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     311 /     512             ( 60.74%) | total_pruned =     201 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    1274 /    5120             ( 24.88%) | total_pruned =    3846 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 146/200 Loss: 0.035282 Accuracy: 77.73 99.98 % Best test Accuracy: 80.11%
tensor(0.0141, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-7.3896e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.823002
Average KL loss: 0.213255
Average total loss: 1.036256
tensor(0.0119, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-4.3812e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.852369
Average KL loss: 0.177131
Average total loss: 1.029500
tensor(0.0103, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-4.7001e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.831505
Average KL loss: 0.154602
Average total loss: 0.986107
tensor(0.0093, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-7.8658e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.813259
Average KL loss: 0.143050
Average total loss: 0.956310
tensor(0.0086, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-3.9329e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.802598
Average KL loss: 0.138351
Average total loss: 0.940949
tensor(0.0082, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-6.9124e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.811702
Average KL loss: 0.136763
Average total loss: 0.948465
tensor(0.0081, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-6.0514e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.769349
Average KL loss: 0.136394
Average total loss: 0.905742
tensor(0.0080, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-5.5800e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.780779
Average KL loss: 0.136482
Average total loss: 0.917261
tensor(0.0080, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-3.9767e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.722555
Average KL loss: 0.136717
Average total loss: 0.859272
tensor(0.0080, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-5.2780e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.728943
Average KL loss: 0.136961
Average total loss: 0.865904
tensor(0.0081, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.1604e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.703009
Average KL loss: 0.137225
Average total loss: 0.840233
tensor(0.0081, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-6.8065e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.676930
Average KL loss: 0.137468
Average total loss: 0.814398
tensor(0.0081, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-7.5523e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.663646
Average KL loss: 0.137713
Average total loss: 0.801359
tensor(0.0081, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-4.1749e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.686711
Average KL loss: 0.137969
Average total loss: 0.824680
tensor(0.0082, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-3.6886e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.633698
Average KL loss: 0.138214
Average total loss: 0.771912
tensor(0.0082, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-4.7083e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.629567
Average KL loss: 0.138432
Average total loss: 0.767998
tensor(0.0082, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-3.6807e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.633308
Average KL loss: 0.138650
Average total loss: 0.771958
tensor(0.0082, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-6.7334e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.609495
Average KL loss: 0.138873
Average total loss: 0.748368
tensor(0.0082, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-4.1134e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.595945
Average KL loss: 0.139077
Average total loss: 0.735023
tensor(0.0083, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-4.2176e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.610173
Average KL loss: 0.139291
Average total loss: 0.749463
tensor(0.0083, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-4.6425e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.598068
Average KL loss: 0.139516
Average total loss: 0.737583
tensor(0.0083, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-3.9922e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.579210
Average KL loss: 0.139724
Average total loss: 0.718934
tensor(0.0083, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-4.9974e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.557659
Average KL loss: 0.139943
Average total loss: 0.697602
tensor(0.0084, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-4.5263e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.562098
Average KL loss: 0.140174
Average total loss: 0.702272
tensor(0.0084, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-5.2890e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.540071
Average KL loss: 0.140382
Average total loss: 0.680453
tensor(0.0084, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-3.3361e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.521852
Average KL loss: 0.140577
Average total loss: 0.662429
tensor(0.0084, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-3.6316e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.536608
Average KL loss: 0.140770
Average total loss: 0.677378
tensor(0.0085, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-3.6128e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.527515
Average KL loss: 0.140969
Average total loss: 0.668484
tensor(0.0085, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-3.6381e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.509139
Average KL loss: 0.141160
Average total loss: 0.650299
tensor(0.0085, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-3.4126e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.497852
Average KL loss: 0.141347
Average total loss: 0.639198
tensor(0.0085, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-3.1327e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.491451
Average KL loss: 0.141527
Average total loss: 0.632978
tensor(0.0086, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-4.5854e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.504451
Average KL loss: 0.141720
Average total loss: 0.646171
tensor(0.0086, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-3.6309e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.467472
Average KL loss: 0.141904
Average total loss: 0.609376
tensor(0.0086, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-2.9467e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.479535
Average KL loss: 0.142096
Average total loss: 0.621632
tensor(0.0086, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-4.1323e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.451250
Average KL loss: 0.142292
Average total loss: 0.593542
tensor(0.0086, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-3.0653e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.453548
Average KL loss: 0.142472
Average total loss: 0.596021
tensor(0.0087, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-3.4442e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.451822
Average KL loss: 0.142652
Average total loss: 0.594473
tensor(0.0087, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-2.3814e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.441657
Average KL loss: 0.142832
Average total loss: 0.584489
tensor(0.0087, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-2.6857e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.433942
Average KL loss: 0.143013
Average total loss: 0.576955
tensor(0.0087, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-3.5539e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.430032
Average KL loss: 0.143200
Average total loss: 0.573232
tensor(0.0088, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-2.8805e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.407594
Average KL loss: 0.143377
Average total loss: 0.550971
tensor(0.0088, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-4.0463e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.414161
Average KL loss: 0.143543
Average total loss: 0.557704
tensor(0.0088, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-3.5801e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.413829
Average KL loss: 0.143704
Average total loss: 0.557533
tensor(0.0088, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-4.6957e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.403790
Average KL loss: 0.143876
Average total loss: 0.547666
tensor(0.0088, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-3.2715e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.391367
Average KL loss: 0.144052
Average total loss: 0.535419
tensor(0.0089, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(-2.7703e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.395508
Average KL loss: 0.144202
Average total loss: 0.539709
tensor(0.0089, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-3.0850e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.368536
Average KL loss: 0.144359
Average total loss: 0.512895
tensor(0.0089, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-3.1942e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.385482
Average KL loss: 0.144513
Average total loss: 0.529995
tensor(0.0089, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-4.0865e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.384874
Average KL loss: 0.144678
Average total loss: 0.529551
tensor(0.0090, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-3.2986e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.375530
Average KL loss: 0.144844
Average total loss: 0.520375
tensor(0.0090, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.9901e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.362883
Average KL loss: 0.145009
Average total loss: 0.507891
tensor(0.0090, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-4.9032e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.353123
Average KL loss: 0.145170
Average total loss: 0.498293
tensor(0.0090, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-2.6605e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.347711
Average KL loss: 0.145322
Average total loss: 0.493032
tensor(0.0090, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-3.7110e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.344916
Average KL loss: 0.145485
Average total loss: 0.490402
tensor(0.0091, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-1.4184e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.331153
Average KL loss: 0.145643
Average total loss: 0.476796
tensor(0.0091, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-3.6957e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.337088
Average KL loss: 0.145796
Average total loss: 0.482884
tensor(0.0091, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-2.8231e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.340193
Average KL loss: 0.145953
Average total loss: 0.486146
tensor(0.0091, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-2.6668e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.327965
Average KL loss: 0.146100
Average total loss: 0.474065
tensor(0.0092, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-3.9089e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.322901
Average KL loss: 0.146247
Average total loss: 0.469148
tensor(0.0092, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-2.3363e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.308153
Average KL loss: 0.146392
Average total loss: 0.454545
tensor(0.0092, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-3.3536e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.310636
Average KL loss: 0.146539
Average total loss: 0.457175
tensor(0.0092, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.0902e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.327048
Average KL loss: 0.146675
Average total loss: 0.473723
tensor(0.0092, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-2.6488e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.304585
Average KL loss: 0.146822
Average total loss: 0.451406
tensor(0.0093, device='cuda:0') tensor(0.0408, device='cuda:0') tensor(-2.4805e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.299915
Average KL loss: 0.146966
Average total loss: 0.446881
tensor(0.0093, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(-2.1415e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.299317
Average KL loss: 0.147104
Average total loss: 0.446421
tensor(0.0093, device='cuda:0') tensor(0.0412, device='cuda:0') tensor(-3.2247e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.296521
Average KL loss: 0.147241
Average total loss: 0.443762
tensor(0.0093, device='cuda:0') tensor(0.0414, device='cuda:0') tensor(-2.4402e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.296696
Average KL loss: 0.147384
Average total loss: 0.444080
tensor(0.0094, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(-2.9215e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.278426
Average KL loss: 0.147524
Average total loss: 0.425951
tensor(0.0094, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-4.1075e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.287266
Average KL loss: 0.147654
Average total loss: 0.434921
tensor(0.0094, device='cuda:0') tensor(0.0420, device='cuda:0') tensor(-1.9558e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.280973
Average KL loss: 0.147771
Average total loss: 0.428744
tensor(0.0094, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-1.7939e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.273999
Average KL loss: 0.147893
Average total loss: 0.421892
tensor(0.0094, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-2.2301e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.276202
Average KL loss: 0.148019
Average total loss: 0.424220
tensor(0.0095, device='cuda:0') tensor(0.0426, device='cuda:0') tensor(-8.4089e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.266616
Average KL loss: 0.148140
Average total loss: 0.414755
tensor(0.0095, device='cuda:0') tensor(0.0428, device='cuda:0') tensor(-1.9847e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.269224
Average KL loss: 0.148277
Average total loss: 0.417501
tensor(0.0095, device='cuda:0') tensor(0.0430, device='cuda:0') tensor(-2.4719e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.258278
Average KL loss: 0.148409
Average total loss: 0.406687
tensor(0.0095, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(-1.7761e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.262778
Average KL loss: 0.148523
Average total loss: 0.411301
tensor(0.0095, device='cuda:0') tensor(0.0433, device='cuda:0') tensor(-2.5847e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.259868
Average KL loss: 0.148648
Average total loss: 0.408516
tensor(0.0096, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(-1.5321e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.234945
Average KL loss: 0.148785
Average total loss: 0.383730
tensor(0.0096, device='cuda:0') tensor(0.0437, device='cuda:0') tensor(-2.0276e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.248481
Average KL loss: 0.148898
Average total loss: 0.397379
tensor(0.0096, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-1.8917e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.239903
Average KL loss: 0.149015
Average total loss: 0.388918
tensor(0.0096, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-1.8490e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.236382
Average KL loss: 0.149134
Average total loss: 0.385517
tensor(0.0097, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-1.8947e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.232454
Average KL loss: 0.149246
Average total loss: 0.381699
tensor(0.0097, device='cuda:0') tensor(0.0445, device='cuda:0') tensor(-1.8679e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.227896
Average KL loss: 0.149359
Average total loss: 0.377255
tensor(0.0097, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-9.8842e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.223247
Average KL loss: 0.149465
Average total loss: 0.372712
tensor(0.0097, device='cuda:0') tensor(0.0449, device='cuda:0') tensor(-1.6235e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.231383
Average KL loss: 0.149574
Average total loss: 0.380957
tensor(0.0097, device='cuda:0') tensor(0.0451, device='cuda:0') tensor(-2.8174e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.221132
Average KL loss: 0.149688
Average total loss: 0.370820
tensor(0.0098, device='cuda:0') tensor(0.0453, device='cuda:0') tensor(-3.0057e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.226047
Average KL loss: 0.149808
Average total loss: 0.375855
tensor(0.0098, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(-2.1386e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.209047
Average KL loss: 0.149927
Average total loss: 0.358974
tensor(0.0098, device='cuda:0') tensor(0.0457, device='cuda:0') tensor(-8.5624e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.220223
Average KL loss: 0.150036
Average total loss: 0.370259
tensor(0.0098, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(-2.1938e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.210544
Average KL loss: 0.150144
Average total loss: 0.360688
tensor(0.0098, device='cuda:0') tensor(0.0461, device='cuda:0') tensor(-2.8961e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.210738
Average KL loss: 0.150259
Average total loss: 0.360997
tensor(0.0099, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-1.2385e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.211285
Average KL loss: 0.150359
Average total loss: 0.361644
tensor(0.0099, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-2.3253e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.207988
Average KL loss: 0.150460
Average total loss: 0.358449
tensor(0.0099, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.5227e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.204046
Average KL loss: 0.150572
Average total loss: 0.354618
tensor(0.0099, device='cuda:0') tensor(0.0469, device='cuda:0') tensor(-1.7844e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.196914
Average KL loss: 0.150678
Average total loss: 0.347593
tensor(0.0099, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-1.8997e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.191434
Average KL loss: 0.150778
Average total loss: 0.342212
tensor(0.0100, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-1.4649e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.193403
Average KL loss: 0.150882
Average total loss: 0.344285
tensor(0.0100, device='cuda:0') tensor(0.0475, device='cuda:0') tensor(-1.3623e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.182687
Average KL loss: 0.150974
Average total loss: 0.333661
tensor(0.0100, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-3.4407e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.192348
Average KL loss: 0.151066
Average total loss: 0.343415
tensor(0.0100, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-1.8805e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.184006
Average KL loss: 0.151169
Average total loss: 0.335175
tensor(0.0100, device='cuda:0') tensor(0.0481, device='cuda:0') tensor(-1.9195e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.188079
Average KL loss: 0.151258
Average total loss: 0.339337
tensor(0.0101, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-2.7883e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.176773
Average KL loss: 0.151358
Average total loss: 0.328131
tensor(0.0101, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-1.9878e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.178895
Average KL loss: 0.151454
Average total loss: 0.330349
tensor(0.0101, device='cuda:0') tensor(0.0486, device='cuda:0') tensor(-1.7630e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.176993
Average KL loss: 0.151546
Average total loss: 0.328539
tensor(0.0101, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-5.7207e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.163730
Average KL loss: 0.151633
Average total loss: 0.315363
tensor(0.0101, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(-1.5733e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.169868
Average KL loss: 0.151727
Average total loss: 0.321595
tensor(0.0102, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(-1.2171e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.167042
Average KL loss: 0.151818
Average total loss: 0.318860
tensor(0.0102, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-1.1051e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.167067
Average KL loss: 0.151908
Average total loss: 0.318975
tensor(0.0102, device='cuda:0') tensor(0.0496, device='cuda:0') tensor(-1.3489e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.170422
Average KL loss: 0.151982
Average total loss: 0.322405
tensor(0.0102, device='cuda:0') tensor(0.0498, device='cuda:0') tensor(-9.4313e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.160339
Average KL loss: 0.152067
Average total loss: 0.312405
tensor(0.0102, device='cuda:0') tensor(0.0500, device='cuda:0') tensor(-1.3729e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.160840
Average KL loss: 0.152152
Average total loss: 0.312992
tensor(0.0103, device='cuda:0') tensor(0.0502, device='cuda:0') tensor(-1.6152e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.155582
Average KL loss: 0.152243
Average total loss: 0.307825
tensor(0.0103, device='cuda:0') tensor(0.0504, device='cuda:0') tensor(-1.7293e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.150947
Average KL loss: 0.152329
Average total loss: 0.303276
tensor(0.0103, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(-1.4100e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.146183
Average KL loss: 0.152416
Average total loss: 0.298598
tensor(0.0103, device='cuda:0') tensor(0.0508, device='cuda:0') tensor(-1.0539e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.151331
Average KL loss: 0.152502
Average total loss: 0.303833
tensor(0.0103, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(-1.4616e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.152213
Average KL loss: 0.152584
Average total loss: 0.304797
tensor(0.0104, device='cuda:0') tensor(0.0512, device='cuda:0') tensor(-9.3706e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.150281
Average KL loss: 0.152674
Average total loss: 0.302955
tensor(0.0104, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(-1.9309e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.144063
Average KL loss: 0.152766
Average total loss: 0.296829
tensor(0.0104, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-8.4647e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.138536
Average KL loss: 0.152847
Average total loss: 0.291383
tensor(0.0104, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-1.3262e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.145943
Average KL loss: 0.152926
Average total loss: 0.298869
tensor(0.0104, device='cuda:0') tensor(0.0519, device='cuda:0') tensor(-1.4005e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.139825
Average KL loss: 0.152996
Average total loss: 0.292821
tensor(0.0104, device='cuda:0') tensor(0.0521, device='cuda:0') tensor(-1.7348e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.144250
Average KL loss: 0.153088
Average total loss: 0.297338
tensor(0.0105, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(-1.9081e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.137679
Average KL loss: 0.153173
Average total loss: 0.290852
tensor(0.0105, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(-1.2336e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.136108
Average KL loss: 0.153250
Average total loss: 0.289357
tensor(0.0105, device='cuda:0') tensor(0.0527, device='cuda:0') tensor(-1.3694e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.130730
Average KL loss: 0.153329
Average total loss: 0.284059
tensor(0.0105, device='cuda:0') tensor(0.0529, device='cuda:0') tensor(-1.2209e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.130413
Average KL loss: 0.153402
Average total loss: 0.283815
tensor(0.0105, device='cuda:0') tensor(0.0531, device='cuda:0') tensor(-1.4445e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.131826
Average KL loss: 0.153466
Average total loss: 0.285292
tensor(0.0106, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(-7.2286e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.127027
Average KL loss: 0.153531
Average total loss: 0.280558
tensor(0.0106, device='cuda:0') tensor(0.0535, device='cuda:0') tensor(-1.5098e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.143878
Average KL loss: 0.153604
Average total loss: 0.297482
tensor(0.0106, device='cuda:0') tensor(0.0537, device='cuda:0') tensor(-1.7985e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.122575
Average KL loss: 0.153671
Average total loss: 0.276246
tensor(0.0106, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(-7.9461e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.126531
Average KL loss: 0.153732
Average total loss: 0.280263
tensor(0.0106, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(-9.8113e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.130273
Average KL loss: 0.153805
Average total loss: 0.284078
tensor(0.0107, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(-1.9134e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.129115
Average KL loss: 0.153869
Average total loss: 0.282984
tensor(0.0107, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-1.4543e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.133914
Average KL loss: 0.153933
Average total loss: 0.287847
tensor(0.0107, device='cuda:0') tensor(0.0546, device='cuda:0') tensor(-5.8172e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.119195
Average KL loss: 0.153999
Average total loss: 0.273194
tensor(0.0107, device='cuda:0') tensor(0.0548, device='cuda:0') tensor(-9.1774e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.117295
Average KL loss: 0.154051
Average total loss: 0.271346
tensor(0.0107, device='cuda:0') tensor(0.0550, device='cuda:0') tensor(-1.0236e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.121368
Average KL loss: 0.154108
Average total loss: 0.275475
tensor(0.0107, device='cuda:0') tensor(0.0552, device='cuda:0') tensor(-6.4295e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.121393
Average KL loss: 0.154165
Average total loss: 0.275558
tensor(0.0108, device='cuda:0') tensor(0.0554, device='cuda:0') tensor(-1.0642e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.113909
Average KL loss: 0.154234
Average total loss: 0.268143
tensor(0.0108, device='cuda:0') tensor(0.0556, device='cuda:0') tensor(-1.2648e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.114599
Average KL loss: 0.154290
Average total loss: 0.268889
tensor(0.0108, device='cuda:0') tensor(0.0558, device='cuda:0') tensor(-1.3903e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.111815
Average KL loss: 0.154354
Average total loss: 0.266169
tensor(0.0108, device='cuda:0') tensor(0.0560, device='cuda:0') tensor(-1.0774e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.111032
Average KL loss: 0.154417
Average total loss: 0.265448
tensor(0.0108, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(-1.0234e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.107504
Average KL loss: 0.154475
Average total loss: 0.261979
tensor(0.0108, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-1.2412e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.118215
Average KL loss: 0.154539
Average total loss: 0.272754
tensor(0.0109, device='cuda:0') tensor(0.0565, device='cuda:0') tensor(-1.1640e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.108888
Average KL loss: 0.154603
Average total loss: 0.263491
tensor(0.0109, device='cuda:0') tensor(0.0567, device='cuda:0') tensor(-1.0123e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.104355
Average KL loss: 0.154670
Average total loss: 0.259025
tensor(0.0109, device='cuda:0') tensor(0.0569, device='cuda:0') tensor(-1.0043e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.101882
Average KL loss: 0.154730
Average total loss: 0.256612
tensor(0.0109, device='cuda:0') tensor(0.0571, device='cuda:0') tensor(-1.2960e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.110169
Average KL loss: 0.154784
Average total loss: 0.264953
tensor(0.0109, device='cuda:0') tensor(0.0573, device='cuda:0') tensor(-5.7582e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.104240
Average KL loss: 0.154837
Average total loss: 0.259077
tensor(0.0110, device='cuda:0') tensor(0.0575, device='cuda:0') tensor(-7.9999e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.101026
Average KL loss: 0.154899
Average total loss: 0.255925
tensor(0.0110, device='cuda:0') tensor(0.0577, device='cuda:0') tensor(-1.0432e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.097949
Average KL loss: 0.154954
Average total loss: 0.252902
tensor(0.0110, device='cuda:0') tensor(0.0578, device='cuda:0') tensor(-9.7432e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.095652
Average KL loss: 0.155001
Average total loss: 0.250652
tensor(0.0110, device='cuda:0') tensor(0.0580, device='cuda:0') tensor(-4.5305e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.101568
Average KL loss: 0.155052
Average total loss: 0.256620
tensor(0.0110, device='cuda:0') tensor(0.0582, device='cuda:0') tensor(-6.8917e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.093311
Average KL loss: 0.155109
Average total loss: 0.248420
tensor(0.0110, device='cuda:0') tensor(0.0584, device='cuda:0') tensor(-5.4364e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.092978
Average KL loss: 0.155160
Average total loss: 0.248138
tensor(0.0111, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(-1.3639e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.097438
Average KL loss: 0.155210
Average total loss: 0.252648
tensor(0.0111, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-7.1312e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.097709
Average KL loss: 0.155255
Average total loss: 0.252964
tensor(0.0111, device='cuda:0') tensor(0.0589, device='cuda:0') tensor(-8.1482e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.095088
Average KL loss: 0.155304
Average total loss: 0.250391
tensor(0.0111, device='cuda:0') tensor(0.0591, device='cuda:0') tensor(-5.8575e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.090983
Average KL loss: 0.155350
Average total loss: 0.246333
tensor(0.0111, device='cuda:0') tensor(0.0593, device='cuda:0') tensor(-7.1795e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.098123
Average KL loss: 0.155395
Average total loss: 0.253519
tensor(0.0111, device='cuda:0') tensor(0.0595, device='cuda:0') tensor(-6.5179e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.092925
Average KL loss: 0.155445
Average total loss: 0.248369
tensor(0.0112, device='cuda:0') tensor(0.0597, device='cuda:0') tensor(-5.8161e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.090588
Average KL loss: 0.155495
Average total loss: 0.246083
tensor(0.0112, device='cuda:0') tensor(0.0599, device='cuda:0') tensor(-6.4005e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.090728
Average KL loss: 0.155556
Average total loss: 0.246284
tensor(0.0112, device='cuda:0') tensor(0.0600, device='cuda:0') tensor(-9.0356e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.094795
Average KL loss: 0.155622
Average total loss: 0.250417
tensor(0.0112, device='cuda:0') tensor(0.0602, device='cuda:0') tensor(-3.3939e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.086012
Average KL loss: 0.155670
Average total loss: 0.241682
tensor(0.0112, device='cuda:0') tensor(0.0604, device='cuda:0') tensor(-6.3088e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.085830
Average KL loss: 0.155720
Average total loss: 0.241549
tensor(0.0112, device='cuda:0') tensor(0.0606, device='cuda:0') tensor(-1.0235e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.092763
Average KL loss: 0.155775
Average total loss: 0.248538
tensor(0.0113, device='cuda:0') tensor(0.0608, device='cuda:0') tensor(-6.9242e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.088968
Average KL loss: 0.155823
Average total loss: 0.244790
tensor(0.0113, device='cuda:0') tensor(0.0610, device='cuda:0') tensor(-7.3120e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.083081
Average KL loss: 0.155867
Average total loss: 0.238948
tensor(0.0113, device='cuda:0') tensor(0.0612, device='cuda:0') tensor(-6.9334e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.086361
Average KL loss: 0.155909
Average total loss: 0.242270
tensor(0.0113, device='cuda:0') tensor(0.0613, device='cuda:0') tensor(-6.4247e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.085846
Average KL loss: 0.155963
Average total loss: 0.241809
tensor(0.0113, device='cuda:0') tensor(0.0615, device='cuda:0') tensor(-4.5365e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.086595
Average KL loss: 0.156011
Average total loss: 0.242606
tensor(0.0113, device='cuda:0') tensor(0.0617, device='cuda:0') tensor(-2.8735e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.082261
Average KL loss: 0.156054
Average total loss: 0.238315
tensor(0.0114, device='cuda:0') tensor(0.0619, device='cuda:0') tensor(-9.7221e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.080448
Average KL loss: 0.156099
Average total loss: 0.236547
tensor(0.0114, device='cuda:0') tensor(0.0620, device='cuda:0') tensor(-7.5156e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.080875
Average KL loss: 0.156138
Average total loss: 0.237013
tensor(0.0114, device='cuda:0') tensor(0.0622, device='cuda:0') tensor(-6.4297e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.080499
Average KL loss: 0.156177
Average total loss: 0.236676
tensor(0.0114, device='cuda:0') tensor(0.0624, device='cuda:0') tensor(-7.9127e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.074538
Average KL loss: 0.156219
Average total loss: 0.230756
tensor(0.0114, device='cuda:0') tensor(0.0626, device='cuda:0') tensor(-5.8373e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.075752
Average KL loss: 0.156258
Average total loss: 0.232009
tensor(0.0114, device='cuda:0') tensor(0.0628, device='cuda:0') tensor(-4.8032e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.075685
Average KL loss: 0.156298
Average total loss: 0.231983
tensor(0.0115, device='cuda:0') tensor(0.0630, device='cuda:0') tensor(-3.8696e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.074853
Average KL loss: 0.156334
Average total loss: 0.231186
tensor(0.0115, device='cuda:0') tensor(0.0631, device='cuda:0') tensor(-5.7511e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.074990
Average KL loss: 0.156375
Average total loss: 0.231365
tensor(0.0115, device='cuda:0') tensor(0.0633, device='cuda:0') tensor(-6.2153e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.078419
Average KL loss: 0.156412
Average total loss: 0.234832
tensor(0.0115, device='cuda:0') tensor(0.0635, device='cuda:0') tensor(-7.9950e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.071761
Average KL loss: 0.156455
Average total loss: 0.228216
tensor(0.0115, device='cuda:0') tensor(0.0637, device='cuda:0') tensor(-5.3733e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.071838
Average KL loss: 0.156496
Average total loss: 0.228335
tensor(0.0115, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-8.0424e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.077774
Average KL loss: 0.156536
Average total loss: 0.234310
tensor(0.0116, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-1.0490e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.077837
Average KL loss: 0.156571
Average total loss: 0.234408
tensor(0.0116, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-3.9308e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.075284
Average KL loss: 0.156603
Average total loss: 0.231887
tensor(0.0116, device='cuda:0') tensor(0.0644, device='cuda:0') tensor(-4.2080e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.070604
Average KL loss: 0.156638
Average total loss: 0.227242
tensor(0.0116, device='cuda:0') tensor(0.0646, device='cuda:0') tensor(-5.3911e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.069949
Average KL loss: 0.156668
Average total loss: 0.226618
tensor(0.0116, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-4.0982e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.070383
Average KL loss: 0.156699
Average total loss: 0.227082
tensor(0.0116, device='cuda:0') tensor(0.0649, device='cuda:0') tensor(-4.9185e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.068510
Average KL loss: 0.156731
Average total loss: 0.225240
tensor(0.0116, device='cuda:0') tensor(0.0651, device='cuda:0') tensor(-8.8920e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.070569
Average KL loss: 0.156751
Average total loss: 0.227320
tensor(0.0117, device='cuda:0') tensor(0.0652, device='cuda:0') tensor(-5.4627e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.075134
Average KL loss: 0.156781
Average total loss: 0.231914
tensor(0.0117, device='cuda:0') tensor(0.0654, device='cuda:0') tensor(-9.2928e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.067441
Average KL loss: 0.156816
Average total loss: 0.224257
tensor(0.0117, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-3.8773e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.075496
Average KL loss: 0.156855
Average total loss: 0.232351
tensor(0.0117, device='cuda:0') tensor(0.0657, device='cuda:0') tensor(-9.0223e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.072625
Average KL loss: 0.156892
Average total loss: 0.229517
tensor(0.0117, device='cuda:0') tensor(0.0659, device='cuda:0') tensor(-1.6839e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.067730
Average KL loss: 0.156930
Average total loss: 0.224660
tensor(0.0117, device='cuda:0') tensor(0.0661, device='cuda:0') tensor(-5.3142e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.067427
Average KL loss: 0.156963
Average total loss: 0.224390
tensor(0.0117, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-2.5401e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.067098
Average KL loss: 0.156992
Average total loss: 0.224091
tensor(0.0118, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-3.2849e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.058340
Average KL loss: 0.157019
Average total loss: 0.215359
 Percentile value: 6.88291301727295
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =     678 /    1728             ( 39.24%) | total_pruned =    1050 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     309 /   36864             (  0.84%) | total_pruned =   36555 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     301 /   36864             (  0.82%) | total_pruned =   36563 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     281 /   36864             (  0.76%) | total_pruned =   36583 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     263 /   36864             (  0.71%) | total_pruned =   36601 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     315 /   73728             (  0.43%) | total_pruned =   73413 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     304 /  147456             (  0.21%) | total_pruned =  147152 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     325 /    8192             (  3.97%) | total_pruned =    7867 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     224 /  147456             (  0.15%) | total_pruned =  147232 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     184 /  147456             (  0.12%) | total_pruned =  147272 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     344 /  294912             (  0.12%) | total_pruned =  294568 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      57 /     256             ( 22.27%) | total_pruned =     199 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     306 /  589824             (  0.05%) | total_pruned =  589518 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     201 /   32768             (  0.61%) | total_pruned =   32567 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     163 /  589824             (  0.03%) | total_pruned =  589661 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     133 /     256             ( 51.95%) | total_pruned =     123 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     163 /  589824             (  0.03%) | total_pruned =  589661 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     180 /     256             ( 70.31%) | total_pruned =      76 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     241 / 1179648             (  0.02%) | total_pruned = 1179407 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     166 / 2359296             (  0.01%) | total_pruned = 2359130 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     232 /     512             ( 45.31%) | total_pruned =     280 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      62 /  131072             (  0.05%) | total_pruned =  131010 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     127 /     512             ( 24.80%) | total_pruned =     385 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      82 / 2359296             (  0.00%) | total_pruned = 2359214 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      10 / 2359296             (  0.00%) | total_pruned = 2359286 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      85 /     512             ( 16.60%) | total_pruned =     427 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     308 /    5120             (  6.02%) | total_pruned =    4812 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 199/200 Loss: 0.870366 Accuracy: 63.72 69.59 % Best test Accuracy: 64.16%
