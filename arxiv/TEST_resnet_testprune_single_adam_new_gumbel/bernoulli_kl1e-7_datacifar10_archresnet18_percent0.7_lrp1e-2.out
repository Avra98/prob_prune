Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1415e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.772276
Average KL loss: 0.000356
Average total loss: 1.772632
tensor(0.0010, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.1419e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.463522
Average KL loss: 0.001150
Average total loss: 1.464672
tensor(0.0015, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.5731e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.255921
Average KL loss: 0.001837
Average total loss: 1.257758
tensor(0.0017, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.5558e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.120438
Average KL loss: 0.002382
Average total loss: 1.122820
tensor(0.0019, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-1.1704e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.031083
Average KL loss: 0.002875
Average total loss: 1.033959
tensor(0.0021, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-8.9093e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.948574
Average KL loss: 0.003322
Average total loss: 0.951897
tensor(0.0022, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-9.7989e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.880998
Average KL loss: 0.003732
Average total loss: 0.884730
tensor(0.0024, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.0773e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.824969
Average KL loss: 0.004137
Average total loss: 0.829106
tensor(0.0026, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-8.2846e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.752437
Average KL loss: 0.004531
Average total loss: 0.756968
tensor(0.0028, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-8.9238e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.722602
Average KL loss: 0.004890
Average total loss: 0.727492
tensor(0.0030, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-7.1781e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.686106
Average KL loss: 0.005235
Average total loss: 0.691341
tensor(0.0033, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-7.0106e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.644879
Average KL loss: 0.005584
Average total loss: 0.650463
tensor(0.0035, device='cuda:0') tensor(0.0419, device='cuda:0') tensor(-8.0843e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.601318
Average KL loss: 0.005929
Average total loss: 0.607247
tensor(0.0038, device='cuda:0') tensor(0.0445, device='cuda:0') tensor(-6.8084e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.587990
Average KL loss: 0.006269
Average total loss: 0.594259
tensor(0.0041, device='cuda:0') tensor(0.0470, device='cuda:0') tensor(-6.9214e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.555146
Average KL loss: 0.006597
Average total loss: 0.561743
tensor(0.0044, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-4.2937e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.518805
Average KL loss: 0.006918
Average total loss: 0.525723
tensor(0.0046, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-5.7146e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.483653
Average KL loss: 0.007204
Average total loss: 0.490857
tensor(0.0049, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(-5.9749e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.474276
Average KL loss: 0.007483
Average total loss: 0.481759
tensor(0.0053, device='cuda:0') tensor(0.0559, device='cuda:0') tensor(-6.0421e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.451527
Average KL loss: 0.007774
Average total loss: 0.459301
tensor(0.0056, device='cuda:0') tensor(0.0581, device='cuda:0') tensor(-6.2682e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.434918
Average KL loss: 0.008072
Average total loss: 0.442990
tensor(0.0059, device='cuda:0') tensor(0.0604, device='cuda:0') tensor(-4.9027e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.409119
Average KL loss: 0.008367
Average total loss: 0.417487
tensor(0.0062, device='cuda:0') tensor(0.0626, device='cuda:0') tensor(-6.1462e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.389252
Average KL loss: 0.008654
Average total loss: 0.397907
tensor(0.0066, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-6.4722e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.373795
Average KL loss: 0.008926
Average total loss: 0.382721
tensor(0.0069, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-4.2726e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.355166
Average KL loss: 0.009197
Average total loss: 0.364363
tensor(0.0072, device='cuda:0') tensor(0.0689, device='cuda:0') tensor(-4.4138e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.339775
Average KL loss: 0.009470
Average total loss: 0.349245
tensor(0.0076, device='cuda:0') tensor(0.0710, device='cuda:0') tensor(-3.8973e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.320730
Average KL loss: 0.009736
Average total loss: 0.330466
tensor(0.0079, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(-4.7181e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.311737
Average KL loss: 0.009999
Average total loss: 0.321736
tensor(0.0082, device='cuda:0') tensor(0.0750, device='cuda:0') tensor(-4.3551e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.294213
Average KL loss: 0.010270
Average total loss: 0.304483
tensor(0.0085, device='cuda:0') tensor(0.0771, device='cuda:0') tensor(-3.7726e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.285213
Average KL loss: 0.010543
Average total loss: 0.295756
tensor(0.0089, device='cuda:0') tensor(0.0791, device='cuda:0') tensor(-3.9775e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.269602
Average KL loss: 0.010797
Average total loss: 0.280399
tensor(0.0091, device='cuda:0') tensor(0.0810, device='cuda:0') tensor(-3.9722e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.267391
Average KL loss: 0.011044
Average total loss: 0.278435
tensor(0.0095, device='cuda:0') tensor(0.0830, device='cuda:0') tensor(-4.1739e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.247619
Average KL loss: 0.011300
Average total loss: 0.258919
tensor(0.0098, device='cuda:0') tensor(0.0849, device='cuda:0') tensor(-3.4458e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.231020
Average KL loss: 0.011538
Average total loss: 0.242558
tensor(0.0101, device='cuda:0') tensor(0.0868, device='cuda:0') tensor(-3.2087e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.226302
Average KL loss: 0.011778
Average total loss: 0.238080
tensor(0.0104, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(-3.2991e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.222588
Average KL loss: 0.012025
Average total loss: 0.234613
tensor(0.0107, device='cuda:0') tensor(0.0907, device='cuda:0') tensor(-2.2769e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.206312
Average KL loss: 0.012268
Average total loss: 0.218580
tensor(0.0110, device='cuda:0') tensor(0.0925, device='cuda:0') tensor(-4.3241e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.203412
Average KL loss: 0.012518
Average total loss: 0.215930
tensor(0.0113, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(-3.4407e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.193915
Average KL loss: 0.012771
Average total loss: 0.206685
tensor(0.0115, device='cuda:0') tensor(0.0965, device='cuda:0') tensor(-2.8911e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.184045
Average KL loss: 0.013014
Average total loss: 0.197059
tensor(0.0118, device='cuda:0') tensor(0.0983, device='cuda:0') tensor(-2.9057e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.170011
Average KL loss: 0.013237
Average total loss: 0.183248
tensor(0.0121, device='cuda:0') tensor(0.1000, device='cuda:0') tensor(-1.9265e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.165569
Average KL loss: 0.013435
Average total loss: 0.179004
tensor(0.0124, device='cuda:0') tensor(0.1016, device='cuda:0') tensor(-2.5582e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.158071
Average KL loss: 0.013648
Average total loss: 0.171719
tensor(0.0127, device='cuda:0') tensor(0.1033, device='cuda:0') tensor(-2.7154e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.148123
Average KL loss: 0.013859
Average total loss: 0.161982
tensor(0.0129, device='cuda:0') tensor(0.1050, device='cuda:0') tensor(-2.3907e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.153714
Average KL loss: 0.014073
Average total loss: 0.167787
tensor(0.0132, device='cuda:0') tensor(0.1068, device='cuda:0') tensor(-2.3461e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.141168
Average KL loss: 0.014294
Average total loss: 0.155462
tensor(0.0134, device='cuda:0') tensor(0.1085, device='cuda:0') tensor(-2.2682e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.130537
Average KL loss: 0.014489
Average total loss: 0.145026
tensor(0.0137, device='cuda:0') tensor(0.1100, device='cuda:0') tensor(-2.6607e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.133337
Average KL loss: 0.014681
Average total loss: 0.148018
tensor(0.0139, device='cuda:0') tensor(0.1116, device='cuda:0') tensor(-1.7594e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.120319
Average KL loss: 0.014876
Average total loss: 0.135195
tensor(0.0142, device='cuda:0') tensor(0.1131, device='cuda:0') tensor(-2.1491e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.109568
Average KL loss: 0.015059
Average total loss: 0.124627
tensor(0.0144, device='cuda:0') tensor(0.1145, device='cuda:0') tensor(-2.1524e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.112471
Average KL loss: 0.015225
Average total loss: 0.127696
tensor(0.0146, device='cuda:0') tensor(0.1160, device='cuda:0') tensor(-2.9074e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.105848
Average KL loss: 0.015403
Average total loss: 0.121251
tensor(0.0149, device='cuda:0') tensor(0.1173, device='cuda:0') tensor(-2.7277e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.101227
Average KL loss: 0.015569
Average total loss: 0.116796
tensor(0.0151, device='cuda:0') tensor(0.1187, device='cuda:0') tensor(-1.7406e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.096511
Average KL loss: 0.015733
Average total loss: 0.112244
tensor(0.0153, device='cuda:0') tensor(0.1199, device='cuda:0') tensor(-2.4398e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.094298
Average KL loss: 0.015877
Average total loss: 0.110175
tensor(0.0155, device='cuda:0') tensor(0.1212, device='cuda:0') tensor(-1.5478e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.089703
Average KL loss: 0.016028
Average total loss: 0.105731
tensor(0.0157, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-1.9736e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.085705
Average KL loss: 0.016168
Average total loss: 0.101873
tensor(0.0159, device='cuda:0') tensor(0.1235, device='cuda:0') tensor(-1.9189e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.081335
Average KL loss: 0.016288
Average total loss: 0.097623
tensor(0.0161, device='cuda:0') tensor(0.1245, device='cuda:0') tensor(-1.3947e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.081342
Average KL loss: 0.016421
Average total loss: 0.097763
tensor(0.0163, device='cuda:0') tensor(0.1257, device='cuda:0') tensor(-2.2314e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.076687
Average KL loss: 0.016555
Average total loss: 0.093242
tensor(0.0165, device='cuda:0') tensor(0.1268, device='cuda:0') tensor(-1.7791e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.072433
Average KL loss: 0.016680
Average total loss: 0.089114
tensor(0.0167, device='cuda:0') tensor(0.1278, device='cuda:0') tensor(-1.7208e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.066922
Average KL loss: 0.016791
Average total loss: 0.083713
tensor(0.0169, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-1.2711e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.066362
Average KL loss: 0.016888
Average total loss: 0.083250
tensor(0.0171, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-1.2587e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.066575
Average KL loss: 0.017006
Average total loss: 0.083581
tensor(0.0172, device='cuda:0') tensor(0.1306, device='cuda:0') tensor(-1.6619e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.060161
Average KL loss: 0.017114
Average total loss: 0.077276
tensor(0.0174, device='cuda:0') tensor(0.1315, device='cuda:0') tensor(-9.4759e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.057103
Average KL loss: 0.017207
Average total loss: 0.074310
tensor(0.0176, device='cuda:0') tensor(0.1322, device='cuda:0') tensor(-1.6048e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.060216
Average KL loss: 0.017293
Average total loss: 0.077509
tensor(0.0177, device='cuda:0') tensor(0.1331, device='cuda:0') tensor(-1.4179e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.053581
Average KL loss: 0.017389
Average total loss: 0.070970
tensor(0.0179, device='cuda:0') tensor(0.1338, device='cuda:0') tensor(-1.4147e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.054273
Average KL loss: 0.017472
Average total loss: 0.071744
tensor(0.0180, device='cuda:0') tensor(0.1345, device='cuda:0') tensor(-1.0840e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.053643
Average KL loss: 0.017555
Average total loss: 0.071198
tensor(0.0181, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-2.0212e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.050553
Average KL loss: 0.017646
Average total loss: 0.068199
tensor(0.0183, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-9.7244e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.047103
Average KL loss: 0.017726
Average total loss: 0.064829
tensor(0.0184, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-1.1702e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.045994
Average KL loss: 0.017786
Average total loss: 0.063780
tensor(0.0186, device='cuda:0') tensor(0.1373, device='cuda:0') tensor(-1.1863e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.043395
Average KL loss: 0.017839
Average total loss: 0.061233
tensor(0.0187, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(-9.1453e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.043148
Average KL loss: 0.017901
Average total loss: 0.061049
tensor(0.0189, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(-1.1359e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.038987
Average KL loss: 0.017950
Average total loss: 0.056937
tensor(0.0190, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(-5.2917e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.041959
Average KL loss: 0.017989
Average total loss: 0.059949
tensor(0.0192, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-1.7559e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.038331
Average KL loss: 0.018058
Average total loss: 0.056390
tensor(0.0193, device='cuda:0') tensor(0.1399, device='cuda:0') tensor(-9.0064e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.039121
Average KL loss: 0.018109
Average total loss: 0.057229
tensor(0.0194, device='cuda:0') tensor(0.1403, device='cuda:0') tensor(-6.2986e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.036278
Average KL loss: 0.018161
Average total loss: 0.054440
tensor(0.0195, device='cuda:0') tensor(0.1409, device='cuda:0') tensor(-5.8388e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.033559
Average KL loss: 0.018203
Average total loss: 0.051762
tensor(0.0197, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(-1.1183e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.030995
Average KL loss: 0.018222
Average total loss: 0.049217
tensor(0.0198, device='cuda:0') tensor(0.1413, device='cuda:0') tensor(-4.8620e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.032327
Average KL loss: 0.018235
Average total loss: 0.050562
tensor(0.0199, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(-6.0653e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.029123
Average KL loss: 0.018245
Average total loss: 0.047367
tensor(0.0200, device='cuda:0') tensor(0.1417, device='cuda:0') tensor(-1.2417e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.029641
Average KL loss: 0.018261
Average total loss: 0.047903
tensor(0.0201, device='cuda:0') tensor(0.1419, device='cuda:0') tensor(-6.0541e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.030569
Average KL loss: 0.018281
Average total loss: 0.048850
tensor(0.0202, device='cuda:0') tensor(0.1423, device='cuda:0') tensor(-6.5181e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.028573
Average KL loss: 0.018318
Average total loss: 0.046891
tensor(0.0203, device='cuda:0') tensor(0.1426, device='cuda:0') tensor(-4.8195e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.028535
Average KL loss: 0.018348
Average total loss: 0.046883
tensor(0.0204, device='cuda:0') tensor(0.1429, device='cuda:0') tensor(-7.1490e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.025244
Average KL loss: 0.018359
Average total loss: 0.043602
tensor(0.0204, device='cuda:0') tensor(0.1430, device='cuda:0') tensor(-6.1071e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.024961
Average KL loss: 0.018351
Average total loss: 0.043312
tensor(0.0205, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-1.1524e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.025465
Average KL loss: 0.018363
Average total loss: 0.043828
tensor(0.0206, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-5.4179e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.023452
Average KL loss: 0.018381
Average total loss: 0.041833
tensor(0.0207, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(-5.1764e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.022777
Average KL loss: 0.018377
Average total loss: 0.041154
tensor(0.0209, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(-6.0092e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.021761
Average KL loss: 0.018358
Average total loss: 0.040119
tensor(0.0209, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(-4.1706e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.019715
Average KL loss: 0.018349
Average total loss: 0.038063
tensor(0.0210, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-8.3223e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.021746
Average KL loss: 0.018332
Average total loss: 0.040078
tensor(0.0211, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(-3.2636e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.020635
Average KL loss: 0.018327
Average total loss: 0.038961
tensor(0.0212, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-9.9498e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.019502
Average KL loss: 0.018308
Average total loss: 0.037810
tensor(0.0213, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-4.1076e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.018832
Average KL loss: 0.018287
Average total loss: 0.037118
tensor(0.0213, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-8.0032e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.018618
Average KL loss: 0.018270
Average total loss: 0.036888
tensor(0.0214, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-5.3115e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.017998
Average KL loss: 0.018253
Average total loss: 0.036251
tensor(0.0215, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-6.8443e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.017602
Average KL loss: 0.018239
Average total loss: 0.035841
tensor(0.0215, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-2.2601e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.017548
Average KL loss: 0.018224
Average total loss: 0.035772
tensor(0.0216, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-4.4996e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.016346
Average KL loss: 0.018215
Average total loss: 0.034561
tensor(0.0216, device='cuda:0') tensor(0.1429, device='cuda:0') tensor(-4.6669e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.016204
Average KL loss: 0.018176
Average total loss: 0.034380
tensor(0.0217, device='cuda:0') tensor(0.1427, device='cuda:0') tensor(-4.2176e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.014439
Average KL loss: 0.018131
Average total loss: 0.032570
tensor(0.0218, device='cuda:0') tensor(0.1424, device='cuda:0') tensor(-5.4449e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.014308
Average KL loss: 0.018090
Average total loss: 0.032398
tensor(0.0218, device='cuda:0') tensor(0.1422, device='cuda:0') tensor(-3.4717e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.014001
Average KL loss: 0.018049
Average total loss: 0.032050
tensor(0.0218, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(-3.0948e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.014308
Average KL loss: 0.018010
Average total loss: 0.032318
tensor(0.0219, device='cuda:0') tensor(0.1417, device='cuda:0') tensor(-4.8688e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.013599
Average KL loss: 0.017970
Average total loss: 0.031570
tensor(0.0220, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-4.2018e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.014289
Average KL loss: 0.017929
Average total loss: 0.032218
tensor(0.0220, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(-3.9645e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.014805
Average KL loss: 0.017921
Average total loss: 0.032725
tensor(0.0221, device='cuda:0') tensor(0.1413, device='cuda:0') tensor(-1.7957e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.011971
Average KL loss: 0.017895
Average total loss: 0.029866
tensor(0.0221, device='cuda:0') tensor(0.1410, device='cuda:0') tensor(-4.6241e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.011564
Average KL loss: 0.017848
Average total loss: 0.029412
tensor(0.0222, device='cuda:0') tensor(0.1407, device='cuda:0') tensor(-2.0644e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.013923
Average KL loss: 0.017807
Average total loss: 0.031730
tensor(0.0222, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(-2.4900e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.012709
Average KL loss: 0.017792
Average total loss: 0.030501
tensor(0.0223, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(-2.8846e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.012119
Average KL loss: 0.017779
Average total loss: 0.029898
tensor(0.0224, device='cuda:0') tensor(0.1404, device='cuda:0') tensor(-2.3453e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.011327
Average KL loss: 0.017747
Average total loss: 0.029073
tensor(0.0224, device='cuda:0') tensor(0.1402, device='cuda:0') tensor(-3.9371e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.011970
Average KL loss: 0.017713
Average total loss: 0.029682
tensor(0.0224, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-1.7185e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.010931
Average KL loss: 0.017675
Average total loss: 0.028607
tensor(0.0225, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(-3.3346e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.010310
Average KL loss: 0.017619
Average total loss: 0.027930
tensor(0.0226, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-1.6086e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.009327
Average KL loss: 0.017555
Average total loss: 0.026882
tensor(0.0226, device='cuda:0') tensor(0.1389, device='cuda:0') tensor(-3.1941e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.010963
Average KL loss: 0.017490
Average total loss: 0.028453
tensor(0.0226, device='cuda:0') tensor(0.1386, device='cuda:0') tensor(-5.4919e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.010126
Average KL loss: 0.017466
Average total loss: 0.027592
tensor(0.0227, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(-4.3253e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.009818
Average KL loss: 0.017427
Average total loss: 0.027245
tensor(0.0227, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(-1.4831e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.009306
Average KL loss: 0.017373
Average total loss: 0.026679
tensor(0.0228, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(-1.4488e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.010207
Average KL loss: 0.017332
Average total loss: 0.027539
tensor(0.0228, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(-2.7108e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.009196
Average KL loss: 0.017319
Average total loss: 0.026516
tensor(0.0229, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-3.2543e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.009993
Average KL loss: 0.017289
Average total loss: 0.027282
tensor(0.0229, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(-1.7570e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.008523
Average KL loss: 0.017253
Average total loss: 0.025776
tensor(0.0229, device='cuda:0') tensor(0.1371, device='cuda:0') tensor(-6.6495e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.008428
Average KL loss: 0.017201
Average total loss: 0.025628
tensor(0.0229, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-2.0162e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.009120
Average KL loss: 0.017154
Average total loss: 0.026274
tensor(0.0230, device='cuda:0') tensor(0.1365, device='cuda:0') tensor(-2.0188e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.008563
Average KL loss: 0.017126
Average total loss: 0.025688
tensor(0.0230, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(-1.5243e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.007904
Average KL loss: 0.017093
Average total loss: 0.024997
tensor(0.0230, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(-4.4238e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.008013
Average KL loss: 0.017045
Average total loss: 0.025058
tensor(0.0231, device='cuda:0') tensor(0.1357, device='cuda:0') tensor(-2.2378e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.008068
Average KL loss: 0.016987
Average total loss: 0.025055
tensor(0.0231, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-1.2147e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.008410
Average KL loss: 0.016955
Average total loss: 0.025364
tensor(0.0232, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-1.6369e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.007077
Average KL loss: 0.016934
Average total loss: 0.024011
tensor(0.0232, device='cuda:0') tensor(0.1351, device='cuda:0') tensor(-1.1565e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.008142
Average KL loss: 0.016881
Average total loss: 0.025023
tensor(0.0232, device='cuda:0') tensor(0.1349, device='cuda:0') tensor(-1.5736e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.007218
Average KL loss: 0.016852
Average total loss: 0.024070
tensor(0.0232, device='cuda:0') tensor(0.1345, device='cuda:0') tensor(-3.5369e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.008229
Average KL loss: 0.016824
Average total loss: 0.025053
tensor(0.0232, device='cuda:0') tensor(0.1346, device='cuda:0') tensor(-1.6977e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.006633
Average KL loss: 0.016807
Average total loss: 0.023440
tensor(0.0232, device='cuda:0') tensor(0.1343, device='cuda:0') tensor(-1.5497e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.007459
Average KL loss: 0.016752
Average total loss: 0.024211
tensor(0.0233, device='cuda:0') tensor(0.1340, device='cuda:0') tensor(-1.2832e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.006236
Average KL loss: 0.016715
Average total loss: 0.022951
tensor(0.0233, device='cuda:0') tensor(0.1336, device='cuda:0') tensor(-1.0536e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.006231
Average KL loss: 0.016637
Average total loss: 0.022867
tensor(0.0233, device='cuda:0') tensor(0.1331, device='cuda:0') tensor(-7.9213e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.006687
Average KL loss: 0.016569
Average total loss: 0.023256
tensor(0.0233, device='cuda:0') tensor(0.1328, device='cuda:0') tensor(-1.6831e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.006086
Average KL loss: 0.016528
Average total loss: 0.022614
tensor(0.0234, device='cuda:0') tensor(0.1324, device='cuda:0') tensor(-2.2757e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.005448
Average KL loss: 0.016455
Average total loss: 0.021903
tensor(0.0233, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-5.3860e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.005987
Average KL loss: 0.016373
Average total loss: 0.022360
tensor(0.0233, device='cuda:0') tensor(0.1313, device='cuda:0') tensor(-1.7760e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.006187
Average KL loss: 0.016334
Average total loss: 0.022521
tensor(0.0234, device='cuda:0') tensor(0.1311, device='cuda:0') tensor(-1.6531e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.006031
Average KL loss: 0.016296
Average total loss: 0.022327
tensor(0.0234, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-1.7139e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.006274
Average KL loss: 0.016238
Average total loss: 0.022511
tensor(0.0234, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-1.8751e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.006072
Average KL loss: 0.016216
Average total loss: 0.022288
tensor(0.0234, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-9.3591e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.005624
Average KL loss: 0.016182
Average total loss: 0.021806
tensor(0.0234, device='cuda:0') tensor(0.1301, device='cuda:0') tensor(-3.5059e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.005582
Average KL loss: 0.016136
Average total loss: 0.021719
tensor(0.0234, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.2491e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.005329
Average KL loss: 0.016088
Average total loss: 0.021417
tensor(0.0234, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-7.6690e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.004494
Average KL loss: 0.016037
Average total loss: 0.020530
tensor(0.0234, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-4.0351e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.005150
Average KL loss: 0.015928
Average total loss: 0.021078
tensor(0.0234, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-1.6587e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.005222
Average KL loss: 0.015864
Average total loss: 0.021086
tensor(0.0234, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-1.9090e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.005409
Average KL loss: 0.015830
Average total loss: 0.021238
tensor(0.0235, device='cuda:0') tensor(0.1276, device='cuda:0') tensor(-2.2130e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.004844
Average KL loss: 0.015789
Average total loss: 0.020633
tensor(0.0235, device='cuda:0') tensor(0.1273, device='cuda:0') tensor(-7.4611e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.004411
Average KL loss: 0.015725
Average total loss: 0.020136
tensor(0.0234, device='cuda:0') tensor(0.1268, device='cuda:0') tensor(-8.9484e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.005245
Average KL loss: 0.015663
Average total loss: 0.020908
tensor(0.0235, device='cuda:0') tensor(0.1266, device='cuda:0') tensor(-4.6199e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.005669
Average KL loss: 0.015648
Average total loss: 0.021317
tensor(0.0235, device='cuda:0') tensor(0.1266, device='cuda:0') tensor(-2.2049e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.004175
Average KL loss: 0.015632
Average total loss: 0.019807
tensor(0.0235, device='cuda:0') tensor(0.1262, device='cuda:0') tensor(-1.5628e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.005252
Average KL loss: 0.015578
Average total loss: 0.020830
tensor(0.0236, device='cuda:0') tensor(0.1261, device='cuda:0') tensor(-5.3958e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.004782
Average KL loss: 0.015576
Average total loss: 0.020359
tensor(0.0235, device='cuda:0') tensor(0.1260, device='cuda:0') tensor(-4.6031e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.004794
Average KL loss: 0.015525
Average total loss: 0.020319
tensor(0.0236, device='cuda:0') tensor(0.1257, device='cuda:0') tensor(-2.0749e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.004371
Average KL loss: 0.015495
Average total loss: 0.019866
tensor(0.0235, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-3.9158e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.004669
Average KL loss: 0.015435
Average total loss: 0.020104
tensor(0.0235, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-4.3850e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.004189
Average KL loss: 0.015400
Average total loss: 0.019589
tensor(0.0236, device='cuda:0') tensor(0.1248, device='cuda:0') tensor(-8.4563e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.004241
Average KL loss: 0.015346
Average total loss: 0.019587
tensor(0.0235, device='cuda:0') tensor(0.1245, device='cuda:0') tensor(-4.3425e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.003804
Average KL loss: 0.015300
Average total loss: 0.019104
tensor(0.0235, device='cuda:0') tensor(0.1240, device='cuda:0') tensor(-8.8513e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.004672
Average KL loss: 0.015218
Average total loss: 0.019890
tensor(0.0235, device='cuda:0') tensor(0.1236, device='cuda:0') tensor(-1.8295e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.003807
Average KL loss: 0.015199
Average total loss: 0.019006
tensor(0.0235, device='cuda:0') tensor(0.1233, device='cuda:0') tensor(-1.1742e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.004283
Average KL loss: 0.015148
Average total loss: 0.019431
tensor(0.0235, device='cuda:0') tensor(0.1231, device='cuda:0') tensor(-4.8128e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.003769
Average KL loss: 0.015107
Average total loss: 0.018877
tensor(0.0234, device='cuda:0') tensor(0.1227, device='cuda:0') tensor(-2.2965e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.003845
Average KL loss: 0.015044
Average total loss: 0.018888
tensor(0.0235, device='cuda:0') tensor(0.1222, device='cuda:0') tensor(-1.4924e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.004003
Average KL loss: 0.014981
Average total loss: 0.018983
tensor(0.0235, device='cuda:0') tensor(0.1220, device='cuda:0') tensor(-2.1584e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.003752
Average KL loss: 0.014939
Average total loss: 0.018692
tensor(0.0235, device='cuda:0') tensor(0.1216, device='cuda:0') tensor(-1.5079e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.004148
Average KL loss: 0.014900
Average total loss: 0.019048
tensor(0.0235, device='cuda:0') tensor(0.1215, device='cuda:0') tensor(-5.1849e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.003962
Average KL loss: 0.014873
Average total loss: 0.018835
tensor(0.0235, device='cuda:0') tensor(0.1213, device='cuda:0') tensor(-9.4392e-11, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.003796
Average KL loss: 0.014849
Average total loss: 0.018646
tensor(0.0235, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-1.3305e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.003856
Average KL loss: 0.014813
Average total loss: 0.018669
tensor(0.0235, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-1.5353e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.003571
Average KL loss: 0.014771
Average total loss: 0.018342
tensor(0.0234, device='cuda:0') tensor(0.1204, device='cuda:0') tensor(-9.8528e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.003782
Average KL loss: 0.014735
Average total loss: 0.018517
tensor(0.0235, device='cuda:0') tensor(0.1204, device='cuda:0') tensor(-1.2648e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.003292
Average KL loss: 0.014692
Average total loss: 0.017984
tensor(0.0235, device='cuda:0') tensor(0.1198, device='cuda:0') tensor(-1.9916e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.003331
Average KL loss: 0.014606
Average total loss: 0.017937
tensor(0.0234, device='cuda:0') tensor(0.1193, device='cuda:0') tensor(-1.2097e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.003163
Average KL loss: 0.014553
Average total loss: 0.017716
tensor(0.0234, device='cuda:0') tensor(0.1190, device='cuda:0') tensor(-4.4353e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.002890
Average KL loss: 0.014503
Average total loss: 0.017394
tensor(0.0234, device='cuda:0') tensor(0.1185, device='cuda:0') tensor(-1.3738e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.003381
Average KL loss: 0.014418
Average total loss: 0.017799
tensor(0.0234, device='cuda:0') tensor(0.1180, device='cuda:0') tensor(-2.6186e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.003213
Average KL loss: 0.014371
Average total loss: 0.017584
tensor(0.0234, device='cuda:0') tensor(0.1175, device='cuda:0') tensor(2.9649e-11, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.003023
Average KL loss: 0.014303
Average total loss: 0.017326
tensor(0.0234, device='cuda:0') tensor(0.1172, device='cuda:0') tensor(-2.7978e-11, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.002976
Average KL loss: 0.014256
Average total loss: 0.017232
tensor(0.0234, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-1.8680e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.003273
Average KL loss: 0.014202
Average total loss: 0.017475
tensor(0.0234, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(-2.6047e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.003215
Average KL loss: 0.014151
Average total loss: 0.017366
tensor(0.0234, device='cuda:0') tensor(0.1162, device='cuda:0') tensor(-1.0134e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.003579
Average KL loss: 0.014152
Average total loss: 0.017731
tensor(0.0234, device='cuda:0') tensor(0.1165, device='cuda:0') tensor(-3.1643e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.002950
Average KL loss: 0.014125
Average total loss: 0.017075
tensor(0.0234, device='cuda:0') tensor(0.1159, device='cuda:0') tensor(-2.5530e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.003506
Average KL loss: 0.014117
Average total loss: 0.017623
tensor(0.0234, device='cuda:0') tensor(0.1164, device='cuda:0') tensor(7.2290e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.003177
Average KL loss: 0.014164
Average total loss: 0.017342
tensor(0.0234, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(1.9591e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.002763
Average KL loss: 0.014123
Average total loss: 0.016887
 Percentile value: 0.3789695143699642
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1276 /    1728             ( 73.84%) | total_pruned =     452 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   18551 /   36864             ( 50.32%) | total_pruned =   18313 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   19071 /   36864             ( 51.73%) | total_pruned =   17793 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   18801 /   36864             ( 51.00%) | total_pruned =   18063 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18629 /   36864             ( 50.53%) | total_pruned =   18235 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   36838 /   73728             ( 49.96%) | total_pruned =   36890 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   71164 /  147456             ( 48.26%) | total_pruned =   76292 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5363 /    8192             ( 65.47%) | total_pruned =    2829 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   65589 /  147456             ( 44.48%) | total_pruned =   81867 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   65496 /  147456             ( 44.42%) | total_pruned =   81960 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  141122 /  294912             ( 47.85%) | total_pruned =  153790 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  270987 /  589824             ( 45.94%) | total_pruned =  318837 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19815 /   32768             ( 60.47%) | total_pruned =   12953 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  227752 /  589824             ( 38.61%) | total_pruned =  362072 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  224449 /  589824             ( 38.05%) | total_pruned =  365375 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  510090 / 1179648             ( 43.24%) | total_pruned =  669558 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     492 /     512             ( 96.09%) | total_pruned =      20 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  794184 / 2359296             ( 33.66%) | total_pruned = 1565112 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   62859 /  131072             ( 47.96%) | total_pruned =   68213 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     404 /     512             ( 78.91%) | total_pruned =     108 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  498323 / 2359296             ( 21.12%) | total_pruned = 1860973 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     465 /     512             ( 90.82%) | total_pruned =      47 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  270579 / 2359296             ( 11.47%) | total_pruned = 2088717 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
linear.weight        | nonzeros =    4535 /    5120             ( 88.57%) | total_pruned =     585 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 39/200 Loss: 0.000062 Accuracy: 86.71 100.00 % Best test Accuracy: 86.79%
tensor(0.0234, device='cuda:0') tensor(0.1160, device='cuda:0') tensor(-1.1678e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.036417
Average KL loss: 0.012110
Average total loss: 0.048527
tensor(0.0607, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-5.3710e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.029184
Average KL loss: 0.009968
Average total loss: 0.039152
tensor(0.0815, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(-2.9934e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.024689
Average KL loss: 0.009204
Average total loss: 0.033893
tensor(0.0913, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-2.9625e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.020701
Average KL loss: 0.008971
Average total loss: 0.029672
tensor(0.0958, device='cuda:0') tensor(0.0670, device='cuda:0') tensor(-5.3939e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.020933
Average KL loss: 0.008947
Average total loss: 0.029880
tensor(0.0979, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-4.8190e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.018611
Average KL loss: 0.008999
Average total loss: 0.027610
tensor(0.0986, device='cuda:0') tensor(0.0675, device='cuda:0') tensor(-4.8487e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.016996
Average KL loss: 0.009074
Average total loss: 0.026070
tensor(0.0988, device='cuda:0') tensor(0.0682, device='cuda:0') tensor(-3.7188e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.015889
Average KL loss: 0.009161
Average total loss: 0.025050
tensor(0.0988, device='cuda:0') tensor(0.0690, device='cuda:0') tensor(1.7683e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.014060
Average KL loss: 0.009241
Average total loss: 0.023301
tensor(0.0985, device='cuda:0') tensor(0.0698, device='cuda:0') tensor(-1.1111e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.012774
Average KL loss: 0.009312
Average total loss: 0.022086
tensor(0.0982, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-2.4750e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.012169
Average KL loss: 0.009376
Average total loss: 0.021545
tensor(0.0978, device='cuda:0') tensor(0.0711, device='cuda:0') tensor(-2.0163e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.011046
Average KL loss: 0.009439
Average total loss: 0.020485
tensor(0.0974, device='cuda:0') tensor(0.0718, device='cuda:0') tensor(-1.9679e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.011458
Average KL loss: 0.009504
Average total loss: 0.020962
tensor(0.0971, device='cuda:0') tensor(0.0724, device='cuda:0') tensor(-2.3749e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.010940
Average KL loss: 0.009563
Average total loss: 0.020503
tensor(0.0967, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(-6.2963e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.010017
Average KL loss: 0.009622
Average total loss: 0.019639
tensor(0.0963, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(-9.3376e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.009377
Average KL loss: 0.009680
Average total loss: 0.019057
tensor(0.0959, device='cuda:0') tensor(0.0743, device='cuda:0') tensor(-1.1693e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.009349
Average KL loss: 0.009725
Average total loss: 0.019074
tensor(0.0955, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(-1.6369e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.008933
Average KL loss: 0.009773
Average total loss: 0.018706
tensor(0.0951, device='cuda:0') tensor(0.0753, device='cuda:0') tensor(-7.5575e-11, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.008871
Average KL loss: 0.009823
Average total loss: 0.018695
tensor(0.0948, device='cuda:0') tensor(0.0759, device='cuda:0') tensor(-2.2365e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.008439
Average KL loss: 0.009872
Average total loss: 0.018311
tensor(0.0944, device='cuda:0') tensor(0.0765, device='cuda:0') tensor(-1.3779e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.007732
Average KL loss: 0.009922
Average total loss: 0.017654
tensor(0.0940, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(8.9005e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.006839
Average KL loss: 0.009955
Average total loss: 0.016794
tensor(0.0936, device='cuda:0') tensor(0.0773, device='cuda:0') tensor(-1.7326e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.007203
Average KL loss: 0.009980
Average total loss: 0.017183
tensor(0.0932, device='cuda:0') tensor(0.0777, device='cuda:0') tensor(2.5850e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.007120
Average KL loss: 0.010015
Average total loss: 0.017135
tensor(0.0928, device='cuda:0') tensor(0.0782, device='cuda:0') tensor(-7.2009e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.007489
Average KL loss: 0.010055
Average total loss: 0.017544
tensor(0.0925, device='cuda:0') tensor(0.0787, device='cuda:0') tensor(7.8838e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.006404
Average KL loss: 0.010093
Average total loss: 0.016498
tensor(0.0921, device='cuda:0') tensor(0.0791, device='cuda:0') tensor(-2.0532e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.006057
Average KL loss: 0.010121
Average total loss: 0.016178
tensor(0.0917, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.8274e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.005989
Average KL loss: 0.010142
Average total loss: 0.016131
tensor(0.0913, device='cuda:0') tensor(0.0797, device='cuda:0') tensor(-7.1134e-11, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.005683
Average KL loss: 0.010164
Average total loss: 0.015847
tensor(0.0909, device='cuda:0') tensor(0.0800, device='cuda:0') tensor(9.9885e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.005001
Average KL loss: 0.010180
Average total loss: 0.015180
tensor(0.0905, device='cuda:0') tensor(0.0802, device='cuda:0') tensor(2.2358e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.005327
Average KL loss: 0.010191
Average total loss: 0.015518
tensor(0.0901, device='cuda:0') tensor(0.0805, device='cuda:0') tensor(-6.0404e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.005323
Average KL loss: 0.010212
Average total loss: 0.015535
tensor(0.0897, device='cuda:0') tensor(0.0808, device='cuda:0') tensor(-1.2250e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.005324
Average KL loss: 0.010229
Average total loss: 0.015552
tensor(0.0893, device='cuda:0') tensor(0.0811, device='cuda:0') tensor(-7.7418e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.004964
Average KL loss: 0.010246
Average total loss: 0.015210
tensor(0.0889, device='cuda:0') tensor(0.0813, device='cuda:0') tensor(4.7080e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.004878
Average KL loss: 0.010261
Average total loss: 0.015139
tensor(0.0886, device='cuda:0') tensor(0.0816, device='cuda:0') tensor(-4.4816e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.004585
Average KL loss: 0.010277
Average total loss: 0.014862
tensor(0.0882, device='cuda:0') tensor(0.0818, device='cuda:0') tensor(5.0939e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.004401
Average KL loss: 0.010287
Average total loss: 0.014688
tensor(0.0878, device='cuda:0') tensor(0.0821, device='cuda:0') tensor(5.9177e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.004337
Average KL loss: 0.010298
Average total loss: 0.014635
tensor(0.0874, device='cuda:0') tensor(0.0822, device='cuda:0') tensor(5.9408e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.003910
Average KL loss: 0.010301
Average total loss: 0.014211
tensor(0.0870, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(-3.4021e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.004507
Average KL loss: 0.010308
Average total loss: 0.014815
tensor(0.0867, device='cuda:0') tensor(0.0826, device='cuda:0') tensor(4.4986e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.004322
Average KL loss: 0.010324
Average total loss: 0.014647
tensor(0.0863, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(-1.5844e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.004080
Average KL loss: 0.010331
Average total loss: 0.014411
tensor(0.0859, device='cuda:0') tensor(0.0830, device='cuda:0') tensor(5.6363e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.004520
Average KL loss: 0.010342
Average total loss: 0.014862
tensor(0.0855, device='cuda:0') tensor(0.0833, device='cuda:0') tensor(-2.0494e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.003885
Average KL loss: 0.010354
Average total loss: 0.014239
tensor(0.0851, device='cuda:0') tensor(0.0835, device='cuda:0') tensor(-2.5362e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.004398
Average KL loss: 0.010366
Average total loss: 0.014764
tensor(0.0848, device='cuda:0') tensor(0.0838, device='cuda:0') tensor(-1.2313e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.003798
Average KL loss: 0.010390
Average total loss: 0.014188
tensor(0.0844, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(-9.5006e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.003513
Average KL loss: 0.010397
Average total loss: 0.013910
tensor(0.0840, device='cuda:0') tensor(0.0842, device='cuda:0') tensor(1.0582e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.003926
Average KL loss: 0.010404
Average total loss: 0.014330
tensor(0.0836, device='cuda:0') tensor(0.0844, device='cuda:0') tensor(1.4934e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.003756
Average KL loss: 0.010418
Average total loss: 0.014174
tensor(0.0833, device='cuda:0') tensor(0.0846, device='cuda:0') tensor(5.3234e-11, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.003572
Average KL loss: 0.010420
Average total loss: 0.013991
tensor(0.0829, device='cuda:0') tensor(0.0848, device='cuda:0') tensor(7.6770e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.003594
Average KL loss: 0.010421
Average total loss: 0.014015
tensor(0.0825, device='cuda:0') tensor(0.0849, device='cuda:0') tensor(1.3139e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.003315
Average KL loss: 0.010425
Average total loss: 0.013740
tensor(0.0821, device='cuda:0') tensor(0.0851, device='cuda:0') tensor(-1.5299e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.002906
Average KL loss: 0.010422
Average total loss: 0.013328
tensor(0.0818, device='cuda:0') tensor(0.0851, device='cuda:0') tensor(5.6927e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.003475
Average KL loss: 0.010420
Average total loss: 0.013896
tensor(0.0814, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(1.2496e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.003349
Average KL loss: 0.010431
Average total loss: 0.013781
tensor(0.0810, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(1.0843e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.003067
Average KL loss: 0.010430
Average total loss: 0.013497
tensor(0.0806, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(7.9023e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.003203
Average KL loss: 0.010430
Average total loss: 0.013633
tensor(0.0802, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-1.0356e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.003133
Average KL loss: 0.010433
Average total loss: 0.013566
tensor(0.0799, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(2.5274e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.002986
Average KL loss: 0.010437
Average total loss: 0.013423
tensor(0.0795, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-3.0948e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.003239
Average KL loss: 0.010440
Average total loss: 0.013679
tensor(0.0792, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(4.4530e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.002934
Average KL loss: 0.010443
Average total loss: 0.013377
tensor(0.0788, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(5.1856e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.002677
Average KL loss: 0.010442
Average total loss: 0.013119
tensor(0.0784, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(2.6874e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.002878
Average KL loss: 0.010432
Average total loss: 0.013310
tensor(0.0781, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(4.3701e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.002657
Average KL loss: 0.010427
Average total loss: 0.013084
tensor(0.0777, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(7.4311e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.002762
Average KL loss: 0.010420
Average total loss: 0.013182
tensor(0.0773, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(7.2180e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.002580
Average KL loss: 0.010413
Average total loss: 0.012992
tensor(0.0770, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(1.0221e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.002536
Average KL loss: 0.010405
Average total loss: 0.012941
tensor(0.0766, device='cuda:0') tensor(0.0866, device='cuda:0') tensor(1.1990e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.002891
Average KL loss: 0.010396
Average total loss: 0.013287
tensor(0.0763, device='cuda:0') tensor(0.0867, device='cuda:0') tensor(1.0676e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.002432
Average KL loss: 0.010405
Average total loss: 0.012836
tensor(0.0759, device='cuda:0') tensor(0.0868, device='cuda:0') tensor(1.5573e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.002772
Average KL loss: 0.010411
Average total loss: 0.013183
tensor(0.0756, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(1.2009e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.002692
Average KL loss: 0.010418
Average total loss: 0.013110
tensor(0.0752, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-1.3476e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.002705
Average KL loss: 0.010422
Average total loss: 0.013128
tensor(0.0749, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-9.7718e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.002558
Average KL loss: 0.010431
Average total loss: 0.012989
tensor(0.0745, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(4.9646e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.002290
Average KL loss: 0.010427
Average total loss: 0.012717
tensor(0.0742, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(9.5501e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.002143
Average KL loss: 0.010412
Average total loss: 0.012554
tensor(0.0738, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(8.7619e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.002475
Average KL loss: 0.010405
Average total loss: 0.012880
tensor(0.0735, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(9.4773e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.002084
Average KL loss: 0.010399
Average total loss: 0.012483
tensor(0.0731, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(9.9508e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.002348
Average KL loss: 0.010379
Average total loss: 0.012727
tensor(0.0728, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(9.8581e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.002139
Average KL loss: 0.010380
Average total loss: 0.012519
tensor(0.0724, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(3.8048e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.002301
Average KL loss: 0.010379
Average total loss: 0.012680
tensor(0.0721, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-3.0967e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.002053
Average KL loss: 0.010360
Average total loss: 0.012413
tensor(0.0717, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-2.3333e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.002509
Average KL loss: 0.010349
Average total loss: 0.012858
tensor(0.0714, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(8.8066e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.002031
Average KL loss: 0.010359
Average total loss: 0.012389
tensor(0.0711, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(1.3229e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.002248
Average KL loss: 0.010351
Average total loss: 0.012599
tensor(0.0708, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(1.4665e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.002082
Average KL loss: 0.010351
Average total loss: 0.012433
tensor(0.0704, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(1.1266e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.002156
Average KL loss: 0.010344
Average total loss: 0.012500
tensor(0.0701, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(3.8623e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.002055
Average KL loss: 0.010347
Average total loss: 0.012402
tensor(0.0698, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(3.9185e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.002222
Average KL loss: 0.010340
Average total loss: 0.012561
tensor(0.0695, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(6.3228e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.002179
Average KL loss: 0.010337
Average total loss: 0.012516
tensor(0.0691, device='cuda:0') tensor(0.0884, device='cuda:0') tensor(2.5085e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.002037
Average KL loss: 0.010348
Average total loss: 0.012385
tensor(0.0688, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(8.9573e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.001833
Average KL loss: 0.010330
Average total loss: 0.012163
tensor(0.0685, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(9.8252e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.002095
Average KL loss: 0.010315
Average total loss: 0.012411
tensor(0.0682, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-2.7284e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.002352
Average KL loss: 0.010315
Average total loss: 0.012667
tensor(0.0678, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(5.5582e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.001849
Average KL loss: 0.010323
Average total loss: 0.012173
tensor(0.0675, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(6.8436e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.001921
Average KL loss: 0.010308
Average total loss: 0.012228
tensor(0.0672, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(1.1554e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.002042
Average KL loss: 0.010301
Average total loss: 0.012343
tensor(0.0669, device='cuda:0') tensor(0.0888, device='cuda:0') tensor(-1.5587e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.002125
Average KL loss: 0.010312
Average total loss: 0.012437
tensor(0.0666, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(-8.1756e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.002079
Average KL loss: 0.010316
Average total loss: 0.012395
tensor(0.0663, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(1.0101e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.002326
Average KL loss: 0.010322
Average total loss: 0.012649
tensor(0.0660, device='cuda:0') tensor(0.0894, device='cuda:0') tensor(-1.4012e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.001958
Average KL loss: 0.010342
Average total loss: 0.012300
tensor(0.0657, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-8.0328e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.001878
Average KL loss: 0.010346
Average total loss: 0.012224
tensor(0.0655, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-2.0167e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.001819
Average KL loss: 0.010328
Average total loss: 0.012147
tensor(0.0652, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(2.6199e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.001615
Average KL loss: 0.010308
Average total loss: 0.011922
tensor(0.0648, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(9.5464e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.002047
Average KL loss: 0.010288
Average total loss: 0.012336
tensor(0.0645, device='cuda:0') tensor(0.0894, device='cuda:0') tensor(6.8875e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.001793
Average KL loss: 0.010286
Average total loss: 0.012079
tensor(0.0643, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(8.4169e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.001437
Average KL loss: 0.010268
Average total loss: 0.011704
tensor(0.0640, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(4.9461e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.001639
Average KL loss: 0.010237
Average total loss: 0.011877
tensor(0.0637, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(5.6693e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.001634
Average KL loss: 0.010216
Average total loss: 0.011850
tensor(0.0634, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(-1.0047e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.001648
Average KL loss: 0.010206
Average total loss: 0.011854
tensor(0.0631, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(1.0734e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.001785
Average KL loss: 0.010196
Average total loss: 0.011981
tensor(0.0628, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(1.0031e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.001985
Average KL loss: 0.010192
Average total loss: 0.012177
tensor(0.0625, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(6.8881e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.002024
Average KL loss: 0.010211
Average total loss: 0.012235
tensor(0.0623, device='cuda:0') tensor(0.0896, device='cuda:0') tensor(6.5773e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.001581
Average KL loss: 0.010230
Average total loss: 0.011811
tensor(0.0620, device='cuda:0') tensor(0.0896, device='cuda:0') tensor(2.8825e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.001487
Average KL loss: 0.010209
Average total loss: 0.011697
tensor(0.0617, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(4.7487e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.001814
Average KL loss: 0.010182
Average total loss: 0.011996
tensor(0.0615, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-2.0397e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.001784
Average KL loss: 0.010197
Average total loss: 0.011982
tensor(0.0612, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(3.7377e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.001642
Average KL loss: 0.010190
Average total loss: 0.011832
tensor(0.0610, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(1.0053e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.001661
Average KL loss: 0.010192
Average total loss: 0.011853
tensor(0.0607, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(-9.4868e-11, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.001615
Average KL loss: 0.010175
Average total loss: 0.011789
tensor(0.0604, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(-2.5207e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.001629
Average KL loss: 0.010172
Average total loss: 0.011801
tensor(0.0602, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(7.7194e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.001581
Average KL loss: 0.010150
Average total loss: 0.011731
tensor(0.0599, device='cuda:0') tensor(0.0896, device='cuda:0') tensor(8.6223e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.001723
Average KL loss: 0.010139
Average total loss: 0.011862
tensor(0.0597, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(3.7552e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.001846
Average KL loss: 0.010147
Average total loss: 0.011993
tensor(0.0594, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(8.0270e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.001604
Average KL loss: 0.010148
Average total loss: 0.011752
tensor(0.0591, device='cuda:0') tensor(0.0898, device='cuda:0') tensor(4.8979e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.001701
Average KL loss: 0.010143
Average total loss: 0.011844
tensor(0.0589, device='cuda:0') tensor(0.0900, device='cuda:0') tensor(6.8343e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.001612
Average KL loss: 0.010142
Average total loss: 0.011754
tensor(0.0589, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(5.7065e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.001719
Average KL loss: 0.010130
Average total loss: 0.011849
tensor(0.0588, device='cuda:0') tensor(0.0898, device='cuda:0') tensor(6.6222e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.001349
Average KL loss: 0.010118
Average total loss: 0.011468
tensor(0.0588, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(5.9125e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.001812
Average KL loss: 0.010106
Average total loss: 0.011918
tensor(0.0588, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(1.0484e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.001412
Average KL loss: 0.010094
Average total loss: 0.011506
tensor(0.0588, device='cuda:0') tensor(0.0896, device='cuda:0') tensor(-8.5459e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.001643
Average KL loss: 0.010082
Average total loss: 0.011725
tensor(0.0587, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(4.6156e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.001426
Average KL loss: 0.010070
Average total loss: 0.011496
tensor(0.0587, device='cuda:0') tensor(0.0894, device='cuda:0') tensor(5.5638e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.001651
Average KL loss: 0.010058
Average total loss: 0.011709
tensor(0.0587, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(6.7751e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.001583
Average KL loss: 0.010046
Average total loss: 0.011629
tensor(0.0587, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(9.4761e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.001280
Average KL loss: 0.010034
Average total loss: 0.011314
tensor(0.0586, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(5.2831e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.001457
Average KL loss: 0.010021
Average total loss: 0.011478
tensor(0.0586, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(6.4152e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.001276
Average KL loss: 0.010009
Average total loss: 0.011285
tensor(0.0586, device='cuda:0') tensor(0.0889, device='cuda:0') tensor(-3.2070e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.001566
Average KL loss: 0.009997
Average total loss: 0.011563
tensor(0.0585, device='cuda:0') tensor(0.0888, device='cuda:0') tensor(6.3966e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.001509
Average KL loss: 0.009985
Average total loss: 0.011495
tensor(0.0585, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(3.4744e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.001378
Average KL loss: 0.009973
Average total loss: 0.011351
tensor(0.0585, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(6.9453e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.001432
Average KL loss: 0.009961
Average total loss: 0.011393
tensor(0.0585, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-7.5810e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.001668
Average KL loss: 0.009949
Average total loss: 0.011617
tensor(0.0584, device='cuda:0') tensor(0.0884, device='cuda:0') tensor(7.0064e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.001335
Average KL loss: 0.009937
Average total loss: 0.011272
tensor(0.0584, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(7.8046e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.001614
Average KL loss: 0.009925
Average total loss: 0.011539
tensor(0.0584, device='cuda:0') tensor(0.0882, device='cuda:0') tensor(-4.6419e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.001370
Average KL loss: 0.009914
Average total loss: 0.011283
tensor(0.0583, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(7.1833e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.001310
Average KL loss: 0.009901
Average total loss: 0.011211
tensor(0.0583, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(-6.0921e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.001307
Average KL loss: 0.009889
Average total loss: 0.011196
tensor(0.0583, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(4.9240e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.001250
Average KL loss: 0.009877
Average total loss: 0.011127
tensor(0.0583, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(6.4471e-11, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.001327
Average KL loss: 0.009865
Average total loss: 0.011192
tensor(0.0582, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(5.9917e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.001286
Average KL loss: 0.009853
Average total loss: 0.011139
tensor(0.0582, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(5.7958e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.001323
Average KL loss: 0.009841
Average total loss: 0.011163
tensor(0.0582, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(3.9528e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.001648
Average KL loss: 0.009828
Average total loss: 0.011476
tensor(0.0581, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(2.4238e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.001493
Average KL loss: 0.009816
Average total loss: 0.011309
tensor(0.0581, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-1.1030e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.001547
Average KL loss: 0.009805
Average total loss: 0.011351
tensor(0.0581, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(5.8486e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.001422
Average KL loss: 0.009793
Average total loss: 0.011215
tensor(0.0581, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(7.7466e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.001684
Average KL loss: 0.009782
Average total loss: 0.011465
tensor(0.0580, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(7.0342e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.001299
Average KL loss: 0.009770
Average total loss: 0.011069
tensor(0.0580, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(7.0462e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.001411
Average KL loss: 0.009759
Average total loss: 0.011170
tensor(0.0580, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(8.6768e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.001278
Average KL loss: 0.009747
Average total loss: 0.011024
tensor(0.0579, device='cuda:0') tensor(0.0868, device='cuda:0') tensor(9.3467e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.001064
Average KL loss: 0.009735
Average total loss: 0.010799
tensor(0.0579, device='cuda:0') tensor(0.0867, device='cuda:0') tensor(3.5122e-12, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.001513
Average KL loss: 0.009723
Average total loss: 0.011236
tensor(0.0579, device='cuda:0') tensor(0.0866, device='cuda:0') tensor(8.9610e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.001337
Average KL loss: 0.009711
Average total loss: 0.011048
tensor(0.0578, device='cuda:0') tensor(0.0866, device='cuda:0') tensor(4.1099e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.001259
Average KL loss: 0.009699
Average total loss: 0.010959
tensor(0.0578, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(2.2734e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.001291
Average KL loss: 0.009688
Average total loss: 0.010979
tensor(0.0578, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-7.2757e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.001373
Average KL loss: 0.009676
Average total loss: 0.011049
tensor(0.0577, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(3.1741e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.001086
Average KL loss: 0.009664
Average total loss: 0.010750
tensor(0.0577, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(8.5560e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.001076
Average KL loss: 0.009652
Average total loss: 0.010728
tensor(0.0577, device='cuda:0') tensor(0.0861, device='cuda:0') tensor(7.5675e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.001177
Average KL loss: 0.009640
Average total loss: 0.010816
tensor(0.0576, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(8.4600e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.001406
Average KL loss: 0.009627
Average total loss: 0.011033
tensor(0.0576, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(1.8762e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.001567
Average KL loss: 0.009616
Average total loss: 0.011183
tensor(0.0576, device='cuda:0') tensor(0.0858, device='cuda:0') tensor(6.0135e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.001125
Average KL loss: 0.009605
Average total loss: 0.010730
tensor(0.0576, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(2.7183e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.001095
Average KL loss: 0.009593
Average total loss: 0.010687
tensor(0.0575, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(2.4881e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.001556
Average KL loss: 0.009581
Average total loss: 0.011137
tensor(0.0575, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(8.3325e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.001179
Average KL loss: 0.009569
Average total loss: 0.010748
tensor(0.0575, device='cuda:0') tensor(0.0854, device='cuda:0') tensor(8.6954e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.001506
Average KL loss: 0.009558
Average total loss: 0.011064
tensor(0.0574, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(2.8181e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.001185
Average KL loss: 0.009547
Average total loss: 0.010732
tensor(0.0574, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(4.6601e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.001445
Average KL loss: 0.009535
Average total loss: 0.010980
tensor(0.0574, device='cuda:0') tensor(0.0852, device='cuda:0') tensor(7.7383e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.001107
Average KL loss: 0.009524
Average total loss: 0.010631
tensor(0.0573, device='cuda:0') tensor(0.0851, device='cuda:0') tensor(8.4260e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.001497
Average KL loss: 0.009512
Average total loss: 0.011010
tensor(0.0573, device='cuda:0') tensor(0.0850, device='cuda:0') tensor(-2.4289e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.001217
Average KL loss: 0.009501
Average total loss: 0.010718
tensor(0.0573, device='cuda:0') tensor(0.0849, device='cuda:0') tensor(-1.0970e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.001167
Average KL loss: 0.009490
Average total loss: 0.010657
tensor(0.0572, device='cuda:0') tensor(0.0848, device='cuda:0') tensor(4.7510e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.001503
Average KL loss: 0.009478
Average total loss: 0.010981
tensor(0.0572, device='cuda:0') tensor(0.0847, device='cuda:0') tensor(-1.3514e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.001090
Average KL loss: 0.009467
Average total loss: 0.010557
tensor(0.0572, device='cuda:0') tensor(0.0846, device='cuda:0') tensor(7.4420e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.001541
Average KL loss: 0.009456
Average total loss: 0.010997
tensor(0.0571, device='cuda:0') tensor(0.0846, device='cuda:0') tensor(7.5185e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.001089
Average KL loss: 0.009445
Average total loss: 0.010534
tensor(0.0571, device='cuda:0') tensor(0.0845, device='cuda:0') tensor(8.4779e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.001363
Average KL loss: 0.009434
Average total loss: 0.010797
tensor(0.0571, device='cuda:0') tensor(0.0844, device='cuda:0') tensor(-7.1037e-12, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.001215
Average KL loss: 0.009423
Average total loss: 0.010638
tensor(0.0570, device='cuda:0') tensor(0.0843, device='cuda:0') tensor(5.1346e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.001384
Average KL loss: 0.009412
Average total loss: 0.010796
tensor(0.0570, device='cuda:0') tensor(0.0842, device='cuda:0') tensor(8.2474e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.001187
Average KL loss: 0.009401
Average total loss: 0.010588
tensor(0.0570, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(8.1197e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.001666
Average KL loss: 0.009391
Average total loss: 0.011057
tensor(0.0570, device='cuda:0') tensor(0.0840, device='cuda:0') tensor(2.3772e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.001431
Average KL loss: 0.009381
Average total loss: 0.010812
tensor(0.0569, device='cuda:0') tensor(0.0840, device='cuda:0') tensor(2.9493e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.001286
Average KL loss: 0.009371
Average total loss: 0.010656
tensor(0.0569, device='cuda:0') tensor(0.0839, device='cuda:0') tensor(9.6555e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.001074
Average KL loss: 0.009359
Average total loss: 0.010434
tensor(0.0569, device='cuda:0') tensor(0.0838, device='cuda:0') tensor(9.6247e-11, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.001111
Average KL loss: 0.009348
Average total loss: 0.010459
tensor(0.0568, device='cuda:0') tensor(0.0837, device='cuda:0') tensor(-9.4088e-12, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.000996
Average KL loss: 0.009337
Average total loss: 0.010333
tensor(0.0568, device='cuda:0') tensor(0.0836, device='cuda:0') tensor(-4.2393e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.001352
Average KL loss: 0.009326
Average total loss: 0.010678
tensor(0.0568, device='cuda:0') tensor(0.0835, device='cuda:0') tensor(6.2639e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.001013
Average KL loss: 0.009315
Average total loss: 0.010328
tensor(0.0567, device='cuda:0') tensor(0.0834, device='cuda:0') tensor(6.5904e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.001230
Average KL loss: 0.009304
Average total loss: 0.010534
tensor(0.0567, device='cuda:0') tensor(0.0833, device='cuda:0') tensor(3.8602e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.001353
Average KL loss: 0.009293
Average total loss: 0.010646
tensor(0.0567, device='cuda:0') tensor(0.0833, device='cuda:0') tensor(5.8636e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.001191
Average KL loss: 0.009282
Average total loss: 0.010473
 Percentile value: 0.8512223362922668
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =    1177 /    1728             ( 68.11%) | total_pruned =     551 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   10211 /   36864             ( 27.70%) | total_pruned =   26653 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   10509 /   36864             ( 28.51%) | total_pruned =   26355 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   10263 /   36864             ( 27.84%) | total_pruned =   26601 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   10120 /   36864             ( 27.45%) | total_pruned =   26744 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   19137 /   73728             ( 25.96%) | total_pruned =   54591 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   35038 /  147456             ( 23.76%) | total_pruned =  112418 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4121 /    8192             ( 50.31%) | total_pruned =    4071 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   26571 /  147456             ( 18.02%) | total_pruned =  120885 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   27267 /  147456             ( 18.49%) | total_pruned =  120189 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   68710 /  294912             ( 23.30%) | total_pruned =  226202 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  122048 /  589824             ( 20.69%) | total_pruned =  467776 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   14005 /   32768             ( 42.74%) | total_pruned =   18763 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   72735 /  589824             ( 12.33%) | total_pruned =  517089 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   70148 /  589824             ( 11.89%) | total_pruned =  519676 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  203861 / 1179648             ( 17.28%) | total_pruned =  975787 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     487 /     512             ( 95.12%) | total_pruned =      25 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  178924 / 2359296             (  7.58%) | total_pruned = 2180372 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     356 /     512             ( 69.53%) | total_pruned =     156 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   29504 /  131072             ( 22.51%) | total_pruned =  101568 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     347 /     512             ( 67.77%) | total_pruned =     165 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   64049 / 2359296             (  2.71%) | total_pruned = 2295247 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     394 /     512             ( 76.95%) | total_pruned =     118 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     317 /     512             ( 61.91%) | total_pruned =     195 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   15771 / 2359296             (  0.67%) | total_pruned = 2343525 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
linear.weight        | nonzeros =    4152 /    5120             ( 81.09%) | total_pruned =     968 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 24/200 Loss: 0.000026 Accuracy: 86.44 100.00 % Best test Accuracy: 86.44%
tensor(0.0566, device='cuda:0') tensor(0.0832, device='cuda:0') tensor(-6.8735e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.033345
Average KL loss: 0.008644
Average total loss: 0.041988
tensor(0.0610, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-9.5800e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.029394
Average KL loss: 0.008105
Average total loss: 0.037499
tensor(0.0644, device='cuda:0') tensor(0.0728, device='cuda:0') tensor(-2.9741e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.023848
Average KL loss: 0.007991
Average total loss: 0.031839
tensor(0.0662, device='cuda:0') tensor(0.0725, device='cuda:0') tensor(-3.7608e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.023110
Average KL loss: 0.007992
Average total loss: 0.031103
tensor(0.0672, device='cuda:0') tensor(0.0728, device='cuda:0') tensor(-1.4792e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.020526
Average KL loss: 0.008027
Average total loss: 0.028553
tensor(0.0676, device='cuda:0') tensor(0.0733, device='cuda:0') tensor(-2.1201e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.018859
Average KL loss: 0.008065
Average total loss: 0.026924
tensor(0.0678, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(-3.6650e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.019755
Average KL loss: 0.008108
Average total loss: 0.027863
tensor(0.0680, device='cuda:0') tensor(0.0743, device='cuda:0') tensor(-3.6916e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.016836
Average KL loss: 0.008153
Average total loss: 0.024989
tensor(0.0681, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(-3.4553e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.015655
Average KL loss: 0.008193
Average total loss: 0.023848
tensor(0.0681, device='cuda:0') tensor(0.0753, device='cuda:0') tensor(-3.9094e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.015693
Average KL loss: 0.008230
Average total loss: 0.023923
tensor(0.0681, device='cuda:0') tensor(0.0757, device='cuda:0') tensor(-3.5060e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.015364
Average KL loss: 0.008273
Average total loss: 0.023637
tensor(0.0682, device='cuda:0') tensor(0.0763, device='cuda:0') tensor(-2.6196e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.013406
Average KL loss: 0.008312
Average total loss: 0.021718
tensor(0.0682, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(-2.1678e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.014581
Average KL loss: 0.008348
Average total loss: 0.022929
tensor(0.0682, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(-1.4574e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.012246
Average KL loss: 0.008386
Average total loss: 0.020632
tensor(0.0682, device='cuda:0') tensor(0.0776, device='cuda:0') tensor(-6.7600e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.012481
Average KL loss: 0.008419
Average total loss: 0.020900
tensor(0.0683, device='cuda:0') tensor(0.0780, device='cuda:0') tensor(-1.4929e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.012257
Average KL loss: 0.008452
Average total loss: 0.020709
tensor(0.0683, device='cuda:0') tensor(0.0785, device='cuda:0') tensor(-2.6649e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.010344
Average KL loss: 0.008485
Average total loss: 0.018829
tensor(0.0683, device='cuda:0') tensor(0.0789, device='cuda:0') tensor(-7.7258e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.010914
Average KL loss: 0.008515
Average total loss: 0.019429
tensor(0.0683, device='cuda:0') tensor(0.0793, device='cuda:0') tensor(-2.1813e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.010197
Average KL loss: 0.008546
Average total loss: 0.018744
tensor(0.0683, device='cuda:0') tensor(0.0797, device='cuda:0') tensor(-2.1485e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.009202
Average KL loss: 0.008574
Average total loss: 0.017776
tensor(0.0683, device='cuda:0') tensor(0.0800, device='cuda:0') tensor(-1.0446e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.008546
Average KL loss: 0.008598
Average total loss: 0.017145
tensor(0.0683, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(-1.9793e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.009209
Average KL loss: 0.008622
Average total loss: 0.017831
tensor(0.0683, device='cuda:0') tensor(0.0807, device='cuda:0') tensor(-3.0724e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.008844
Average KL loss: 0.008648
Average total loss: 0.017492
tensor(0.0682, device='cuda:0') tensor(0.0810, device='cuda:0') tensor(-1.4523e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.008803
Average KL loss: 0.008674
Average total loss: 0.017476
tensor(0.0682, device='cuda:0') tensor(0.0814, device='cuda:0') tensor(-4.9777e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.008406
Average KL loss: 0.008700
Average total loss: 0.017106
tensor(0.0682, device='cuda:0') tensor(0.0818, device='cuda:0') tensor(-6.1127e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.008351
Average KL loss: 0.008727
Average total loss: 0.017078
tensor(0.0682, device='cuda:0') tensor(0.0821, device='cuda:0') tensor(-1.0543e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.008614
Average KL loss: 0.008753
Average total loss: 0.017367
tensor(0.0682, device='cuda:0') tensor(0.0825, device='cuda:0') tensor(-1.4606e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.006953
Average KL loss: 0.008777
Average total loss: 0.015729
tensor(0.0682, device='cuda:0') tensor(0.0828, device='cuda:0') tensor(-2.8165e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.007863
Average KL loss: 0.008797
Average total loss: 0.016660
tensor(0.0682, device='cuda:0') tensor(0.0831, device='cuda:0') tensor(-1.7137e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.007144
Average KL loss: 0.008820
Average total loss: 0.015965
tensor(0.0681, device='cuda:0') tensor(0.0834, device='cuda:0') tensor(-1.0392e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.006169
Average KL loss: 0.008839
Average total loss: 0.015009
tensor(0.0681, device='cuda:0') tensor(0.0836, device='cuda:0') tensor(-1.1243e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.006999
Average KL loss: 0.008857
Average total loss: 0.015856
tensor(0.0681, device='cuda:0') tensor(0.0839, device='cuda:0') tensor(3.0827e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.006749
Average KL loss: 0.008877
Average total loss: 0.015626
tensor(0.0680, device='cuda:0') tensor(0.0842, device='cuda:0') tensor(-5.2671e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.006502
Average KL loss: 0.008895
Average total loss: 0.015397
tensor(0.0680, device='cuda:0') tensor(0.0845, device='cuda:0') tensor(-5.5443e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.006353
Average KL loss: 0.008917
Average total loss: 0.015270
tensor(0.0680, device='cuda:0') tensor(0.0848, device='cuda:0') tensor(-2.0973e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.007556
Average KL loss: 0.008938
Average total loss: 0.016495
tensor(0.0680, device='cuda:0') tensor(0.0852, device='cuda:0') tensor(-8.5840e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.005954
Average KL loss: 0.008963
Average total loss: 0.014917
tensor(0.0679, device='cuda:0') tensor(0.0854, device='cuda:0') tensor(-2.3599e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.005959
Average KL loss: 0.008979
Average total loss: 0.014938
tensor(0.0679, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-3.2720e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.005983
Average KL loss: 0.008995
Average total loss: 0.014978
tensor(0.0678, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-1.3733e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.005389
Average KL loss: 0.009012
Average total loss: 0.014401
tensor(0.0678, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-8.6343e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.005206
Average KL loss: 0.009024
Average total loss: 0.014230
tensor(0.0677, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-3.9777e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.005625
Average KL loss: 0.009039
Average total loss: 0.014664
tensor(0.0677, device='cuda:0') tensor(0.0867, device='cuda:0') tensor(5.1910e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.005422
Average KL loss: 0.009053
Average total loss: 0.014475
tensor(0.0676, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(-1.0361e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.005580
Average KL loss: 0.009071
Average total loss: 0.014651
tensor(0.0676, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-9.3696e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.004667
Average KL loss: 0.009087
Average total loss: 0.013753
tensor(0.0676, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-8.4515e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.004943
Average KL loss: 0.009099
Average total loss: 0.014042
tensor(0.0675, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(-1.7662e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.005023
Average KL loss: 0.009114
Average total loss: 0.014138
tensor(0.0675, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(-1.4217e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.004822
Average KL loss: 0.009130
Average total loss: 0.013952
tensor(0.0674, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(2.4539e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.005363
Average KL loss: 0.009147
Average total loss: 0.014510
tensor(0.0674, device='cuda:0') tensor(0.0884, device='cuda:0') tensor(7.6259e-12, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.004604
Average KL loss: 0.009164
Average total loss: 0.013768
tensor(0.0673, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(4.6793e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.004598
Average KL loss: 0.009177
Average total loss: 0.013775
tensor(0.0673, device='cuda:0') tensor(0.0889, device='cuda:0') tensor(-8.3637e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.005182
Average KL loss: 0.009190
Average total loss: 0.014372
tensor(0.0672, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(1.1317e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.003963
Average KL loss: 0.009204
Average total loss: 0.013167
tensor(0.0671, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(4.1852e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.004325
Average KL loss: 0.009212
Average total loss: 0.013537
tensor(0.0671, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-1.6725e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.004599
Average KL loss: 0.009225
Average total loss: 0.013824
tensor(0.0670, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(7.4189e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.003764
Average KL loss: 0.009236
Average total loss: 0.013000
tensor(0.0669, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(-2.7850e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.003735
Average KL loss: 0.009245
Average total loss: 0.012980
tensor(0.0669, device='cuda:0') tensor(0.0901, device='cuda:0') tensor(2.5182e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.003674
Average KL loss: 0.009251
Average total loss: 0.012925
tensor(0.0668, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(-2.6548e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.003992
Average KL loss: 0.009261
Average total loss: 0.013253
tensor(0.0668, device='cuda:0') tensor(0.0904, device='cuda:0') tensor(5.5545e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.003910
Average KL loss: 0.009270
Average total loss: 0.013180
tensor(0.0667, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(-5.9571e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.003686
Average KL loss: 0.009274
Average total loss: 0.012961
tensor(0.0666, device='cuda:0') tensor(0.0907, device='cuda:0') tensor(1.5418e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.004115
Average KL loss: 0.009281
Average total loss: 0.013396
tensor(0.0665, device='cuda:0') tensor(0.0909, device='cuda:0') tensor(-6.1864e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.004377
Average KL loss: 0.009296
Average total loss: 0.013673
tensor(0.0665, device='cuda:0') tensor(0.0912, device='cuda:0') tensor(-1.0371e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.003386
Average KL loss: 0.009309
Average total loss: 0.012695
tensor(0.0664, device='cuda:0') tensor(0.0914, device='cuda:0') tensor(-2.7544e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.003466
Average KL loss: 0.009316
Average total loss: 0.012782
tensor(0.0663, device='cuda:0') tensor(0.0915, device='cuda:0') tensor(-8.8649e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.003521
Average KL loss: 0.009323
Average total loss: 0.012843
tensor(0.0663, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.0803e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.003190
Average KL loss: 0.009329
Average total loss: 0.012519
tensor(0.0662, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(2.9493e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.003499
Average KL loss: 0.009336
Average total loss: 0.012835
tensor(0.0661, device='cuda:0') tensor(0.0920, device='cuda:0') tensor(4.4490e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.003192
Average KL loss: 0.009342
Average total loss: 0.012534
tensor(0.0660, device='cuda:0') tensor(0.0922, device='cuda:0') tensor(3.6763e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.002950
Average KL loss: 0.009344
Average total loss: 0.012295
tensor(0.0659, device='cuda:0') tensor(0.0923, device='cuda:0') tensor(-1.6577e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.003376
Average KL loss: 0.009351
Average total loss: 0.012727
tensor(0.0659, device='cuda:0') tensor(0.0924, device='cuda:0') tensor(-9.6341e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.003360
Average KL loss: 0.009356
Average total loss: 0.012716
tensor(0.0658, device='cuda:0') tensor(0.0926, device='cuda:0') tensor(3.2883e-11, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.003434
Average KL loss: 0.009364
Average total loss: 0.012798
tensor(0.0657, device='cuda:0') tensor(0.0928, device='cuda:0') tensor(2.8784e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.002612
Average KL loss: 0.009371
Average total loss: 0.011983
tensor(0.0656, device='cuda:0') tensor(0.0929, device='cuda:0') tensor(-7.0968e-11, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.003428
Average KL loss: 0.009373
Average total loss: 0.012802
tensor(0.0655, device='cuda:0') tensor(0.0931, device='cuda:0') tensor(2.8348e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.003352
Average KL loss: 0.009383
Average total loss: 0.012736
tensor(0.0655, device='cuda:0') tensor(0.0932, device='cuda:0') tensor(-2.8147e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.003577
Average KL loss: 0.009393
Average total loss: 0.012970
tensor(0.0654, device='cuda:0') tensor(0.0935, device='cuda:0') tensor(-1.2196e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.002940
Average KL loss: 0.009403
Average total loss: 0.012343
tensor(0.0653, device='cuda:0') tensor(0.0936, device='cuda:0') tensor(5.7782e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.003132
Average KL loss: 0.009407
Average total loss: 0.012538
tensor(0.0652, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(4.6600e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.002634
Average KL loss: 0.009409
Average total loss: 0.012043
tensor(0.0651, device='cuda:0') tensor(0.0938, device='cuda:0') tensor(-3.5938e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.003008
Average KL loss: 0.009412
Average total loss: 0.012420
tensor(0.0650, device='cuda:0') tensor(0.0940, device='cuda:0') tensor(6.6171e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.002913
Average KL loss: 0.009419
Average total loss: 0.012332
tensor(0.0650, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-1.4996e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.002700
Average KL loss: 0.009423
Average total loss: 0.012123
tensor(0.0649, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(3.2096e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.002769
Average KL loss: 0.009427
Average total loss: 0.012196
tensor(0.0648, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(4.5095e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.003375
Average KL loss: 0.009435
Average total loss: 0.012809
tensor(0.0647, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(-9.7266e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.002874
Average KL loss: 0.009442
Average total loss: 0.012316
tensor(0.0647, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(3.8139e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.003155
Average KL loss: 0.009440
Average total loss: 0.012595
tensor(0.0647, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(-5.0888e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.002784
Average KL loss: 0.009439
Average total loss: 0.012223
tensor(0.0647, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(1.1101e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.002894
Average KL loss: 0.009437
Average total loss: 0.012330
tensor(0.0647, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(4.9371e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.002998
Average KL loss: 0.009435
Average total loss: 0.012433
tensor(0.0647, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(-7.2976e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.003035
Average KL loss: 0.009433
Average total loss: 0.012468
tensor(0.0647, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(5.9836e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.002433
Average KL loss: 0.009432
Average total loss: 0.011864
tensor(0.0647, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(4.9839e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.002682
Average KL loss: 0.009429
Average total loss: 0.012112
tensor(0.0646, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(1.1738e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.002507
Average KL loss: 0.009427
Average total loss: 0.011935
tensor(0.0646, device='cuda:0') tensor(0.0945, device='cuda:0') tensor(3.1318e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.002399
Average KL loss: 0.009425
Average total loss: 0.011824
tensor(0.0646, device='cuda:0') tensor(0.0945, device='cuda:0') tensor(-7.7388e-11, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.002869
Average KL loss: 0.009424
Average total loss: 0.012292
tensor(0.0646, device='cuda:0') tensor(0.0945, device='cuda:0') tensor(6.8846e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.002722
Average KL loss: 0.009422
Average total loss: 0.012144
tensor(0.0646, device='cuda:0') tensor(0.0945, device='cuda:0') tensor(6.9697e-12, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.002912
Average KL loss: 0.009420
Average total loss: 0.012332
tensor(0.0646, device='cuda:0') tensor(0.0945, device='cuda:0') tensor(7.4908e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.002656
Average KL loss: 0.009418
Average total loss: 0.012074
tensor(0.0646, device='cuda:0') tensor(0.0945, device='cuda:0') tensor(-5.5601e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.002655
Average KL loss: 0.009416
Average total loss: 0.012071
tensor(0.0646, device='cuda:0') tensor(0.0945, device='cuda:0') tensor(3.1698e-11, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.002698
Average KL loss: 0.009414
Average total loss: 0.012112
tensor(0.0646, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(-3.0079e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.002692
Average KL loss: 0.009412
Average total loss: 0.012104
tensor(0.0646, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(2.7760e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.002781
Average KL loss: 0.009410
Average total loss: 0.012192
tensor(0.0645, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(-8.3261e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.002197
Average KL loss: 0.009408
Average total loss: 0.011605
tensor(0.0645, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(9.0159e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.002671
Average KL loss: 0.009406
Average total loss: 0.012077
tensor(0.0645, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(2.4767e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.002824
Average KL loss: 0.009404
Average total loss: 0.012228
tensor(0.0645, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(-1.1166e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.002503
Average KL loss: 0.009402
Average total loss: 0.011905
tensor(0.0645, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(-2.6706e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.003289
Average KL loss: 0.009400
Average total loss: 0.012689
tensor(0.0645, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(1.4831e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.002674
Average KL loss: 0.009399
Average total loss: 0.012073
tensor(0.0645, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(8.0683e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.002434
Average KL loss: 0.009396
Average total loss: 0.011830
tensor(0.0645, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(1.7411e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.002662
Average KL loss: 0.009394
Average total loss: 0.012056
tensor(0.0645, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(3.3720e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.002325
Average KL loss: 0.009392
Average total loss: 0.011717
tensor(0.0644, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(5.5627e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.002530
Average KL loss: 0.009390
Average total loss: 0.011920
tensor(0.0644, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(-8.7112e-11, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.002253
Average KL loss: 0.009388
Average total loss: 0.011641
tensor(0.0644, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(6.0576e-11, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.002419
Average KL loss: 0.009385
Average total loss: 0.011804
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(7.0071e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.002597
Average KL loss: 0.009384
Average total loss: 0.011982
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-3.9368e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.002835
Average KL loss: 0.009384
Average total loss: 0.012219
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(3.5699e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.002550
Average KL loss: 0.009384
Average total loss: 0.011934
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(3.9105e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.002221
Average KL loss: 0.009384
Average total loss: 0.011605
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(4.0353e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.002216
Average KL loss: 0.009383
Average total loss: 0.011599
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-2.0061e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.002778
Average KL loss: 0.009383
Average total loss: 0.012161
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(4.9246e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.002708
Average KL loss: 0.009383
Average total loss: 0.012090
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(1.2914e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.002788
Average KL loss: 0.009383
Average total loss: 0.012171
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(5.1263e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.002074
Average KL loss: 0.009382
Average total loss: 0.011456
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(2.7557e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.002223
Average KL loss: 0.009382
Average total loss: 0.011605
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-1.2514e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.002897
Average KL loss: 0.009382
Average total loss: 0.012278
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-4.1609e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.002598
Average KL loss: 0.009382
Average total loss: 0.011979
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(5.5789e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.002746
Average KL loss: 0.009381
Average total loss: 0.012127
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(2.6799e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.002609
Average KL loss: 0.009381
Average total loss: 0.011990
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-9.1073e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.002477
Average KL loss: 0.009381
Average total loss: 0.011858
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(1.7909e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.002070
Average KL loss: 0.009381
Average total loss: 0.011450
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(5.6715e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.002355
Average KL loss: 0.009380
Average total loss: 0.011735
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-1.3754e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.002110
Average KL loss: 0.009380
Average total loss: 0.011490
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(5.9159e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.002143
Average KL loss: 0.009380
Average total loss: 0.011523
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(3.3524e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.002193
Average KL loss: 0.009379
Average total loss: 0.011573
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(3.4335e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.002401
Average KL loss: 0.009379
Average total loss: 0.011780
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-9.6945e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.002292
Average KL loss: 0.009379
Average total loss: 0.011671
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(5.1818e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.002449
Average KL loss: 0.009379
Average total loss: 0.011828
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(5.7556e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.002835
Average KL loss: 0.009378
Average total loss: 0.012213
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(3.0795e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.002346
Average KL loss: 0.009378
Average total loss: 0.011724
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(3.0629e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.002498
Average KL loss: 0.009378
Average total loss: 0.011876
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(5.3507e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.002493
Average KL loss: 0.009378
Average total loss: 0.011871
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(8.6045e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.002315
Average KL loss: 0.009377
Average total loss: 0.011692
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(3.7873e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.002690
Average KL loss: 0.009377
Average total loss: 0.012067
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-2.4431e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.002404
Average KL loss: 0.009377
Average total loss: 0.011782
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(5.3001e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.002102
Average KL loss: 0.009377
Average total loss: 0.011479
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-5.5964e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.002422
Average KL loss: 0.009377
Average total loss: 0.011800
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(7.9905e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.002174
Average KL loss: 0.009377
Average total loss: 0.011551
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-2.0381e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.002441
Average KL loss: 0.009377
Average total loss: 0.011818
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(2.7622e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.002054
Average KL loss: 0.009377
Average total loss: 0.011432
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(4.3529e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.002490
Average KL loss: 0.009377
Average total loss: 0.011867
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(6.9980e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.002346
Average KL loss: 0.009377
Average total loss: 0.011723
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(8.5201e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.002971
Average KL loss: 0.009377
Average total loss: 0.012348
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(4.6661e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.002694
Average KL loss: 0.009377
Average total loss: 0.012071
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(5.9265e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.002459
Average KL loss: 0.009377
Average total loss: 0.011836
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(5.1079e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.002147
Average KL loss: 0.009377
Average total loss: 0.011524
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(4.3177e-11, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.002561
Average KL loss: 0.009377
Average total loss: 0.011938
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-1.6858e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.002339
Average KL loss: 0.009377
Average total loss: 0.011716
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(1.1386e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.002723
Average KL loss: 0.009377
Average total loss: 0.012100
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-1.4735e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.002811
Average KL loss: 0.009377
Average total loss: 0.012188
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-3.9889e-11, device='cuda:0')
 Percentile value: 1.7034621238708496
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =    1046 /    1728             ( 60.53%) | total_pruned =     682 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4439 /   36864             ( 12.04%) | total_pruned =   32425 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4545 /   36864             ( 12.33%) | total_pruned =   32319 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4479 /   36864             ( 12.15%) | total_pruned =   32385 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4435 /   36864             ( 12.03%) | total_pruned =   32429 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    7677 /   73728             ( 10.41%) | total_pruned =   66051 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   13261 /  147456             (  8.99%) | total_pruned =  134195 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2891 /    8192             ( 35.29%) | total_pruned =    5301 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8303 /  147456             (  5.63%) | total_pruned =  139153 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    8524 /  147456             (  5.78%) | total_pruned =  138932 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   25914 /  294912             (  8.79%) | total_pruned =  268998 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     214 /     256             ( 83.59%) | total_pruned =      42 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   41990 /  589824             (  7.12%) | total_pruned =  547834 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    8514 /   32768             ( 25.98%) | total_pruned =   24254 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   17820 /  589824             (  3.02%) | total_pruned =  572004 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   17249 /  589824             (  2.92%) | total_pruned =  572575 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     183 /     256             ( 71.48%) | total_pruned =      73 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   60754 / 1179648             (  5.15%) | total_pruned = 1118894 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     477 /     512             ( 93.16%) | total_pruned =      35 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   33642 / 2359296             (  1.43%) | total_pruned = 2325654 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     271 /     512             ( 52.93%) | total_pruned =     241 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   10854 /  131072             (  8.28%) | total_pruned =  120218 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     267 /     512             ( 52.15%) | total_pruned =     245 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   11064 / 2359296             (  0.47%) | total_pruned = 2348232 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     369 /     512             ( 72.07%) | total_pruned =     143 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     213 /     512             ( 41.60%) | total_pruned =     299 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    3465 / 2359296             (  0.15%) | total_pruned = 2355831 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
linear.weight        | nonzeros =    3640 /    5120             ( 71.09%) | total_pruned =    1480 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 24/200 Loss: 0.000056 Accuracy: 85.88 100.00 % Best test Accuracy: 86.07%
tensor(0.0644, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-1.5525e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.081739
Average KL loss: 0.008566
Average total loss: 0.090306
tensor(0.0557, device='cuda:0') tensor(0.0837, device='cuda:0') tensor(-2.1122e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.077766
Average KL loss: 0.007607
Average total loss: 0.085373
tensor(0.0501, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(-8.1440e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.072199
Average KL loss: 0.007251
Average total loss: 0.079450
tensor(0.0468, device='cuda:0') tensor(0.0796, device='cuda:0') tensor(-8.3024e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.069503
Average KL loss: 0.007156
Average total loss: 0.076659
tensor(0.0452, device='cuda:0') tensor(0.0799, device='cuda:0') tensor(-9.8470e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.063207
Average KL loss: 0.007148
Average total loss: 0.070355
tensor(0.0444, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(-1.1687e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.065983
Average KL loss: 0.007166
Average total loss: 0.073149
tensor(0.0441, device='cuda:0') tensor(0.0808, device='cuda:0') tensor(-9.7256e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.060574
Average KL loss: 0.007190
Average total loss: 0.067764
tensor(0.0440, device='cuda:0') tensor(0.0813, device='cuda:0') tensor(-1.0624e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.058163
Average KL loss: 0.007214
Average total loss: 0.065377
tensor(0.0440, device='cuda:0') tensor(0.0818, device='cuda:0') tensor(-9.2007e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.056796
Average KL loss: 0.007238
Average total loss: 0.064034
tensor(0.0441, device='cuda:0') tensor(0.0823, device='cuda:0') tensor(-1.1059e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.053698
Average KL loss: 0.007261
Average total loss: 0.060958
tensor(0.0442, device='cuda:0') tensor(0.0828, device='cuda:0') tensor(-1.0256e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.054017
Average KL loss: 0.007284
Average total loss: 0.061301
tensor(0.0443, device='cuda:0') tensor(0.0832, device='cuda:0') tensor(-9.8407e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.050738
Average KL loss: 0.007308
Average total loss: 0.058045
tensor(0.0444, device='cuda:0') tensor(0.0837, device='cuda:0') tensor(-8.6796e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.050456
Average KL loss: 0.007331
Average total loss: 0.057788
tensor(0.0445, device='cuda:0') tensor(0.0842, device='cuda:0') tensor(-1.2107e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.048160
Average KL loss: 0.007354
Average total loss: 0.055514
tensor(0.0446, device='cuda:0') tensor(0.0847, device='cuda:0') tensor(-9.9001e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.048196
Average KL loss: 0.007376
Average total loss: 0.055572
tensor(0.0447, device='cuda:0') tensor(0.0851, device='cuda:0') tensor(-9.7523e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.047852
Average KL loss: 0.007398
Average total loss: 0.055249
tensor(0.0448, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.0987e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.043773
Average KL loss: 0.007420
Average total loss: 0.051193
tensor(0.0448, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-8.9909e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.043564
Average KL loss: 0.007441
Average total loss: 0.051006
tensor(0.0449, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-1.1348e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.044597
Average KL loss: 0.007463
Average total loss: 0.052060
tensor(0.0450, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(-2.0279e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.043211
Average KL loss: 0.007483
Average total loss: 0.050694
tensor(0.0451, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(-9.7200e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.041606
Average KL loss: 0.007504
Average total loss: 0.049110
tensor(0.0452, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-7.4918e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.038552
Average KL loss: 0.007523
Average total loss: 0.046076
tensor(0.0453, device='cuda:0') tensor(0.0882, device='cuda:0') tensor(-9.5318e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.037145
Average KL loss: 0.007542
Average total loss: 0.044688
tensor(0.0454, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-9.5415e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.038610
Average KL loss: 0.007561
Average total loss: 0.046172
tensor(0.0454, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(-5.6985e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.038379
Average KL loss: 0.007581
Average total loss: 0.045960
tensor(0.0455, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-6.3220e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.035403
Average KL loss: 0.007600
Average total loss: 0.043003
tensor(0.0456, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(-6.6691e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.036330
Average KL loss: 0.007619
Average total loss: 0.043949
tensor(0.0457, device='cuda:0') tensor(0.0903, device='cuda:0') tensor(-3.8518e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.033498
Average KL loss: 0.007637
Average total loss: 0.041135
tensor(0.0457, device='cuda:0') tensor(0.0907, device='cuda:0') tensor(-7.6711e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.035222
Average KL loss: 0.007655
Average total loss: 0.042877
tensor(0.0458, device='cuda:0') tensor(0.0911, device='cuda:0') tensor(-7.6999e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.034025
Average KL loss: 0.007674
Average total loss: 0.041699
tensor(0.0459, device='cuda:0') tensor(0.0916, device='cuda:0') tensor(-8.2123e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.034545
Average KL loss: 0.007693
Average total loss: 0.042238
tensor(0.0460, device='cuda:0') tensor(0.0920, device='cuda:0') tensor(-6.1220e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.029992
Average KL loss: 0.007710
Average total loss: 0.037702
tensor(0.0461, device='cuda:0') tensor(0.0924, device='cuda:0') tensor(-6.6528e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.030450
Average KL loss: 0.007727
Average total loss: 0.038177
tensor(0.0461, device='cuda:0') tensor(0.0928, device='cuda:0') tensor(-7.5774e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.030969
Average KL loss: 0.007743
Average total loss: 0.038712
tensor(0.0462, device='cuda:0') tensor(0.0931, device='cuda:0') tensor(-4.5263e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.028789
Average KL loss: 0.007760
Average total loss: 0.036549
tensor(0.0463, device='cuda:0') tensor(0.0935, device='cuda:0') tensor(-4.9563e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.028523
Average KL loss: 0.007777
Average total loss: 0.036300
tensor(0.0463, device='cuda:0') tensor(0.0939, device='cuda:0') tensor(-2.3754e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.027614
Average KL loss: 0.007793
Average total loss: 0.035407
tensor(0.0464, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(-7.0432e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.027572
Average KL loss: 0.007809
Average total loss: 0.035381
tensor(0.0465, device='cuda:0') tensor(0.0947, device='cuda:0') tensor(-6.1163e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.028006
Average KL loss: 0.007824
Average total loss: 0.035830
tensor(0.0465, device='cuda:0') tensor(0.0951, device='cuda:0') tensor(-5.6101e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.027248
Average KL loss: 0.007840
Average total loss: 0.035088
tensor(0.0466, device='cuda:0') tensor(0.0954, device='cuda:0') tensor(-3.8650e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.026814
Average KL loss: 0.007856
Average total loss: 0.034670
tensor(0.0467, device='cuda:0') tensor(0.0958, device='cuda:0') tensor(-4.4976e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.025571
Average KL loss: 0.007872
Average total loss: 0.033444
tensor(0.0467, device='cuda:0') tensor(0.0962, device='cuda:0') tensor(-3.6854e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.025935
Average KL loss: 0.007887
Average total loss: 0.033822
tensor(0.0468, device='cuda:0') tensor(0.0966, device='cuda:0') tensor(-6.2177e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.024208
Average KL loss: 0.007902
Average total loss: 0.032110
tensor(0.0469, device='cuda:0') tensor(0.0969, device='cuda:0') tensor(-5.1008e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.025416
Average KL loss: 0.007918
Average total loss: 0.033333
tensor(0.0469, device='cuda:0') tensor(0.0973, device='cuda:0') tensor(-3.7493e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.024316
Average KL loss: 0.007933
Average total loss: 0.032249
tensor(0.0470, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(-3.2932e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.021981
Average KL loss: 0.007947
Average total loss: 0.029928
tensor(0.0470, device='cuda:0') tensor(0.0980, device='cuda:0') tensor(-3.7366e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.024102
Average KL loss: 0.007962
Average total loss: 0.032064
tensor(0.0471, device='cuda:0') tensor(0.0984, device='cuda:0') tensor(-4.2032e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.023385
Average KL loss: 0.007977
Average total loss: 0.031362
tensor(0.0472, device='cuda:0') tensor(0.0988, device='cuda:0') tensor(-6.2648e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.024543
Average KL loss: 0.007993
Average total loss: 0.032535
tensor(0.0472, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-3.7317e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.021334
Average KL loss: 0.008008
Average total loss: 0.029342
tensor(0.0473, device='cuda:0') tensor(0.0996, device='cuda:0') tensor(-3.0176e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.022155
Average KL loss: 0.008021
Average total loss: 0.030176
tensor(0.0474, device='cuda:0') tensor(0.0999, device='cuda:0') tensor(-2.1446e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.021007
Average KL loss: 0.008035
Average total loss: 0.029043
tensor(0.0474, device='cuda:0') tensor(0.1002, device='cuda:0') tensor(-3.1957e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.023164
Average KL loss: 0.008049
Average total loss: 0.031213
tensor(0.0475, device='cuda:0') tensor(0.1006, device='cuda:0') tensor(-3.7629e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.020546
Average KL loss: 0.008063
Average total loss: 0.028609
tensor(0.0475, device='cuda:0') tensor(0.1010, device='cuda:0') tensor(-3.0672e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.020025
Average KL loss: 0.008077
Average total loss: 0.028101
tensor(0.0476, device='cuda:0') tensor(0.1013, device='cuda:0') tensor(-4.6473e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.020253
Average KL loss: 0.008090
Average total loss: 0.028343
tensor(0.0476, device='cuda:0') tensor(0.1017, device='cuda:0') tensor(-2.6104e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.019584
Average KL loss: 0.008104
Average total loss: 0.027688
tensor(0.0477, device='cuda:0') tensor(0.1020, device='cuda:0') tensor(-3.2444e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.020567
Average KL loss: 0.008118
Average total loss: 0.028686
tensor(0.0478, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-3.0174e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.018136
Average KL loss: 0.008131
Average total loss: 0.026267
tensor(0.0478, device='cuda:0') tensor(0.1027, device='cuda:0') tensor(-2.6905e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.018882
Average KL loss: 0.008143
Average total loss: 0.027025
tensor(0.0479, device='cuda:0') tensor(0.1031, device='cuda:0') tensor(-3.5635e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.018281
Average KL loss: 0.008156
Average total loss: 0.026438
tensor(0.0479, device='cuda:0') tensor(0.1034, device='cuda:0') tensor(-3.9246e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.018882
Average KL loss: 0.008170
Average total loss: 0.027052
tensor(0.0480, device='cuda:0') tensor(0.1038, device='cuda:0') tensor(-1.8102e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.016608
Average KL loss: 0.008182
Average total loss: 0.024790
tensor(0.0480, device='cuda:0') tensor(0.1041, device='cuda:0') tensor(-3.1878e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.018116
Average KL loss: 0.008194
Average total loss: 0.026310
tensor(0.0481, device='cuda:0') tensor(0.1045, device='cuda:0') tensor(-1.1369e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.016600
Average KL loss: 0.008208
Average total loss: 0.024807
tensor(0.0481, device='cuda:0') tensor(0.1048, device='cuda:0') tensor(-4.5868e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.016608
Average KL loss: 0.008220
Average total loss: 0.024828
tensor(0.0482, device='cuda:0') tensor(0.1051, device='cuda:0') tensor(-2.9878e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.016560
Average KL loss: 0.008232
Average total loss: 0.024792
tensor(0.0482, device='cuda:0') tensor(0.1055, device='cuda:0') tensor(-4.3110e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.017119
Average KL loss: 0.008244
Average total loss: 0.025363
tensor(0.0483, device='cuda:0') tensor(0.1058, device='cuda:0') tensor(-2.9076e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.014718
Average KL loss: 0.008257
Average total loss: 0.022975
tensor(0.0483, device='cuda:0') tensor(0.1061, device='cuda:0') tensor(-5.0557e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.016861
Average KL loss: 0.008270
Average total loss: 0.025130
tensor(0.0484, device='cuda:0') tensor(0.1065, device='cuda:0') tensor(-3.9583e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.016661
Average KL loss: 0.008283
Average total loss: 0.024944
tensor(0.0485, device='cuda:0') tensor(0.1069, device='cuda:0') tensor(-4.3600e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.015945
Average KL loss: 0.008296
Average total loss: 0.024240
tensor(0.0485, device='cuda:0') tensor(0.1072, device='cuda:0') tensor(-2.1873e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.015229
Average KL loss: 0.008307
Average total loss: 0.023537
tensor(0.0486, device='cuda:0') tensor(0.1075, device='cuda:0') tensor(-2.1853e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.014536
Average KL loss: 0.008319
Average total loss: 0.022855
tensor(0.0486, device='cuda:0') tensor(0.1078, device='cuda:0') tensor(-2.9480e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.013917
Average KL loss: 0.008329
Average total loss: 0.022246
tensor(0.0486, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-2.9846e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.014305
Average KL loss: 0.008340
Average total loss: 0.022645
tensor(0.0487, device='cuda:0') tensor(0.1085, device='cuda:0') tensor(-2.3700e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.013757
Average KL loss: 0.008351
Average total loss: 0.022108
tensor(0.0487, device='cuda:0') tensor(0.1088, device='cuda:0') tensor(-2.9960e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.013489
Average KL loss: 0.008362
Average total loss: 0.021851
tensor(0.0488, device='cuda:0') tensor(0.1091, device='cuda:0') tensor(-1.7046e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.014748
Average KL loss: 0.008373
Average total loss: 0.023121
tensor(0.0488, device='cuda:0') tensor(0.1094, device='cuda:0') tensor(-1.4588e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.014247
Average KL loss: 0.008384
Average total loss: 0.022631
tensor(0.0489, device='cuda:0') tensor(0.1097, device='cuda:0') tensor(-2.8843e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.014041
Average KL loss: 0.008395
Average total loss: 0.022436
tensor(0.0489, device='cuda:0') tensor(0.1101, device='cuda:0') tensor(-2.0246e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.013161
Average KL loss: 0.008405
Average total loss: 0.021567
tensor(0.0490, device='cuda:0') tensor(0.1104, device='cuda:0') tensor(-2.3452e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.012774
Average KL loss: 0.008415
Average total loss: 0.021189
tensor(0.0490, device='cuda:0') tensor(0.1107, device='cuda:0') tensor(-1.3785e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.012982
Average KL loss: 0.008425
Average total loss: 0.021407
tensor(0.0490, device='cuda:0') tensor(0.1110, device='cuda:0') tensor(-2.6194e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.012233
Average KL loss: 0.008435
Average total loss: 0.020668
tensor(0.0491, device='cuda:0') tensor(0.1113, device='cuda:0') tensor(-3.6359e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.012912
Average KL loss: 0.008446
Average total loss: 0.021357
tensor(0.0491, device='cuda:0') tensor(0.1116, device='cuda:0') tensor(-2.8711e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.012874
Average KL loss: 0.008457
Average total loss: 0.021331
tensor(0.0492, device='cuda:0') tensor(0.1120, device='cuda:0') tensor(-3.3629e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.011540
Average KL loss: 0.008468
Average total loss: 0.020008
tensor(0.0492, device='cuda:0') tensor(0.1123, device='cuda:0') tensor(-2.9257e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.011798
Average KL loss: 0.008478
Average total loss: 0.020275
tensor(0.0493, device='cuda:0') tensor(0.1126, device='cuda:0') tensor(-1.4992e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.010895
Average KL loss: 0.008487
Average total loss: 0.019382
tensor(0.0493, device='cuda:0') tensor(0.1129, device='cuda:0') tensor(-4.0380e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.013133
Average KL loss: 0.008496
Average total loss: 0.021630
tensor(0.0493, device='cuda:0') tensor(0.1132, device='cuda:0') tensor(-2.9513e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.011111
Average KL loss: 0.008507
Average total loss: 0.019618
tensor(0.0494, device='cuda:0') tensor(0.1135, device='cuda:0') tensor(-1.7934e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.011951
Average KL loss: 0.008517
Average total loss: 0.020468
tensor(0.0494, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-2.5708e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.011367
Average KL loss: 0.008527
Average total loss: 0.019894
tensor(0.0495, device='cuda:0') tensor(0.1141, device='cuda:0') tensor(-3.1640e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.011836
Average KL loss: 0.008537
Average total loss: 0.020373
tensor(0.0495, device='cuda:0') tensor(0.1144, device='cuda:0') tensor(-3.6005e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.012376
Average KL loss: 0.008548
Average total loss: 0.020924
tensor(0.0496, device='cuda:0') tensor(0.1148, device='cuda:0') tensor(-1.8272e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.010705
Average KL loss: 0.008558
Average total loss: 0.019263
tensor(0.0496, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-3.2955e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.011287
Average KL loss: 0.008568
Average total loss: 0.019855
tensor(0.0496, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-1.2625e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.009965
Average KL loss: 0.008577
Average total loss: 0.018543
tensor(0.0497, device='cuda:0') tensor(0.1157, device='cuda:0') tensor(-2.2182e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.010234
Average KL loss: 0.008587
Average total loss: 0.018821
tensor(0.0497, device='cuda:0') tensor(0.1160, device='cuda:0') tensor(-4.0766e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.010259
Average KL loss: 0.008597
Average total loss: 0.018856
tensor(0.0498, device='cuda:0') tensor(0.1163, device='cuda:0') tensor(-1.1210e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.009577
Average KL loss: 0.008607
Average total loss: 0.018184
tensor(0.0498, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(-9.9702e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.009874
Average KL loss: 0.008615
Average total loss: 0.018489
tensor(0.0498, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-1.2474e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.009628
Average KL loss: 0.008623
Average total loss: 0.018251
tensor(0.0499, device='cuda:0') tensor(0.1172, device='cuda:0') tensor(-6.7263e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.010313
Average KL loss: 0.008633
Average total loss: 0.018946
tensor(0.0499, device='cuda:0') tensor(0.1175, device='cuda:0') tensor(-1.6376e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.009321
Average KL loss: 0.008642
Average total loss: 0.017963
tensor(0.0499, device='cuda:0') tensor(0.1177, device='cuda:0') tensor(-1.1372e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.009535
Average KL loss: 0.008651
Average total loss: 0.018186
tensor(0.0500, device='cuda:0') tensor(0.1180, device='cuda:0') tensor(-2.0713e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.009825
Average KL loss: 0.008660
Average total loss: 0.018485
tensor(0.0500, device='cuda:0') tensor(0.1183, device='cuda:0') tensor(-3.2143e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.010402
Average KL loss: 0.008669
Average total loss: 0.019071
tensor(0.0501, device='cuda:0') tensor(0.1187, device='cuda:0') tensor(-2.9682e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.009335
Average KL loss: 0.008679
Average total loss: 0.018013
tensor(0.0501, device='cuda:0') tensor(0.1190, device='cuda:0') tensor(-9.9437e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.008675
Average KL loss: 0.008688
Average total loss: 0.017363
tensor(0.0501, device='cuda:0') tensor(0.1192, device='cuda:0') tensor(-2.1680e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.009540
Average KL loss: 0.008696
Average total loss: 0.018236
tensor(0.0502, device='cuda:0') tensor(0.1195, device='cuda:0') tensor(-1.2868e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.009630
Average KL loss: 0.008705
Average total loss: 0.018335
tensor(0.0502, device='cuda:0') tensor(0.1198, device='cuda:0') tensor(-7.8767e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.008280
Average KL loss: 0.008713
Average total loss: 0.016993
tensor(0.0502, device='cuda:0') tensor(0.1201, device='cuda:0') tensor(-8.3267e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.008035
Average KL loss: 0.008721
Average total loss: 0.016756
tensor(0.0503, device='cuda:0') tensor(0.1204, device='cuda:0') tensor(-2.0477e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.009492
Average KL loss: 0.008729
Average total loss: 0.018221
tensor(0.0503, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-9.3077e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.009347
Average KL loss: 0.008738
Average total loss: 0.018085
tensor(0.0503, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-1.8607e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.008933
Average KL loss: 0.008746
Average total loss: 0.017679
tensor(0.0504, device='cuda:0') tensor(0.1213, device='cuda:0') tensor(-5.5430e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.008889
Average KL loss: 0.008755
Average total loss: 0.017644
tensor(0.0504, device='cuda:0') tensor(0.1216, device='cuda:0') tensor(-1.9000e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.008347
Average KL loss: 0.008764
Average total loss: 0.017111
tensor(0.0505, device='cuda:0') tensor(0.1219, device='cuda:0') tensor(-1.1714e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.008327
Average KL loss: 0.008773
Average total loss: 0.017100
tensor(0.0505, device='cuda:0') tensor(0.1222, device='cuda:0') tensor(-4.6408e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.008228
Average KL loss: 0.008781
Average total loss: 0.017009
tensor(0.0505, device='cuda:0') tensor(0.1225, device='cuda:0') tensor(-1.0642e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.008246
Average KL loss: 0.008788
Average total loss: 0.017035
tensor(0.0506, device='cuda:0') tensor(0.1228, device='cuda:0') tensor(-1.7081e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.008697
Average KL loss: 0.008797
Average total loss: 0.017494
tensor(0.0506, device='cuda:0') tensor(0.1231, device='cuda:0') tensor(-7.5673e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.007914
Average KL loss: 0.008805
Average total loss: 0.016719
tensor(0.0506, device='cuda:0') tensor(0.1234, device='cuda:0') tensor(-1.5065e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.007653
Average KL loss: 0.008811
Average total loss: 0.016464
tensor(0.0507, device='cuda:0') tensor(0.1236, device='cuda:0') tensor(-7.0569e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.007427
Average KL loss: 0.008819
Average total loss: 0.016246
tensor(0.0507, device='cuda:0') tensor(0.1239, device='cuda:0') tensor(-1.2994e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.008077
Average KL loss: 0.008827
Average total loss: 0.016904
tensor(0.0507, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-1.9364e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.007827
Average KL loss: 0.008835
Average total loss: 0.016663
tensor(0.0508, device='cuda:0') tensor(0.1245, device='cuda:0') tensor(-4.5849e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.007793
Average KL loss: 0.008844
Average total loss: 0.016637
tensor(0.0508, device='cuda:0') tensor(0.1248, device='cuda:0') tensor(-3.9146e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.007218
Average KL loss: 0.008852
Average total loss: 0.016070
tensor(0.0508, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-1.5427e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.006941
Average KL loss: 0.008859
Average total loss: 0.015800
tensor(0.0509, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-5.9755e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.007539
Average KL loss: 0.008866
Average total loss: 0.016405
tensor(0.0509, device='cuda:0') tensor(0.1256, device='cuda:0') tensor(-7.0947e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.006799
Average KL loss: 0.008873
Average total loss: 0.015672
tensor(0.0509, device='cuda:0') tensor(0.1259, device='cuda:0') tensor(-1.8159e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.007066
Average KL loss: 0.008879
Average total loss: 0.015946
tensor(0.0509, device='cuda:0') tensor(0.1261, device='cuda:0') tensor(-3.0533e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.006663
Average KL loss: 0.008886
Average total loss: 0.015548
tensor(0.0510, device='cuda:0') tensor(0.1264, device='cuda:0') tensor(-3.0755e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.007356
Average KL loss: 0.008892
Average total loss: 0.016248
tensor(0.0510, device='cuda:0') tensor(0.1266, device='cuda:0') tensor(-2.6129e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.006918
Average KL loss: 0.008899
Average total loss: 0.015817
tensor(0.0510, device='cuda:0') tensor(0.1269, device='cuda:0') tensor(-2.9062e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.006510
Average KL loss: 0.008906
Average total loss: 0.015416
tensor(0.0511, device='cuda:0') tensor(0.1272, device='cuda:0') tensor(-1.3148e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.006889
Average KL loss: 0.008913
Average total loss: 0.015802
tensor(0.0511, device='cuda:0') tensor(0.1275, device='cuda:0') tensor(-5.2529e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.006922
Average KL loss: 0.008920
Average total loss: 0.015843
tensor(0.0511, device='cuda:0') tensor(0.1277, device='cuda:0') tensor(-4.4733e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.006283
Average KL loss: 0.008928
Average total loss: 0.015210
tensor(0.0511, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(-8.8172e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.006419
Average KL loss: 0.008934
Average total loss: 0.015353
tensor(0.0512, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-1.3318e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.006002
Average KL loss: 0.008940
Average total loss: 0.014941
tensor(0.0512, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-1.7488e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.006666
Average KL loss: 0.008946
Average total loss: 0.015612
tensor(0.0512, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-1.0282e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.006448
Average KL loss: 0.008953
Average total loss: 0.015401
tensor(0.0513, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-2.0484e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.006670
Average KL loss: 0.008960
Average total loss: 0.015630
tensor(0.0513, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-2.2492e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.005689
Average KL loss: 0.008967
Average total loss: 0.014655
tensor(0.0513, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-6.2079e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.005820
Average KL loss: 0.008972
Average total loss: 0.014791
tensor(0.0513, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-1.0298e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.006205
Average KL loss: 0.008977
Average total loss: 0.015182
tensor(0.0513, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-1.6136e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.005474
Average KL loss: 0.008983
Average total loss: 0.014457
tensor(0.0514, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-1.1470e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.006723
Average KL loss: 0.008989
Average total loss: 0.015711
tensor(0.0514, device='cuda:0') tensor(0.1305, device='cuda:0') tensor(-5.5159e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.006299
Average KL loss: 0.008995
Average total loss: 0.015295
tensor(0.0514, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-2.6869e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.005764
Average KL loss: 0.009002
Average total loss: 0.014766
tensor(0.0515, device='cuda:0') tensor(0.1311, device='cuda:0') tensor(-9.3375e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.005350
Average KL loss: 0.009008
Average total loss: 0.014358
tensor(0.0515, device='cuda:0') tensor(0.1313, device='cuda:0') tensor(-6.5331e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.005338
Average KL loss: 0.009014
Average total loss: 0.014352
tensor(0.0515, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-6.2801e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.005500
Average KL loss: 0.009020
Average total loss: 0.014520
tensor(0.0515, device='cuda:0') tensor(0.1318, device='cuda:0') tensor(-1.2896e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.005498
Average KL loss: 0.009025
Average total loss: 0.014523
tensor(0.0516, device='cuda:0') tensor(0.1321, device='cuda:0') tensor(-9.3901e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.005961
Average KL loss: 0.009031
Average total loss: 0.014992
tensor(0.0516, device='cuda:0') tensor(0.1323, device='cuda:0') tensor(-6.3193e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.005620
Average KL loss: 0.009037
Average total loss: 0.014657
tensor(0.0516, device='cuda:0') tensor(0.1326, device='cuda:0') tensor(-2.4470e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.005654
Average KL loss: 0.009043
Average total loss: 0.014696
tensor(0.0516, device='cuda:0') tensor(0.1328, device='cuda:0') tensor(-2.0401e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.005466
Average KL loss: 0.009049
Average total loss: 0.014515
tensor(0.0517, device='cuda:0') tensor(0.1331, device='cuda:0') tensor(-2.0937e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.005534
Average KL loss: 0.009056
Average total loss: 0.014590
tensor(0.0517, device='cuda:0') tensor(0.1334, device='cuda:0') tensor(-6.1921e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.005008
Average KL loss: 0.009061
Average total loss: 0.014069
tensor(0.0517, device='cuda:0') tensor(0.1336, device='cuda:0') tensor(-2.5271e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.005066
Average KL loss: 0.009067
Average total loss: 0.014133
tensor(0.0517, device='cuda:0') tensor(0.1339, device='cuda:0') tensor(-1.5164e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.005754
Average KL loss: 0.009072
Average total loss: 0.014826
tensor(0.0517, device='cuda:0') tensor(0.1341, device='cuda:0') tensor(2.2800e-11, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.005196
Average KL loss: 0.009077
Average total loss: 0.014273
tensor(0.0518, device='cuda:0') tensor(0.1343, device='cuda:0') tensor(-1.7738e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.004995
Average KL loss: 0.009081
Average total loss: 0.014076
tensor(0.0518, device='cuda:0') tensor(0.1346, device='cuda:0') tensor(-7.0249e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.004939
Average KL loss: 0.009086
Average total loss: 0.014025
tensor(0.0518, device='cuda:0') tensor(0.1348, device='cuda:0') tensor(-6.8168e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.004948
Average KL loss: 0.009091
Average total loss: 0.014038
tensor(0.0518, device='cuda:0') tensor(0.1350, device='cuda:0') tensor(-1.9676e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.004744
Average KL loss: 0.009096
Average total loss: 0.013840
tensor(0.0518, device='cuda:0') tensor(0.1352, device='cuda:0') tensor(-1.6452e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.005447
Average KL loss: 0.009101
Average total loss: 0.014548
tensor(0.0519, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-3.5605e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.004459
Average KL loss: 0.009105
Average total loss: 0.013564
tensor(0.0519, device='cuda:0') tensor(0.1357, device='cuda:0') tensor(-2.8891e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.005416
Average KL loss: 0.009110
Average total loss: 0.014526
tensor(0.0519, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(-8.3163e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.004852
Average KL loss: 0.009116
Average total loss: 0.013969
tensor(0.0519, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(3.4586e-11, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.004599
Average KL loss: 0.009120
Average total loss: 0.013719
tensor(0.0519, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(-6.9864e-11, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.004930
Average KL loss: 0.009124
Average total loss: 0.014054
tensor(0.0519, device='cuda:0') tensor(0.1366, device='cuda:0') tensor(-9.1033e-12, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.004175
Average KL loss: 0.009128
Average total loss: 0.013303
tensor(0.0520, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-4.4001e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.004655
Average KL loss: 0.009131
Average total loss: 0.013786
tensor(0.0520, device='cuda:0') tensor(0.1370, device='cuda:0') tensor(-1.1321e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.004340
Average KL loss: 0.009135
Average total loss: 0.013476
tensor(0.0520, device='cuda:0') tensor(0.1373, device='cuda:0') tensor(-4.3548e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.003842
Average KL loss: 0.009139
Average total loss: 0.012981
tensor(0.0520, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-1.9070e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.005227
Average KL loss: 0.009143
Average total loss: 0.014370
tensor(0.0520, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(-5.3804e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.003867
Average KL loss: 0.009148
Average total loss: 0.013015
tensor(0.0520, device='cuda:0') tensor(0.1379, device='cuda:0') tensor(-1.1225e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.004439
Average KL loss: 0.009151
Average total loss: 0.013590
tensor(0.0521, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(-1.2494e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.004708
Average KL loss: 0.009155
Average total loss: 0.013863
tensor(0.0521, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(7.3276e-11, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.004574
Average KL loss: 0.009160
Average total loss: 0.013734
tensor(0.0521, device='cuda:0') tensor(0.1386, device='cuda:0') tensor(-1.7370e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.004629
Average KL loss: 0.009165
Average total loss: 0.013795
tensor(0.0521, device='cuda:0') tensor(0.1389, device='cuda:0') tensor(-1.0995e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.004195
Average KL loss: 0.009169
Average total loss: 0.013365
tensor(0.0521, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(-4.4469e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.004472
Average KL loss: 0.009174
Average total loss: 0.013646
tensor(0.0522, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-8.3534e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.004410
Average KL loss: 0.009179
Average total loss: 0.013589
tensor(0.0522, device='cuda:0') tensor(0.1396, device='cuda:0') tensor(-1.3158e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.004375
Average KL loss: 0.009184
Average total loss: 0.013558
tensor(0.0522, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(-6.3736e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.004173
Average KL loss: 0.009187
Average total loss: 0.013360
tensor(0.0522, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(-2.5372e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.004172
Average KL loss: 0.009188
Average total loss: 0.013361
tensor(0.0522, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(-7.5298e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.004229
Average KL loss: 0.009189
Average total loss: 0.013418
tensor(0.0522, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(-1.0223e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.004978
Average KL loss: 0.009189
Average total loss: 0.014167
tensor(0.0522, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-3.0223e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.004571
Average KL loss: 0.009189
Average total loss: 0.013761
tensor(0.0522, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-4.7178e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.004171
Average KL loss: 0.009190
Average total loss: 0.013361
tensor(0.0522, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-1.2497e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.004451
Average KL loss: 0.009190
Average total loss: 0.013641
tensor(0.0522, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-1.4934e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.004213
Average KL loss: 0.009190
Average total loss: 0.013403
 Percentile value: 3.458294916152954
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =     918 /    1728             ( 53.12%) | total_pruned =     810 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1472 /   36864             (  3.99%) | total_pruned =   35392 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1575 /   36864             (  4.27%) | total_pruned =   35289 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1527 /   36864             (  4.14%) | total_pruned =   35337 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1583 /   36864             (  4.29%) | total_pruned =   35281 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2484 /   73728             (  3.37%) | total_pruned =   71244 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4142 /  147456             (  2.81%) | total_pruned =  143314 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1749 /    8192             ( 21.35%) | total_pruned =    6443 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2302 /  147456             (  1.56%) | total_pruned =  145154 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2342 /  147456             (  1.59%) | total_pruned =  145114 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7744 /  294912             (  2.63%) | total_pruned =  287168 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   11418 /  589824             (  1.94%) | total_pruned =  578406 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     161 /     256             ( 62.89%) | total_pruned =      95 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4102 /   32768             ( 12.52%) | total_pruned =   28666 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     155 /     256             ( 60.55%) | total_pruned =     101 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    4268 /  589824             (  0.72%) | total_pruned =  585556 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4072 /  589824             (  0.69%) | total_pruned =  585752 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     145 /     256             ( 56.64%) | total_pruned =     111 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   14781 / 1179648             (  1.25%) | total_pruned = 1164867 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     462 /     512             ( 90.23%) | total_pruned =      50 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    7410 / 2359296             (  0.31%) | total_pruned = 2351886 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     125 /     512             ( 24.41%) | total_pruned =     387 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3111 /  131072             (  2.37%) | total_pruned =  127961 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     481 /     512             ( 93.95%) | total_pruned =      31 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     121 /     512             ( 23.63%) | total_pruned =     391 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2976 / 2359296             (  0.13%) | total_pruned = 2356320 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     297 /     512             ( 58.01%) | total_pruned =     215 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1170 / 2359296             (  0.05%) | total_pruned = 2358126 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
linear.weight        | nonzeros =    2883 /    5120             ( 56.31%) | total_pruned =    2237 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 40/200 Loss: 0.003564 Accuracy: 82.26 100.00 % Best test Accuracy: 82.50%
tensor(0.0522, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-1.4471e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.096257
Average KL loss: 0.008592
Average total loss: 0.104849
tensor(0.0471, device='cuda:0') tensor(0.1240, device='cuda:0') tensor(-2.5368e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.100299
Average KL loss: 0.007485
Average total loss: 0.107784
tensor(0.0425, device='cuda:0') tensor(0.1128, device='cuda:0') tensor(-1.3753e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.094512
Average KL loss: 0.006544
Average total loss: 0.101057
tensor(0.0384, device='cuda:0') tensor(0.1050, device='cuda:0') tensor(-1.6531e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.088891
Average KL loss: 0.005818
Average total loss: 0.094709
tensor(0.0350, device='cuda:0') tensor(0.1002, device='cuda:0') tensor(-1.3664e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.090033
Average KL loss: 0.005325
Average total loss: 0.095357
tensor(0.0324, device='cuda:0') tensor(0.0976, device='cuda:0') tensor(-1.1217e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.088186
Average KL loss: 0.005036
Average total loss: 0.093222
tensor(0.0305, device='cuda:0') tensor(0.0966, device='cuda:0') tensor(-1.4176e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.087623
Average KL loss: 0.004893
Average total loss: 0.092516
tensor(0.0293, device='cuda:0') tensor(0.0964, device='cuda:0') tensor(-1.4084e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.082551
Average KL loss: 0.004832
Average total loss: 0.087383
tensor(0.0285, device='cuda:0') tensor(0.0966, device='cuda:0') tensor(-1.5703e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.079976
Average KL loss: 0.004810
Average total loss: 0.084786
tensor(0.0281, device='cuda:0') tensor(0.0969, device='cuda:0') tensor(-8.8400e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.082775
Average KL loss: 0.004806
Average total loss: 0.087581
tensor(0.0278, device='cuda:0') tensor(0.0973, device='cuda:0') tensor(-9.5384e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.077543
Average KL loss: 0.004809
Average total loss: 0.082352
tensor(0.0277, device='cuda:0') tensor(0.0978, device='cuda:0') tensor(-8.9658e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.076195
Average KL loss: 0.004814
Average total loss: 0.081009
tensor(0.0276, device='cuda:0') tensor(0.0982, device='cuda:0') tensor(-1.4250e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.074576
Average KL loss: 0.004819
Average total loss: 0.079396
tensor(0.0276, device='cuda:0') tensor(0.0986, device='cuda:0') tensor(-1.3465e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.075405
Average KL loss: 0.004825
Average total loss: 0.080230
tensor(0.0277, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-1.5980e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.067658
Average KL loss: 0.004831
Average total loss: 0.072489
tensor(0.0277, device='cuda:0') tensor(0.0995, device='cuda:0') tensor(-1.1506e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.071547
Average KL loss: 0.004837
Average total loss: 0.076384
tensor(0.0277, device='cuda:0') tensor(0.0999, device='cuda:0') tensor(-1.1914e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.069991
Average KL loss: 0.004843
Average total loss: 0.074834
tensor(0.0278, device='cuda:0') tensor(0.1003, device='cuda:0') tensor(-1.0033e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.067951
Average KL loss: 0.004848
Average total loss: 0.072799
tensor(0.0278, device='cuda:0') tensor(0.1007, device='cuda:0') tensor(-1.1784e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.066282
Average KL loss: 0.004854
Average total loss: 0.071135
tensor(0.0279, device='cuda:0') tensor(0.1012, device='cuda:0') tensor(-9.6790e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.065104
Average KL loss: 0.004860
Average total loss: 0.069963
tensor(0.0280, device='cuda:0') tensor(0.1016, device='cuda:0') tensor(-9.1438e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.062096
Average KL loss: 0.004865
Average total loss: 0.066962
tensor(0.0280, device='cuda:0') tensor(0.1020, device='cuda:0') tensor(-9.1470e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.062051
Average KL loss: 0.004871
Average total loss: 0.066922
tensor(0.0281, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-8.6630e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.064142
Average KL loss: 0.004876
Average total loss: 0.069018
tensor(0.0281, device='cuda:0') tensor(0.1028, device='cuda:0') tensor(-8.6133e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.054907
Average KL loss: 0.004882
Average total loss: 0.059789
tensor(0.0282, device='cuda:0') tensor(0.1032, device='cuda:0') tensor(-9.9218e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.060328
Average KL loss: 0.004887
Average total loss: 0.065215
tensor(0.0282, device='cuda:0') tensor(0.1036, device='cuda:0') tensor(-1.0048e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.058033
Average KL loss: 0.004892
Average total loss: 0.062925
tensor(0.0283, device='cuda:0') tensor(0.1040, device='cuda:0') tensor(-1.1147e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.055701
Average KL loss: 0.004897
Average total loss: 0.060598
tensor(0.0283, device='cuda:0') tensor(0.1044, device='cuda:0') tensor(-1.0177e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.054560
Average KL loss: 0.004902
Average total loss: 0.059462
tensor(0.0284, device='cuda:0') tensor(0.1048, device='cuda:0') tensor(-5.7199e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.054797
Average KL loss: 0.004907
Average total loss: 0.059704
tensor(0.0284, device='cuda:0') tensor(0.1052, device='cuda:0') tensor(-1.4626e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.057424
Average KL loss: 0.004912
Average total loss: 0.062336
tensor(0.0285, device='cuda:0') tensor(0.1056, device='cuda:0') tensor(-8.6503e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.049706
Average KL loss: 0.004917
Average total loss: 0.054623
tensor(0.0285, device='cuda:0') tensor(0.1060, device='cuda:0') tensor(-6.0851e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.052325
Average KL loss: 0.004922
Average total loss: 0.057247
tensor(0.0286, device='cuda:0') tensor(0.1064, device='cuda:0') tensor(-7.3892e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.053338
Average KL loss: 0.004927
Average total loss: 0.058266
tensor(0.0286, device='cuda:0') tensor(0.1068, device='cuda:0') tensor(-7.1924e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.049726
Average KL loss: 0.004932
Average total loss: 0.054658
tensor(0.0287, device='cuda:0') tensor(0.1072, device='cuda:0') tensor(-8.0083e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.048352
Average KL loss: 0.004937
Average total loss: 0.053288
tensor(0.0287, device='cuda:0') tensor(0.1075, device='cuda:0') tensor(-1.2286e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.047972
Average KL loss: 0.004941
Average total loss: 0.052914
tensor(0.0288, device='cuda:0') tensor(0.1079, device='cuda:0') tensor(-6.9144e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.045154
Average KL loss: 0.004946
Average total loss: 0.050100
tensor(0.0288, device='cuda:0') tensor(0.1083, device='cuda:0') tensor(-1.2364e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.046349
Average KL loss: 0.004950
Average total loss: 0.051299
tensor(0.0289, device='cuda:0') tensor(0.1087, device='cuda:0') tensor(-5.1235e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.045238
Average KL loss: 0.004955
Average total loss: 0.050192
tensor(0.0289, device='cuda:0') tensor(0.1090, device='cuda:0') tensor(-6.5305e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.043546
Average KL loss: 0.004959
Average total loss: 0.048505
tensor(0.0290, device='cuda:0') tensor(0.1094, device='cuda:0') tensor(-8.1140e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.044679
Average KL loss: 0.004963
Average total loss: 0.049642
tensor(0.0290, device='cuda:0') tensor(0.1098, device='cuda:0') tensor(-6.2591e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.043731
Average KL loss: 0.004968
Average total loss: 0.048698
tensor(0.0291, device='cuda:0') tensor(0.1102, device='cuda:0') tensor(-5.7000e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.041194
Average KL loss: 0.004972
Average total loss: 0.046166
tensor(0.0291, device='cuda:0') tensor(0.1105, device='cuda:0') tensor(-4.7868e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.040525
Average KL loss: 0.004976
Average total loss: 0.045500
tensor(0.0292, device='cuda:0') tensor(0.1109, device='cuda:0') tensor(-6.3458e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.043684
Average KL loss: 0.004980
Average total loss: 0.048664
tensor(0.0292, device='cuda:0') tensor(0.1112, device='cuda:0') tensor(-5.5924e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.039097
Average KL loss: 0.004984
Average total loss: 0.044081
tensor(0.0293, device='cuda:0') tensor(0.1116, device='cuda:0') tensor(-7.2178e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.039194
Average KL loss: 0.004988
Average total loss: 0.044182
tensor(0.0293, device='cuda:0') tensor(0.1120, device='cuda:0') tensor(-6.7762e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.039542
Average KL loss: 0.004992
Average total loss: 0.044534
tensor(0.0294, device='cuda:0') tensor(0.1123, device='cuda:0') tensor(-5.6817e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.037624
Average KL loss: 0.004996
Average total loss: 0.042620
tensor(0.0294, device='cuda:0') tensor(0.1127, device='cuda:0') tensor(-4.5141e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.036588
Average KL loss: 0.005000
Average total loss: 0.041588
tensor(0.0294, device='cuda:0') tensor(0.1130, device='cuda:0') tensor(-3.5076e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.037454
Average KL loss: 0.005003
Average total loss: 0.042457
tensor(0.0295, device='cuda:0') tensor(0.1134, device='cuda:0') tensor(-8.7203e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.036597
Average KL loss: 0.005007
Average total loss: 0.041604
tensor(0.0295, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-7.8527e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.037297
Average KL loss: 0.005011
Average total loss: 0.042308
tensor(0.0296, device='cuda:0') tensor(0.1141, device='cuda:0') tensor(-3.2197e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.034792
Average KL loss: 0.005015
Average total loss: 0.039807
tensor(0.0296, device='cuda:0') tensor(0.1144, device='cuda:0') tensor(-4.3613e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.034274
Average KL loss: 0.005019
Average total loss: 0.039292
tensor(0.0297, device='cuda:0') tensor(0.1148, device='cuda:0') tensor(-6.4825e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.033683
Average KL loss: 0.005022
Average total loss: 0.038705
tensor(0.0297, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-6.3760e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.034378
Average KL loss: 0.005026
Average total loss: 0.039404
tensor(0.0297, device='cuda:0') tensor(0.1155, device='cuda:0') tensor(-6.6161e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.033040
Average KL loss: 0.005029
Average total loss: 0.038069
tensor(0.0298, device='cuda:0') tensor(0.1158, device='cuda:0') tensor(-5.6077e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.032879
Average KL loss: 0.005033
Average total loss: 0.037912
tensor(0.0298, device='cuda:0') tensor(0.1162, device='cuda:0') tensor(-8.9366e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.031463
Average KL loss: 0.005037
Average total loss: 0.036500
tensor(0.0299, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(-5.2850e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.031346
Average KL loss: 0.005041
Average total loss: 0.036386
tensor(0.0299, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-3.1378e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.030735
Average KL loss: 0.005044
Average total loss: 0.035779
tensor(0.0300, device='cuda:0') tensor(0.1172, device='cuda:0') tensor(-6.3229e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.030941
Average KL loss: 0.005048
Average total loss: 0.035989
tensor(0.0300, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-3.1797e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.029922
Average KL loss: 0.005051
Average total loss: 0.034973
tensor(0.0301, device='cuda:0') tensor(0.1180, device='cuda:0') tensor(-5.4518e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.029198
Average KL loss: 0.005055
Average total loss: 0.034253
tensor(0.0301, device='cuda:0') tensor(0.1183, device='cuda:0') tensor(-4.9243e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.027475
Average KL loss: 0.005058
Average total loss: 0.032533
tensor(0.0301, device='cuda:0') tensor(0.1186, device='cuda:0') tensor(-5.5185e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.028798
Average KL loss: 0.005062
Average total loss: 0.033860
tensor(0.0302, device='cuda:0') tensor(0.1190, device='cuda:0') tensor(-4.6024e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.028369
Average KL loss: 0.005065
Average total loss: 0.033434
tensor(0.0302, device='cuda:0') tensor(0.1193, device='cuda:0') tensor(-6.8113e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.028621
Average KL loss: 0.005068
Average total loss: 0.033689
tensor(0.0303, device='cuda:0') tensor(0.1196, device='cuda:0') tensor(-5.8944e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.028933
Average KL loss: 0.005072
Average total loss: 0.034004
tensor(0.0303, device='cuda:0') tensor(0.1200, device='cuda:0') tensor(-4.8909e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.024633
Average KL loss: 0.005075
Average total loss: 0.029708
tensor(0.0303, device='cuda:0') tensor(0.1203, device='cuda:0') tensor(-3.3702e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.027918
Average KL loss: 0.005078
Average total loss: 0.032996
tensor(0.0304, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-5.3847e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.025606
Average KL loss: 0.005082
Average total loss: 0.030687
tensor(0.0304, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-3.3689e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.027087
Average KL loss: 0.005085
Average total loss: 0.032172
tensor(0.0305, device='cuda:0') tensor(0.1213, device='cuda:0') tensor(-3.4882e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.026882
Average KL loss: 0.005088
Average total loss: 0.031969
tensor(0.0305, device='cuda:0') tensor(0.1217, device='cuda:0') tensor(-4.0796e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.025407
Average KL loss: 0.005091
Average total loss: 0.030498
tensor(0.0306, device='cuda:0') tensor(0.1220, device='cuda:0') tensor(-2.7944e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.023673
Average KL loss: 0.005094
Average total loss: 0.028767
tensor(0.0306, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-4.1601e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.025398
Average KL loss: 0.005097
Average total loss: 0.030496
tensor(0.0306, device='cuda:0') tensor(0.1227, device='cuda:0') tensor(-5.2234e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.024866
Average KL loss: 0.005100
Average total loss: 0.029966
tensor(0.0307, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(-3.9001e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.022305
Average KL loss: 0.005103
Average total loss: 0.027408
tensor(0.0307, device='cuda:0') tensor(0.1233, device='cuda:0') tensor(-5.9324e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.022482
Average KL loss: 0.005106
Average total loss: 0.027588
tensor(0.0307, device='cuda:0') tensor(0.1237, device='cuda:0') tensor(-2.7534e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.022296
Average KL loss: 0.005109
Average total loss: 0.027405
tensor(0.0308, device='cuda:0') tensor(0.1240, device='cuda:0') tensor(-4.9563e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.022623
Average KL loss: 0.005112
Average total loss: 0.027735
tensor(0.0308, device='cuda:0') tensor(0.1243, device='cuda:0') tensor(-3.7805e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.022873
Average KL loss: 0.005115
Average total loss: 0.027987
tensor(0.0309, device='cuda:0') tensor(0.1246, device='cuda:0') tensor(-4.7232e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.024116
Average KL loss: 0.005118
Average total loss: 0.029234
tensor(0.0309, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-4.1017e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.021708
Average KL loss: 0.005121
Average total loss: 0.026829
tensor(0.0309, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-4.1297e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.022423
Average KL loss: 0.005124
Average total loss: 0.027547
tensor(0.0310, device='cuda:0') tensor(0.1257, device='cuda:0') tensor(-2.9619e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.021195
Average KL loss: 0.005127
Average total loss: 0.026322
tensor(0.0310, device='cuda:0') tensor(0.1260, device='cuda:0') tensor(-4.4037e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.022611
Average KL loss: 0.005129
Average total loss: 0.027741
tensor(0.0311, device='cuda:0') tensor(0.1263, device='cuda:0') tensor(-5.4005e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.020288
Average KL loss: 0.005132
Average total loss: 0.025420
tensor(0.0311, device='cuda:0') tensor(0.1266, device='cuda:0') tensor(-3.6103e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.021536
Average KL loss: 0.005135
Average total loss: 0.026671
tensor(0.0311, device='cuda:0') tensor(0.1270, device='cuda:0') tensor(-3.2547e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.020027
Average KL loss: 0.005138
Average total loss: 0.025164
tensor(0.0312, device='cuda:0') tensor(0.1273, device='cuda:0') tensor(-2.9025e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.019706
Average KL loss: 0.005140
Average total loss: 0.024847
tensor(0.0312, device='cuda:0') tensor(0.1276, device='cuda:0') tensor(-4.4128e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.020699
Average KL loss: 0.005143
Average total loss: 0.025842
tensor(0.0313, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(-4.2424e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.019591
Average KL loss: 0.005146
Average total loss: 0.024737
tensor(0.0313, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-3.0024e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.019394
Average KL loss: 0.005149
Average total loss: 0.024543
tensor(0.0313, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-2.9216e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.018771
Average KL loss: 0.005152
Average total loss: 0.023923
tensor(0.0314, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.4836e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.020507
Average KL loss: 0.005154
Average total loss: 0.025662
tensor(0.0314, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-3.5423e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.019704
Average KL loss: 0.005157
Average total loss: 0.024862
tensor(0.0314, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-2.9895e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.019214
Average KL loss: 0.005160
Average total loss: 0.024374
tensor(0.0315, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-3.2936e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.019175
Average KL loss: 0.005162
Average total loss: 0.024338
tensor(0.0315, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-2.3456e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.018619
Average KL loss: 0.005165
Average total loss: 0.023784
tensor(0.0316, device='cuda:0') tensor(0.1306, device='cuda:0') tensor(-2.9834e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.018712
Average KL loss: 0.005167
Average total loss: 0.023880
tensor(0.0316, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-2.4877e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.017842
Average KL loss: 0.005170
Average total loss: 0.023012
tensor(0.0316, device='cuda:0') tensor(0.1313, device='cuda:0') tensor(-3.8651e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.017852
Average KL loss: 0.005173
Average total loss: 0.023024
tensor(0.0317, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-2.9621e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.017173
Average KL loss: 0.005175
Average total loss: 0.022348
tensor(0.0317, device='cuda:0') tensor(0.1319, device='cuda:0') tensor(-2.6395e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.015982
Average KL loss: 0.005178
Average total loss: 0.021159
tensor(0.0317, device='cuda:0') tensor(0.1322, device='cuda:0') tensor(-3.5314e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.016377
Average KL loss: 0.005180
Average total loss: 0.021557
tensor(0.0318, device='cuda:0') tensor(0.1326, device='cuda:0') tensor(-2.9003e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.016111
Average KL loss: 0.005182
Average total loss: 0.021293
tensor(0.0318, device='cuda:0') tensor(0.1329, device='cuda:0') tensor(-3.0258e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.016692
Average KL loss: 0.005185
Average total loss: 0.021877
tensor(0.0319, device='cuda:0') tensor(0.1332, device='cuda:0') tensor(-3.2624e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.016096
Average KL loss: 0.005187
Average total loss: 0.021284
tensor(0.0319, device='cuda:0') tensor(0.1336, device='cuda:0') tensor(-5.3422e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.016994
Average KL loss: 0.005190
Average total loss: 0.022184
tensor(0.0319, device='cuda:0') tensor(0.1339, device='cuda:0') tensor(-1.8386e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.015444
Average KL loss: 0.005193
Average total loss: 0.020637
tensor(0.0320, device='cuda:0') tensor(0.1342, device='cuda:0') tensor(-2.8555e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.015478
Average KL loss: 0.005195
Average total loss: 0.020673
tensor(0.0320, device='cuda:0') tensor(0.1345, device='cuda:0') tensor(-2.5909e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.015025
Average KL loss: 0.005197
Average total loss: 0.020223
tensor(0.0320, device='cuda:0') tensor(0.1349, device='cuda:0') tensor(-2.4225e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.015628
Average KL loss: 0.005200
Average total loss: 0.020828
tensor(0.0321, device='cuda:0') tensor(0.1352, device='cuda:0') tensor(-1.6628e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.014147
Average KL loss: 0.005202
Average total loss: 0.019350
tensor(0.0321, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-1.4954e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.014080
Average KL loss: 0.005204
Average total loss: 0.019284
tensor(0.0322, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-2.4759e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.014811
Average KL loss: 0.005207
Average total loss: 0.020017
tensor(0.0322, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-2.1721e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.014612
Average KL loss: 0.005209
Average total loss: 0.019821
tensor(0.0322, device='cuda:0') tensor(0.1365, device='cuda:0') tensor(-2.6326e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.014406
Average KL loss: 0.005212
Average total loss: 0.019617
tensor(0.0323, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-2.5935e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.014854
Average KL loss: 0.005214
Average total loss: 0.020067
tensor(0.0323, device='cuda:0') tensor(0.1371, device='cuda:0') tensor(-2.7721e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.014060
Average KL loss: 0.005216
Average total loss: 0.019276
tensor(0.0323, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-2.1387e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.014713
Average KL loss: 0.005218
Average total loss: 0.019932
tensor(0.0324, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(-1.5561e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.012962
Average KL loss: 0.005221
Average total loss: 0.018183
tensor(0.0324, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(-1.8981e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.013476
Average KL loss: 0.005223
Average total loss: 0.018699
tensor(0.0324, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(-1.6486e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.013436
Average KL loss: 0.005225
Average total loss: 0.018661
tensor(0.0325, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(-1.1871e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.013902
Average KL loss: 0.005227
Average total loss: 0.019129
tensor(0.0325, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(-2.4303e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.012583
Average KL loss: 0.005229
Average total loss: 0.017812
tensor(0.0325, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-2.3069e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.012712
Average KL loss: 0.005231
Average total loss: 0.017943
tensor(0.0326, device='cuda:0') tensor(0.1397, device='cuda:0') tensor(-2.3985e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.012445
Average KL loss: 0.005233
Average total loss: 0.017678
tensor(0.0326, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(-1.7924e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.012361
Average KL loss: 0.005235
Average total loss: 0.017596
tensor(0.0326, device='cuda:0') tensor(0.1403, device='cuda:0') tensor(-1.0979e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.012369
Average KL loss: 0.005237
Average total loss: 0.017606
tensor(0.0327, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(-1.8627e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.011568
Average KL loss: 0.005239
Average total loss: 0.016807
tensor(0.0327, device='cuda:0') tensor(0.1409, device='cuda:0') tensor(-3.6570e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.012051
Average KL loss: 0.005241
Average total loss: 0.017292
tensor(0.0327, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(-2.5753e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.012498
Average KL loss: 0.005243
Average total loss: 0.017741
tensor(0.0328, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-1.7079e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.012049
Average KL loss: 0.005245
Average total loss: 0.017294
tensor(0.0328, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(-1.9666e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.011588
Average KL loss: 0.005247
Average total loss: 0.016835
tensor(0.0328, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-2.8706e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.011472
Average KL loss: 0.005249
Average total loss: 0.016721
tensor(0.0329, device='cuda:0') tensor(0.1424, device='cuda:0') tensor(-9.3400e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.011596
Average KL loss: 0.005251
Average total loss: 0.016847
tensor(0.0329, device='cuda:0') tensor(0.1427, device='cuda:0') tensor(-3.1838e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.011061
Average KL loss: 0.005253
Average total loss: 0.016314
tensor(0.0329, device='cuda:0') tensor(0.1430, device='cuda:0') tensor(-1.8201e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.010959
Average KL loss: 0.005255
Average total loss: 0.016214
tensor(0.0330, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-2.6479e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.011028
Average KL loss: 0.005257
Average total loss: 0.016285
tensor(0.0330, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(-2.2325e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.010670
Average KL loss: 0.005259
Average total loss: 0.015928
tensor(0.0330, device='cuda:0') tensor(0.1439, device='cuda:0') tensor(-2.1309e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.011094
Average KL loss: 0.005260
Average total loss: 0.016354
tensor(0.0331, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(-7.1313e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.010654
Average KL loss: 0.005262
Average total loss: 0.015917
tensor(0.0331, device='cuda:0') tensor(0.1445, device='cuda:0') tensor(-1.4000e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.011046
Average KL loss: 0.005264
Average total loss: 0.016310
tensor(0.0331, device='cuda:0') tensor(0.1449, device='cuda:0') tensor(-1.1347e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.010389
Average KL loss: 0.005266
Average total loss: 0.015655
tensor(0.0332, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-1.5004e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.009677
Average KL loss: 0.005268
Average total loss: 0.014945
tensor(0.0332, device='cuda:0') tensor(0.1455, device='cuda:0') tensor(-3.1230e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.010889
Average KL loss: 0.005270
Average total loss: 0.016160
tensor(0.0332, device='cuda:0') tensor(0.1458, device='cuda:0') tensor(-1.1951e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.010869
Average KL loss: 0.005272
Average total loss: 0.016141
tensor(0.0333, device='cuda:0') tensor(0.1461, device='cuda:0') tensor(-1.7652e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.010125
Average KL loss: 0.005274
Average total loss: 0.015399
tensor(0.0333, device='cuda:0') tensor(0.1464, device='cuda:0') tensor(-1.5949e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.010263
Average KL loss: 0.005276
Average total loss: 0.015539
tensor(0.0333, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-1.1420e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.010946
Average KL loss: 0.005277
Average total loss: 0.016223
tensor(0.0334, device='cuda:0') tensor(0.1470, device='cuda:0') tensor(-1.0887e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.009565
Average KL loss: 0.005279
Average total loss: 0.014844
tensor(0.0334, device='cuda:0') tensor(0.1473, device='cuda:0') tensor(-1.9101e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.009365
Average KL loss: 0.005281
Average total loss: 0.014645
tensor(0.0334, device='cuda:0') tensor(0.1476, device='cuda:0') tensor(-3.0402e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.009308
Average KL loss: 0.005283
Average total loss: 0.014590
tensor(0.0335, device='cuda:0') tensor(0.1479, device='cuda:0') tensor(-1.2603e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.008883
Average KL loss: 0.005284
Average total loss: 0.014167
tensor(0.0335, device='cuda:0') tensor(0.1482, device='cuda:0') tensor(-8.9927e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.009073
Average KL loss: 0.005286
Average total loss: 0.014359
tensor(0.0335, device='cuda:0') tensor(0.1485, device='cuda:0') tensor(-1.5233e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.008904
Average KL loss: 0.005287
Average total loss: 0.014191
tensor(0.0336, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(-1.5222e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.008949
Average KL loss: 0.005289
Average total loss: 0.014238
tensor(0.0336, device='cuda:0') tensor(0.1491, device='cuda:0') tensor(-1.8565e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.009362
Average KL loss: 0.005291
Average total loss: 0.014653
tensor(0.0336, device='cuda:0') tensor(0.1494, device='cuda:0') tensor(-7.2321e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.009147
Average KL loss: 0.005293
Average total loss: 0.014440
tensor(0.0337, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.2709e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.009207
Average KL loss: 0.005294
Average total loss: 0.014501
tensor(0.0337, device='cuda:0') tensor(0.1500, device='cuda:0') tensor(-3.0613e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.008512
Average KL loss: 0.005296
Average total loss: 0.013808
tensor(0.0337, device='cuda:0') tensor(0.1503, device='cuda:0') tensor(-9.9160e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.008901
Average KL loss: 0.005298
Average total loss: 0.014199
tensor(0.0338, device='cuda:0') tensor(0.1506, device='cuda:0') tensor(-1.2356e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.008068
Average KL loss: 0.005300
Average total loss: 0.013367
tensor(0.0338, device='cuda:0') tensor(0.1509, device='cuda:0') tensor(-6.1908e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.008487
Average KL loss: 0.005301
Average total loss: 0.013788
tensor(0.0338, device='cuda:0') tensor(0.1512, device='cuda:0') tensor(-8.7883e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.008577
Average KL loss: 0.005303
Average total loss: 0.013880
tensor(0.0339, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(-6.7381e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.008531
Average KL loss: 0.005304
Average total loss: 0.013835
tensor(0.0339, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(-6.3268e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.008064
Average KL loss: 0.005306
Average total loss: 0.013370
tensor(0.0339, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(-1.0892e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.008764
Average KL loss: 0.005308
Average total loss: 0.014071
tensor(0.0340, device='cuda:0') tensor(0.1524, device='cuda:0') tensor(-1.3089e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.008365
Average KL loss: 0.005309
Average total loss: 0.013675
tensor(0.0340, device='cuda:0') tensor(0.1527, device='cuda:0') tensor(-9.7614e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.008464
Average KL loss: 0.005311
Average total loss: 0.013775
tensor(0.0340, device='cuda:0') tensor(0.1530, device='cuda:0') tensor(-1.7697e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.008180
Average KL loss: 0.005312
Average total loss: 0.013492
tensor(0.0340, device='cuda:0') tensor(0.1533, device='cuda:0') tensor(-4.9662e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.007399
Average KL loss: 0.005314
Average total loss: 0.012713
tensor(0.0341, device='cuda:0') tensor(0.1536, device='cuda:0') tensor(-4.0280e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.007371
Average KL loss: 0.005315
Average total loss: 0.012686
tensor(0.0341, device='cuda:0') tensor(0.1539, device='cuda:0') tensor(-1.6937e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.007477
Average KL loss: 0.005317
Average total loss: 0.012794
tensor(0.0341, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(-1.1797e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.007855
Average KL loss: 0.005318
Average total loss: 0.013174
tensor(0.0342, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(-1.0788e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.007377
Average KL loss: 0.005320
Average total loss: 0.012697
tensor(0.0342, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(-1.6825e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.007841
Average KL loss: 0.005321
Average total loss: 0.013162
tensor(0.0342, device='cuda:0') tensor(0.1551, device='cuda:0') tensor(-8.9935e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.008387
Average KL loss: 0.005323
Average total loss: 0.013709
tensor(0.0343, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-1.3091e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.006773
Average KL loss: 0.005324
Average total loss: 0.012098
tensor(0.0343, device='cuda:0') tensor(0.1557, device='cuda:0') tensor(-9.9794e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.007466
Average KL loss: 0.005326
Average total loss: 0.012792
tensor(0.0343, device='cuda:0') tensor(0.1560, device='cuda:0') tensor(-1.6272e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.007029
Average KL loss: 0.005327
Average total loss: 0.012356
tensor(0.0344, device='cuda:0') tensor(0.1563, device='cuda:0') tensor(-1.1165e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.007157
Average KL loss: 0.005329
Average total loss: 0.012486
tensor(0.0344, device='cuda:0') tensor(0.1566, device='cuda:0') tensor(-1.6849e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.007349
Average KL loss: 0.005330
Average total loss: 0.012679
tensor(0.0344, device='cuda:0') tensor(0.1569, device='cuda:0') tensor(-1.0149e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.006873
Average KL loss: 0.005332
Average total loss: 0.012205
tensor(0.0344, device='cuda:0') tensor(0.1572, device='cuda:0') tensor(-1.6519e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.006955
Average KL loss: 0.005333
Average total loss: 0.012288
tensor(0.0345, device='cuda:0') tensor(0.1575, device='cuda:0') tensor(-5.7128e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.006953
Average KL loss: 0.005334
Average total loss: 0.012288
tensor(0.0345, device='cuda:0') tensor(0.1578, device='cuda:0') tensor(-1.1317e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.006706
Average KL loss: 0.005336
Average total loss: 0.012042
tensor(0.0345, device='cuda:0') tensor(0.1581, device='cuda:0') tensor(-6.1500e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.006106
Average KL loss: 0.005337
Average total loss: 0.011443
tensor(0.0346, device='cuda:0') tensor(0.1583, device='cuda:0') tensor(-1.4081e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.006455
Average KL loss: 0.005338
Average total loss: 0.011793
tensor(0.0346, device='cuda:0') tensor(0.1586, device='cuda:0') tensor(-1.5291e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.006064
Average KL loss: 0.005339
Average total loss: 0.011403
tensor(0.0346, device='cuda:0') tensor(0.1589, device='cuda:0') tensor(-1.0614e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.006398
Average KL loss: 0.005341
Average total loss: 0.011739
tensor(0.0346, device='cuda:0') tensor(0.1592, device='cuda:0') tensor(-1.2136e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.006495
Average KL loss: 0.005342
Average total loss: 0.011837
tensor(0.0347, device='cuda:0') tensor(0.1595, device='cuda:0') tensor(-4.8177e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.006685
Average KL loss: 0.005344
Average total loss: 0.012028
tensor(0.0347, device='cuda:0') tensor(0.1598, device='cuda:0') tensor(-4.8444e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.006327
Average KL loss: 0.005345
Average total loss: 0.011672
tensor(0.0347, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(-7.5016e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.006002
Average KL loss: 0.005346
Average total loss: 0.011348
tensor(0.0348, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(-1.3140e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.006516
Average KL loss: 0.005347
Average total loss: 0.011864
 Percentile value: 5.734107875823975
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     809 /    1728             ( 46.82%) | total_pruned =     919 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     498 /   36864             (  1.35%) | total_pruned =   36366 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     588 /   36864             (  1.60%) | total_pruned =   36276 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     567 /   36864             (  1.54%) | total_pruned =   36297 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     586 /   36864             (  1.59%) | total_pruned =   36278 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     846 /   73728             (  1.15%) | total_pruned =   72882 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1276 /  147456             (  0.87%) | total_pruned =  146180 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     894 /    8192             ( 10.91%) | total_pruned =    7298 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     725 /  147456             (  0.49%) | total_pruned =  146731 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     650 /  147456             (  0.44%) | total_pruned =  146806 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1980 /  294912             (  0.67%) | total_pruned =  292932 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     185 /     256             ( 72.27%) | total_pruned =      71 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2283 /  589824             (  0.39%) | total_pruned =  587541 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      89 /     256             ( 34.77%) | total_pruned =     167 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1366 /   32768             (  4.17%) | total_pruned =   31402 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     922 /  589824             (  0.16%) | total_pruned =  588902 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     119 /     256             ( 46.48%) | total_pruned =     137 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     864 /  589824             (  0.15%) | total_pruned =  588960 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2361 / 1179648             (  0.20%) | total_pruned = 1177287 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     340 /     512             ( 66.41%) | total_pruned =     172 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1284 / 2359296             (  0.05%) | total_pruned = 2358012 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     483 /     512             ( 94.34%) | total_pruned =      29 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     622 /  131072             (  0.47%) | total_pruned =  130450 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     405 /     512             ( 79.10%) | total_pruned =     107 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      27 /     512             (  5.27%) | total_pruned =     485 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     746 / 2359296             (  0.03%) | total_pruned = 2358550 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     211 /     512             ( 41.21%) | total_pruned =     301 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     236 / 2359296             (  0.01%) | total_pruned = 2359060 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     467 /     512             ( 91.21%) | total_pruned =      45 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
linear.weight        | nonzeros =    1613 /    5120             ( 31.50%) | total_pruned =    3507 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 199/200 Loss: 0.167531 Accuracy: 71.61 99.10 % Best test Accuracy: 74.12%
tensor(0.0348, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(-2.5087e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.246214
Average KL loss: 0.005277
Average total loss: 0.251491
tensor(0.0335, device='cuda:0') tensor(0.1511, device='cuda:0') tensor(-8.4021e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.253796
Average KL loss: 0.005114
Average total loss: 0.258910
tensor(0.0321, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-1.9218e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.254094
Average KL loss: 0.004917
Average total loss: 0.259011
tensor(0.0306, device='cuda:0') tensor(0.1332, device='cuda:0') tensor(-1.2596e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.245624
Average KL loss: 0.004680
Average total loss: 0.250304
tensor(0.0290, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-1.2882e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.245687
Average KL loss: 0.004400
Average total loss: 0.250087
tensor(0.0272, device='cuda:0') tensor(0.1155, device='cuda:0') tensor(-1.4671e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.235978
Average KL loss: 0.004078
Average total loss: 0.240056
tensor(0.0254, device='cuda:0') tensor(0.1072, device='cuda:0') tensor(-1.6724e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.238444
Average KL loss: 0.003721
Average total loss: 0.242166
tensor(0.0235, device='cuda:0') tensor(0.0995, device='cuda:0') tensor(-2.0584e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.228693
Average KL loss: 0.003346
Average total loss: 0.232039
tensor(0.0216, device='cuda:0') tensor(0.0929, device='cuda:0') tensor(-1.4526e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.223892
Average KL loss: 0.002971
Average total loss: 0.226863
tensor(0.0198, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-2.0533e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.236516
Average KL loss: 0.002623
Average total loss: 0.239139
tensor(0.0182, device='cuda:0') tensor(0.0832, device='cuda:0') tensor(-9.9487e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.231154
Average KL loss: 0.002323
Average total loss: 0.233477
tensor(0.0168, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(-1.1582e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.209810
Average KL loss: 0.002090
Average total loss: 0.211901
tensor(0.0157, device='cuda:0') tensor(0.0785, device='cuda:0') tensor(-1.0754e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.221720
Average KL loss: 0.001932
Average total loss: 0.223652
tensor(0.0148, device='cuda:0') tensor(0.0775, device='cuda:0') tensor(-1.7510e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.217993
Average KL loss: 0.001841
Average total loss: 0.219834
tensor(0.0143, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(-2.2063e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.221974
Average KL loss: 0.001796
Average total loss: 0.223770
tensor(0.0139, device='cuda:0') tensor(0.0771, device='cuda:0') tensor(-1.2582e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.212999
Average KL loss: 0.001775
Average total loss: 0.214774
tensor(0.0137, device='cuda:0') tensor(0.0771, device='cuda:0') tensor(-1.2300e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.215928
Average KL loss: 0.001764
Average total loss: 0.217692
tensor(0.0136, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(-1.2250e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.204921
Average KL loss: 0.001758
Average total loss: 0.206679
tensor(0.0135, device='cuda:0') tensor(0.0774, device='cuda:0') tensor(-9.3608e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.208250
Average KL loss: 0.001754
Average total loss: 0.210004
tensor(0.0134, device='cuda:0') tensor(0.0775, device='cuda:0') tensor(-3.1849e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.201655
Average KL loss: 0.001751
Average total loss: 0.203406
tensor(0.0134, device='cuda:0') tensor(0.0776, device='cuda:0') tensor(-1.5017e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.201797
Average KL loss: 0.001748
Average total loss: 0.203544
tensor(0.0134, device='cuda:0') tensor(0.0778, device='cuda:0') tensor(-1.6365e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.215769
Average KL loss: 0.001745
Average total loss: 0.217514
tensor(0.0134, device='cuda:0') tensor(0.0779, device='cuda:0') tensor(-1.4683e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.204438
Average KL loss: 0.001743
Average total loss: 0.206180
tensor(0.0134, device='cuda:0') tensor(0.0781, device='cuda:0') tensor(-9.2935e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.200573
Average KL loss: 0.001741
Average total loss: 0.202314
tensor(0.0134, device='cuda:0') tensor(0.0783, device='cuda:0') tensor(-1.9094e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.196902
Average KL loss: 0.001739
Average total loss: 0.198641
tensor(0.0134, device='cuda:0') tensor(0.0785, device='cuda:0') tensor(-1.0928e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.192510
Average KL loss: 0.001737
Average total loss: 0.194247
tensor(0.0134, device='cuda:0') tensor(0.0787, device='cuda:0') tensor(-8.4416e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.191144
Average KL loss: 0.001736
Average total loss: 0.192880
tensor(0.0134, device='cuda:0') tensor(0.0789, device='cuda:0') tensor(-1.1195e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.189633
Average KL loss: 0.001735
Average total loss: 0.191368
tensor(0.0134, device='cuda:0') tensor(0.0790, device='cuda:0') tensor(-6.8818e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.188395
Average KL loss: 0.001733
Average total loss: 0.190128
tensor(0.0134, device='cuda:0') tensor(0.0792, device='cuda:0') tensor(-1.0777e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.193729
Average KL loss: 0.001732
Average total loss: 0.195461
tensor(0.0135, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-7.3003e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.191264
Average KL loss: 0.001731
Average total loss: 0.192995
tensor(0.0135, device='cuda:0') tensor(0.0796, device='cuda:0') tensor(-2.2250e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.190265
Average KL loss: 0.001730
Average total loss: 0.191996
tensor(0.0135, device='cuda:0') tensor(0.0798, device='cuda:0') tensor(-1.4826e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.181024
Average KL loss: 0.001730
Average total loss: 0.182754
tensor(0.0135, device='cuda:0') tensor(0.0800, device='cuda:0') tensor(-7.2573e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.184389
Average KL loss: 0.001729
Average total loss: 0.186119
tensor(0.0135, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(-8.7499e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.178551
Average KL loss: 0.001729
Average total loss: 0.180280
tensor(0.0135, device='cuda:0') tensor(0.0805, device='cuda:0') tensor(-6.7625e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.183306
Average KL loss: 0.001728
Average total loss: 0.185035
tensor(0.0135, device='cuda:0') tensor(0.0807, device='cuda:0') tensor(-7.1081e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.194948
Average KL loss: 0.001728
Average total loss: 0.196676
tensor(0.0135, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-7.6507e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.175273
Average KL loss: 0.001728
Average total loss: 0.177001
tensor(0.0136, device='cuda:0') tensor(0.0811, device='cuda:0') tensor(-1.2530e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.187877
Average KL loss: 0.001728
Average total loss: 0.189605
tensor(0.0136, device='cuda:0') tensor(0.0813, device='cuda:0') tensor(-6.4524e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.177749
Average KL loss: 0.001728
Average total loss: 0.179477
tensor(0.0136, device='cuda:0') tensor(0.0816, device='cuda:0') tensor(-5.2565e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.172002
Average KL loss: 0.001728
Average total loss: 0.173729
tensor(0.0136, device='cuda:0') tensor(0.0818, device='cuda:0') tensor(-4.0480e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.169329
Average KL loss: 0.001728
Average total loss: 0.171056
tensor(0.0136, device='cuda:0') tensor(0.0820, device='cuda:0') tensor(-1.2242e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.173643
Average KL loss: 0.001727
Average total loss: 0.175371
tensor(0.0136, device='cuda:0') tensor(0.0822, device='cuda:0') tensor(-9.6126e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.173598
Average KL loss: 0.001727
Average total loss: 0.175325
tensor(0.0137, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(-2.3123e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.179140
Average KL loss: 0.001727
Average total loss: 0.180867
tensor(0.0137, device='cuda:0') tensor(0.0827, device='cuda:0') tensor(-6.6303e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.171004
Average KL loss: 0.001727
Average total loss: 0.172731
tensor(0.0137, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(-1.0908e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.167224
Average KL loss: 0.001727
Average total loss: 0.168951
tensor(0.0137, device='cuda:0') tensor(0.0831, device='cuda:0') tensor(-1.1159e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.172835
Average KL loss: 0.001727
Average total loss: 0.174562
tensor(0.0137, device='cuda:0') tensor(0.0833, device='cuda:0') tensor(-6.8974e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.166876
Average KL loss: 0.001727
Average total loss: 0.168603
tensor(0.0137, device='cuda:0') tensor(0.0835, device='cuda:0') tensor(-1.3109e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.168863
Average KL loss: 0.001727
Average total loss: 0.170590
tensor(0.0138, device='cuda:0') tensor(0.0837, device='cuda:0') tensor(-8.6120e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.166306
Average KL loss: 0.001727
Average total loss: 0.168033
tensor(0.0138, device='cuda:0') tensor(0.0839, device='cuda:0') tensor(-1.5612e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.163609
Average KL loss: 0.001727
Average total loss: 0.165336
tensor(0.0138, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(-7.1747e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.156129
Average KL loss: 0.001727
Average total loss: 0.157856
tensor(0.0138, device='cuda:0') tensor(0.0844, device='cuda:0') tensor(-1.6242e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.167317
Average KL loss: 0.001727
Average total loss: 0.169044
tensor(0.0138, device='cuda:0') tensor(0.0846, device='cuda:0') tensor(-4.2172e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.156758
Average KL loss: 0.001728
Average total loss: 0.158486
tensor(0.0138, device='cuda:0') tensor(0.0848, device='cuda:0') tensor(-9.6101e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.162298
Average KL loss: 0.001728
Average total loss: 0.164026
tensor(0.0139, device='cuda:0') tensor(0.0850, device='cuda:0') tensor(-5.5257e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.161294
Average KL loss: 0.001728
Average total loss: 0.163022
tensor(0.0139, device='cuda:0') tensor(0.0852, device='cuda:0') tensor(-9.1021e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.155070
Average KL loss: 0.001728
Average total loss: 0.156798
tensor(0.0139, device='cuda:0') tensor(0.0854, device='cuda:0') tensor(-4.1112e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.162274
Average KL loss: 0.001728
Average total loss: 0.164002
tensor(0.0139, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-5.0799e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.148793
Average KL loss: 0.001728
Average total loss: 0.150521
tensor(0.0139, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-1.2064e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.157099
Average KL loss: 0.001729
Average total loss: 0.158828
tensor(0.0139, device='cuda:0') tensor(0.0861, device='cuda:0') tensor(-6.8383e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.159055
Average KL loss: 0.001729
Average total loss: 0.160783
tensor(0.0140, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-4.0016e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.158311
Average KL loss: 0.001729
Average total loss: 0.160040
tensor(0.0140, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-1.1045e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.147945
Average KL loss: 0.001729
Average total loss: 0.149675
tensor(0.0140, device='cuda:0') tensor(0.0867, device='cuda:0') tensor(-5.7156e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.152202
Average KL loss: 0.001729
Average total loss: 0.153932
tensor(0.0140, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(-8.9506e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.152123
Average KL loss: 0.001730
Average total loss: 0.153852
tensor(0.0140, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-4.7322e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.152687
Average KL loss: 0.001730
Average total loss: 0.154417
tensor(0.0140, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-9.9866e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.153704
Average KL loss: 0.001730
Average total loss: 0.155434
tensor(0.0141, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(-5.6281e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.143774
Average KL loss: 0.001730
Average total loss: 0.145504
tensor(0.0141, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-5.1618e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.147429
Average KL loss: 0.001730
Average total loss: 0.149159
tensor(0.0141, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(-6.5853e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.144462
Average KL loss: 0.001730
Average total loss: 0.146192
tensor(0.0141, device='cuda:0') tensor(0.0882, device='cuda:0') tensor(-9.7086e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.143995
Average KL loss: 0.001731
Average total loss: 0.145726
tensor(0.0141, device='cuda:0') tensor(0.0884, device='cuda:0') tensor(-7.2145e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.143520
Average KL loss: 0.001731
Average total loss: 0.145251
tensor(0.0141, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-1.3080e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.149043
Average KL loss: 0.001731
Average total loss: 0.150774
tensor(0.0142, device='cuda:0') tensor(0.0888, device='cuda:0') tensor(-9.5138e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.149505
Average KL loss: 0.001731
Average total loss: 0.151236
tensor(0.0142, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(-1.9109e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.147758
Average KL loss: 0.001731
Average total loss: 0.149489
tensor(0.0142, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-5.8802e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.150758
Average KL loss: 0.001732
Average total loss: 0.152490
tensor(0.0142, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-7.3173e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.139999
Average KL loss: 0.001732
Average total loss: 0.141731
tensor(0.0142, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(-9.8288e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.147492
Average KL loss: 0.001732
Average total loss: 0.149224
tensor(0.0143, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(-1.1801e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.142470
Average KL loss: 0.001732
Average total loss: 0.144202
tensor(0.0143, device='cuda:0') tensor(0.0901, device='cuda:0') tensor(-2.6670e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.142226
Average KL loss: 0.001732
Average total loss: 0.143959
tensor(0.0143, device='cuda:0') tensor(0.0903, device='cuda:0') tensor(-7.0589e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.149130
Average KL loss: 0.001733
Average total loss: 0.150863
tensor(0.0143, device='cuda:0') tensor(0.0905, device='cuda:0') tensor(-3.9059e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.129834
Average KL loss: 0.001733
Average total loss: 0.131567
tensor(0.0143, device='cuda:0') tensor(0.0907, device='cuda:0') tensor(-6.3195e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.134332
Average KL loss: 0.001733
Average total loss: 0.136065
tensor(0.0143, device='cuda:0') tensor(0.0909, device='cuda:0') tensor(-3.7691e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.137037
Average KL loss: 0.001733
Average total loss: 0.138770
tensor(0.0143, device='cuda:0') tensor(0.0911, device='cuda:0') tensor(-1.0417e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.141977
Average KL loss: 0.001733
Average total loss: 0.143710
tensor(0.0144, device='cuda:0') tensor(0.0913, device='cuda:0') tensor(-5.4621e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.151095
Average KL loss: 0.001734
Average total loss: 0.152829
tensor(0.0144, device='cuda:0') tensor(0.0915, device='cuda:0') tensor(-5.2749e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.141932
Average KL loss: 0.001734
Average total loss: 0.143666
tensor(0.0144, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-7.2452e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.131466
Average KL loss: 0.001734
Average total loss: 0.133200
tensor(0.0144, device='cuda:0') tensor(0.0920, device='cuda:0') tensor(-4.0796e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.137031
Average KL loss: 0.001734
Average total loss: 0.138765
tensor(0.0144, device='cuda:0') tensor(0.0922, device='cuda:0') tensor(-4.4514e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.133997
Average KL loss: 0.001734
Average total loss: 0.135732
tensor(0.0144, device='cuda:0') tensor(0.0924, device='cuda:0') tensor(-6.2572e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.138144
Average KL loss: 0.001735
Average total loss: 0.139878
tensor(0.0145, device='cuda:0') tensor(0.0926, device='cuda:0') tensor(-3.0006e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.130743
Average KL loss: 0.001735
Average total loss: 0.132477
tensor(0.0145, device='cuda:0') tensor(0.0928, device='cuda:0') tensor(-6.2935e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.129838
Average KL loss: 0.001735
Average total loss: 0.131573
tensor(0.0145, device='cuda:0') tensor(0.0930, device='cuda:0') tensor(-4.7868e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.127077
Average KL loss: 0.001735
Average total loss: 0.128812
tensor(0.0145, device='cuda:0') tensor(0.0930, device='cuda:0') tensor(-4.0808e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.131785
Average KL loss: 0.001735
Average total loss: 0.133520
tensor(0.0145, device='cuda:0') tensor(0.0930, device='cuda:0') tensor(-2.1058e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.132732
Average KL loss: 0.001735
Average total loss: 0.134467
tensor(0.0145, device='cuda:0') tensor(0.0930, device='cuda:0') tensor(-3.3171e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.130216
Average KL loss: 0.001735
Average total loss: 0.131951
tensor(0.0145, device='cuda:0') tensor(0.0930, device='cuda:0') tensor(-5.5240e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.127924
Average KL loss: 0.001735
Average total loss: 0.129659
tensor(0.0145, device='cuda:0') tensor(0.0931, device='cuda:0') tensor(-6.5260e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.131218
Average KL loss: 0.001735
Average total loss: 0.132954
tensor(0.0145, device='cuda:0') tensor(0.0931, device='cuda:0') tensor(-4.9877e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.134687
Average KL loss: 0.001735
Average total loss: 0.136422
tensor(0.0145, device='cuda:0') tensor(0.0931, device='cuda:0') tensor(-1.5615e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.139534
Average KL loss: 0.001735
Average total loss: 0.141270
tensor(0.0145, device='cuda:0') tensor(0.0931, device='cuda:0') tensor(-4.7440e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.128283
Average KL loss: 0.001735
Average total loss: 0.130019
tensor(0.0145, device='cuda:0') tensor(0.0931, device='cuda:0') tensor(-9.8226e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.132693
Average KL loss: 0.001735
Average total loss: 0.134429
tensor(0.0145, device='cuda:0') tensor(0.0932, device='cuda:0') tensor(-1.8024e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.141935
Average KL loss: 0.001735
Average total loss: 0.143670
tensor(0.0145, device='cuda:0') tensor(0.0932, device='cuda:0') tensor(-3.7059e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.126136
Average KL loss: 0.001735
Average total loss: 0.127872
tensor(0.0145, device='cuda:0') tensor(0.0932, device='cuda:0') tensor(-2.9646e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.130052
Average KL loss: 0.001735
Average total loss: 0.131788
tensor(0.0145, device='cuda:0') tensor(0.0932, device='cuda:0') tensor(-2.7587e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.135287
Average KL loss: 0.001735
Average total loss: 0.137022
tensor(0.0145, device='cuda:0') tensor(0.0932, device='cuda:0') tensor(-5.3851e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.132048
Average KL loss: 0.001735
Average total loss: 0.133783
tensor(0.0145, device='cuda:0') tensor(0.0933, device='cuda:0') tensor(-8.4900e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.133718
Average KL loss: 0.001735
Average total loss: 0.135453
tensor(0.0145, device='cuda:0') tensor(0.0933, device='cuda:0') tensor(-5.0005e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.127380
Average KL loss: 0.001735
Average total loss: 0.129115
tensor(0.0145, device='cuda:0') tensor(0.0933, device='cuda:0') tensor(-6.2500e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.131505
Average KL loss: 0.001735
Average total loss: 0.133240
tensor(0.0145, device='cuda:0') tensor(0.0933, device='cuda:0') tensor(-7.7061e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.132435
Average KL loss: 0.001735
Average total loss: 0.134170
tensor(0.0145, device='cuda:0') tensor(0.0933, device='cuda:0') tensor(-4.9086e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.137718
Average KL loss: 0.001735
Average total loss: 0.139454
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-9.8376e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.128701
Average KL loss: 0.001735
Average total loss: 0.130436
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-3.5827e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.140498
Average KL loss: 0.001735
Average total loss: 0.142233
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-4.2731e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.133468
Average KL loss: 0.001735
Average total loss: 0.135203
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-2.1145e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.133006
Average KL loss: 0.001735
Average total loss: 0.134742
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-7.2184e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.136841
Average KL loss: 0.001735
Average total loss: 0.138576
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-7.0515e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.132705
Average KL loss: 0.001735
Average total loss: 0.134440
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-5.7992e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.134274
Average KL loss: 0.001735
Average total loss: 0.136010
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-4.0493e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.131207
Average KL loss: 0.001735
Average total loss: 0.132943
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-6.2938e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.128867
Average KL loss: 0.001735
Average total loss: 0.130602
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-2.9168e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.131268
Average KL loss: 0.001736
Average total loss: 0.133004
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-4.6567e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.135246
Average KL loss: 0.001736
Average total loss: 0.136981
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-9.3107e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.134373
Average KL loss: 0.001736
Average total loss: 0.136108
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-8.4110e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.127478
Average KL loss: 0.001736
Average total loss: 0.129213
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-6.2740e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.137409
Average KL loss: 0.001736
Average total loss: 0.139144
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-4.7068e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.128662
Average KL loss: 0.001736
Average total loss: 0.130398
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-6.9451e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.126839
Average KL loss: 0.001736
Average total loss: 0.128574
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-3.2647e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.128616
Average KL loss: 0.001736
Average total loss: 0.130352
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-4.8173e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.125929
Average KL loss: 0.001736
Average total loss: 0.127664
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-7.6961e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.130380
Average KL loss: 0.001736
Average total loss: 0.132116
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-3.0066e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.134016
Average KL loss: 0.001736
Average total loss: 0.135751
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-2.9740e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.135644
Average KL loss: 0.001736
Average total loss: 0.137380
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-1.0497e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.132137
Average KL loss: 0.001736
Average total loss: 0.133873
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-3.9146e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.133766
Average KL loss: 0.001736
Average total loss: 0.135502
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-6.1781e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.129352
Average KL loss: 0.001736
Average total loss: 0.131087
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-8.8934e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.136430
Average KL loss: 0.001736
Average total loss: 0.138166
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-5.9250e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.131818
Average KL loss: 0.001736
Average total loss: 0.133553
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-4.5273e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.128414
Average KL loss: 0.001736
Average total loss: 0.130150
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-5.8155e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.135151
Average KL loss: 0.001736
Average total loss: 0.136886
tensor(0.0145, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-6.4663e-09, device='cuda:0')
 Percentile value: 7.44136414527893
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =     601 /    1728             ( 34.78%) | total_pruned =    1127 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     209 /   36864             (  0.57%) | total_pruned =   36655 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     222 /   36864             (  0.60%) | total_pruned =   36642 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     232 /   36864             (  0.63%) | total_pruned =   36632 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     231 /   36864             (  0.63%) | total_pruned =   36633 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     276 /   73728             (  0.37%) | total_pruned =   73452 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     305 /  147456             (  0.21%) | total_pruned =  147151 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     290 /    8192             (  3.54%) | total_pruned =    7902 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     182 /  147456             (  0.12%) | total_pruned =  147274 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     161 /  147456             (  0.11%) | total_pruned =  147295 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     350 /  294912             (  0.12%) | total_pruned =  294562 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      74 /     256             ( 28.91%) | total_pruned =     182 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     302 /  589824             (  0.05%) | total_pruned =  589522 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     231 /   32768             (  0.70%) | total_pruned =   32537 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     154 /  589824             (  0.03%) | total_pruned =  589670 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     150 /     256             ( 58.59%) | total_pruned =     106 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     124 /  589824             (  0.02%) | total_pruned =  589700 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     209 / 1179648             (  0.02%) | total_pruned = 1179439 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     341 /     512             ( 66.60%) | total_pruned =     171 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      92 /     512             ( 17.97%) | total_pruned =     420 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     138 / 2359296             (  0.01%) | total_pruned = 2359158 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     300 /     512             ( 58.59%) | total_pruned =     212 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      43 /  131072             (  0.03%) | total_pruned =  131029 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     144 /     512             ( 28.12%) | total_pruned =     368 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      88 / 2359296             (  0.00%) | total_pruned = 2359208 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      73 /     512             ( 14.26%) | total_pruned =     439 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =       8 / 2359296             (  0.00%) | total_pruned = 2359288 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     138 /     512             ( 26.95%) | total_pruned =     374 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     455 /    5120             (  8.89%) | total_pruned =    4665 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 199/200 Loss: 1.054342 Accuracy: 55.48 60.17 % Best test Accuracy: 55.70%
