Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/200 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2564e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.805554
Average KL loss: 0.043553
Average total loss: 1.849106
tensor(0.0433, device='cuda:0') tensor(0.1148, device='cuda:0') tensor(-6.5664e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.532874
Average KL loss: 0.208521
Average total loss: 0.741395
tensor(0.0457, device='cuda:0') tensor(0.2009, device='cuda:0') tensor(-1.9620e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.289955
Average KL loss: 0.239460
Average total loss: 0.529415
tensor(0.0476, device='cuda:0') tensor(0.2148, device='cuda:0') tensor(-1.2558e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.215817
Average KL loss: 0.237326
Average total loss: 0.453144
tensor(0.0483, device='cuda:0') tensor(0.2180, device='cuda:0') tensor(-1.0904e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.167365
Average KL loss: 0.231819
Average total loss: 0.399185
tensor(0.0489, device='cuda:0') tensor(0.2123, device='cuda:0') tensor(-1.0988e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.139594
Average KL loss: 0.218623
Average total loss: 0.358217
tensor(0.0485, device='cuda:0') tensor(0.2079, device='cuda:0') tensor(-5.9343e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.122396
Average KL loss: 0.212928
Average total loss: 0.335324
tensor(0.0479, device='cuda:0') tensor(0.2021, device='cuda:0') tensor(-3.5848e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.107301
Average KL loss: 0.198922
Average total loss: 0.306223
tensor(0.0473, device='cuda:0') tensor(0.1928, device='cuda:0') tensor(-4.3332e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.097936
Average KL loss: 0.190741
Average total loss: 0.288676
tensor(0.0471, device='cuda:0') tensor(0.1869, device='cuda:0') tensor(-2.1269e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.093234
Average KL loss: 0.183782
Average total loss: 0.277016
tensor(0.0465, device='cuda:0') tensor(0.1843, device='cuda:0') tensor(-3.1863e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.081674
Average KL loss: 0.176469
Average total loss: 0.258144
tensor(0.0458, device='cuda:0') tensor(0.1747, device='cuda:0') tensor(-2.0309e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.082210
Average KL loss: 0.167976
Average total loss: 0.250186
tensor(0.0459, device='cuda:0') tensor(0.1742, device='cuda:0') tensor(-1.5998e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.078159
Average KL loss: 0.165772
Average total loss: 0.243931
tensor(0.0452, device='cuda:0') tensor(0.1694, device='cuda:0') tensor(-2.2420e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.071860
Average KL loss: 0.159584
Average total loss: 0.231444
tensor(0.0445, device='cuda:0') tensor(0.1635, device='cuda:0') tensor(-1.5718e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.068341
Average KL loss: 0.150829
Average total loss: 0.219170
tensor(0.0440, device='cuda:0') tensor(0.1581, device='cuda:0') tensor(-1.4731e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.068512
Average KL loss: 0.147403
Average total loss: 0.215915
tensor(0.0438, device='cuda:0') tensor(0.1571, device='cuda:0') tensor(-2.1338e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.065326
Average KL loss: 0.145292
Average total loss: 0.210618
tensor(0.0434, device='cuda:0') tensor(0.1537, device='cuda:0') tensor(-1.2189e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.064167
Average KL loss: 0.140377
Average total loss: 0.204545
tensor(0.0429, device='cuda:0') tensor(0.1523, device='cuda:0') tensor(-1.5725e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.063550
Average KL loss: 0.139989
Average total loss: 0.203539
tensor(0.0427, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(-1.0247e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.060969
Average KL loss: 0.137798
Average total loss: 0.198767
tensor(0.0424, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(-4.7410e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.059387
Average KL loss: 0.133827
Average total loss: 0.193213
tensor(0.0420, device='cuda:0') tensor(0.1466, device='cuda:0') tensor(1.2741e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.059093
Average KL loss: 0.131543
Average total loss: 0.190635
tensor(0.0418, device='cuda:0') tensor(0.1475, device='cuda:0') tensor(-8.9558e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.059292
Average KL loss: 0.131945
Average total loss: 0.191237
tensor(0.0419, device='cuda:0') tensor(0.1495, device='cuda:0') tensor(-1.2233e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.058314
Average KL loss: 0.135677
Average total loss: 0.193991
tensor(0.0417, device='cuda:0') tensor(0.1491, device='cuda:0') tensor(-5.2793e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.057368
Average KL loss: 0.129971
Average total loss: 0.187339
tensor(0.0418, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(5.5333e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.056844
Average KL loss: 0.133318
Average total loss: 0.190162
tensor(0.0413, device='cuda:0') tensor(0.1500, device='cuda:0') tensor(-1.4586e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.054999
Average KL loss: 0.130067
Average total loss: 0.185066
tensor(0.0408, device='cuda:0') tensor(0.1476, device='cuda:0') tensor(-4.0433e-11, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.054813
Average KL loss: 0.127890
Average total loss: 0.182702
tensor(0.0408, device='cuda:0') tensor(0.1482, device='cuda:0') tensor(-3.7044e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.053395
Average KL loss: 0.126565
Average total loss: 0.179960
tensor(0.0406, device='cuda:0') tensor(0.1463, device='cuda:0') tensor(3.5829e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.053831
Average KL loss: 0.126240
Average total loss: 0.180071
tensor(0.0404, device='cuda:0') tensor(0.1459, device='cuda:0') tensor(4.3897e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.053094
Average KL loss: 0.123709
Average total loss: 0.176804
tensor(0.0403, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-1.3346e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.052830
Average KL loss: 0.123024
Average total loss: 0.175855
tensor(0.0404, device='cuda:0') tensor(0.1457, device='cuda:0') tensor(-1.6021e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.052993
Average KL loss: 0.125225
Average total loss: 0.178218
tensor(0.0402, device='cuda:0') tensor(0.1481, device='cuda:0') tensor(3.8855e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.052835
Average KL loss: 0.126014
Average total loss: 0.178849
tensor(0.0402, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-2.1150e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.051071
Average KL loss: 0.124828
Average total loss: 0.175898
tensor(0.0399, device='cuda:0') tensor(0.1476, device='cuda:0') tensor(-4.2974e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.051278
Average KL loss: 0.121838
Average total loss: 0.173116
tensor(0.0401, device='cuda:0') tensor(0.1478, device='cuda:0') tensor(-2.4418e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.050520
Average KL loss: 0.122006
Average total loss: 0.172526
tensor(0.0397, device='cuda:0') tensor(0.1473, device='cuda:0') tensor(1.3505e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.051969
Average KL loss: 0.121680
Average total loss: 0.173649
tensor(0.0405, device='cuda:0') tensor(0.1523, device='cuda:0') tensor(-8.7968e-11, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.050172
Average KL loss: 0.124262
Average total loss: 0.174434
tensor(0.0397, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(-8.1394e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.049719
Average KL loss: 0.120727
Average total loss: 0.170446
tensor(0.0396, device='cuda:0') tensor(0.1481, device='cuda:0') tensor(2.7931e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.050361
Average KL loss: 0.122064
Average total loss: 0.172424
tensor(0.0397, device='cuda:0') tensor(0.1508, device='cuda:0') tensor(-7.2159e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.050447
Average KL loss: 0.124504
Average total loss: 0.174951
tensor(0.0398, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(6.1530e-11, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.050767
Average KL loss: 0.124704
Average total loss: 0.175471
tensor(0.0402, device='cuda:0') tensor(0.1555, device='cuda:0') tensor(-7.4955e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.049242
Average KL loss: 0.124749
Average total loss: 0.173991
tensor(0.0397, device='cuda:0') tensor(0.1537, device='cuda:0') tensor(6.5739e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.048906
Average KL loss: 0.122318
Average total loss: 0.171223
tensor(0.0396, device='cuda:0') tensor(0.1530, device='cuda:0') tensor(1.3452e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.049113
Average KL loss: 0.120886
Average total loss: 0.169999
tensor(0.0399, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(7.9136e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.049629
Average KL loss: 0.123000
Average total loss: 0.172629
tensor(0.0398, device='cuda:0') tensor(0.1574, device='cuda:0') tensor(1.2184e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.048778
Average KL loss: 0.126425
Average total loss: 0.175203
tensor(0.0397, device='cuda:0') tensor(0.1569, device='cuda:0') tensor(-4.3948e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.049143
Average KL loss: 0.125975
Average total loss: 0.175118
tensor(0.0398, device='cuda:0') tensor(0.1615, device='cuda:0') tensor(6.0315e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.047759
Average KL loss: 0.125234
Average total loss: 0.172994
tensor(0.0395, device='cuda:0') tensor(0.1591, device='cuda:0') tensor(5.6342e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.047914
Average KL loss: 0.121951
Average total loss: 0.169865
tensor(0.0395, device='cuda:0') tensor(0.1589, device='cuda:0') tensor(2.7372e-11, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.048324
Average KL loss: 0.123009
Average total loss: 0.171333
tensor(0.0394, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(1.1284e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.048385
Average KL loss: 0.125835
Average total loss: 0.174220
tensor(0.0393, device='cuda:0') tensor(0.1622, device='cuda:0') tensor(1.1175e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.047347
Average KL loss: 0.124536
Average total loss: 0.171883
tensor(0.0394, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(1.6117e-11, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.047777
Average KL loss: 0.123810
Average total loss: 0.171587
tensor(0.0397, device='cuda:0') tensor(0.1625, device='cuda:0') tensor(-6.8117e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.048935
Average KL loss: 0.128725
Average total loss: 0.177660
tensor(0.0397, device='cuda:0') tensor(0.1693, device='cuda:0') tensor(8.9616e-11, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.047077
Average KL loss: 0.128633
Average total loss: 0.175710
tensor(0.0396, device='cuda:0') tensor(0.1645, device='cuda:0') tensor(9.3707e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.046251
Average KL loss: 0.123188
Average total loss: 0.169439
tensor(0.0393, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(1.0119e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.047224
Average KL loss: 0.121596
Average total loss: 0.168820
tensor(0.0393, device='cuda:0') tensor(0.1645, device='cuda:0') tensor(-6.6492e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.049004
Average KL loss: 0.127460
Average total loss: 0.176464
tensor(0.0398, device='cuda:0') tensor(0.1743, device='cuda:0') tensor(-1.3244e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.048335
Average KL loss: 0.133863
Average total loss: 0.182198
tensor(0.0397, device='cuda:0') tensor(0.1751, device='cuda:0') tensor(-1.0427e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.046845
Average KL loss: 0.130526
Average total loss: 0.177372
tensor(0.0394, device='cuda:0') tensor(0.1695, device='cuda:0') tensor(-4.8366e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.048073
Average KL loss: 0.127888
Average total loss: 0.175961
tensor(0.0400, device='cuda:0') tensor(0.1739, device='cuda:0') tensor(5.4973e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.046734
Average KL loss: 0.128218
Average total loss: 0.174952
tensor(0.0397, device='cuda:0') tensor(0.1723, device='cuda:0') tensor(8.1345e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.046598
Average KL loss: 0.125537
Average total loss: 0.172135
tensor(0.0394, device='cuda:0') tensor(0.1703, device='cuda:0') tensor(-8.4808e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.047058
Average KL loss: 0.129200
Average total loss: 0.176258
tensor(0.0396, device='cuda:0') tensor(0.1739, device='cuda:0') tensor(2.8615e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.046730
Average KL loss: 0.127523
Average total loss: 0.174254
tensor(0.0397, device='cuda:0') tensor(0.1745, device='cuda:0') tensor(-9.2879e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.046876
Average KL loss: 0.126647
Average total loss: 0.173523
tensor(0.0399, device='cuda:0') tensor(0.1747, device='cuda:0') tensor(5.9019e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.046425
Average KL loss: 0.126653
Average total loss: 0.173078
tensor(0.0397, device='cuda:0') tensor(0.1743, device='cuda:0') tensor(2.8610e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.046049
Average KL loss: 0.127641
Average total loss: 0.173690
tensor(0.0394, device='cuda:0') tensor(0.1736, device='cuda:0') tensor(-1.0082e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.042225
Average KL loss: 0.119940
Average total loss: 0.162165
tensor(0.0391, device='cuda:0') tensor(0.1640, device='cuda:0') tensor(1.7228e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.040181
Average KL loss: 0.109100
Average total loss: 0.149281
tensor(0.0387, device='cuda:0') tensor(0.1568, device='cuda:0') tensor(5.0767e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.039898
Average KL loss: 0.101795
Average total loss: 0.141692
tensor(0.0383, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(7.0515e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.039758
Average KL loss: 0.096298
Average total loss: 0.136056
tensor(0.0381, device='cuda:0') tensor(0.1471, device='cuda:0') tensor(4.7353e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.039835
Average KL loss: 0.091827
Average total loss: 0.131661
tensor(0.0378, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(7.6605e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.039909
Average KL loss: 0.088106
Average total loss: 0.128014
tensor(0.0377, device='cuda:0') tensor(0.1404, device='cuda:0') tensor(1.4490e-11, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.039611
Average KL loss: 0.084963
Average total loss: 0.124574
tensor(0.0375, device='cuda:0') tensor(0.1376, device='cuda:0') tensor(8.2781e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.039599
Average KL loss: 0.082185
Average total loss: 0.121784
tensor(0.0374, device='cuda:0') tensor(0.1352, device='cuda:0') tensor(7.2143e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.039397
Average KL loss: 0.079692
Average total loss: 0.119089
tensor(0.0372, device='cuda:0') tensor(0.1329, device='cuda:0') tensor(1.9323e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.039521
Average KL loss: 0.077450
Average total loss: 0.116971
tensor(0.0370, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(4.9932e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.039683
Average KL loss: 0.075436
Average total loss: 0.115118
tensor(0.0369, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(5.5601e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.039479
Average KL loss: 0.073688
Average total loss: 0.113167
tensor(0.0367, device='cuda:0') tensor(0.1274, device='cuda:0') tensor(4.3044e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.039973
Average KL loss: 0.072006
Average total loss: 0.111979
tensor(0.0367, device='cuda:0') tensor(0.1258, device='cuda:0') tensor(4.3388e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.039737
Average KL loss: 0.070598
Average total loss: 0.110335
tensor(0.0366, device='cuda:0') tensor(0.1244, device='cuda:0') tensor(6.3183e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.040030
Average KL loss: 0.069239
Average total loss: 0.109269
tensor(0.0364, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(5.6688e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.040121
Average KL loss: 0.068004
Average total loss: 0.108124
tensor(0.0364, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(5.2589e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.039965
Average KL loss: 0.066873
Average total loss: 0.106839
tensor(0.0363, device='cuda:0') tensor(0.1206, device='cuda:0') tensor(-3.0311e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.039851
Average KL loss: 0.065736
Average total loss: 0.105587
tensor(0.0362, device='cuda:0') tensor(0.1195, device='cuda:0') tensor(4.0987e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.040328
Average KL loss: 0.064834
Average total loss: 0.105163
tensor(0.0361, device='cuda:0') tensor(0.1185, device='cuda:0') tensor(1.0150e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.040407
Average KL loss: 0.063930
Average total loss: 0.104337
tensor(0.0361, device='cuda:0') tensor(0.1175, device='cuda:0') tensor(1.2035e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.040156
Average KL loss: 0.063112
Average total loss: 0.103268
tensor(0.0360, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(1.2893e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.040487
Average KL loss: 0.062343
Average total loss: 0.102830
tensor(0.0359, device='cuda:0') tensor(0.1158, device='cuda:0') tensor(9.0859e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.040464
Average KL loss: 0.061614
Average total loss: 0.102078
tensor(0.0359, device='cuda:0') tensor(0.1150, device='cuda:0') tensor(-3.8456e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.040649
Average KL loss: 0.060898
Average total loss: 0.101548
tensor(0.0358, device='cuda:0') tensor(0.1141, device='cuda:0') tensor(3.6984e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.041050
Average KL loss: 0.060290
Average total loss: 0.101340
tensor(0.0357, device='cuda:0') tensor(0.1135, device='cuda:0') tensor(4.5546e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.040649
Average KL loss: 0.059802
Average total loss: 0.100451
tensor(0.0357, device='cuda:0') tensor(0.1128, device='cuda:0') tensor(-1.3427e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.040708
Average KL loss: 0.059140
Average total loss: 0.099847
tensor(0.0356, device='cuda:0') tensor(0.1121, device='cuda:0') tensor(4.7649e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.041113
Average KL loss: 0.058608
Average total loss: 0.099721
tensor(0.0356, device='cuda:0') tensor(0.1115, device='cuda:0') tensor(5.4274e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.040855
Average KL loss: 0.058165
Average total loss: 0.099020
tensor(0.0356, device='cuda:0') tensor(0.1109, device='cuda:0') tensor(-3.5546e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.040554
Average KL loss: 0.057573
Average total loss: 0.098127
tensor(0.0355, device='cuda:0') tensor(0.1102, device='cuda:0') tensor(5.4723e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.040679
Average KL loss: 0.057095
Average total loss: 0.097773
tensor(0.0354, device='cuda:0') tensor(0.1097, device='cuda:0') tensor(2.3849e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.041238
Average KL loss: 0.056702
Average total loss: 0.097940
tensor(0.0354, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(5.2349e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.040877
Average KL loss: 0.056333
Average total loss: 0.097210
tensor(0.0353, device='cuda:0') tensor(0.1086, device='cuda:0') tensor(7.5545e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.041540
Average KL loss: 0.055940
Average total loss: 0.097480
tensor(0.0353, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(7.4054e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.040322
Average KL loss: 0.055551
Average total loss: 0.095874
tensor(0.0353, device='cuda:0') tensor(0.1075, device='cuda:0') tensor(6.9165e-11, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.040699
Average KL loss: 0.055056
Average total loss: 0.095754
tensor(0.0352, device='cuda:0') tensor(0.1070, device='cuda:0') tensor(2.4260e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.041121
Average KL loss: 0.054717
Average total loss: 0.095837
tensor(0.0352, device='cuda:0') tensor(0.1066, device='cuda:0') tensor(-1.3549e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.041366
Average KL loss: 0.054374
Average total loss: 0.095740
tensor(0.0352, device='cuda:0') tensor(0.1062, device='cuda:0') tensor(-4.0031e-12, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.041066
Average KL loss: 0.054136
Average total loss: 0.095201
tensor(0.0351, device='cuda:0') tensor(0.1058, device='cuda:0') tensor(4.8044e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.041331
Average KL loss: 0.053816
Average total loss: 0.095147
tensor(0.0350, device='cuda:0') tensor(0.1053, device='cuda:0') tensor(1.0001e-11, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.041087
Average KL loss: 0.053494
Average total loss: 0.094581
tensor(0.0350, device='cuda:0') tensor(0.1049, device='cuda:0') tensor(3.0184e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.040827
Average KL loss: 0.053166
Average total loss: 0.093993
tensor(0.0349, device='cuda:0') tensor(0.1044, device='cuda:0') tensor(-5.9018e-13, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.041546
Average KL loss: 0.052930
Average total loss: 0.094476
tensor(0.0349, device='cuda:0') tensor(0.1042, device='cuda:0') tensor(1.8487e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.041700
Average KL loss: 0.052759
Average total loss: 0.094460
tensor(0.0349, device='cuda:0') tensor(0.1038, device='cuda:0') tensor(-4.3831e-11, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.041600
Average KL loss: 0.052582
Average total loss: 0.094182
tensor(0.0349, device='cuda:0') tensor(0.1035, device='cuda:0') tensor(8.0809e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.041348
Average KL loss: 0.052315
Average total loss: 0.093663
tensor(0.0349, device='cuda:0') tensor(0.1031, device='cuda:0') tensor(-3.3707e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.041796
Average KL loss: 0.052063
Average total loss: 0.093859
tensor(0.0348, device='cuda:0') tensor(0.1028, device='cuda:0') tensor(1.7602e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.041812
Average KL loss: 0.051910
Average total loss: 0.093722
tensor(0.0349, device='cuda:0') tensor(0.1025, device='cuda:0') tensor(-5.2908e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.041411
Average KL loss: 0.051654
Average total loss: 0.093065
tensor(0.0348, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(3.8510e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.041710
Average KL loss: 0.051444
Average total loss: 0.093154
tensor(0.0348, device='cuda:0') tensor(0.1018, device='cuda:0') tensor(4.2730e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.042209
Average KL loss: 0.051210
Average total loss: 0.093419
tensor(0.0349, device='cuda:0') tensor(0.1015, device='cuda:0') tensor(-5.5427e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.041861
Average KL loss: 0.051101
Average total loss: 0.092962
tensor(0.0348, device='cuda:0') tensor(0.1013, device='cuda:0') tensor(3.6927e-12, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.041983
Average KL loss: 0.050879
Average total loss: 0.092862
tensor(0.0348, device='cuda:0') tensor(0.1010, device='cuda:0') tensor(7.8581e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.042224
Average KL loss: 0.050796
Average total loss: 0.093021
tensor(0.0348, device='cuda:0') tensor(0.1008, device='cuda:0') tensor(5.4367e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.041531
Average KL loss: 0.050591
Average total loss: 0.092123
tensor(0.0348, device='cuda:0') tensor(0.1004, device='cuda:0') tensor(3.2693e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.042103
Average KL loss: 0.050478
Average total loss: 0.092581
tensor(0.0348, device='cuda:0') tensor(0.1002, device='cuda:0') tensor(4.5084e-11, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.041696
Average KL loss: 0.050340
Average total loss: 0.092035
tensor(0.0348, device='cuda:0') tensor(0.1000, device='cuda:0') tensor(-2.1488e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.042712
Average KL loss: 0.050204
Average total loss: 0.092916
tensor(0.0347, device='cuda:0') tensor(0.0998, device='cuda:0') tensor(-2.4946e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.041431
Average KL loss: 0.050089
Average total loss: 0.091521
tensor(0.0347, device='cuda:0') tensor(0.0995, device='cuda:0') tensor(-2.1833e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.041665
Average KL loss: 0.049818
Average total loss: 0.091482
tensor(0.0347, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-2.5928e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.042024
Average KL loss: 0.049579
Average total loss: 0.091603
tensor(0.0346, device='cuda:0') tensor(0.0989, device='cuda:0') tensor(-8.8105e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.042143
Average KL loss: 0.049510
Average total loss: 0.091653
tensor(0.0346, device='cuda:0') tensor(0.0988, device='cuda:0') tensor(7.6840e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.042127
Average KL loss: 0.049399
Average total loss: 0.091526
tensor(0.0346, device='cuda:0') tensor(0.0985, device='cuda:0') tensor(-7.8572e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.042462
Average KL loss: 0.049275
Average total loss: 0.091737
tensor(0.0346, device='cuda:0') tensor(0.0984, device='cuda:0') tensor(3.3684e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.042166
Average KL loss: 0.049245
Average total loss: 0.091411
tensor(0.0346, device='cuda:0') tensor(0.0982, device='cuda:0') tensor(-1.9442e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.041985
Average KL loss: 0.049034
Average total loss: 0.091019
tensor(0.0346, device='cuda:0') tensor(0.0979, device='cuda:0') tensor(3.4773e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.041718
Average KL loss: 0.048920
Average total loss: 0.090638
tensor(0.0345, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(3.4328e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.041867
Average KL loss: 0.048754
Average total loss: 0.090621
tensor(0.0345, device='cuda:0') tensor(0.0975, device='cuda:0') tensor(8.4164e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.042074
Average KL loss: 0.048568
Average total loss: 0.090642
tensor(0.0344, device='cuda:0') tensor(0.0973, device='cuda:0') tensor(-1.7044e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.042187
Average KL loss: 0.048511
Average total loss: 0.090698
tensor(0.0344, device='cuda:0') tensor(0.0971, device='cuda:0') tensor(-8.4737e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.042529
Average KL loss: 0.048351
Average total loss: 0.090880
tensor(0.0345, device='cuda:0') tensor(0.0969, device='cuda:0') tensor(2.9451e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.042402
Average KL loss: 0.048318
Average total loss: 0.090720
tensor(0.0344, device='cuda:0') tensor(0.0968, device='cuda:0') tensor(7.4700e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.042892
Average KL loss: 0.048306
Average total loss: 0.091198
tensor(0.0345, device='cuda:0') tensor(0.0968, device='cuda:0') tensor(-1.0548e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.042412
Average KL loss: 0.048264
Average total loss: 0.090676
tensor(0.0344, device='cuda:0') tensor(0.0965, device='cuda:0') tensor(-8.1403e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.042386
Average KL loss: 0.048144
Average total loss: 0.090530
tensor(0.0344, device='cuda:0') tensor(0.0964, device='cuda:0') tensor(5.8475e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.042245
Average KL loss: 0.047935
Average total loss: 0.090180
tensor(0.0344, device='cuda:0') tensor(0.0961, device='cuda:0') tensor(-9.3385e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.042368
Average KL loss: 0.047904
Average total loss: 0.090272
tensor(0.0344, device='cuda:0') tensor(0.0960, device='cuda:0') tensor(-4.1580e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.042670
Average KL loss: 0.047789
Average total loss: 0.090458
tensor(0.0344, device='cuda:0') tensor(0.0959, device='cuda:0') tensor(-1.0997e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.042274
Average KL loss: 0.047732
Average total loss: 0.090006
tensor(0.0344, device='cuda:0') tensor(0.0958, device='cuda:0') tensor(-6.9019e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.042736
Average KL loss: 0.047646
Average total loss: 0.090382
tensor(0.0344, device='cuda:0') tensor(0.0956, device='cuda:0') tensor(-5.2691e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.042507
Average KL loss: 0.047521
Average total loss: 0.090027
tensor(0.0344, device='cuda:0') tensor(0.0954, device='cuda:0') tensor(-3.3280e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.042801
Average KL loss: 0.047444
Average total loss: 0.090245
tensor(0.0344, device='cuda:0') tensor(0.0954, device='cuda:0') tensor(2.6249e-12, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.042600
Average KL loss: 0.047421
Average total loss: 0.090021
tensor(0.0344, device='cuda:0') tensor(0.0952, device='cuda:0') tensor(7.9625e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.042433
Average KL loss: 0.047292
Average total loss: 0.089725
tensor(0.0343, device='cuda:0') tensor(0.0950, device='cuda:0') tensor(5.2159e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.042482
Average KL loss: 0.047275
Average total loss: 0.089758
tensor(0.0343, device='cuda:0') tensor(0.0949, device='cuda:0') tensor(6.2502e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.042238
Average KL loss: 0.047073
Average total loss: 0.089311
tensor(0.0342, device='cuda:0') tensor(0.0947, device='cuda:0') tensor(1.3629e-11, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.042332
Average KL loss: 0.046984
Average total loss: 0.089316
tensor(0.0343, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(6.1166e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.042480
Average KL loss: 0.046915
Average total loss: 0.089395
tensor(0.0342, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(-3.9415e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.042430
Average KL loss: 0.046838
Average total loss: 0.089268
tensor(0.0343, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(-3.6319e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.042922
Average KL loss: 0.046728
Average total loss: 0.089650
tensor(0.0343, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(6.1474e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.042169
Average KL loss: 0.046749
Average total loss: 0.088917
tensor(0.0343, device='cuda:0') tensor(0.0941, device='cuda:0') tensor(7.3448e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.042373
Average KL loss: 0.046579
Average total loss: 0.088952
tensor(0.0343, device='cuda:0') tensor(0.0939, device='cuda:0') tensor(-5.8352e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.042493
Average KL loss: 0.046502
Average total loss: 0.088995
tensor(0.0343, device='cuda:0') tensor(0.0938, device='cuda:0') tensor(2.0037e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.042359
Average KL loss: 0.046486
Average total loss: 0.088846
tensor(0.0343, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(9.4793e-11, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.042169
Average KL loss: 0.046409
Average total loss: 0.088578
tensor(0.0342, device='cuda:0') tensor(0.0936, device='cuda:0') tensor(-1.0684e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.041716
Average KL loss: 0.046213
Average total loss: 0.087929
tensor(0.0341, device='cuda:0') tensor(0.0933, device='cuda:0') tensor(1.1966e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.042231
Average KL loss: 0.046046
Average total loss: 0.088278
tensor(0.0341, device='cuda:0') tensor(0.0932, device='cuda:0') tensor(1.1358e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.042197
Average KL loss: 0.046006
Average total loss: 0.088203
tensor(0.0341, device='cuda:0') tensor(0.0931, device='cuda:0') tensor(1.0311e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.042842
Average KL loss: 0.045922
Average total loss: 0.088764
tensor(0.0341, device='cuda:0') tensor(0.0930, device='cuda:0') tensor(2.6516e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.042478
Average KL loss: 0.045993
Average total loss: 0.088471
tensor(0.0342, device='cuda:0') tensor(0.0930, device='cuda:0') tensor(2.5245e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.042533
Average KL loss: 0.045898
Average total loss: 0.088431
tensor(0.0341, device='cuda:0') tensor(0.0929, device='cuda:0') tensor(1.4013e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.042488
Average KL loss: 0.045870
Average total loss: 0.088358
tensor(0.0341, device='cuda:0') tensor(0.0928, device='cuda:0') tensor(-1.6262e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.042774
Average KL loss: 0.045788
Average total loss: 0.088563
tensor(0.0341, device='cuda:0') tensor(0.0927, device='cuda:0') tensor(-6.6969e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.042444
Average KL loss: 0.045776
Average total loss: 0.088220
tensor(0.0341, device='cuda:0') tensor(0.0926, device='cuda:0') tensor(-5.7743e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.042479
Average KL loss: 0.045769
Average total loss: 0.088248
tensor(0.0341, device='cuda:0') tensor(0.0926, device='cuda:0') tensor(-7.5108e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.042906
Average KL loss: 0.045742
Average total loss: 0.088648
tensor(0.0341, device='cuda:0') tensor(0.0925, device='cuda:0') tensor(6.1958e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.042598
Average KL loss: 0.045695
Average total loss: 0.088293
tensor(0.0341, device='cuda:0') tensor(0.0924, device='cuda:0') tensor(6.3559e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.042127
Average KL loss: 0.045565
Average total loss: 0.087692
tensor(0.0341, device='cuda:0') tensor(0.0922, device='cuda:0') tensor(-5.6957e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.041879
Average KL loss: 0.045305
Average total loss: 0.087184
tensor(0.0341, device='cuda:0') tensor(0.0920, device='cuda:0') tensor(-2.9840e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.041799
Average KL loss: 0.045085
Average total loss: 0.086884
tensor(0.0341, device='cuda:0') tensor(0.0919, device='cuda:0') tensor(5.3081e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.041785
Average KL loss: 0.044892
Average total loss: 0.086677
tensor(0.0341, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(8.9285e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.041852
Average KL loss: 0.044712
Average total loss: 0.086563
tensor(0.0341, device='cuda:0') tensor(0.0916, device='cuda:0') tensor(4.7912e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.041705
Average KL loss: 0.044547
Average total loss: 0.086252
tensor(0.0340, device='cuda:0') tensor(0.0915, device='cuda:0') tensor(2.5308e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.042055
Average KL loss: 0.044392
Average total loss: 0.086447
tensor(0.0340, device='cuda:0') tensor(0.0914, device='cuda:0') tensor(5.5172e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.041582
Average KL loss: 0.044255
Average total loss: 0.085837
tensor(0.0340, device='cuda:0') tensor(0.0913, device='cuda:0') tensor(1.1540e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.042443
Average KL loss: 0.044120
Average total loss: 0.086563
tensor(0.0340, device='cuda:0') tensor(0.0912, device='cuda:0') tensor(-9.1200e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.042390
Average KL loss: 0.044002
Average total loss: 0.086391
tensor(0.0340, device='cuda:0') tensor(0.0911, device='cuda:0') tensor(-1.0014e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.041841
Average KL loss: 0.043889
Average total loss: 0.085730
tensor(0.0340, device='cuda:0') tensor(0.0910, device='cuda:0') tensor(3.3301e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.041566
Average KL loss: 0.043776
Average total loss: 0.085343
tensor(0.0340, device='cuda:0') tensor(0.0909, device='cuda:0') tensor(-2.8000e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.042076
Average KL loss: 0.043668
Average total loss: 0.085744
tensor(0.0340, device='cuda:0') tensor(0.0908, device='cuda:0') tensor(-5.2562e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.041355
Average KL loss: 0.043565
Average total loss: 0.084920
tensor(0.0340, device='cuda:0') tensor(0.0907, device='cuda:0') tensor(6.6641e-11, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.041540
Average KL loss: 0.043466
Average total loss: 0.085006
tensor(0.0340, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(9.5966e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.041561
Average KL loss: 0.043367
Average total loss: 0.084929
tensor(0.0339, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(-1.7599e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.041659
Average KL loss: 0.043276
Average total loss: 0.084935
tensor(0.0339, device='cuda:0') tensor(0.0905, device='cuda:0') tensor(1.2748e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.042121
Average KL loss: 0.043190
Average total loss: 0.085310
tensor(0.0339, device='cuda:0') tensor(0.0904, device='cuda:0') tensor(8.6314e-11, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.042248
Average KL loss: 0.043106
Average total loss: 0.085354
tensor(0.0339, device='cuda:0') tensor(0.0904, device='cuda:0') tensor(8.3240e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.040964
Average KL loss: 0.043023
Average total loss: 0.083987
tensor(0.0339, device='cuda:0') tensor(0.0903, device='cuda:0') tensor(7.8370e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.041892
Average KL loss: 0.042940
Average total loss: 0.084832
tensor(0.0339, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(2.3079e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.041977
Average KL loss: 0.042866
Average total loss: 0.084843
tensor(0.0339, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(-7.5228e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.042015
Average KL loss: 0.042798
Average total loss: 0.084813
 Percentile value: 0.10965397357940664
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =     407 /    1728             ( 23.55%) | total_pruned =    1321 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
bn1.bias             | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5195 /   36864             ( 14.09%) | total_pruned =   31669 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   11282 /   36864             ( 30.60%) | total_pruned =   25582 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   11552 /   36864             ( 31.34%) | total_pruned =   25312 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   13246 /   36864             ( 35.93%) | total_pruned =   23618 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   33931 /   73728             ( 46.02%) | total_pruned =   39797 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   68080 /  147456             ( 46.17%) | total_pruned =   79376 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4377 /    8192             ( 53.43%) | total_pruned =    3815 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   49416 /  147456             ( 33.51%) | total_pruned =   98040 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   46494 /  147456             ( 31.53%) | total_pruned =  100962 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  143353 /  294912             ( 48.61%) | total_pruned =  151559 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  275819 /  589824             ( 46.76%) | total_pruned =  314005 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   16377 /   32768             ( 49.98%) | total_pruned =   16391 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     155 /     256             ( 60.55%) | total_pruned =     101 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  232806 /  589824             ( 39.47%) | total_pruned =  357018 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  187797 /  589824             ( 31.84%) | total_pruned =  402027 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  437170 / 1179648             ( 37.06%) | total_pruned =  742478 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     231 /     512             ( 45.12%) | total_pruned =     281 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  534250 / 2359296             ( 22.64%) | total_pruned = 1825046 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     353 /     512             ( 68.95%) | total_pruned =     159 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   26353 /  131072             ( 20.11%) | total_pruned =  104719 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     343 /     512             ( 66.99%) | total_pruned =     169 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  506798 / 2359296             ( 21.48%) | total_pruned = 1852498 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  736375 / 2359296             ( 31.21%) | total_pruned = 1622921 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5083 /    5120             ( 99.28%) | total_pruned =      37 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 51/200 Loss: 0.022471 Accuracy: 88.21 100.00 % Best test Accuracy: 88.21%
tensor(0.0339, device='cuda:0') tensor(0.0901, device='cuda:0') tensor(-1.6744e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.290186
Average KL loss: 0.063983
Average total loss: 0.354169
tensor(0.0347, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(-2.3924e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.183458
Average KL loss: 0.085815
Average total loss: 0.269273
tensor(0.0364, device='cuda:0') tensor(0.0983, device='cuda:0') tensor(-1.7503e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.151129
Average KL loss: 0.097611
Average total loss: 0.248740
tensor(0.0381, device='cuda:0') tensor(0.1099, device='cuda:0') tensor(-7.7496e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.124701
Average KL loss: 0.104507
Average total loss: 0.229208
tensor(0.0390, device='cuda:0') tensor(0.1187, device='cuda:0') tensor(-8.6181e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.108572
Average KL loss: 0.108167
Average total loss: 0.216739
tensor(0.0398, device='cuda:0') tensor(0.1244, device='cuda:0') tensor(-5.8170e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.095449
Average KL loss: 0.109612
Average total loss: 0.205061
tensor(0.0404, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-5.4951e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.088980
Average KL loss: 0.110775
Average total loss: 0.199755
tensor(0.0406, device='cuda:0') tensor(0.1322, device='cuda:0') tensor(-3.1191e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.080211
Average KL loss: 0.110666
Average total loss: 0.190878
tensor(0.0409, device='cuda:0') tensor(0.1342, device='cuda:0') tensor(-2.5612e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.074122
Average KL loss: 0.109877
Average total loss: 0.183999
tensor(0.0410, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-2.3011e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.071040
Average KL loss: 0.108889
Average total loss: 0.179929
tensor(0.0410, device='cuda:0') tensor(0.1369, device='cuda:0') tensor(-2.5891e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.066693
Average KL loss: 0.108166
Average total loss: 0.174859
tensor(0.0412, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(-3.6010e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.064039
Average KL loss: 0.107181
Average total loss: 0.171221
tensor(0.0413, device='cuda:0') tensor(0.1385, device='cuda:0') tensor(-2.0128e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.061763
Average KL loss: 0.106318
Average total loss: 0.168082
tensor(0.0413, device='cuda:0') tensor(0.1394, device='cuda:0') tensor(-4.5973e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.058811
Average KL loss: 0.105045
Average total loss: 0.163856
tensor(0.0411, device='cuda:0') tensor(0.1394, device='cuda:0') tensor(-5.1104e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.056721
Average KL loss: 0.103609
Average total loss: 0.160330
tensor(0.0409, device='cuda:0') tensor(0.1394, device='cuda:0') tensor(-1.3847e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.056495
Average KL loss: 0.102946
Average total loss: 0.159441
tensor(0.0409, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(-9.5849e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.055432
Average KL loss: 0.102721
Average total loss: 0.158153
tensor(0.0409, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-5.4081e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.053017
Average KL loss: 0.101765
Average total loss: 0.154782
tensor(0.0407, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-1.7312e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.052175
Average KL loss: 0.100943
Average total loss: 0.153119
tensor(0.0406, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-8.2654e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.051006
Average KL loss: 0.099951
Average total loss: 0.150957
tensor(0.0404, device='cuda:0') tensor(0.1417, device='cuda:0') tensor(-5.0838e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.050168
Average KL loss: 0.098974
Average total loss: 0.149142
tensor(0.0405, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-5.8825e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.049630
Average KL loss: 0.098094
Average total loss: 0.147724
tensor(0.0403, device='cuda:0') tensor(0.1423, device='cuda:0') tensor(-6.8799e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.049851
Average KL loss: 0.098625
Average total loss: 0.148476
tensor(0.0403, device='cuda:0') tensor(0.1440, device='cuda:0') tensor(8.2834e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.049362
Average KL loss: 0.098596
Average total loss: 0.147958
tensor(0.0403, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(-3.0715e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.047099
Average KL loss: 0.098324
Average total loss: 0.145423
tensor(0.0402, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-1.4150e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.047092
Average KL loss: 0.097294
Average total loss: 0.144387
tensor(0.0401, device='cuda:0') tensor(0.1454, device='cuda:0') tensor(-6.3412e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.046988
Average KL loss: 0.097095
Average total loss: 0.144082
tensor(0.0400, device='cuda:0') tensor(0.1461, device='cuda:0') tensor(-3.7967e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.046527
Average KL loss: 0.096806
Average total loss: 0.143333
tensor(0.0399, device='cuda:0') tensor(0.1471, device='cuda:0') tensor(-1.6577e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.045665
Average KL loss: 0.096444
Average total loss: 0.142109
tensor(0.0398, device='cuda:0') tensor(0.1474, device='cuda:0') tensor(-3.0910e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.045654
Average KL loss: 0.096673
Average total loss: 0.142327
tensor(0.0397, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(-7.3730e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.045155
Average KL loss: 0.097116
Average total loss: 0.142271
tensor(0.0397, device='cuda:0') tensor(0.1499, device='cuda:0') tensor(-4.0064e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.045889
Average KL loss: 0.097110
Average total loss: 0.142999
tensor(0.0398, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(-1.8709e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.045211
Average KL loss: 0.097628
Average total loss: 0.142839
tensor(0.0397, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(-3.3087e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.045028
Average KL loss: 0.097770
Average total loss: 0.142798
tensor(0.0397, device='cuda:0') tensor(0.1540, device='cuda:0') tensor(-1.0781e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.044239
Average KL loss: 0.098029
Average total loss: 0.142268
tensor(0.0397, device='cuda:0') tensor(0.1550, device='cuda:0') tensor(-8.6178e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.043825
Average KL loss: 0.097065
Average total loss: 0.140890
tensor(0.0397, device='cuda:0') tensor(0.1551, device='cuda:0') tensor(-7.2235e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.043770
Average KL loss: 0.096711
Average total loss: 0.140481
tensor(0.0397, device='cuda:0') tensor(0.1565, device='cuda:0') tensor(-3.2127e-11, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.043745
Average KL loss: 0.097285
Average total loss: 0.141030
tensor(0.0397, device='cuda:0') tensor(0.1578, device='cuda:0') tensor(6.0839e-11, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.043580
Average KL loss: 0.097619
Average total loss: 0.141199
tensor(0.0399, device='cuda:0') tensor(0.1593, device='cuda:0') tensor(-1.2217e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.042653
Average KL loss: 0.097264
Average total loss: 0.139917
tensor(0.0397, device='cuda:0') tensor(0.1591, device='cuda:0') tensor(-1.1966e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.042470
Average KL loss: 0.097131
Average total loss: 0.139601
tensor(0.0397, device='cuda:0') tensor(0.1598, device='cuda:0') tensor(4.2769e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.042061
Average KL loss: 0.096659
Average total loss: 0.138720
tensor(0.0396, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-3.9088e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.042390
Average KL loss: 0.096761
Average total loss: 0.139151
tensor(0.0396, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-1.0808e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.042043
Average KL loss: 0.096692
Average total loss: 0.138735
tensor(0.0394, device='cuda:0') tensor(0.1629, device='cuda:0') tensor(-2.0651e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.042397
Average KL loss: 0.097437
Average total loss: 0.139834
tensor(0.0395, device='cuda:0') tensor(0.1642, device='cuda:0') tensor(-5.1656e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.042724
Average KL loss: 0.098065
Average total loss: 0.140789
tensor(0.0398, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(2.0275e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.042039
Average KL loss: 0.098588
Average total loss: 0.140627
tensor(0.0398, device='cuda:0') tensor(0.1672, device='cuda:0') tensor(-2.3580e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.042049
Average KL loss: 0.098800
Average total loss: 0.140849
tensor(0.0398, device='cuda:0') tensor(0.1687, device='cuda:0') tensor(1.3643e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.042036
Average KL loss: 0.098934
Average total loss: 0.140970
tensor(0.0398, device='cuda:0') tensor(0.1696, device='cuda:0') tensor(1.8591e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.041389
Average KL loss: 0.099534
Average total loss: 0.140923
tensor(0.0400, device='cuda:0') tensor(0.1713, device='cuda:0') tensor(1.9141e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.041369
Average KL loss: 0.098735
Average total loss: 0.140104
tensor(0.0398, device='cuda:0') tensor(0.1714, device='cuda:0') tensor(-7.4650e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.040929
Average KL loss: 0.098706
Average total loss: 0.139636
tensor(0.0398, device='cuda:0') tensor(0.1719, device='cuda:0') tensor(-1.5212e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.040423
Average KL loss: 0.097828
Average total loss: 0.138251
tensor(0.0398, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(2.6129e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.040556
Average KL loss: 0.098679
Average total loss: 0.139235
tensor(0.0396, device='cuda:0') tensor(0.1738, device='cuda:0') tensor(-1.1161e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.041201
Average KL loss: 0.098807
Average total loss: 0.140008
tensor(0.0399, device='cuda:0') tensor(0.1758, device='cuda:0') tensor(2.4063e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.041015
Average KL loss: 0.099644
Average total loss: 0.140659
tensor(0.0399, device='cuda:0') tensor(0.1779, device='cuda:0') tensor(-1.5962e-11, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.039979
Average KL loss: 0.099712
Average total loss: 0.139690
tensor(0.0397, device='cuda:0') tensor(0.1776, device='cuda:0') tensor(-3.3957e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.041157
Average KL loss: 0.099657
Average total loss: 0.140814
tensor(0.0400, device='cuda:0') tensor(0.1799, device='cuda:0') tensor(2.5160e-11, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.040001
Average KL loss: 0.100673
Average total loss: 0.140675
tensor(0.0399, device='cuda:0') tensor(0.1808, device='cuda:0') tensor(-9.2606e-11, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.040199
Average KL loss: 0.100017
Average total loss: 0.140216
tensor(0.0400, device='cuda:0') tensor(0.1821, device='cuda:0') tensor(6.5868e-11, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.040724
Average KL loss: 0.100624
Average total loss: 0.141348
tensor(0.0401, device='cuda:0') tensor(0.1840, device='cuda:0') tensor(-1.0713e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.040473
Average KL loss: 0.101230
Average total loss: 0.141703
tensor(0.0401, device='cuda:0') tensor(0.1849, device='cuda:0') tensor(4.7792e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.040244
Average KL loss: 0.101327
Average total loss: 0.141571
tensor(0.0402, device='cuda:0') tensor(0.1859, device='cuda:0') tensor(1.7728e-11, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.039312
Average KL loss: 0.100837
Average total loss: 0.140150
tensor(0.0401, device='cuda:0') tensor(0.1866, device='cuda:0') tensor(-2.9314e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.037830
Average KL loss: 0.099521
Average total loss: 0.137351
tensor(0.0401, device='cuda:0') tensor(0.1837, device='cuda:0') tensor(-3.8407e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.037283
Average KL loss: 0.096341
Average total loss: 0.133624
tensor(0.0399, device='cuda:0') tensor(0.1811, device='cuda:0') tensor(4.2136e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.036489
Average KL loss: 0.093873
Average total loss: 0.130362
tensor(0.0398, device='cuda:0') tensor(0.1789, device='cuda:0') tensor(5.6809e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.036767
Average KL loss: 0.091820
Average total loss: 0.128587
tensor(0.0397, device='cuda:0') tensor(0.1770, device='cuda:0') tensor(2.0798e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.036791
Average KL loss: 0.090049
Average total loss: 0.126840
tensor(0.0396, device='cuda:0') tensor(0.1752, device='cuda:0') tensor(7.5787e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.036665
Average KL loss: 0.088450
Average total loss: 0.125115
tensor(0.0396, device='cuda:0') tensor(0.1736, device='cuda:0') tensor(-6.1665e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.036156
Average KL loss: 0.087008
Average total loss: 0.123165
tensor(0.0395, device='cuda:0') tensor(0.1721, device='cuda:0') tensor(1.1462e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.036276
Average KL loss: 0.085673
Average total loss: 0.121949
tensor(0.0394, device='cuda:0') tensor(0.1707, device='cuda:0') tensor(6.3818e-11, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.035741
Average KL loss: 0.084434
Average total loss: 0.120175
tensor(0.0393, device='cuda:0') tensor(0.1694, device='cuda:0') tensor(1.1605e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.035848
Average KL loss: 0.083266
Average total loss: 0.119114
tensor(0.0392, device='cuda:0') tensor(0.1681, device='cuda:0') tensor(4.0320e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.035862
Average KL loss: 0.082190
Average total loss: 0.118052
tensor(0.0391, device='cuda:0') tensor(0.1669, device='cuda:0') tensor(-2.8215e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.035865
Average KL loss: 0.081171
Average total loss: 0.117036
tensor(0.0390, device='cuda:0') tensor(0.1658, device='cuda:0') tensor(3.1087e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.036243
Average KL loss: 0.080220
Average total loss: 0.116464
tensor(0.0390, device='cuda:0') tensor(0.1647, device='cuda:0') tensor(-1.4757e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.036349
Average KL loss: 0.079354
Average total loss: 0.115703
tensor(0.0389, device='cuda:0') tensor(0.1637, device='cuda:0') tensor(1.3413e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.035422
Average KL loss: 0.078483
Average total loss: 0.113905
tensor(0.0388, device='cuda:0') tensor(0.1626, device='cuda:0') tensor(3.6990e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.036103
Average KL loss: 0.077657
Average total loss: 0.113761
tensor(0.0388, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-3.3088e-11, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.036203
Average KL loss: 0.076889
Average total loss: 0.113092
tensor(0.0387, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(4.6413e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.036339
Average KL loss: 0.076155
Average total loss: 0.112494
tensor(0.0386, device='cuda:0') tensor(0.1598, device='cuda:0') tensor(1.5984e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.036222
Average KL loss: 0.075477
Average total loss: 0.111699
tensor(0.0386, device='cuda:0') tensor(0.1590, device='cuda:0') tensor(1.8099e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.035779
Average KL loss: 0.074811
Average total loss: 0.110590
tensor(0.0385, device='cuda:0') tensor(0.1581, device='cuda:0') tensor(9.4636e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.036082
Average KL loss: 0.074140
Average total loss: 0.110221
tensor(0.0384, device='cuda:0') tensor(0.1573, device='cuda:0') tensor(2.6355e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.035738
Average KL loss: 0.073521
Average total loss: 0.109259
tensor(0.0384, device='cuda:0') tensor(0.1565, device='cuda:0') tensor(-1.3084e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.035904
Average KL loss: 0.072907
Average total loss: 0.108811
tensor(0.0383, device='cuda:0') tensor(0.1557, device='cuda:0') tensor(5.8177e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.036600
Average KL loss: 0.072361
Average total loss: 0.108961
tensor(0.0383, device='cuda:0') tensor(0.1550, device='cuda:0') tensor(-2.2977e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.035961
Average KL loss: 0.071827
Average total loss: 0.107788
tensor(0.0382, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(9.2775e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.036562
Average KL loss: 0.071282
Average total loss: 0.107844
tensor(0.0381, device='cuda:0') tensor(0.1535, device='cuda:0') tensor(6.9382e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.036287
Average KL loss: 0.070796
Average total loss: 0.107083
tensor(0.0381, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(2.9793e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.036147
Average KL loss: 0.070316
Average total loss: 0.106463
tensor(0.0380, device='cuda:0') tensor(0.1522, device='cuda:0') tensor(7.9964e-11, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.036179
Average KL loss: 0.069840
Average total loss: 0.106019
tensor(0.0380, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(6.8588e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.036258
Average KL loss: 0.069389
Average total loss: 0.105646
tensor(0.0379, device='cuda:0') tensor(0.1509, device='cuda:0') tensor(-3.3995e-12, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.035984
Average KL loss: 0.068942
Average total loss: 0.104926
tensor(0.0379, device='cuda:0') tensor(0.1503, device='cuda:0') tensor(1.1892e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.036622
Average KL loss: 0.068509
Average total loss: 0.105131
tensor(0.0378, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(5.2036e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.036612
Average KL loss: 0.068149
Average total loss: 0.104761
tensor(0.0378, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(8.2554e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.036892
Average KL loss: 0.067809
Average total loss: 0.104701
tensor(0.0378, device='cuda:0') tensor(0.1486, device='cuda:0') tensor(-7.5593e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.036819
Average KL loss: 0.067473
Average total loss: 0.104292
tensor(0.0377, device='cuda:0') tensor(0.1481, device='cuda:0') tensor(2.8574e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.036481
Average KL loss: 0.067098
Average total loss: 0.103579
tensor(0.0376, device='cuda:0') tensor(0.1475, device='cuda:0') tensor(-3.3751e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.036790
Average KL loss: 0.066730
Average total loss: 0.103520
tensor(0.0376, device='cuda:0') tensor(0.1470, device='cuda:0') tensor(7.3326e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.036264
Average KL loss: 0.066368
Average total loss: 0.102632
tensor(0.0375, device='cuda:0') tensor(0.1465, device='cuda:0') tensor(-1.0788e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.036674
Average KL loss: 0.066037
Average total loss: 0.102711
tensor(0.0375, device='cuda:0') tensor(0.1460, device='cuda:0') tensor(7.8401e-11, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.036982
Average KL loss: 0.065705
Average total loss: 0.102687
tensor(0.0375, device='cuda:0') tensor(0.1455, device='cuda:0') tensor(-1.5067e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.037267
Average KL loss: 0.065447
Average total loss: 0.102714
tensor(0.0375, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(5.9358e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.036851
Average KL loss: 0.065140
Average total loss: 0.101991
tensor(0.0374, device='cuda:0') tensor(0.1446, device='cuda:0') tensor(1.8283e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.036601
Average KL loss: 0.064837
Average total loss: 0.101438
tensor(0.0373, device='cuda:0') tensor(0.1441, device='cuda:0') tensor(4.2708e-12, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.036852
Average KL loss: 0.064524
Average total loss: 0.101376
tensor(0.0373, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(7.9685e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.036981
Average KL loss: 0.064229
Average total loss: 0.101210
tensor(0.0372, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-3.0834e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.036871
Average KL loss: 0.063961
Average total loss: 0.100833
tensor(0.0372, device='cuda:0') tensor(0.1427, device='cuda:0') tensor(1.5045e-11, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.037133
Average KL loss: 0.063726
Average total loss: 0.100859
tensor(0.0372, device='cuda:0') tensor(0.1423, device='cuda:0') tensor(-2.2927e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.036415
Average KL loss: 0.063464
Average total loss: 0.099880
tensor(0.0371, device='cuda:0') tensor(0.1419, device='cuda:0') tensor(2.0676e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.036849
Average KL loss: 0.063155
Average total loss: 0.100004
tensor(0.0371, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-8.5113e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.036977
Average KL loss: 0.062930
Average total loss: 0.099907
tensor(0.0370, device='cuda:0') tensor(0.1410, device='cuda:0') tensor(-1.0506e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.036967
Average KL loss: 0.062690
Average total loss: 0.099657
tensor(0.0370, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(7.1915e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.037191
Average KL loss: 0.062421
Average total loss: 0.099612
tensor(0.0370, device='cuda:0') tensor(0.1402, device='cuda:0') tensor(2.4177e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.037198
Average KL loss: 0.062230
Average total loss: 0.099428
tensor(0.0369, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(-3.6996e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.037390
Average KL loss: 0.062035
Average total loss: 0.099426
tensor(0.0369, device='cuda:0') tensor(0.1394, device='cuda:0') tensor(6.2623e-11, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.037575
Average KL loss: 0.061823
Average total loss: 0.099397
tensor(0.0369, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(9.5376e-11, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.037556
Average KL loss: 0.061661
Average total loss: 0.099217
tensor(0.0369, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(1.9796e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.037570
Average KL loss: 0.061476
Average total loss: 0.099047
tensor(0.0368, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(3.9457e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.037273
Average KL loss: 0.061273
Average total loss: 0.098546
tensor(0.0368, device='cuda:0') tensor(0.1380, device='cuda:0') tensor(-5.0448e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.037704
Average KL loss: 0.061068
Average total loss: 0.098772
tensor(0.0368, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(-2.8856e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.037715
Average KL loss: 0.060898
Average total loss: 0.098614
tensor(0.0367, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(-8.7968e-11, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.036844
Average KL loss: 0.060713
Average total loss: 0.097557
tensor(0.0366, device='cuda:0') tensor(0.1370, device='cuda:0') tensor(3.7054e-11, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.037762
Average KL loss: 0.060517
Average total loss: 0.098279
tensor(0.0366, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(-4.2921e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.038205
Average KL loss: 0.060394
Average total loss: 0.098598
tensor(0.0366, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(5.2151e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.037983
Average KL loss: 0.060280
Average total loss: 0.098263
tensor(0.0366, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(2.5041e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.037240
Average KL loss: 0.060113
Average total loss: 0.097353
tensor(0.0366, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(3.5900e-11, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.037066
Average KL loss: 0.059913
Average total loss: 0.096978
tensor(0.0365, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-3.9609e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.037357
Average KL loss: 0.059722
Average total loss: 0.097079
tensor(0.0365, device='cuda:0') tensor(0.1352, device='cuda:0') tensor(6.9748e-11, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.037482
Average KL loss: 0.059558
Average total loss: 0.097041
tensor(0.0365, device='cuda:0') tensor(0.1349, device='cuda:0') tensor(8.2577e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.037920
Average KL loss: 0.059391
Average total loss: 0.097311
tensor(0.0365, device='cuda:0') tensor(0.1346, device='cuda:0') tensor(2.1434e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.037414
Average KL loss: 0.059254
Average total loss: 0.096668
tensor(0.0364, device='cuda:0') tensor(0.1343, device='cuda:0') tensor(5.9815e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.037141
Average KL loss: 0.059084
Average total loss: 0.096225
tensor(0.0364, device='cuda:0') tensor(0.1340, device='cuda:0') tensor(3.0919e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.038215
Average KL loss: 0.058954
Average total loss: 0.097170
tensor(0.0364, device='cuda:0') tensor(0.1338, device='cuda:0') tensor(3.6670e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.038420
Average KL loss: 0.058882
Average total loss: 0.097302
tensor(0.0364, device='cuda:0') tensor(0.1336, device='cuda:0') tensor(4.4992e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.037604
Average KL loss: 0.058778
Average total loss: 0.096382
tensor(0.0364, device='cuda:0') tensor(0.1333, device='cuda:0') tensor(1.8592e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.037904
Average KL loss: 0.058633
Average total loss: 0.096537
tensor(0.0363, device='cuda:0') tensor(0.1330, device='cuda:0') tensor(1.6240e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.037488
Average KL loss: 0.058482
Average total loss: 0.095971
tensor(0.0363, device='cuda:0') tensor(0.1327, device='cuda:0') tensor(3.5864e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.038026
Average KL loss: 0.058336
Average total loss: 0.096362
tensor(0.0363, device='cuda:0') tensor(0.1325, device='cuda:0') tensor(-6.0768e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.037549
Average KL loss: 0.058217
Average total loss: 0.095766
tensor(0.0362, device='cuda:0') tensor(0.1322, device='cuda:0') tensor(6.5526e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.037654
Average KL loss: 0.058061
Average total loss: 0.095715
tensor(0.0362, device='cuda:0') tensor(0.1319, device='cuda:0') tensor(-2.7161e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.037963
Average KL loss: 0.057965
Average total loss: 0.095928
tensor(0.0362, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-6.9032e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.038541
Average KL loss: 0.057876
Average total loss: 0.096418
tensor(0.0362, device='cuda:0') tensor(0.1315, device='cuda:0') tensor(-6.6242e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.037959
Average KL loss: 0.057799
Average total loss: 0.095758
tensor(0.0362, device='cuda:0') tensor(0.1313, device='cuda:0') tensor(-4.0649e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.037815
Average KL loss: 0.057672
Average total loss: 0.095487
tensor(0.0361, device='cuda:0') tensor(0.1311, device='cuda:0') tensor(3.7591e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.038030
Average KL loss: 0.057524
Average total loss: 0.095554
tensor(0.0361, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(4.4485e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.038637
Average KL loss: 0.057452
Average total loss: 0.096089
tensor(0.0361, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(5.2662e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.037930
Average KL loss: 0.057367
Average total loss: 0.095297
tensor(0.0361, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(5.8251e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.037671
Average KL loss: 0.057241
Average total loss: 0.094912
tensor(0.0360, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(3.2757e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.038103
Average KL loss: 0.057145
Average total loss: 0.095248
tensor(0.0360, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-3.2405e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.037964
Average KL loss: 0.057032
Average total loss: 0.094997
tensor(0.0360, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(4.3583e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.038095
Average KL loss: 0.056883
Average total loss: 0.094977
tensor(0.0360, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.1799e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.038460
Average KL loss: 0.056811
Average total loss: 0.095271
tensor(0.0360, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-4.0926e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.038182
Average KL loss: 0.056754
Average total loss: 0.094936
tensor(0.0360, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(1.1950e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.038612
Average KL loss: 0.056678
Average total loss: 0.095290
tensor(0.0360, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(1.0065e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.037988
Average KL loss: 0.056588
Average total loss: 0.094576
tensor(0.0359, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-8.4435e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.039142
Average KL loss: 0.056506
Average total loss: 0.095648
tensor(0.0360, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(3.8261e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.038393
Average KL loss: 0.056484
Average total loss: 0.094877
tensor(0.0359, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(5.3900e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.038185
Average KL loss: 0.056366
Average total loss: 0.094551
tensor(0.0359, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(2.9298e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.038256
Average KL loss: 0.056261
Average total loss: 0.094517
tensor(0.0359, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(1.4964e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.038593
Average KL loss: 0.056172
Average total loss: 0.094765
tensor(0.0359, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-4.5233e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.038056
Average KL loss: 0.056094
Average total loss: 0.094150
tensor(0.0358, device='cuda:0') tensor(0.1277, device='cuda:0') tensor(4.0246e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.038674
Average KL loss: 0.056000
Average total loss: 0.094674
tensor(0.0358, device='cuda:0') tensor(0.1275, device='cuda:0') tensor(-8.0468e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.038502
Average KL loss: 0.055960
Average total loss: 0.094462
tensor(0.0358, device='cuda:0') tensor(0.1273, device='cuda:0') tensor(6.1650e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.038241
Average KL loss: 0.055839
Average total loss: 0.094080
tensor(0.0358, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(3.9489e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.038285
Average KL loss: 0.055760
Average total loss: 0.094045
tensor(0.0358, device='cuda:0') tensor(0.1270, device='cuda:0') tensor(3.0175e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.038406
Average KL loss: 0.055691
Average total loss: 0.094097
tensor(0.0358, device='cuda:0') tensor(0.1268, device='cuda:0') tensor(3.5385e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.038714
Average KL loss: 0.055640
Average total loss: 0.094354
tensor(0.0357, device='cuda:0') tensor(0.1267, device='cuda:0') tensor(5.6011e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.038372
Average KL loss: 0.055568
Average total loss: 0.093941
tensor(0.0357, device='cuda:0') tensor(0.1265, device='cuda:0') tensor(-4.4792e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.038664
Average KL loss: 0.055499
Average total loss: 0.094163
tensor(0.0357, device='cuda:0') tensor(0.1263, device='cuda:0') tensor(-5.5659e-12, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.038324
Average KL loss: 0.055459
Average total loss: 0.093782
tensor(0.0357, device='cuda:0') tensor(0.1262, device='cuda:0') tensor(5.2373e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.038639
Average KL loss: 0.055366
Average total loss: 0.094005
tensor(0.0357, device='cuda:0') tensor(0.1260, device='cuda:0') tensor(-1.8713e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.038016
Average KL loss: 0.055291
Average total loss: 0.093307
tensor(0.0357, device='cuda:0') tensor(0.1258, device='cuda:0') tensor(-6.9202e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.039241
Average KL loss: 0.055220
Average total loss: 0.094461
tensor(0.0356, device='cuda:0') tensor(0.1257, device='cuda:0') tensor(1.2595e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.038605
Average KL loss: 0.055176
Average total loss: 0.093781
tensor(0.0356, device='cuda:0') tensor(0.1256, device='cuda:0') tensor(6.0529e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.038321
Average KL loss: 0.055116
Average total loss: 0.093437
tensor(0.0356, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-4.0173e-11, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.038494
Average KL loss: 0.055013
Average total loss: 0.093507
tensor(0.0356, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(8.4756e-13, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.038638
Average KL loss: 0.054963
Average total loss: 0.093601
tensor(0.0356, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(-1.2865e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.039050
Average KL loss: 0.054931
Average total loss: 0.093981
tensor(0.0356, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(2.5526e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.038822
Average KL loss: 0.054896
Average total loss: 0.093718
tensor(0.0356, device='cuda:0') tensor(0.1249, device='cuda:0') tensor(5.1122e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.038664
Average KL loss: 0.054836
Average total loss: 0.093501
tensor(0.0356, device='cuda:0') tensor(0.1248, device='cuda:0') tensor(-1.1595e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.038296
Average KL loss: 0.054760
Average total loss: 0.093057
tensor(0.0355, device='cuda:0') tensor(0.1246, device='cuda:0') tensor(3.0434e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.038794
Average KL loss: 0.054706
Average total loss: 0.093500
tensor(0.0355, device='cuda:0') tensor(0.1245, device='cuda:0') tensor(8.8004e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.038613
Average KL loss: 0.054640
Average total loss: 0.093253
tensor(0.0355, device='cuda:0') tensor(0.1243, device='cuda:0') tensor(1.9911e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.039242
Average KL loss: 0.054604
Average total loss: 0.093846
tensor(0.0355, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(4.6958e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.038164
Average KL loss: 0.054562
Average total loss: 0.092726
tensor(0.0355, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-3.0586e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.038521
Average KL loss: 0.054470
Average total loss: 0.092990
tensor(0.0355, device='cuda:0') tensor(0.1239, device='cuda:0') tensor(8.3446e-11, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.038599
Average KL loss: 0.054417
Average total loss: 0.093016
tensor(0.0354, device='cuda:0') tensor(0.1238, device='cuda:0') tensor(-6.7771e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.039016
Average KL loss: 0.054371
Average total loss: 0.093387
tensor(0.0355, device='cuda:0') tensor(0.1237, device='cuda:0') tensor(1.0093e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.039475
Average KL loss: 0.054348
Average total loss: 0.093823
tensor(0.0355, device='cuda:0') tensor(0.1236, device='cuda:0') tensor(-4.8457e-11, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.038706
Average KL loss: 0.054345
Average total loss: 0.093051
tensor(0.0354, device='cuda:0') tensor(0.1235, device='cuda:0') tensor(-3.1247e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.039028
Average KL loss: 0.054268
Average total loss: 0.093297
tensor(0.0354, device='cuda:0') tensor(0.1234, device='cuda:0') tensor(5.5112e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.038631
Average KL loss: 0.054240
Average total loss: 0.092871
tensor(0.0354, device='cuda:0') tensor(0.1232, device='cuda:0') tensor(2.7859e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.038264
Average KL loss: 0.054145
Average total loss: 0.092409
tensor(0.0354, device='cuda:0') tensor(0.1231, device='cuda:0') tensor(9.9886e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.038635
Average KL loss: 0.054078
Average total loss: 0.092713
tensor(0.0354, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(1.0781e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.039102
Average KL loss: 0.054006
Average total loss: 0.093108
tensor(0.0354, device='cuda:0') tensor(0.1229, device='cuda:0') tensor(1.0590e-12, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.038009
Average KL loss: 0.053960
Average total loss: 0.091969
tensor(0.0353, device='cuda:0') tensor(0.1227, device='cuda:0') tensor(7.7894e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.038704
Average KL loss: 0.053878
Average total loss: 0.092583
 Percentile value: 0.3259682238101959
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =     177 /    1728             ( 10.24%) | total_pruned =    1551 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
bn1.bias             | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1058 /   36864             (  2.87%) | total_pruned =   35806 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2677 /   36864             (  7.26%) | total_pruned =   34187 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2422 /   36864             (  6.57%) | total_pruned =   34442 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3472 /   36864             (  9.42%) | total_pruned =   33392 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13029 /   73728             ( 17.67%) | total_pruned =   60699 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   24249 /  147456             ( 16.44%) | total_pruned =  123207 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1851 /    8192             ( 22.60%) | total_pruned =    6341 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   13739 /  147456             (  9.32%) | total_pruned =  133717 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   13122 /  147456             (  8.90%) | total_pruned =  134334 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   54627 /  294912             ( 18.52%) | total_pruned =  240285 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     200 /     256             ( 78.12%) | total_pruned =      56 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   81393 /  589824             ( 13.80%) | total_pruned =  508431 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     174 /     256             ( 67.97%) | total_pruned =      82 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5932 /   32768             ( 18.10%) | total_pruned =   26836 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   58141 /  589824             (  9.86%) | total_pruned =  531683 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   47932 /  589824             (  8.13%) | total_pruned =  541892 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     174 /     256             ( 67.97%) | total_pruned =      82 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     109 /     256             ( 42.58%) | total_pruned =     147 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  138549 / 1179648             ( 11.74%) | total_pruned = 1041099 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     418 /     512             ( 81.64%) | total_pruned =      94 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     140 /     512             ( 27.34%) | total_pruned =     372 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  166430 / 2359296             (  7.05%) | total_pruned = 2192866 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     477 /     512             ( 93.16%) | total_pruned =      35 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     273 /     512             ( 53.32%) | total_pruned =     239 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    6099 /  131072             (  4.65%) | total_pruned =  124973 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     291 /     512             ( 56.84%) | total_pruned =     221 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  128129 / 2359296             (  5.43%) | total_pruned = 2231167 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     418 /     512             ( 81.64%) | total_pruned =      94 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  232544 / 2359296             (  9.86%) | total_pruned = 2126752 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     492 /     512             ( 96.09%) | total_pruned =      20 | shape = torch.Size([512])
linear.weight        | nonzeros =    4845 /    5120             ( 94.63%) | total_pruned =     275 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 58/200 Loss: 0.036023 Accuracy: 86.61 100.00 % Best test Accuracy: 86.75%
tensor(0.0353, device='cuda:0') tensor(0.1226, device='cuda:0') tensor(-7.6192e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.377163
Average KL loss: 0.048912
Average total loss: 0.426076
tensor(0.0281, device='cuda:0') tensor(0.0861, device='cuda:0') tensor(-2.6002e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.256077
Average KL loss: 0.056388
Average total loss: 0.312465
tensor(0.0288, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-1.8740e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.221955
Average KL loss: 0.063104
Average total loss: 0.285059
tensor(0.0298, device='cuda:0') tensor(0.0947, device='cuda:0') tensor(-1.2546e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.193332
Average KL loss: 0.068472
Average total loss: 0.261804
tensor(0.0307, device='cuda:0') tensor(0.1011, device='cuda:0') tensor(-1.0121e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.170292
Average KL loss: 0.072742
Average total loss: 0.243033
tensor(0.0317, device='cuda:0') tensor(0.1073, device='cuda:0') tensor(-7.3072e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.148031
Average KL loss: 0.076114
Average total loss: 0.224145
tensor(0.0325, device='cuda:0') tensor(0.1128, device='cuda:0') tensor(-6.8440e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.135371
Average KL loss: 0.078824
Average total loss: 0.214195
tensor(0.0334, device='cuda:0') tensor(0.1181, device='cuda:0') tensor(-8.7303e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.121348
Average KL loss: 0.081014
Average total loss: 0.202362
tensor(0.0340, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-4.7040e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.109873
Average KL loss: 0.082564
Average total loss: 0.192438
tensor(0.0346, device='cuda:0') tensor(0.1263, device='cuda:0') tensor(-7.2744e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.100455
Average KL loss: 0.083747
Average total loss: 0.184202
tensor(0.0351, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-6.1957e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.094694
Average KL loss: 0.084630
Average total loss: 0.179324
tensor(0.0355, device='cuda:0') tensor(0.1329, device='cuda:0') tensor(-5.1980e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.089044
Average KL loss: 0.085425
Average total loss: 0.174469
tensor(0.0359, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-3.5253e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.082843
Average KL loss: 0.086015
Average total loss: 0.168858
tensor(0.0363, device='cuda:0') tensor(0.1385, device='cuda:0') tensor(-4.2865e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.078478
Average KL loss: 0.086643
Average total loss: 0.165121
tensor(0.0366, device='cuda:0') tensor(0.1409, device='cuda:0') tensor(-2.4458e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.073866
Average KL loss: 0.086725
Average total loss: 0.160591
tensor(0.0367, device='cuda:0') tensor(0.1424, device='cuda:0') tensor(-3.7736e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.070402
Average KL loss: 0.086790
Average total loss: 0.157192
tensor(0.0369, device='cuda:0') tensor(0.1443, device='cuda:0') tensor(-1.5870e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.067923
Average KL loss: 0.086952
Average total loss: 0.154874
tensor(0.0371, device='cuda:0') tensor(0.1460, device='cuda:0') tensor(-2.5256e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.065059
Average KL loss: 0.086960
Average total loss: 0.152019
tensor(0.0373, device='cuda:0') tensor(0.1475, device='cuda:0') tensor(-2.6521e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.061429
Average KL loss: 0.086790
Average total loss: 0.148219
tensor(0.0374, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(-2.3247e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.059529
Average KL loss: 0.086625
Average total loss: 0.146154
tensor(0.0376, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-3.0054e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.058483
Average KL loss: 0.086467
Average total loss: 0.144950
tensor(0.0377, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(-2.3223e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.055669
Average KL loss: 0.086243
Average total loss: 0.141913
tensor(0.0379, device='cuda:0') tensor(0.1520, device='cuda:0') tensor(-9.6102e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.054427
Average KL loss: 0.086048
Average total loss: 0.140476
tensor(0.0379, device='cuda:0') tensor(0.1530, device='cuda:0') tensor(-2.7529e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.053042
Average KL loss: 0.085776
Average total loss: 0.138818
tensor(0.0380, device='cuda:0') tensor(0.1538, device='cuda:0') tensor(-1.7418e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.051846
Average KL loss: 0.085580
Average total loss: 0.137426
tensor(0.0380, device='cuda:0') tensor(0.1546, device='cuda:0') tensor(-1.7392e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.051460
Average KL loss: 0.085238
Average total loss: 0.136697
tensor(0.0381, device='cuda:0') tensor(0.1555, device='cuda:0') tensor(-1.0154e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.049939
Average KL loss: 0.085172
Average total loss: 0.135111
tensor(0.0382, device='cuda:0') tensor(0.1565, device='cuda:0') tensor(-8.8081e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.048012
Average KL loss: 0.084777
Average total loss: 0.132789
tensor(0.0381, device='cuda:0') tensor(0.1571, device='cuda:0') tensor(-7.0520e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.048164
Average KL loss: 0.084475
Average total loss: 0.132639
tensor(0.0382, device='cuda:0') tensor(0.1581, device='cuda:0') tensor(2.2412e-11, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.047162
Average KL loss: 0.084315
Average total loss: 0.131477
tensor(0.0382, device='cuda:0') tensor(0.1588, device='cuda:0') tensor(-9.6973e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.046438
Average KL loss: 0.084111
Average total loss: 0.130549
tensor(0.0382, device='cuda:0') tensor(0.1594, device='cuda:0') tensor(-1.3290e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.046058
Average KL loss: 0.083931
Average total loss: 0.129989
tensor(0.0382, device='cuda:0') tensor(0.1605, device='cuda:0') tensor(-1.2171e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.044624
Average KL loss: 0.083735
Average total loss: 0.128359
tensor(0.0382, device='cuda:0') tensor(0.1612, device='cuda:0') tensor(-3.8389e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.044406
Average KL loss: 0.083547
Average total loss: 0.127953
tensor(0.0383, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-5.9687e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.042776
Average KL loss: 0.083196
Average total loss: 0.125973
tensor(0.0382, device='cuda:0') tensor(0.1623, device='cuda:0') tensor(-1.0301e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.043425
Average KL loss: 0.082919
Average total loss: 0.126344
tensor(0.0382, device='cuda:0') tensor(0.1634, device='cuda:0') tensor(-1.0859e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.042384
Average KL loss: 0.082876
Average total loss: 0.125260
tensor(0.0383, device='cuda:0') tensor(0.1641, device='cuda:0') tensor(1.9138e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.042945
Average KL loss: 0.082812
Average total loss: 0.125757
tensor(0.0382, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-8.0448e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.042296
Average KL loss: 0.082765
Average total loss: 0.125061
tensor(0.0383, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(-1.0050e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.041557
Average KL loss: 0.082704
Average total loss: 0.124262
tensor(0.0383, device='cuda:0') tensor(0.1668, device='cuda:0') tensor(-6.7544e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.041280
Average KL loss: 0.082636
Average total loss: 0.123916
tensor(0.0384, device='cuda:0') tensor(0.1680, device='cuda:0') tensor(-8.0824e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.040971
Average KL loss: 0.082783
Average total loss: 0.123754
tensor(0.0384, device='cuda:0') tensor(0.1689, device='cuda:0') tensor(1.6801e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.040961
Average KL loss: 0.082544
Average total loss: 0.123505
tensor(0.0385, device='cuda:0') tensor(0.1697, device='cuda:0') tensor(-4.5161e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.039917
Average KL loss: 0.082573
Average total loss: 0.122490
tensor(0.0385, device='cuda:0') tensor(0.1705, device='cuda:0') tensor(-1.0656e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.039828
Average KL loss: 0.082437
Average total loss: 0.122265
tensor(0.0385, device='cuda:0') tensor(0.1712, device='cuda:0') tensor(-1.6415e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.040546
Average KL loss: 0.082519
Average total loss: 0.123065
tensor(0.0386, device='cuda:0') tensor(0.1727, device='cuda:0') tensor(-3.8993e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.039611
Average KL loss: 0.082921
Average total loss: 0.122532
tensor(0.0386, device='cuda:0') tensor(0.1739, device='cuda:0') tensor(-4.8572e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.039375
Average KL loss: 0.082672
Average total loss: 0.122047
tensor(0.0386, device='cuda:0') tensor(0.1745, device='cuda:0') tensor(2.4368e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.039662
Average KL loss: 0.082629
Average total loss: 0.122290
tensor(0.0386, device='cuda:0') tensor(0.1758, device='cuda:0') tensor(-5.9882e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.038869
Average KL loss: 0.083107
Average total loss: 0.121976
tensor(0.0387, device='cuda:0') tensor(0.1773, device='cuda:0') tensor(-1.7703e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.038258
Average KL loss: 0.083048
Average total loss: 0.121306
tensor(0.0387, device='cuda:0') tensor(0.1781, device='cuda:0') tensor(-2.0231e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.037820
Average KL loss: 0.082844
Average total loss: 0.120664
tensor(0.0387, device='cuda:0') tensor(0.1789, device='cuda:0') tensor(-3.4046e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.038085
Average KL loss: 0.082690
Average total loss: 0.120774
tensor(0.0388, device='cuda:0') tensor(0.1798, device='cuda:0') tensor(-6.6813e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.037521
Average KL loss: 0.082629
Average total loss: 0.120150
tensor(0.0388, device='cuda:0') tensor(0.1806, device='cuda:0') tensor(7.2548e-11, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.037566
Average KL loss: 0.082568
Average total loss: 0.120134
tensor(0.0388, device='cuda:0') tensor(0.1816, device='cuda:0') tensor(-5.5312e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.037634
Average KL loss: 0.082854
Average total loss: 0.120488
tensor(0.0389, device='cuda:0') tensor(0.1830, device='cuda:0') tensor(-5.0905e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.037503
Average KL loss: 0.083044
Average total loss: 0.120547
tensor(0.0389, device='cuda:0') tensor(0.1843, device='cuda:0') tensor(-1.5684e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.037481
Average KL loss: 0.083320
Average total loss: 0.120801
tensor(0.0389, device='cuda:0') tensor(0.1857, device='cuda:0') tensor(-5.0569e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.037049
Average KL loss: 0.083315
Average total loss: 0.120364
tensor(0.0390, device='cuda:0') tensor(0.1865, device='cuda:0') tensor(-1.1757e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.036841
Average KL loss: 0.083320
Average total loss: 0.120160
tensor(0.0390, device='cuda:0') tensor(0.1878, device='cuda:0') tensor(-2.3432e-11, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.036539
Average KL loss: 0.083288
Average total loss: 0.119826
tensor(0.0391, device='cuda:0') tensor(0.1888, device='cuda:0') tensor(-3.9213e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.036515
Average KL loss: 0.083350
Average total loss: 0.119865
tensor(0.0391, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-6.5078e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.036464
Average KL loss: 0.083199
Average total loss: 0.119663
tensor(0.0392, device='cuda:0') tensor(0.1909, device='cuda:0') tensor(-4.8129e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.036343
Average KL loss: 0.083541
Average total loss: 0.119885
tensor(0.0392, device='cuda:0') tensor(0.1925, device='cuda:0') tensor(-3.3127e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.035518
Average KL loss: 0.083502
Average total loss: 0.119020
tensor(0.0393, device='cuda:0') tensor(0.1932, device='cuda:0') tensor(-3.1116e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.035633
Average KL loss: 0.083413
Average total loss: 0.119046
tensor(0.0392, device='cuda:0') tensor(0.1941, device='cuda:0') tensor(-1.1040e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.035612
Average KL loss: 0.083438
Average total loss: 0.119050
tensor(0.0393, device='cuda:0') tensor(0.1954, device='cuda:0') tensor(3.3681e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.035848
Average KL loss: 0.083584
Average total loss: 0.119431
tensor(0.0393, device='cuda:0') tensor(0.1967, device='cuda:0') tensor(5.8874e-11, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.036359
Average KL loss: 0.083966
Average total loss: 0.120324
tensor(0.0393, device='cuda:0') tensor(0.1983, device='cuda:0') tensor(-4.0822e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.035585
Average KL loss: 0.084211
Average total loss: 0.119796
tensor(0.0395, device='cuda:0') tensor(0.1995, device='cuda:0') tensor(-2.4101e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.035078
Average KL loss: 0.084111
Average total loss: 0.119190
tensor(0.0395, device='cuda:0') tensor(0.2007, device='cuda:0') tensor(-8.6658e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.034602
Average KL loss: 0.084027
Average total loss: 0.118629
tensor(0.0395, device='cuda:0') tensor(0.2014, device='cuda:0') tensor(-2.8786e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.035162
Average KL loss: 0.083913
Average total loss: 0.119075
tensor(0.0395, device='cuda:0') tensor(0.2027, device='cuda:0') tensor(-5.0624e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.034757
Average KL loss: 0.083968
Average total loss: 0.118724
tensor(0.0395, device='cuda:0') tensor(0.2034, device='cuda:0') tensor(-1.4434e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.034866
Average KL loss: 0.084003
Average total loss: 0.118869
tensor(0.0396, device='cuda:0') tensor(0.2048, device='cuda:0') tensor(-6.2802e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.034581
Average KL loss: 0.084211
Average total loss: 0.118792
tensor(0.0397, device='cuda:0') tensor(0.2059, device='cuda:0') tensor(-2.9919e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.034407
Average KL loss: 0.084168
Average total loss: 0.118575
tensor(0.0397, device='cuda:0') tensor(0.2069, device='cuda:0') tensor(-5.2325e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.034746
Average KL loss: 0.084122
Average total loss: 0.118867
tensor(0.0397, device='cuda:0') tensor(0.2082, device='cuda:0') tensor(-1.7282e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.035566
Average KL loss: 0.084703
Average total loss: 0.120269
tensor(0.0399, device='cuda:0') tensor(0.2104, device='cuda:0') tensor(1.8964e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.034735
Average KL loss: 0.085483
Average total loss: 0.120218
tensor(0.0399, device='cuda:0') tensor(0.2125, device='cuda:0') tensor(7.8336e-11, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.034249
Average KL loss: 0.085573
Average total loss: 0.119822
tensor(0.0400, device='cuda:0') tensor(0.2135, device='cuda:0') tensor(-3.5293e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.034209
Average KL loss: 0.085366
Average total loss: 0.119575
tensor(0.0401, device='cuda:0') tensor(0.2146, device='cuda:0') tensor(-1.4870e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.035050
Average KL loss: 0.085725
Average total loss: 0.120775
tensor(0.0401, device='cuda:0') tensor(0.2163, device='cuda:0') tensor(-1.2680e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.033765
Average KL loss: 0.085967
Average total loss: 0.119732
tensor(0.0402, device='cuda:0') tensor(0.2175, device='cuda:0') tensor(2.3311e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.034041
Average KL loss: 0.085761
Average total loss: 0.119802
tensor(0.0402, device='cuda:0') tensor(0.2184, device='cuda:0') tensor(-3.1614e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.033931
Average KL loss: 0.085766
Average total loss: 0.119697
tensor(0.0403, device='cuda:0') tensor(0.2197, device='cuda:0') tensor(3.8165e-11, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.033754
Average KL loss: 0.086025
Average total loss: 0.119778
tensor(0.0403, device='cuda:0') tensor(0.2210, device='cuda:0') tensor(-4.8572e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.033629
Average KL loss: 0.085813
Average total loss: 0.119442
tensor(0.0404, device='cuda:0') tensor(0.2216, device='cuda:0') tensor(-5.7520e-11, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.032392
Average KL loss: 0.085196
Average total loss: 0.117589
tensor(0.0403, device='cuda:0') tensor(0.2206, device='cuda:0') tensor(-1.1268e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.031757
Average KL loss: 0.084150
Average total loss: 0.115908
tensor(0.0403, device='cuda:0') tensor(0.2195, device='cuda:0') tensor(-2.3280e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.031535
Average KL loss: 0.083274
Average total loss: 0.114808
tensor(0.0403, device='cuda:0') tensor(0.2186, device='cuda:0') tensor(-1.2852e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.031613
Average KL loss: 0.082507
Average total loss: 0.114121
tensor(0.0402, device='cuda:0') tensor(0.2177, device='cuda:0') tensor(1.5368e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.031616
Average KL loss: 0.081840
Average total loss: 0.113457
tensor(0.0402, device='cuda:0') tensor(0.2169, device='cuda:0') tensor(-4.3259e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.030696
Average KL loss: 0.081195
Average total loss: 0.111890
tensor(0.0401, device='cuda:0') tensor(0.2161, device='cuda:0') tensor(-2.5912e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.031376
Average KL loss: 0.080592
Average total loss: 0.111968
tensor(0.0401, device='cuda:0') tensor(0.2154, device='cuda:0') tensor(4.1572e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.031156
Average KL loss: 0.080037
Average total loss: 0.111194
tensor(0.0401, device='cuda:0') tensor(0.2147, device='cuda:0') tensor(-3.1865e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.031323
Average KL loss: 0.079507
Average total loss: 0.110830
tensor(0.0400, device='cuda:0') tensor(0.2140, device='cuda:0') tensor(-1.9536e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.030959
Average KL loss: 0.079000
Average total loss: 0.109959
tensor(0.0400, device='cuda:0') tensor(0.2133, device='cuda:0') tensor(-1.0923e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.030564
Average KL loss: 0.078503
Average total loss: 0.109067
tensor(0.0400, device='cuda:0') tensor(0.2126, device='cuda:0') tensor(2.3301e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.030895
Average KL loss: 0.078038
Average total loss: 0.108933
tensor(0.0399, device='cuda:0') tensor(0.2120, device='cuda:0') tensor(6.3850e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.030945
Average KL loss: 0.077587
Average total loss: 0.108532
tensor(0.0399, device='cuda:0') tensor(0.2113, device='cuda:0') tensor(4.0860e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.031183
Average KL loss: 0.077153
Average total loss: 0.108336
tensor(0.0399, device='cuda:0') tensor(0.2107, device='cuda:0') tensor(1.0178e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.030692
Average KL loss: 0.076740
Average total loss: 0.107432
tensor(0.0398, device='cuda:0') tensor(0.2101, device='cuda:0') tensor(6.1434e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.030754
Average KL loss: 0.076346
Average total loss: 0.107100
tensor(0.0398, device='cuda:0') tensor(0.2096, device='cuda:0') tensor(1.4726e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.031014
Average KL loss: 0.075962
Average total loss: 0.106976
tensor(0.0397, device='cuda:0') tensor(0.2090, device='cuda:0') tensor(1.7010e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.030559
Average KL loss: 0.075582
Average total loss: 0.106141
tensor(0.0397, device='cuda:0') tensor(0.2084, device='cuda:0') tensor(1.0743e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.030921
Average KL loss: 0.075205
Average total loss: 0.106127
tensor(0.0397, device='cuda:0') tensor(0.2079, device='cuda:0') tensor(4.8375e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.030754
Average KL loss: 0.074844
Average total loss: 0.105599
tensor(0.0396, device='cuda:0') tensor(0.2073, device='cuda:0') tensor(3.7411e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.030403
Average KL loss: 0.074490
Average total loss: 0.104892
tensor(0.0396, device='cuda:0') tensor(0.2068, device='cuda:0') tensor(3.6780e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.030815
Average KL loss: 0.074158
Average total loss: 0.104973
tensor(0.0395, device='cuda:0') tensor(0.2062, device='cuda:0') tensor(-4.4897e-11, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.030509
Average KL loss: 0.073819
Average total loss: 0.104327
tensor(0.0395, device='cuda:0') tensor(0.2057, device='cuda:0') tensor(5.1991e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.030742
Average KL loss: 0.073493
Average total loss: 0.104235
tensor(0.0395, device='cuda:0') tensor(0.2052, device='cuda:0') tensor(-5.5484e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.030818
Average KL loss: 0.073185
Average total loss: 0.104003
tensor(0.0394, device='cuda:0') tensor(0.2047, device='cuda:0') tensor(2.3788e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.031081
Average KL loss: 0.072889
Average total loss: 0.103970
tensor(0.0394, device='cuda:0') tensor(0.2042, device='cuda:0') tensor(3.6893e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.030885
Average KL loss: 0.072599
Average total loss: 0.103484
tensor(0.0394, device='cuda:0') tensor(0.2037, device='cuda:0') tensor(-4.2098e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.030725
Average KL loss: 0.072315
Average total loss: 0.103040
tensor(0.0393, device='cuda:0') tensor(0.2032, device='cuda:0') tensor(2.8370e-11, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.031032
Average KL loss: 0.072033
Average total loss: 0.103065
tensor(0.0393, device='cuda:0') tensor(0.2028, device='cuda:0') tensor(2.5351e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.030872
Average KL loss: 0.071760
Average total loss: 0.102633
tensor(0.0393, device='cuda:0') tensor(0.2023, device='cuda:0') tensor(-1.8563e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.031173
Average KL loss: 0.071506
Average total loss: 0.102679
tensor(0.0392, device='cuda:0') tensor(0.2018, device='cuda:0') tensor(1.5163e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.030840
Average KL loss: 0.071237
Average total loss: 0.102077
tensor(0.0392, device='cuda:0') tensor(0.2014, device='cuda:0') tensor(3.5074e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.030833
Average KL loss: 0.070987
Average total loss: 0.101819
tensor(0.0391, device='cuda:0') tensor(0.2009, device='cuda:0') tensor(-3.8484e-11, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.030904
Average KL loss: 0.070727
Average total loss: 0.101631
tensor(0.0391, device='cuda:0') tensor(0.2005, device='cuda:0') tensor(3.0991e-11, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.030876
Average KL loss: 0.070476
Average total loss: 0.101352
tensor(0.0391, device='cuda:0') tensor(0.2000, device='cuda:0') tensor(4.9949e-11, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.031055
Average KL loss: 0.070234
Average total loss: 0.101289
tensor(0.0391, device='cuda:0') tensor(0.1996, device='cuda:0') tensor(4.0415e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.031150
Average KL loss: 0.070007
Average total loss: 0.101156
tensor(0.0390, device='cuda:0') tensor(0.1992, device='cuda:0') tensor(-6.5433e-11, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.030945
Average KL loss: 0.069765
Average total loss: 0.100710
tensor(0.0390, device='cuda:0') tensor(0.1987, device='cuda:0') tensor(-1.9152e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.031120
Average KL loss: 0.069533
Average total loss: 0.100653
tensor(0.0389, device='cuda:0') tensor(0.1983, device='cuda:0') tensor(7.0703e-11, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.030973
Average KL loss: 0.069317
Average total loss: 0.100290
tensor(0.0389, device='cuda:0') tensor(0.1978, device='cuda:0') tensor(4.1737e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.030744
Average KL loss: 0.069110
Average total loss: 0.099854
tensor(0.0389, device='cuda:0') tensor(0.1974, device='cuda:0') tensor(1.5679e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.031070
Average KL loss: 0.068885
Average total loss: 0.099955
tensor(0.0388, device='cuda:0') tensor(0.1970, device='cuda:0') tensor(-3.6485e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.030767
Average KL loss: 0.068673
Average total loss: 0.099440
tensor(0.0388, device='cuda:0') tensor(0.1966, device='cuda:0') tensor(-4.0519e-11, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.030974
Average KL loss: 0.068456
Average total loss: 0.099430
tensor(0.0388, device='cuda:0') tensor(0.1962, device='cuda:0') tensor(1.3094e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.030940
Average KL loss: 0.068254
Average total loss: 0.099194
tensor(0.0387, device='cuda:0') tensor(0.1958, device='cuda:0') tensor(1.8363e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.030907
Average KL loss: 0.068053
Average total loss: 0.098960
tensor(0.0387, device='cuda:0') tensor(0.1954, device='cuda:0') tensor(1.7774e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.031613
Average KL loss: 0.067869
Average total loss: 0.099482
tensor(0.0386, device='cuda:0') tensor(0.1950, device='cuda:0') tensor(-1.4538e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.031463
Average KL loss: 0.067687
Average total loss: 0.099150
tensor(0.0386, device='cuda:0') tensor(0.1946, device='cuda:0') tensor(-1.6144e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.030448
Average KL loss: 0.067507
Average total loss: 0.097955
tensor(0.0386, device='cuda:0') tensor(0.1942, device='cuda:0') tensor(3.6274e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.031512
Average KL loss: 0.067302
Average total loss: 0.098814
tensor(0.0385, device='cuda:0') tensor(0.1939, device='cuda:0') tensor(3.2151e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.031559
Average KL loss: 0.067140
Average total loss: 0.098699
tensor(0.0385, device='cuda:0') tensor(0.1935, device='cuda:0') tensor(1.7713e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.031315
Average KL loss: 0.066984
Average total loss: 0.098298
tensor(0.0385, device='cuda:0') tensor(0.1931, device='cuda:0') tensor(2.0490e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.031339
Average KL loss: 0.066804
Average total loss: 0.098143
tensor(0.0385, device='cuda:0') tensor(0.1928, device='cuda:0') tensor(1.7360e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.030860
Average KL loss: 0.066626
Average total loss: 0.097485
tensor(0.0384, device='cuda:0') tensor(0.1924, device='cuda:0') tensor(4.9339e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.031191
Average KL loss: 0.066452
Average total loss: 0.097643
tensor(0.0384, device='cuda:0') tensor(0.1920, device='cuda:0') tensor(2.3351e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.031534
Average KL loss: 0.066308
Average total loss: 0.097841
tensor(0.0384, device='cuda:0') tensor(0.1917, device='cuda:0') tensor(-6.9750e-11, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.030951
Average KL loss: 0.066150
Average total loss: 0.097101
tensor(0.0383, device='cuda:0') tensor(0.1913, device='cuda:0') tensor(1.7303e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.031735
Average KL loss: 0.065987
Average total loss: 0.097722
tensor(0.0383, device='cuda:0') tensor(0.1910, device='cuda:0') tensor(3.9847e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.031061
Average KL loss: 0.065843
Average total loss: 0.096904
tensor(0.0383, device='cuda:0') tensor(0.1906, device='cuda:0') tensor(1.1452e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.031774
Average KL loss: 0.065690
Average total loss: 0.097464
tensor(0.0382, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(2.6509e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.031721
Average KL loss: 0.065555
Average total loss: 0.097276
tensor(0.0382, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(-6.3757e-11, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.031247
Average KL loss: 0.065414
Average total loss: 0.096662
tensor(0.0382, device='cuda:0') tensor(0.1896, device='cuda:0') tensor(-1.6992e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.031636
Average KL loss: 0.065263
Average total loss: 0.096900
tensor(0.0382, device='cuda:0') tensor(0.1893, device='cuda:0') tensor(2.5908e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.031777
Average KL loss: 0.065134
Average total loss: 0.096910
tensor(0.0381, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(2.3995e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.031808
Average KL loss: 0.064995
Average total loss: 0.096803
tensor(0.0381, device='cuda:0') tensor(0.1887, device='cuda:0') tensor(2.9273e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.031422
Average KL loss: 0.064863
Average total loss: 0.096286
tensor(0.0381, device='cuda:0') tensor(0.1883, device='cuda:0') tensor(-1.8594e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.032387
Average KL loss: 0.064738
Average total loss: 0.097125
tensor(0.0381, device='cuda:0') tensor(0.1881, device='cuda:0') tensor(4.3083e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.031068
Average KL loss: 0.064608
Average total loss: 0.095676
tensor(0.0380, device='cuda:0') tensor(0.1877, device='cuda:0') tensor(2.9176e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.031792
Average KL loss: 0.064468
Average total loss: 0.096260
tensor(0.0380, device='cuda:0') tensor(0.1874, device='cuda:0') tensor(1.4055e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.031722
Average KL loss: 0.064338
Average total loss: 0.096060
tensor(0.0380, device='cuda:0') tensor(0.1871, device='cuda:0') tensor(2.0922e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.031708
Average KL loss: 0.064225
Average total loss: 0.095933
tensor(0.0379, device='cuda:0') tensor(0.1868, device='cuda:0') tensor(-3.2543e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.031763
Average KL loss: 0.064102
Average total loss: 0.095865
tensor(0.0379, device='cuda:0') tensor(0.1864, device='cuda:0') tensor(-1.3671e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.031789
Average KL loss: 0.063968
Average total loss: 0.095757
tensor(0.0379, device='cuda:0') tensor(0.1861, device='cuda:0') tensor(6.8964e-11, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.031871
Average KL loss: 0.063858
Average total loss: 0.095729
tensor(0.0378, device='cuda:0') tensor(0.1859, device='cuda:0') tensor(-2.7877e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.032126
Average KL loss: 0.063753
Average total loss: 0.095878
tensor(0.0378, device='cuda:0') tensor(0.1856, device='cuda:0') tensor(6.2798e-12, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.031189
Average KL loss: 0.063626
Average total loss: 0.094815
tensor(0.0378, device='cuda:0') tensor(0.1853, device='cuda:0') tensor(3.3669e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.031691
Average KL loss: 0.063497
Average total loss: 0.095188
tensor(0.0378, device='cuda:0') tensor(0.1850, device='cuda:0') tensor(-1.5828e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.032166
Average KL loss: 0.063387
Average total loss: 0.095553
tensor(0.0378, device='cuda:0') tensor(0.1847, device='cuda:0') tensor(-1.8219e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.031911
Average KL loss: 0.063294
Average total loss: 0.095205
tensor(0.0377, device='cuda:0') tensor(0.1844, device='cuda:0') tensor(2.7377e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.031701
Average KL loss: 0.063186
Average total loss: 0.094887
tensor(0.0377, device='cuda:0') tensor(0.1842, device='cuda:0') tensor(-5.9156e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.031929
Average KL loss: 0.063085
Average total loss: 0.095014
tensor(0.0377, device='cuda:0') tensor(0.1839, device='cuda:0') tensor(5.7003e-13, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.031570
Average KL loss: 0.062984
Average total loss: 0.094554
tensor(0.0376, device='cuda:0') tensor(0.1836, device='cuda:0') tensor(5.6077e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.031906
Average KL loss: 0.062866
Average total loss: 0.094772
tensor(0.0376, device='cuda:0') tensor(0.1833, device='cuda:0') tensor(3.0809e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.031792
Average KL loss: 0.062765
Average total loss: 0.094557
tensor(0.0376, device='cuda:0') tensor(0.1831, device='cuda:0') tensor(4.6432e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.031298
Average KL loss: 0.062657
Average total loss: 0.093954
tensor(0.0375, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(3.8929e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.031888
Average KL loss: 0.062551
Average total loss: 0.094439
tensor(0.0375, device='cuda:0') tensor(0.1825, device='cuda:0') tensor(4.2996e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.031709
Average KL loss: 0.062459
Average total loss: 0.094168
tensor(0.0375, device='cuda:0') tensor(0.1822, device='cuda:0') tensor(4.5825e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.032347
Average KL loss: 0.062354
Average total loss: 0.094700
tensor(0.0375, device='cuda:0') tensor(0.1819, device='cuda:0') tensor(4.0222e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.032125
Average KL loss: 0.062276
Average total loss: 0.094400
tensor(0.0375, device='cuda:0') tensor(0.1817, device='cuda:0') tensor(4.3061e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.032091
Average KL loss: 0.062198
Average total loss: 0.094289
tensor(0.0374, device='cuda:0') tensor(0.1814, device='cuda:0') tensor(2.6361e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.032439
Average KL loss: 0.062117
Average total loss: 0.094557
tensor(0.0374, device='cuda:0') tensor(0.1812, device='cuda:0') tensor(1.8942e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.031938
Average KL loss: 0.062040
Average total loss: 0.093978
tensor(0.0374, device='cuda:0') tensor(0.1809, device='cuda:0') tensor(1.1970e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.032181
Average KL loss: 0.061932
Average total loss: 0.094113
tensor(0.0374, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-2.1338e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.032124
Average KL loss: 0.061846
Average total loss: 0.093970
tensor(0.0373, device='cuda:0') tensor(0.1804, device='cuda:0') tensor(8.3266e-11, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.032253
Average KL loss: 0.061750
Average total loss: 0.094003
tensor(0.0373, device='cuda:0') tensor(0.1802, device='cuda:0') tensor(-2.2128e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.032173
Average KL loss: 0.061686
Average total loss: 0.093859
tensor(0.0373, device='cuda:0') tensor(0.1800, device='cuda:0') tensor(1.2728e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.031869
Average KL loss: 0.061592
Average total loss: 0.093461
tensor(0.0373, device='cuda:0') tensor(0.1797, device='cuda:0') tensor(-1.2562e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.032029
Average KL loss: 0.061504
Average total loss: 0.093533
tensor(0.0372, device='cuda:0') tensor(0.1795, device='cuda:0') tensor(-3.0395e-11, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.032405
Average KL loss: 0.061420
Average total loss: 0.093824
tensor(0.0372, device='cuda:0') tensor(0.1793, device='cuda:0') tensor(-6.2624e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.032464
Average KL loss: 0.061346
Average total loss: 0.093810
tensor(0.0372, device='cuda:0') tensor(0.1790, device='cuda:0') tensor(-1.5171e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.032143
Average KL loss: 0.061256
Average total loss: 0.093398
tensor(0.0372, device='cuda:0') tensor(0.1788, device='cuda:0') tensor(3.6048e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.032131
Average KL loss: 0.061174
Average total loss: 0.093304
tensor(0.0371, device='cuda:0') tensor(0.1785, device='cuda:0') tensor(1.5431e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.032668
Average KL loss: 0.061097
Average total loss: 0.093766
tensor(0.0371, device='cuda:0') tensor(0.1783, device='cuda:0') tensor(-1.3303e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.031952
Average KL loss: 0.061028
Average total loss: 0.092980
tensor(0.0371, device='cuda:0') tensor(0.1781, device='cuda:0') tensor(3.8169e-11, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.032365
Average KL loss: 0.060950
Average total loss: 0.093316
tensor(0.0371, device='cuda:0') tensor(0.1778, device='cuda:0') tensor(-5.7592e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.032712
Average KL loss: 0.060886
Average total loss: 0.093598
tensor(0.0371, device='cuda:0') tensor(0.1776, device='cuda:0') tensor(3.6274e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.032329
Average KL loss: 0.060811
Average total loss: 0.093140
tensor(0.0371, device='cuda:0') tensor(0.1774, device='cuda:0') tensor(9.0966e-11, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.032401
Average KL loss: 0.060747
Average total loss: 0.093148
tensor(0.0370, device='cuda:0') tensor(0.1772, device='cuda:0') tensor(3.6199e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.032275
Average KL loss: 0.060672
Average total loss: 0.092947
tensor(0.0370, device='cuda:0') tensor(0.1770, device='cuda:0') tensor(-1.8343e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.032278
Average KL loss: 0.060597
Average total loss: 0.092875
tensor(0.0370, device='cuda:0') tensor(0.1767, device='cuda:0') tensor(-3.9032e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.032330
Average KL loss: 0.060520
Average total loss: 0.092850
tensor(0.0370, device='cuda:0') tensor(0.1765, device='cuda:0') tensor(-9.6566e-11, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.032239
Average KL loss: 0.060447
Average total loss: 0.092686
 Percentile value: 1.413453960418701
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =     157 /    1728             (  9.09%) | total_pruned =    1571 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     390 /   36864             (  1.06%) | total_pruned =   36474 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     700 /   36864             (  1.90%) | total_pruned =   36164 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     969 /   36864             (  2.63%) | total_pruned =   35895 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1559 /   36864             (  4.23%) | total_pruned =   35305 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    5271 /   73728             (  7.15%) | total_pruned =   68457 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   10063 /  147456             (  6.82%) | total_pruned =  137393 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     872 /    8192             ( 10.64%) | total_pruned =    7320 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4925 /  147456             (  3.34%) | total_pruned =  142531 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    4165 /  147456             (  2.82%) | total_pruned =  143291 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   22534 /  294912             (  7.64%) | total_pruned =  272378 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      96 /     256             ( 37.50%) | total_pruned =     160 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   29971 /  589824             (  5.08%) | total_pruned =  559853 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      85 /     256             ( 33.20%) | total_pruned =     171 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2371 /   32768             (  7.24%) | total_pruned =   30397 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     121 /     256             ( 47.27%) | total_pruned =     135 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      68 /     256             ( 26.56%) | total_pruned =     188 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   17926 /  589824             (  3.04%) | total_pruned =  571898 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     151 /     256             ( 58.98%) | total_pruned =     105 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   14879 /  589824             (  2.52%) | total_pruned =  574945 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     138 /     256             ( 53.91%) | total_pruned =     118 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   48058 / 1179648             (  4.07%) | total_pruned = 1131590 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     363 /     512             ( 70.90%) | total_pruned =     149 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      85 /     512             ( 16.60%) | total_pruned =     427 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   42221 / 2359296             (  1.79%) | total_pruned = 2317075 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     375 /     512             ( 73.24%) | total_pruned =     137 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     223 /     512             ( 43.55%) | total_pruned =     289 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1077 /  131072             (  0.82%) | total_pruned =  129995 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     123 /     512             ( 24.02%) | total_pruned =     389 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     218 /     512             ( 42.58%) | total_pruned =     294 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   26373 / 2359296             (  1.12%) | total_pruned = 2332923 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     247 /     512             ( 48.24%) | total_pruned =     265 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   58723 / 2359296             (  2.49%) | total_pruned = 2300573 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     461 /     512             ( 90.04%) | total_pruned =      51 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     446 /     512             ( 87.11%) | total_pruned =      66 | shape = torch.Size([512])
linear.weight        | nonzeros =    4250 /    5120             ( 83.01%) | total_pruned =     870 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 65/200 Loss: 0.015908 Accuracy: 85.24 100.00 % Best test Accuracy: 85.37%
tensor(0.0369, device='cuda:0') tensor(0.1763, device='cuda:0') tensor(-3.8819e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.340061
Average KL loss: 0.047961
Average total loss: 0.388022
tensor(0.0270, device='cuda:0') tensor(0.1013, device='cuda:0') tensor(-2.1805e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.252986
Average KL loss: 0.043975
Average total loss: 0.296961
tensor(0.0262, device='cuda:0') tensor(0.0960, device='cuda:0') tensor(-1.6057e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.223089
Average KL loss: 0.045919
Average total loss: 0.269008
tensor(0.0264, device='cuda:0') tensor(0.0974, device='cuda:0') tensor(-1.5893e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.199460
Average KL loss: 0.047984
Average total loss: 0.247445
tensor(0.0268, device='cuda:0') tensor(0.1003, device='cuda:0') tensor(-1.2865e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.179555
Average KL loss: 0.049886
Average total loss: 0.229441
tensor(0.0273, device='cuda:0') tensor(0.1040, device='cuda:0') tensor(-1.2988e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.159525
Average KL loss: 0.051364
Average total loss: 0.210889
tensor(0.0277, device='cuda:0') tensor(0.1074, device='cuda:0') tensor(-1.2617e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.140183
Average KL loss: 0.052655
Average total loss: 0.192839
tensor(0.0281, device='cuda:0') tensor(0.1108, device='cuda:0') tensor(-8.3058e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.128488
Average KL loss: 0.053785
Average total loss: 0.182273
tensor(0.0285, device='cuda:0') tensor(0.1141, device='cuda:0') tensor(-8.9485e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.120740
Average KL loss: 0.054733
Average total loss: 0.175473
tensor(0.0289, device='cuda:0') tensor(0.1173, device='cuda:0') tensor(-8.8137e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.114477
Average KL loss: 0.055693
Average total loss: 0.170171
tensor(0.0293, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-5.9513e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.102865
Average KL loss: 0.056529
Average total loss: 0.159394
tensor(0.0297, device='cuda:0') tensor(0.1236, device='cuda:0') tensor(-6.6276e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.094524
Average KL loss: 0.057193
Average total loss: 0.151717
tensor(0.0300, device='cuda:0') tensor(0.1264, device='cuda:0') tensor(-4.2233e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.086351
Average KL loss: 0.057693
Average total loss: 0.144044
tensor(0.0303, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-3.8466e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.080266
Average KL loss: 0.058060
Average total loss: 0.138326
tensor(0.0305, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-5.9206e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.075663
Average KL loss: 0.058362
Average total loss: 0.134026
tensor(0.0308, device='cuda:0') tensor(0.1330, device='cuda:0') tensor(-3.1400e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.074402
Average KL loss: 0.058654
Average total loss: 0.133056
tensor(0.0310, device='cuda:0') tensor(0.1351, device='cuda:0') tensor(-3.2738e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.068912
Average KL loss: 0.058959
Average total loss: 0.127871
tensor(0.0313, device='cuda:0') tensor(0.1373, device='cuda:0') tensor(-2.9560e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.065055
Average KL loss: 0.059130
Average total loss: 0.124185
tensor(0.0315, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(-2.7519e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.065991
Average KL loss: 0.059400
Average total loss: 0.125391
tensor(0.0316, device='cuda:0') tensor(0.1411, device='cuda:0') tensor(-2.0208e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.060057
Average KL loss: 0.059625
Average total loss: 0.119682
tensor(0.0318, device='cuda:0') tensor(0.1426, device='cuda:0') tensor(-1.5483e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.057484
Average KL loss: 0.059712
Average total loss: 0.117196
tensor(0.0320, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(-1.9665e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.056555
Average KL loss: 0.059799
Average total loss: 0.116354
tensor(0.0321, device='cuda:0') tensor(0.1457, device='cuda:0') tensor(-2.1345e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.053468
Average KL loss: 0.059918
Average total loss: 0.113386
tensor(0.0322, device='cuda:0') tensor(0.1471, device='cuda:0') tensor(-2.0649e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.052718
Average KL loss: 0.059923
Average total loss: 0.112641
tensor(0.0324, device='cuda:0') tensor(0.1485, device='cuda:0') tensor(-1.8282e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.052319
Average KL loss: 0.059996
Average total loss: 0.112315
tensor(0.0325, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-1.3819e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.048287
Average KL loss: 0.059974
Average total loss: 0.108260
tensor(0.0326, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(-2.9309e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.050740
Average KL loss: 0.059960
Average total loss: 0.110700
tensor(0.0327, device='cuda:0') tensor(0.1523, device='cuda:0') tensor(-1.1725e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.047786
Average KL loss: 0.060071
Average total loss: 0.107858
tensor(0.0328, device='cuda:0') tensor(0.1536, device='cuda:0') tensor(-5.8266e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.046988
Average KL loss: 0.060068
Average total loss: 0.107057
tensor(0.0330, device='cuda:0') tensor(0.1549, device='cuda:0') tensor(-7.8319e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.044468
Average KL loss: 0.060050
Average total loss: 0.104518
tensor(0.0330, device='cuda:0') tensor(0.1559, device='cuda:0') tensor(-1.1356e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.043709
Average KL loss: 0.059988
Average total loss: 0.103698
tensor(0.0331, device='cuda:0') tensor(0.1570, device='cuda:0') tensor(-7.9948e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.043130
Average KL loss: 0.059917
Average total loss: 0.103048
tensor(0.0332, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-1.0867e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.041633
Average KL loss: 0.059890
Average total loss: 0.101523
tensor(0.0332, device='cuda:0') tensor(0.1591, device='cuda:0') tensor(-1.3080e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.041091
Average KL loss: 0.059802
Average total loss: 0.100893
tensor(0.0333, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-1.9188e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.039933
Average KL loss: 0.059714
Average total loss: 0.099647
tensor(0.0333, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-6.8728e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.040534
Average KL loss: 0.059619
Average total loss: 0.100152
tensor(0.0334, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(-1.2405e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.039518
Average KL loss: 0.059639
Average total loss: 0.099158
tensor(0.0335, device='cuda:0') tensor(0.1629, device='cuda:0') tensor(-1.0214e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.037942
Average KL loss: 0.059548
Average total loss: 0.097490
tensor(0.0335, device='cuda:0') tensor(0.1636, device='cuda:0') tensor(-8.1801e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.037516
Average KL loss: 0.059417
Average total loss: 0.096933
tensor(0.0336, device='cuda:0') tensor(0.1643, device='cuda:0') tensor(-6.5704e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.038668
Average KL loss: 0.059413
Average total loss: 0.098081
tensor(0.0337, device='cuda:0') tensor(0.1655, device='cuda:0') tensor(-5.4328e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.037804
Average KL loss: 0.059406
Average total loss: 0.097209
tensor(0.0338, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-9.6081e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.036977
Average KL loss: 0.059425
Average total loss: 0.096402
tensor(0.0338, device='cuda:0') tensor(0.1674, device='cuda:0') tensor(-6.8576e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.036646
Average KL loss: 0.059347
Average total loss: 0.095993
tensor(0.0339, device='cuda:0') tensor(0.1683, device='cuda:0') tensor(-2.2889e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.036348
Average KL loss: 0.059317
Average total loss: 0.095665
tensor(0.0339, device='cuda:0') tensor(0.1692, device='cuda:0') tensor(-3.3963e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.035694
Average KL loss: 0.059298
Average total loss: 0.094992
tensor(0.0340, device='cuda:0') tensor(0.1702, device='cuda:0') tensor(-3.4750e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.035441
Average KL loss: 0.059226
Average total loss: 0.094667
tensor(0.0340, device='cuda:0') tensor(0.1710, device='cuda:0') tensor(-1.9294e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.035162
Average KL loss: 0.059161
Average total loss: 0.094323
tensor(0.0341, device='cuda:0') tensor(0.1719, device='cuda:0') tensor(-6.4090e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.034859
Average KL loss: 0.059146
Average total loss: 0.094005
tensor(0.0341, device='cuda:0') tensor(0.1728, device='cuda:0') tensor(-4.6489e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.034685
Average KL loss: 0.059104
Average total loss: 0.093789
tensor(0.0342, device='cuda:0') tensor(0.1737, device='cuda:0') tensor(-3.0148e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.033757
Average KL loss: 0.059035
Average total loss: 0.092792
tensor(0.0342, device='cuda:0') tensor(0.1745, device='cuda:0') tensor(-5.5782e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.033382
Average KL loss: 0.058968
Average total loss: 0.092350
tensor(0.0342, device='cuda:0') tensor(0.1754, device='cuda:0') tensor(-5.2305e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.033774
Average KL loss: 0.059011
Average total loss: 0.092785
tensor(0.0343, device='cuda:0') tensor(0.1764, device='cuda:0') tensor(-8.1449e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.033592
Average KL loss: 0.059038
Average total loss: 0.092631
tensor(0.0344, device='cuda:0') tensor(0.1774, device='cuda:0') tensor(-3.0742e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.033146
Average KL loss: 0.059030
Average total loss: 0.092176
tensor(0.0344, device='cuda:0') tensor(0.1783, device='cuda:0') tensor(-3.3328e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.033706
Average KL loss: 0.059056
Average total loss: 0.092762
tensor(0.0345, device='cuda:0') tensor(0.1796, device='cuda:0') tensor(-5.0817e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.032798
Average KL loss: 0.059073
Average total loss: 0.091872
tensor(0.0345, device='cuda:0') tensor(0.1803, device='cuda:0') tensor(-2.2600e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.032738
Average KL loss: 0.059041
Average total loss: 0.091779
tensor(0.0345, device='cuda:0') tensor(0.1814, device='cuda:0') tensor(-3.8969e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.032341
Average KL loss: 0.058995
Average total loss: 0.091336
tensor(0.0345, device='cuda:0') tensor(0.1821, device='cuda:0') tensor(-3.8718e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.032850
Average KL loss: 0.059039
Average total loss: 0.091889
tensor(0.0346, device='cuda:0') tensor(0.1833, device='cuda:0') tensor(-3.3289e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.031955
Average KL loss: 0.059136
Average total loss: 0.091091
tensor(0.0347, device='cuda:0') tensor(0.1844, device='cuda:0') tensor(-6.6833e-11, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.031916
Average KL loss: 0.059047
Average total loss: 0.090962
tensor(0.0347, device='cuda:0') tensor(0.1852, device='cuda:0') tensor(-3.8395e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.031397
Average KL loss: 0.059028
Average total loss: 0.090425
tensor(0.0348, device='cuda:0') tensor(0.1860, device='cuda:0') tensor(-9.8891e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.031208
Average KL loss: 0.058910
Average total loss: 0.090119
tensor(0.0348, device='cuda:0') tensor(0.1870, device='cuda:0') tensor(-1.5747e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.031374
Average KL loss: 0.058888
Average total loss: 0.090262
tensor(0.0349, device='cuda:0') tensor(0.1880, device='cuda:0') tensor(4.9418e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.030668
Average KL loss: 0.058958
Average total loss: 0.089626
tensor(0.0350, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-7.1527e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.030555
Average KL loss: 0.058869
Average total loss: 0.089425
tensor(0.0350, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(-3.4019e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.030882
Average KL loss: 0.058857
Average total loss: 0.089739
tensor(0.0351, device='cuda:0') tensor(0.1910, device='cuda:0') tensor(-9.3103e-11, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.030964
Average KL loss: 0.058906
Average total loss: 0.089870
tensor(0.0351, device='cuda:0') tensor(0.1921, device='cuda:0') tensor(-3.5692e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.030641
Average KL loss: 0.058978
Average total loss: 0.089620
tensor(0.0352, device='cuda:0') tensor(0.1932, device='cuda:0') tensor(1.4959e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.030212
Average KL loss: 0.058928
Average total loss: 0.089140
tensor(0.0352, device='cuda:0') tensor(0.1941, device='cuda:0') tensor(-3.7490e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.030635
Average KL loss: 0.058953
Average total loss: 0.089587
tensor(0.0353, device='cuda:0') tensor(0.1951, device='cuda:0') tensor(-2.7989e-11, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.030026
Average KL loss: 0.058929
Average total loss: 0.088955
tensor(0.0353, device='cuda:0') tensor(0.1960, device='cuda:0') tensor(-2.3878e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.030628
Average KL loss: 0.058963
Average total loss: 0.089590
tensor(0.0354, device='cuda:0') tensor(0.1974, device='cuda:0') tensor(-1.9356e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.030332
Average KL loss: 0.059118
Average total loss: 0.089450
tensor(0.0355, device='cuda:0') tensor(0.1986, device='cuda:0') tensor(-8.4570e-11, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.029890
Average KL loss: 0.059145
Average total loss: 0.089036
tensor(0.0355, device='cuda:0') tensor(0.1997, device='cuda:0') tensor(5.2843e-11, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.029213
Average KL loss: 0.059129
Average total loss: 0.088342
tensor(0.0355, device='cuda:0') tensor(0.2006, device='cuda:0') tensor(-4.1903e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.029661
Average KL loss: 0.059046
Average total loss: 0.088707
tensor(0.0356, device='cuda:0') tensor(0.2016, device='cuda:0') tensor(-4.5115e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.029024
Average KL loss: 0.059027
Average total loss: 0.088051
tensor(0.0356, device='cuda:0') tensor(0.2024, device='cuda:0') tensor(-3.4007e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.029063
Average KL loss: 0.058972
Average total loss: 0.088035
tensor(0.0357, device='cuda:0') tensor(0.2034, device='cuda:0') tensor(-3.9349e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.029502
Average KL loss: 0.059017
Average total loss: 0.088519
tensor(0.0358, device='cuda:0') tensor(0.2048, device='cuda:0') tensor(-2.0387e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.029673
Average KL loss: 0.059155
Average total loss: 0.088828
tensor(0.0358, device='cuda:0') tensor(0.2061, device='cuda:0') tensor(7.8081e-11, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.029225
Average KL loss: 0.059232
Average total loss: 0.088458
tensor(0.0359, device='cuda:0') tensor(0.2071, device='cuda:0') tensor(-2.3687e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.029179
Average KL loss: 0.059194
Average total loss: 0.088373
tensor(0.0359, device='cuda:0') tensor(0.2081, device='cuda:0') tensor(-2.7216e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.028992
Average KL loss: 0.059204
Average total loss: 0.088196
tensor(0.0360, device='cuda:0') tensor(0.2092, device='cuda:0') tensor(5.8850e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.028979
Average KL loss: 0.059244
Average total loss: 0.088223
tensor(0.0361, device='cuda:0') tensor(0.2103, device='cuda:0') tensor(-3.7291e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.028971
Average KL loss: 0.059216
Average total loss: 0.088187
tensor(0.0361, device='cuda:0') tensor(0.2112, device='cuda:0') tensor(-8.6233e-11, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.029034
Average KL loss: 0.059379
Average total loss: 0.088414
tensor(0.0362, device='cuda:0') tensor(0.2124, device='cuda:0') tensor(-4.3037e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.028289
Average KL loss: 0.059345
Average total loss: 0.087634
tensor(0.0363, device='cuda:0') tensor(0.2134, device='cuda:0') tensor(-2.6070e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.028825
Average KL loss: 0.059244
Average total loss: 0.088069
tensor(0.0363, device='cuda:0') tensor(0.2145, device='cuda:0') tensor(-1.0848e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.027782
Average KL loss: 0.059272
Average total loss: 0.087053
tensor(0.0364, device='cuda:0') tensor(0.2152, device='cuda:0') tensor(-2.5809e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.028763
Average KL loss: 0.059203
Average total loss: 0.087966
tensor(0.0364, device='cuda:0') tensor(0.2163, device='cuda:0') tensor(-3.2497e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.028831
Average KL loss: 0.059322
Average total loss: 0.088153
tensor(0.0365, device='cuda:0') tensor(0.2177, device='cuda:0') tensor(-6.4803e-11, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.028627
Average KL loss: 0.059457
Average total loss: 0.088084
tensor(0.0366, device='cuda:0') tensor(0.2191, device='cuda:0') tensor(-1.8176e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.028922
Average KL loss: 0.059533
Average total loss: 0.088455
tensor(0.0367, device='cuda:0') tensor(0.2205, device='cuda:0') tensor(-1.0998e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.028066
Average KL loss: 0.059620
Average total loss: 0.087686
tensor(0.0367, device='cuda:0') tensor(0.2214, device='cuda:0') tensor(-4.5936e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.029016
Average KL loss: 0.059736
Average total loss: 0.088752
tensor(0.0368, device='cuda:0') tensor(0.2231, device='cuda:0') tensor(-6.7895e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.028273
Average KL loss: 0.059803
Average total loss: 0.088076
tensor(0.0369, device='cuda:0') tensor(0.2245, device='cuda:0') tensor(-6.3525e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.027793
Average KL loss: 0.059706
Average total loss: 0.087498
tensor(0.0369, device='cuda:0') tensor(0.2252, device='cuda:0') tensor(3.2284e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.027822
Average KL loss: 0.059630
Average total loss: 0.087452
tensor(0.0370, device='cuda:0') tensor(0.2264, device='cuda:0') tensor(1.1633e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.027995
Average KL loss: 0.059712
Average total loss: 0.087708
tensor(0.0371, device='cuda:0') tensor(0.2276, device='cuda:0') tensor(-1.5860e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.027954
Average KL loss: 0.059765
Average total loss: 0.087719
tensor(0.0371, device='cuda:0') tensor(0.2288, device='cuda:0') tensor(-3.7669e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.027806
Average KL loss: 0.059664
Average total loss: 0.087469
tensor(0.0371, device='cuda:0') tensor(0.2286, device='cuda:0') tensor(-2.1628e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.026448
Average KL loss: 0.059394
Average total loss: 0.085842
tensor(0.0371, device='cuda:0') tensor(0.2282, device='cuda:0') tensor(-1.8989e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.026855
Average KL loss: 0.059145
Average total loss: 0.086000
tensor(0.0371, device='cuda:0') tensor(0.2279, device='cuda:0') tensor(-4.2120e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.026359
Average KL loss: 0.058921
Average total loss: 0.085280
tensor(0.0371, device='cuda:0') tensor(0.2277, device='cuda:0') tensor(-1.1840e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.026726
Average KL loss: 0.058720
Average total loss: 0.085445
tensor(0.0371, device='cuda:0') tensor(0.2274, device='cuda:0') tensor(1.8189e-11, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.027269
Average KL loss: 0.058535
Average total loss: 0.085804
tensor(0.0371, device='cuda:0') tensor(0.2272, device='cuda:0') tensor(-3.7787e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.026554
Average KL loss: 0.058354
Average total loss: 0.084908
tensor(0.0371, device='cuda:0') tensor(0.2269, device='cuda:0') tensor(-1.2529e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.026544
Average KL loss: 0.058180
Average total loss: 0.084724
tensor(0.0370, device='cuda:0') tensor(0.2267, device='cuda:0') tensor(-2.0291e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.026581
Average KL loss: 0.058019
Average total loss: 0.084599
tensor(0.0370, device='cuda:0') tensor(0.2264, device='cuda:0') tensor(-2.7255e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.026511
Average KL loss: 0.057866
Average total loss: 0.084377
tensor(0.0370, device='cuda:0') tensor(0.2262, device='cuda:0') tensor(-7.6181e-11, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.026329
Average KL loss: 0.057713
Average total loss: 0.084043
tensor(0.0370, device='cuda:0') tensor(0.2260, device='cuda:0') tensor(4.5689e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.026295
Average KL loss: 0.057565
Average total loss: 0.083860
tensor(0.0370, device='cuda:0') tensor(0.2257, device='cuda:0') tensor(-2.5570e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.026794
Average KL loss: 0.057423
Average total loss: 0.084217
tensor(0.0370, device='cuda:0') tensor(0.2255, device='cuda:0') tensor(2.8127e-11, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.026372
Average KL loss: 0.057291
Average total loss: 0.083663
tensor(0.0370, device='cuda:0') tensor(0.2253, device='cuda:0') tensor(-9.5784e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.026275
Average KL loss: 0.057161
Average total loss: 0.083436
tensor(0.0370, device='cuda:0') tensor(0.2251, device='cuda:0') tensor(1.9894e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.025799
Average KL loss: 0.057023
Average total loss: 0.082821
tensor(0.0370, device='cuda:0') tensor(0.2248, device='cuda:0') tensor(-6.5026e-12, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.026392
Average KL loss: 0.056895
Average total loss: 0.083287
tensor(0.0369, device='cuda:0') tensor(0.2246, device='cuda:0') tensor(-1.0729e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.026209
Average KL loss: 0.056779
Average total loss: 0.082987
tensor(0.0369, device='cuda:0') tensor(0.2244, device='cuda:0') tensor(7.8303e-11, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.026336
Average KL loss: 0.056659
Average total loss: 0.082996
tensor(0.0369, device='cuda:0') tensor(0.2242, device='cuda:0') tensor(-4.6902e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.026342
Average KL loss: 0.056548
Average total loss: 0.082890
tensor(0.0369, device='cuda:0') tensor(0.2240, device='cuda:0') tensor(1.3492e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.026181
Average KL loss: 0.056434
Average total loss: 0.082615
tensor(0.0369, device='cuda:0') tensor(0.2238, device='cuda:0') tensor(-2.9637e-11, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.026452
Average KL loss: 0.056322
Average total loss: 0.082774
tensor(0.0369, device='cuda:0') tensor(0.2236, device='cuda:0') tensor(-1.3502e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.026245
Average KL loss: 0.056222
Average total loss: 0.082467
tensor(0.0369, device='cuda:0') tensor(0.2235, device='cuda:0') tensor(-1.6796e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.025965
Average KL loss: 0.056115
Average total loss: 0.082080
tensor(0.0369, device='cuda:0') tensor(0.2233, device='cuda:0') tensor(-1.1486e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.025824
Average KL loss: 0.056005
Average total loss: 0.081830
tensor(0.0368, device='cuda:0') tensor(0.2231, device='cuda:0') tensor(7.8876e-11, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.026026
Average KL loss: 0.055903
Average total loss: 0.081929
tensor(0.0368, device='cuda:0') tensor(0.2229, device='cuda:0') tensor(-1.3126e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.025895
Average KL loss: 0.055803
Average total loss: 0.081699
tensor(0.0368, device='cuda:0') tensor(0.2227, device='cuda:0') tensor(-1.0518e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.026128
Average KL loss: 0.055701
Average total loss: 0.081829
tensor(0.0368, device='cuda:0') tensor(0.2225, device='cuda:0') tensor(2.4245e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.026073
Average KL loss: 0.055603
Average total loss: 0.081675
tensor(0.0368, device='cuda:0') tensor(0.2223, device='cuda:0') tensor(1.8353e-12, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.026340
Average KL loss: 0.055516
Average total loss: 0.081856
tensor(0.0368, device='cuda:0') tensor(0.2221, device='cuda:0') tensor(1.2712e-11, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.026049
Average KL loss: 0.055423
Average total loss: 0.081473
tensor(0.0368, device='cuda:0') tensor(0.2219, device='cuda:0') tensor(-1.3099e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.026272
Average KL loss: 0.055334
Average total loss: 0.081607
tensor(0.0368, device='cuda:0') tensor(0.2217, device='cuda:0') tensor(-2.6301e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.026164
Average KL loss: 0.055247
Average total loss: 0.081411
tensor(0.0367, device='cuda:0') tensor(0.2216, device='cuda:0') tensor(-3.4215e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.026188
Average KL loss: 0.055159
Average total loss: 0.081347
tensor(0.0367, device='cuda:0') tensor(0.2214, device='cuda:0') tensor(3.8408e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.025894
Average KL loss: 0.055074
Average total loss: 0.080968
tensor(0.0367, device='cuda:0') tensor(0.2212, device='cuda:0') tensor(-1.9522e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.026410
Average KL loss: 0.054994
Average total loss: 0.081403
tensor(0.0367, device='cuda:0') tensor(0.2210, device='cuda:0') tensor(5.3587e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.025844
Average KL loss: 0.054918
Average total loss: 0.080763
tensor(0.0367, device='cuda:0') tensor(0.2208, device='cuda:0') tensor(-6.7034e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.026067
Average KL loss: 0.054827
Average total loss: 0.080895
tensor(0.0367, device='cuda:0') tensor(0.2206, device='cuda:0') tensor(-7.5961e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.026342
Average KL loss: 0.054742
Average total loss: 0.081084
tensor(0.0367, device='cuda:0') tensor(0.2205, device='cuda:0') tensor(-9.6943e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.026058
Average KL loss: 0.054669
Average total loss: 0.080726
tensor(0.0366, device='cuda:0') tensor(0.2203, device='cuda:0') tensor(1.0978e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.025986
Average KL loss: 0.054589
Average total loss: 0.080575
tensor(0.0366, device='cuda:0') tensor(0.2201, device='cuda:0') tensor(1.1892e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.026089
Average KL loss: 0.054515
Average total loss: 0.080604
tensor(0.0366, device='cuda:0') tensor(0.2199, device='cuda:0') tensor(2.4407e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.026040
Average KL loss: 0.054442
Average total loss: 0.080482
tensor(0.0366, device='cuda:0') tensor(0.2198, device='cuda:0') tensor(-1.4965e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.025789
Average KL loss: 0.054368
Average total loss: 0.080158
tensor(0.0366, device='cuda:0') tensor(0.2196, device='cuda:0') tensor(6.9074e-11, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.026061
Average KL loss: 0.054289
Average total loss: 0.080350
tensor(0.0366, device='cuda:0') tensor(0.2194, device='cuda:0') tensor(-1.6487e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.026503
Average KL loss: 0.054211
Average total loss: 0.080714
tensor(0.0365, device='cuda:0') tensor(0.2192, device='cuda:0') tensor(3.5504e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.025802
Average KL loss: 0.054138
Average total loss: 0.079940
tensor(0.0365, device='cuda:0') tensor(0.2190, device='cuda:0') tensor(-5.8174e-11, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.026025
Average KL loss: 0.054066
Average total loss: 0.080091
tensor(0.0365, device='cuda:0') tensor(0.2188, device='cuda:0') tensor(2.1868e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.025951
Average KL loss: 0.053992
Average total loss: 0.079944
tensor(0.0365, device='cuda:0') tensor(0.2186, device='cuda:0') tensor(1.0364e-12, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.026000
Average KL loss: 0.053924
Average total loss: 0.079924
tensor(0.0365, device='cuda:0') tensor(0.2185, device='cuda:0') tensor(-8.1281e-11, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.025583
Average KL loss: 0.053854
Average total loss: 0.079437
tensor(0.0365, device='cuda:0') tensor(0.2183, device='cuda:0') tensor(1.0633e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.025938
Average KL loss: 0.053779
Average total loss: 0.079717
tensor(0.0365, device='cuda:0') tensor(0.2181, device='cuda:0') tensor(2.2255e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.026067
Average KL loss: 0.053719
Average total loss: 0.079786
tensor(0.0364, device='cuda:0') tensor(0.2180, device='cuda:0') tensor(-6.7306e-11, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.026066
Average KL loss: 0.053656
Average total loss: 0.079722
tensor(0.0364, device='cuda:0') tensor(0.2178, device='cuda:0') tensor(5.8599e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.026363
Average KL loss: 0.053592
Average total loss: 0.079955
tensor(0.0364, device='cuda:0') tensor(0.2176, device='cuda:0') tensor(3.9030e-11, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.026145
Average KL loss: 0.053525
Average total loss: 0.079669
tensor(0.0364, device='cuda:0') tensor(0.2174, device='cuda:0') tensor(7.7829e-11, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.026288
Average KL loss: 0.053467
Average total loss: 0.079755
tensor(0.0364, device='cuda:0') tensor(0.2172, device='cuda:0') tensor(4.1710e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.026259
Average KL loss: 0.053405
Average total loss: 0.079664
tensor(0.0364, device='cuda:0') tensor(0.2170, device='cuda:0') tensor(1.0758e-11, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.026430
Average KL loss: 0.053346
Average total loss: 0.079776
tensor(0.0363, device='cuda:0') tensor(0.2169, device='cuda:0') tensor(-1.3768e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.026144
Average KL loss: 0.053287
Average total loss: 0.079431
tensor(0.0363, device='cuda:0') tensor(0.2167, device='cuda:0') tensor(-3.0975e-12, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.026881
Average KL loss: 0.053231
Average total loss: 0.080112
tensor(0.0363, device='cuda:0') tensor(0.2165, device='cuda:0') tensor(5.9851e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.025879
Average KL loss: 0.053178
Average total loss: 0.079058
tensor(0.0363, device='cuda:0') tensor(0.2164, device='cuda:0') tensor(1.4771e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.026436
Average KL loss: 0.053115
Average total loss: 0.079550
tensor(0.0363, device='cuda:0') tensor(0.2162, device='cuda:0') tensor(-8.9757e-11, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.026053
Average KL loss: 0.053064
Average total loss: 0.079116
tensor(0.0363, device='cuda:0') tensor(0.2160, device='cuda:0') tensor(1.9855e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.026336
Average KL loss: 0.053003
Average total loss: 0.079339
tensor(0.0363, device='cuda:0') tensor(0.2158, device='cuda:0') tensor(9.3078e-11, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.026030
Average KL loss: 0.052945
Average total loss: 0.078975
tensor(0.0362, device='cuda:0') tensor(0.2156, device='cuda:0') tensor(2.0112e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.025887
Average KL loss: 0.052881
Average total loss: 0.078769
tensor(0.0362, device='cuda:0') tensor(0.2154, device='cuda:0') tensor(-2.4607e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.026364
Average KL loss: 0.052828
Average total loss: 0.079192
tensor(0.0362, device='cuda:0') tensor(0.2153, device='cuda:0') tensor(1.6425e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.026077
Average KL loss: 0.052779
Average total loss: 0.078856
tensor(0.0362, device='cuda:0') tensor(0.2151, device='cuda:0') tensor(-2.0762e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.026226
Average KL loss: 0.052718
Average total loss: 0.078944
tensor(0.0362, device='cuda:0') tensor(0.2149, device='cuda:0') tensor(3.6853e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.025830
Average KL loss: 0.052668
Average total loss: 0.078498
tensor(0.0361, device='cuda:0') tensor(0.2147, device='cuda:0') tensor(-5.4544e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.025957
Average KL loss: 0.052615
Average total loss: 0.078573
tensor(0.0361, device='cuda:0') tensor(0.2146, device='cuda:0') tensor(5.0715e-11, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.026449
Average KL loss: 0.052559
Average total loss: 0.079009
tensor(0.0361, device='cuda:0') tensor(0.2144, device='cuda:0') tensor(-5.5342e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.026344
Average KL loss: 0.052507
Average total loss: 0.078850
tensor(0.0361, device='cuda:0') tensor(0.2142, device='cuda:0') tensor(8.5795e-11, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.026101
Average KL loss: 0.052460
Average total loss: 0.078560
tensor(0.0361, device='cuda:0') tensor(0.2141, device='cuda:0') tensor(7.1526e-11, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.026264
Average KL loss: 0.052403
Average total loss: 0.078667
tensor(0.0361, device='cuda:0') tensor(0.2139, device='cuda:0') tensor(-2.8998e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.026180
Average KL loss: 0.052357
Average total loss: 0.078537
tensor(0.0360, device='cuda:0') tensor(0.2137, device='cuda:0') tensor(-3.5801e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.026663
Average KL loss: 0.052319
Average total loss: 0.078983
tensor(0.0360, device='cuda:0') tensor(0.2136, device='cuda:0') tensor(-5.7637e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.026042
Average KL loss: 0.052272
Average total loss: 0.078315
tensor(0.0360, device='cuda:0') tensor(0.2134, device='cuda:0') tensor(1.8165e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.026059
Average KL loss: 0.052222
Average total loss: 0.078281
tensor(0.0360, device='cuda:0') tensor(0.2132, device='cuda:0') tensor(-1.0886e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.026595
Average KL loss: 0.052175
Average total loss: 0.078770
tensor(0.0360, device='cuda:0') tensor(0.2131, device='cuda:0') tensor(1.0272e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.026188
Average KL loss: 0.052132
Average total loss: 0.078320
tensor(0.0360, device='cuda:0') tensor(0.2129, device='cuda:0') tensor(-1.0562e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.026956
Average KL loss: 0.052092
Average total loss: 0.079048
tensor(0.0360, device='cuda:0') tensor(0.2128, device='cuda:0') tensor(-2.2317e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.026230
Average KL loss: 0.052062
Average total loss: 0.078292
tensor(0.0359, device='cuda:0') tensor(0.2126, device='cuda:0') tensor(2.0645e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.026269
Average KL loss: 0.052019
Average total loss: 0.078288
tensor(0.0359, device='cuda:0') tensor(0.2124, device='cuda:0') tensor(-5.6511e-11, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.026377
Average KL loss: 0.051974
Average total loss: 0.078351
tensor(0.0359, device='cuda:0') tensor(0.2123, device='cuda:0') tensor(-1.7268e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.026427
Average KL loss: 0.051928
Average total loss: 0.078355
tensor(0.0359, device='cuda:0') tensor(0.2121, device='cuda:0') tensor(2.1399e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.026488
Average KL loss: 0.051893
Average total loss: 0.078381
tensor(0.0359, device='cuda:0') tensor(0.2119, device='cuda:0') tensor(-1.7567e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.026495
Average KL loss: 0.051852
Average total loss: 0.078347
tensor(0.0359, device='cuda:0') tensor(0.2118, device='cuda:0') tensor(5.1778e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.026450
Average KL loss: 0.051813
Average total loss: 0.078263
tensor(0.0358, device='cuda:0') tensor(0.2116, device='cuda:0') tensor(-2.0523e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.026149
Average KL loss: 0.051774
Average total loss: 0.077922
tensor(0.0358, device='cuda:0') tensor(0.2115, device='cuda:0') tensor(-6.1205e-11, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.026294
Average KL loss: 0.051724
Average total loss: 0.078018
tensor(0.0358, device='cuda:0') tensor(0.2113, device='cuda:0') tensor(-8.0380e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.026190
Average KL loss: 0.051685
Average total loss: 0.077875
tensor(0.0358, device='cuda:0') tensor(0.2111, device='cuda:0') tensor(-5.2208e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.026322
Average KL loss: 0.051647
Average total loss: 0.077969
tensor(0.0358, device='cuda:0') tensor(0.2110, device='cuda:0') tensor(-4.4580e-12, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.026501
Average KL loss: 0.051605
Average total loss: 0.078105
tensor(0.0358, device='cuda:0') tensor(0.2108, device='cuda:0') tensor(-1.9603e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.026097
Average KL loss: 0.051567
Average total loss: 0.077663
tensor(0.0357, device='cuda:0') tensor(0.2106, device='cuda:0') tensor(2.3484e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.026901
Average KL loss: 0.051527
Average total loss: 0.078428
tensor(0.0357, device='cuda:0') tensor(0.2105, device='cuda:0') tensor(3.1376e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.026440
Average KL loss: 0.051488
Average total loss: 0.077928
tensor(0.0357, device='cuda:0') tensor(0.2103, device='cuda:0') tensor(-6.3447e-11, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.026086
Average KL loss: 0.051445
Average total loss: 0.077531
 Percentile value: 5.796079921722412
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =     102 /    1728             (  5.90%) | total_pruned =    1626 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     105 /   36864             (  0.28%) | total_pruned =   36759 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     183 /   36864             (  0.50%) | total_pruned =   36681 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     470 /   36864             (  1.27%) | total_pruned =   36394 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     753 /   36864             (  2.04%) | total_pruned =   36111 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2314 /   73728             (  3.14%) | total_pruned =   71414 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4234 /  147456             (  2.87%) | total_pruned =  143222 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     435 /    8192             (  5.31%) | total_pruned =    7757 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2006 /  147456             (  1.36%) | total_pruned =  145450 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1874 /  147456             (  1.27%) | total_pruned =  145582 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    9578 /  294912             (  3.25%) | total_pruned =  285334 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      67 /     256             ( 26.17%) | total_pruned =     189 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   11506 /  589824             (  1.95%) | total_pruned =  578318 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      65 /     256             ( 25.39%) | total_pruned =     191 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1076 /   32768             (  3.28%) | total_pruned =   31692 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      98 /     256             ( 38.28%) | total_pruned =     158 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      52 /     256             ( 20.31%) | total_pruned =     204 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    7014 /  589824             (  1.19%) | total_pruned =  582810 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     134 /     256             ( 52.34%) | total_pruned =     122 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    5665 /  589824             (  0.96%) | total_pruned =  584159 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      65 /     256             ( 25.39%) | total_pruned =     191 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   15633 / 1179648             (  1.33%) | total_pruned = 1164015 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     321 /     512             ( 62.70%) | total_pruned =     191 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      47 /     512             (  9.18%) | total_pruned =     465 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    9596 / 2359296             (  0.41%) | total_pruned = 2349700 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     262 /     512             ( 51.17%) | total_pruned =     250 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     176 /     512             ( 34.38%) | total_pruned =     336 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     218 /  131072             (  0.17%) | total_pruned =  130854 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     169 /     512             ( 33.01%) | total_pruned =     343 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    4982 / 2359296             (  0.21%) | total_pruned = 2354314 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     138 /     512             ( 26.95%) | total_pruned =     374 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    7464 / 2359296             (  0.32%) | total_pruned = 2351832 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     326 /     512             ( 63.67%) | total_pruned =     186 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     280 /     512             ( 54.69%) | total_pruned =     232 | shape = torch.Size([512])
linear.weight        | nonzeros =    2103 /    5120             ( 41.07%) | total_pruned =    3017 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 61/200 Loss: 0.038580 Accuracy: 81.82 99.98 % Best test Accuracy: 83.23%
tensor(0.0357, device='cuda:0') tensor(0.2101, device='cuda:0') tensor(-6.6598e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.122401
Average KL loss: 0.042153
Average total loss: 0.164554
tensor(0.0252, device='cuda:0') tensor(0.1228, device='cuda:0') tensor(-1.5859e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.130039
Average KL loss: 0.035958
Average total loss: 0.165997
tensor(0.0233, device='cuda:0') tensor(0.1084, device='cuda:0') tensor(-8.8233e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.129584
Average KL loss: 0.035238
Average total loss: 0.164822
tensor(0.0230, device='cuda:0') tensor(0.1063, device='cuda:0') tensor(-6.9001e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.122591
Average KL loss: 0.035346
Average total loss: 0.157937
tensor(0.0230, device='cuda:0') tensor(0.1072, device='cuda:0') tensor(-9.8238e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.110280
Average KL loss: 0.035609
Average total loss: 0.145889
tensor(0.0232, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(-6.8433e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.105640
Average KL loss: 0.035936
Average total loss: 0.141576
tensor(0.0235, device='cuda:0') tensor(0.1120, device='cuda:0') tensor(-5.2274e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.092242
Average KL loss: 0.036231
Average total loss: 0.128472
tensor(0.0237, device='cuda:0') tensor(0.1147, device='cuda:0') tensor(-4.8589e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.093097
Average KL loss: 0.036491
Average total loss: 0.129588
tensor(0.0240, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-4.5915e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.081837
Average KL loss: 0.036745
Average total loss: 0.118582
tensor(0.0242, device='cuda:0') tensor(0.1202, device='cuda:0') tensor(-4.1034e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.074432
Average KL loss: 0.036935
Average total loss: 0.111368
tensor(0.0245, device='cuda:0') tensor(0.1228, device='cuda:0') tensor(-4.0826e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.070820
Average KL loss: 0.037136
Average total loss: 0.107956
tensor(0.0247, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-3.4874e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.062555
Average KL loss: 0.037298
Average total loss: 0.099853
tensor(0.0250, device='cuda:0') tensor(0.1278, device='cuda:0') tensor(-2.5011e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.070814
Average KL loss: 0.037465
Average total loss: 0.108279
tensor(0.0252, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(-3.4271e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.062747
Average KL loss: 0.037619
Average total loss: 0.100366
tensor(0.0254, device='cuda:0') tensor(0.1325, device='cuda:0') tensor(-3.3678e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.057998
Average KL loss: 0.037728
Average total loss: 0.095727
tensor(0.0256, device='cuda:0') tensor(0.1346, device='cuda:0') tensor(-1.8871e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.054691
Average KL loss: 0.037808
Average total loss: 0.092500
tensor(0.0258, device='cuda:0') tensor(0.1366, device='cuda:0') tensor(-2.1814e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.056560
Average KL loss: 0.037913
Average total loss: 0.094473
tensor(0.0259, device='cuda:0') tensor(0.1386, device='cuda:0') tensor(-1.0013e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.052534
Average KL loss: 0.038002
Average total loss: 0.090536
tensor(0.0261, device='cuda:0') tensor(0.1408, device='cuda:0') tensor(-1.5602e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.047531
Average KL loss: 0.038068
Average total loss: 0.085599
tensor(0.0263, device='cuda:0') tensor(0.1425, device='cuda:0') tensor(-2.3207e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.045628
Average KL loss: 0.038089
Average total loss: 0.083717
tensor(0.0265, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(-7.8859e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.045571
Average KL loss: 0.038138
Average total loss: 0.083710
tensor(0.0266, device='cuda:0') tensor(0.1459, device='cuda:0') tensor(-1.7196e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.044526
Average KL loss: 0.038169
Average total loss: 0.082695
tensor(0.0268, device='cuda:0') tensor(0.1477, device='cuda:0') tensor(-1.9101e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.043230
Average KL loss: 0.038234
Average total loss: 0.081465
tensor(0.0269, device='cuda:0') tensor(0.1494, device='cuda:0') tensor(-1.3108e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.042058
Average KL loss: 0.038271
Average total loss: 0.080329
tensor(0.0271, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(-2.0894e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.041046
Average KL loss: 0.038289
Average total loss: 0.079335
tensor(0.0272, device='cuda:0') tensor(0.1526, device='cuda:0') tensor(-2.4654e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.043614
Average KL loss: 0.038319
Average total loss: 0.081933
tensor(0.0273, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(-1.1582e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.039852
Average KL loss: 0.038329
Average total loss: 0.078181
tensor(0.0275, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(-2.1785e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.038633
Average KL loss: 0.038338
Average total loss: 0.076971
tensor(0.0276, device='cuda:0') tensor(0.1571, device='cuda:0') tensor(-6.9839e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.037404
Average KL loss: 0.038356
Average total loss: 0.075760
tensor(0.0277, device='cuda:0') tensor(0.1585, device='cuda:0') tensor(-1.4264e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.037080
Average KL loss: 0.038322
Average total loss: 0.075402
tensor(0.0278, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-6.6436e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.039613
Average KL loss: 0.038352
Average total loss: 0.077965
tensor(0.0279, device='cuda:0') tensor(0.1614, device='cuda:0') tensor(-5.4749e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.036078
Average KL loss: 0.038391
Average total loss: 0.074469
tensor(0.0280, device='cuda:0') tensor(0.1627, device='cuda:0') tensor(-2.2368e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.036202
Average KL loss: 0.038389
Average total loss: 0.074591
tensor(0.0282, device='cuda:0') tensor(0.1641, device='cuda:0') tensor(-6.4093e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.038104
Average KL loss: 0.038414
Average total loss: 0.076519
tensor(0.0283, device='cuda:0') tensor(0.1657, device='cuda:0') tensor(-2.9578e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.036315
Average KL loss: 0.038477
Average total loss: 0.074792
tensor(0.0284, device='cuda:0') tensor(0.1673, device='cuda:0') tensor(-4.8290e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.034254
Average KL loss: 0.038469
Average total loss: 0.072723
tensor(0.0285, device='cuda:0') tensor(0.1685, device='cuda:0') tensor(-2.9067e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.038936
Average KL loss: 0.038484
Average total loss: 0.077420
tensor(0.0286, device='cuda:0') tensor(0.1700, device='cuda:0') tensor(-5.5120e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.033737
Average KL loss: 0.038523
Average total loss: 0.072260
tensor(0.0287, device='cuda:0') tensor(0.1712, device='cuda:0') tensor(-4.9857e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.034265
Average KL loss: 0.038490
Average total loss: 0.072755
tensor(0.0288, device='cuda:0') tensor(0.1724, device='cuda:0') tensor(-3.4992e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.034267
Average KL loss: 0.038483
Average total loss: 0.072750
tensor(0.0289, device='cuda:0') tensor(0.1736, device='cuda:0') tensor(-2.9721e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.033418
Average KL loss: 0.038457
Average total loss: 0.071875
tensor(0.0290, device='cuda:0') tensor(0.1747, device='cuda:0') tensor(-4.5123e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.033969
Average KL loss: 0.038460
Average total loss: 0.072428
tensor(0.0291, device='cuda:0') tensor(0.1761, device='cuda:0') tensor(-3.9432e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.034288
Average KL loss: 0.038458
Average total loss: 0.072746
tensor(0.0292, device='cuda:0') tensor(0.1774, device='cuda:0') tensor(-5.5076e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.034064
Average KL loss: 0.038479
Average total loss: 0.072543
tensor(0.0293, device='cuda:0') tensor(0.1787, device='cuda:0') tensor(-3.2247e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.032124
Average KL loss: 0.038471
Average total loss: 0.070595
tensor(0.0293, device='cuda:0') tensor(0.1799, device='cuda:0') tensor(-2.3335e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.033284
Average KL loss: 0.038448
Average total loss: 0.071732
tensor(0.0294, device='cuda:0') tensor(0.1811, device='cuda:0') tensor(-2.2422e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.032532
Average KL loss: 0.038465
Average total loss: 0.070997
tensor(0.0295, device='cuda:0') tensor(0.1823, device='cuda:0') tensor(-3.6069e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.030917
Average KL loss: 0.038447
Average total loss: 0.069363
tensor(0.0296, device='cuda:0') tensor(0.1835, device='cuda:0') tensor(-2.8996e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.032218
Average KL loss: 0.038430
Average total loss: 0.070648
tensor(0.0297, device='cuda:0') tensor(0.1847, device='cuda:0') tensor(-3.5505e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.034337
Average KL loss: 0.038455
Average total loss: 0.072793
tensor(0.0298, device='cuda:0') tensor(0.1860, device='cuda:0') tensor(-4.8142e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.031239
Average KL loss: 0.038538
Average total loss: 0.069777
tensor(0.0299, device='cuda:0') tensor(0.1874, device='cuda:0') tensor(-2.1811e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.035287
Average KL loss: 0.038564
Average total loss: 0.073851
tensor(0.0300, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-3.1739e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.031152
Average KL loss: 0.038619
Average total loss: 0.069771
tensor(0.0301, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-7.0026e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.031012
Average KL loss: 0.038589
Average total loss: 0.069601
tensor(0.0302, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-3.1228e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.030392
Average KL loss: 0.038550
Average total loss: 0.068942
tensor(0.0303, device='cuda:0') tensor(0.1926, device='cuda:0') tensor(-4.2992e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.029845
Average KL loss: 0.038504
Average total loss: 0.068350
tensor(0.0304, device='cuda:0') tensor(0.1936, device='cuda:0') tensor(-3.1065e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.029828
Average KL loss: 0.038455
Average total loss: 0.068284
tensor(0.0305, device='cuda:0') tensor(0.1946, device='cuda:0') tensor(-5.6601e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.030460
Average KL loss: 0.038466
Average total loss: 0.068925
tensor(0.0306, device='cuda:0') tensor(0.1959, device='cuda:0') tensor(-1.1401e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.031532
Average KL loss: 0.038506
Average total loss: 0.070038
tensor(0.0307, device='cuda:0') tensor(0.1972, device='cuda:0') tensor(-2.5348e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.029603
Average KL loss: 0.038502
Average total loss: 0.068105
tensor(0.0307, device='cuda:0') tensor(0.1983, device='cuda:0') tensor(-2.4695e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.029845
Average KL loss: 0.038480
Average total loss: 0.068325
tensor(0.0308, device='cuda:0') tensor(0.1995, device='cuda:0') tensor(-1.6361e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.029868
Average KL loss: 0.038501
Average total loss: 0.068368
tensor(0.0309, device='cuda:0') tensor(0.2008, device='cuda:0') tensor(-1.6126e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.033208
Average KL loss: 0.038493
Average total loss: 0.071701
tensor(0.0310, device='cuda:0') tensor(0.2020, device='cuda:0') tensor(-3.2261e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.029708
Average KL loss: 0.038640
Average total loss: 0.068348
tensor(0.0311, device='cuda:0') tensor(0.2033, device='cuda:0') tensor(-1.9510e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.029314
Average KL loss: 0.038601
Average total loss: 0.067915
tensor(0.0312, device='cuda:0') tensor(0.2043, device='cuda:0') tensor(-3.5149e-11, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.035584
Average KL loss: 0.038611
Average total loss: 0.074195
tensor(0.0313, device='cuda:0') tensor(0.2058, device='cuda:0') tensor(-2.8133e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.029561
Average KL loss: 0.038748
Average total loss: 0.068308
tensor(0.0313, device='cuda:0') tensor(0.2069, device='cuda:0') tensor(-1.2132e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.028627
Average KL loss: 0.038646
Average total loss: 0.067274
tensor(0.0314, device='cuda:0') tensor(0.2077, device='cuda:0') tensor(-1.6767e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.029692
Average KL loss: 0.038572
Average total loss: 0.068263
tensor(0.0315, device='cuda:0') tensor(0.2089, device='cuda:0') tensor(-2.4874e-11, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.029717
Average KL loss: 0.038604
Average total loss: 0.068321
tensor(0.0315, device='cuda:0') tensor(0.2101, device='cuda:0') tensor(-2.2170e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.030090
Average KL loss: 0.038609
Average total loss: 0.068699
tensor(0.0316, device='cuda:0') tensor(0.2113, device='cuda:0') tensor(-2.3755e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.029331
Average KL loss: 0.038609
Average total loss: 0.067940
tensor(0.0317, device='cuda:0') tensor(0.2124, device='cuda:0') tensor(-2.3905e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.028520
Average KL loss: 0.038553
Average total loss: 0.067073
tensor(0.0318, device='cuda:0') tensor(0.2134, device='cuda:0') tensor(-2.0946e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.029340
Average KL loss: 0.038555
Average total loss: 0.067894
tensor(0.0319, device='cuda:0') tensor(0.2147, device='cuda:0') tensor(-2.1642e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.028923
Average KL loss: 0.038564
Average total loss: 0.067487
tensor(0.0319, device='cuda:0') tensor(0.2158, device='cuda:0') tensor(-3.4965e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.029606
Average KL loss: 0.038561
Average total loss: 0.068167
tensor(0.0320, device='cuda:0') tensor(0.2170, device='cuda:0') tensor(-2.4139e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.028542
Average KL loss: 0.038573
Average total loss: 0.067115
tensor(0.0321, device='cuda:0') tensor(0.2182, device='cuda:0') tensor(-5.6846e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.029240
Average KL loss: 0.038558
Average total loss: 0.067798
tensor(0.0322, device='cuda:0') tensor(0.2194, device='cuda:0') tensor(-2.1033e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.028436
Average KL loss: 0.038551
Average total loss: 0.066987
tensor(0.0323, device='cuda:0') tensor(0.2206, device='cuda:0') tensor(-9.6967e-11, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.028297
Average KL loss: 0.038541
Average total loss: 0.066838
tensor(0.0323, device='cuda:0') tensor(0.2216, device='cuda:0') tensor(-1.6532e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.028540
Average KL loss: 0.038504
Average total loss: 0.067045
tensor(0.0324, device='cuda:0') tensor(0.2228, device='cuda:0') tensor(-9.0563e-11, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.028517
Average KL loss: 0.038523
Average total loss: 0.067040
tensor(0.0325, device='cuda:0') tensor(0.2239, device='cuda:0') tensor(-9.5949e-11, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.029126
Average KL loss: 0.038532
Average total loss: 0.067658
tensor(0.0326, device='cuda:0') tensor(0.2252, device='cuda:0') tensor(-2.1364e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.028146
Average KL loss: 0.038545
Average total loss: 0.066692
tensor(0.0327, device='cuda:0') tensor(0.2263, device='cuda:0') tensor(-2.1422e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.028571
Average KL loss: 0.038544
Average total loss: 0.067115
tensor(0.0327, device='cuda:0') tensor(0.2275, device='cuda:0') tensor(-2.0675e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.027798
Average KL loss: 0.038550
Average total loss: 0.066348
tensor(0.0328, device='cuda:0') tensor(0.2288, device='cuda:0') tensor(-7.7301e-11, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.028108
Average KL loss: 0.038520
Average total loss: 0.066627
tensor(0.0329, device='cuda:0') tensor(0.2300, device='cuda:0') tensor(-3.1244e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.028391
Average KL loss: 0.038517
Average total loss: 0.066909
tensor(0.0330, device='cuda:0') tensor(0.2312, device='cuda:0') tensor(-9.1327e-11, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.028217
Average KL loss: 0.038533
Average total loss: 0.066750
tensor(0.0331, device='cuda:0') tensor(0.2325, device='cuda:0') tensor(-4.8088e-11, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.028491
Average KL loss: 0.038529
Average total loss: 0.067019
tensor(0.0331, device='cuda:0') tensor(0.2337, device='cuda:0') tensor(-4.9637e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.028104
Average KL loss: 0.038564
Average total loss: 0.066668
tensor(0.0332, device='cuda:0') tensor(0.2348, device='cuda:0') tensor(-1.0245e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.027752
Average KL loss: 0.038540
Average total loss: 0.066292
tensor(0.0333, device='cuda:0') tensor(0.2359, device='cuda:0') tensor(-1.7562e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.027899
Average KL loss: 0.038529
Average total loss: 0.066428
tensor(0.0334, device='cuda:0') tensor(0.2370, device='cuda:0') tensor(-2.5653e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.027840
Average KL loss: 0.038549
Average total loss: 0.066389
tensor(0.0334, device='cuda:0') tensor(0.2381, device='cuda:0') tensor(-1.8030e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.027554
Average KL loss: 0.038560
Average total loss: 0.066115
tensor(0.0335, device='cuda:0') tensor(0.2393, device='cuda:0') tensor(-1.4867e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.028500
Average KL loss: 0.038567
Average total loss: 0.067067
tensor(0.0336, device='cuda:0') tensor(0.2403, device='cuda:0') tensor(-3.4977e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.027994
Average KL loss: 0.038580
Average total loss: 0.066574
tensor(0.0336, device='cuda:0') tensor(0.2414, device='cuda:0') tensor(-2.8693e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.030912
Average KL loss: 0.038704
Average total loss: 0.069616
tensor(0.0337, device='cuda:0') tensor(0.2429, device='cuda:0') tensor(-1.2913e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.027675
Average KL loss: 0.038730
Average total loss: 0.066405
tensor(0.0338, device='cuda:0') tensor(0.2439, device='cuda:0') tensor(-8.2283e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.028287
Average KL loss: 0.038696
Average total loss: 0.066983
tensor(0.0339, device='cuda:0') tensor(0.2452, device='cuda:0') tensor(-8.3376e-11, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.028313
Average KL loss: 0.038661
Average total loss: 0.066974
tensor(0.0339, device='cuda:0') tensor(0.2463, device='cuda:0') tensor(-1.0044e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.027748
Average KL loss: 0.038670
Average total loss: 0.066419
tensor(0.0340, device='cuda:0') tensor(0.2473, device='cuda:0') tensor(-1.1342e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.027364
Average KL loss: 0.038659
Average total loss: 0.066023
tensor(0.0341, device='cuda:0') tensor(0.2485, device='cuda:0') tensor(-2.2014e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.027777
Average KL loss: 0.038641
Average total loss: 0.066418
tensor(0.0342, device='cuda:0') tensor(0.2496, device='cuda:0') tensor(1.2199e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.027987
Average KL loss: 0.038643
Average total loss: 0.066630
tensor(0.0342, device='cuda:0') tensor(0.2507, device='cuda:0') tensor(-1.3814e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.027473
Average KL loss: 0.038638
Average total loss: 0.066110
tensor(0.0343, device='cuda:0') tensor(0.2517, device='cuda:0') tensor(-1.3087e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.027260
Average KL loss: 0.038614
Average total loss: 0.065875
tensor(0.0344, device='cuda:0') tensor(0.2528, device='cuda:0') tensor(-1.0885e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.027280
Average KL loss: 0.038582
Average total loss: 0.065862
tensor(0.0344, device='cuda:0') tensor(0.2538, device='cuda:0') tensor(-4.2577e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.028778
Average KL loss: 0.038618
Average total loss: 0.067396
tensor(0.0345, device='cuda:0') tensor(0.2550, device='cuda:0') tensor(-3.5671e-11, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.027609
Average KL loss: 0.038639
Average total loss: 0.066248
tensor(0.0346, device='cuda:0') tensor(0.2561, device='cuda:0') tensor(-1.2903e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.027818
Average KL loss: 0.038642
Average total loss: 0.066461
tensor(0.0346, device='cuda:0') tensor(0.2573, device='cuda:0') tensor(-9.9530e-11, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.027617
Average KL loss: 0.038639
Average total loss: 0.066257
tensor(0.0347, device='cuda:0') tensor(0.2585, device='cuda:0') tensor(-3.6353e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.027674
Average KL loss: 0.038655
Average total loss: 0.066329
tensor(0.0348, device='cuda:0') tensor(0.2595, device='cuda:0') tensor(2.1229e-11, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.027471
Average KL loss: 0.038660
Average total loss: 0.066130
tensor(0.0349, device='cuda:0') tensor(0.2608, device='cuda:0') tensor(-2.2651e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.027478
Average KL loss: 0.038682
Average total loss: 0.066160
tensor(0.0350, device='cuda:0') tensor(0.2619, device='cuda:0') tensor(-2.4728e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.028351
Average KL loss: 0.038681
Average total loss: 0.067032
tensor(0.0350, device='cuda:0') tensor(0.2631, device='cuda:0') tensor(-1.0674e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.027451
Average KL loss: 0.038688
Average total loss: 0.066139
tensor(0.0351, device='cuda:0') tensor(0.2641, device='cuda:0') tensor(-4.6644e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.027335
Average KL loss: 0.038669
Average total loss: 0.066005
tensor(0.0351, device='cuda:0') tensor(0.2651, device='cuda:0') tensor(-1.5807e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.027441
Average KL loss: 0.038686
Average total loss: 0.066128
tensor(0.0352, device='cuda:0') tensor(0.2664, device='cuda:0') tensor(-9.0006e-11, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.027383
Average KL loss: 0.038671
Average total loss: 0.066054
tensor(0.0352, device='cuda:0') tensor(0.2664, device='cuda:0') tensor(-1.5778e-11, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.027375
Average KL loss: 0.038626
Average total loss: 0.066001
tensor(0.0352, device='cuda:0') tensor(0.2663, device='cuda:0') tensor(-2.0363e-11, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.029993
Average KL loss: 0.038584
Average total loss: 0.068577
tensor(0.0352, device='cuda:0') tensor(0.2663, device='cuda:0') tensor(-3.4394e-11, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.026951
Average KL loss: 0.038548
Average total loss: 0.065498
tensor(0.0352, device='cuda:0') tensor(0.2663, device='cuda:0') tensor(-6.5443e-11, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.026967
Average KL loss: 0.038513
Average total loss: 0.065480
tensor(0.0352, device='cuda:0') tensor(0.2663, device='cuda:0') tensor(-6.0592e-11, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.027251
Average KL loss: 0.038479
Average total loss: 0.065730
tensor(0.0352, device='cuda:0') tensor(0.2662, device='cuda:0') tensor(3.4607e-11, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.026681
Average KL loss: 0.038447
Average total loss: 0.065128
tensor(0.0352, device='cuda:0') tensor(0.2662, device='cuda:0') tensor(-7.4667e-11, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.026704
Average KL loss: 0.038417
Average total loss: 0.065121
tensor(0.0352, device='cuda:0') tensor(0.2662, device='cuda:0') tensor(1.1057e-11, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.026895
Average KL loss: 0.038389
Average total loss: 0.065284
tensor(0.0352, device='cuda:0') tensor(0.2662, device='cuda:0') tensor(-6.5062e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.026825
Average KL loss: 0.038360
Average total loss: 0.065185
tensor(0.0352, device='cuda:0') tensor(0.2661, device='cuda:0') tensor(-5.4160e-11, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.026642
Average KL loss: 0.038332
Average total loss: 0.064974
tensor(0.0352, device='cuda:0') tensor(0.2661, device='cuda:0') tensor(-5.8857e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.026670
Average KL loss: 0.038305
Average total loss: 0.064975
tensor(0.0352, device='cuda:0') tensor(0.2661, device='cuda:0') tensor(-7.0500e-12, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.026718
Average KL loss: 0.038280
Average total loss: 0.064999
tensor(0.0352, device='cuda:0') tensor(0.2661, device='cuda:0') tensor(-2.5595e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.026939
Average KL loss: 0.038254
Average total loss: 0.065193
tensor(0.0352, device='cuda:0') tensor(0.2660, device='cuda:0') tensor(-4.7572e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.026398
Average KL loss: 0.038233
Average total loss: 0.064631
tensor(0.0352, device='cuda:0') tensor(0.2660, device='cuda:0') tensor(-3.5037e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.027279
Average KL loss: 0.038212
Average total loss: 0.065491
tensor(0.0352, device='cuda:0') tensor(0.2660, device='cuda:0') tensor(-8.1556e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.026758
Average KL loss: 0.038193
Average total loss: 0.064951
tensor(0.0352, device='cuda:0') tensor(0.2660, device='cuda:0') tensor(-9.4846e-11, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.026948
Average KL loss: 0.038173
Average total loss: 0.065120
tensor(0.0352, device='cuda:0') tensor(0.2660, device='cuda:0') tensor(-1.0505e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.026561
Average KL loss: 0.038152
Average total loss: 0.064712
tensor(0.0352, device='cuda:0') tensor(0.2660, device='cuda:0') tensor(-4.7172e-12, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.026513
Average KL loss: 0.038133
Average total loss: 0.064646
tensor(0.0352, device='cuda:0') tensor(0.2660, device='cuda:0') tensor(-4.1085e-11, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.026457
Average KL loss: 0.038112
Average total loss: 0.064569
tensor(0.0352, device='cuda:0') tensor(0.2659, device='cuda:0') tensor(-1.4485e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.029418
Average KL loss: 0.038093
Average total loss: 0.067511
tensor(0.0352, device='cuda:0') tensor(0.2659, device='cuda:0') tensor(-7.1306e-12, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.026629
Average KL loss: 0.038075
Average total loss: 0.064704
tensor(0.0352, device='cuda:0') tensor(0.2659, device='cuda:0') tensor(-2.9418e-12, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.027131
Average KL loss: 0.038056
Average total loss: 0.065187
tensor(0.0352, device='cuda:0') tensor(0.2659, device='cuda:0') tensor(-2.3297e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.026791
Average KL loss: 0.038037
Average total loss: 0.064829
tensor(0.0352, device='cuda:0') tensor(0.2658, device='cuda:0') tensor(-5.1437e-11, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.026598
Average KL loss: 0.038019
Average total loss: 0.064617
tensor(0.0352, device='cuda:0') tensor(0.2658, device='cuda:0') tensor(-1.5536e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.026785
Average KL loss: 0.038003
Average total loss: 0.064788
tensor(0.0352, device='cuda:0') tensor(0.2658, device='cuda:0') tensor(-3.8796e-11, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.026607
Average KL loss: 0.037986
Average total loss: 0.064593
tensor(0.0352, device='cuda:0') tensor(0.2657, device='cuda:0') tensor(-8.5517e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.026705
Average KL loss: 0.037967
Average total loss: 0.064672
tensor(0.0352, device='cuda:0') tensor(0.2657, device='cuda:0') tensor(-2.5201e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.026590
Average KL loss: 0.037951
Average total loss: 0.064541
tensor(0.0352, device='cuda:0') tensor(0.2657, device='cuda:0') tensor(4.6056e-11, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.026525
Average KL loss: 0.037937
Average total loss: 0.064461
tensor(0.0352, device='cuda:0') tensor(0.2656, device='cuda:0') tensor(-6.1880e-11, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.026667
Average KL loss: 0.037920
Average total loss: 0.064586
tensor(0.0352, device='cuda:0') tensor(0.2656, device='cuda:0') tensor(-2.6633e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.026475
Average KL loss: 0.037902
Average total loss: 0.064377
tensor(0.0352, device='cuda:0') tensor(0.2656, device='cuda:0') tensor(-2.7017e-11, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.026416
Average KL loss: 0.037886
Average total loss: 0.064301
tensor(0.0352, device='cuda:0') tensor(0.2656, device='cuda:0') tensor(-1.8709e-11, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.026490
Average KL loss: 0.037869
Average total loss: 0.064358
tensor(0.0352, device='cuda:0') tensor(0.2655, device='cuda:0') tensor(-2.3218e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.026497
Average KL loss: 0.037855
Average total loss: 0.064351
tensor(0.0352, device='cuda:0') tensor(0.2655, device='cuda:0') tensor(-7.8300e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.026633
Average KL loss: 0.037840
Average total loss: 0.064473
tensor(0.0352, device='cuda:0') tensor(0.2655, device='cuda:0') tensor(-5.8473e-13, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.026634
Average KL loss: 0.037824
Average total loss: 0.064458
tensor(0.0352, device='cuda:0') tensor(0.2654, device='cuda:0') tensor(-8.8866e-11, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.026909
Average KL loss: 0.037808
Average total loss: 0.064717
tensor(0.0352, device='cuda:0') tensor(0.2654, device='cuda:0') tensor(-1.4980e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.026474
Average KL loss: 0.037793
Average total loss: 0.064267
tensor(0.0352, device='cuda:0') tensor(0.2654, device='cuda:0') tensor(-1.0512e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.026827
Average KL loss: 0.037779
Average total loss: 0.064606
tensor(0.0351, device='cuda:0') tensor(0.2653, device='cuda:0') tensor(-1.9480e-11, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.026623
Average KL loss: 0.037766
Average total loss: 0.064389
tensor(0.0351, device='cuda:0') tensor(0.2653, device='cuda:0') tensor(-2.9092e-11, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.026346
Average KL loss: 0.037753
Average total loss: 0.064099
tensor(0.0351, device='cuda:0') tensor(0.2652, device='cuda:0') tensor(3.4206e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.026787
Average KL loss: 0.037740
Average total loss: 0.064527
tensor(0.0351, device='cuda:0') tensor(0.2652, device='cuda:0') tensor(-7.3433e-13, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.026539
Average KL loss: 0.037725
Average total loss: 0.064264
tensor(0.0351, device='cuda:0') tensor(0.2652, device='cuda:0') tensor(-2.1699e-11, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.026901
Average KL loss: 0.037713
Average total loss: 0.064614
tensor(0.0351, device='cuda:0') tensor(0.2651, device='cuda:0') tensor(-3.9723e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.026882
Average KL loss: 0.037702
Average total loss: 0.064584
tensor(0.0351, device='cuda:0') tensor(0.2651, device='cuda:0') tensor(-2.0767e-11, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.028776
Average KL loss: 0.037691
Average total loss: 0.066466
tensor(0.0351, device='cuda:0') tensor(0.2651, device='cuda:0') tensor(8.1103e-11, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.026248
Average KL loss: 0.037679
Average total loss: 0.063928
tensor(0.0351, device='cuda:0') tensor(0.2650, device='cuda:0') tensor(-4.7604e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.026804
Average KL loss: 0.037667
Average total loss: 0.064471
tensor(0.0351, device='cuda:0') tensor(0.2650, device='cuda:0') tensor(-1.6087e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.026383
Average KL loss: 0.037653
Average total loss: 0.064036
tensor(0.0351, device='cuda:0') tensor(0.2649, device='cuda:0') tensor(8.7299e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.029487
Average KL loss: 0.037641
Average total loss: 0.067128
tensor(0.0351, device='cuda:0') tensor(0.2649, device='cuda:0') tensor(-3.6508e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.026736
Average KL loss: 0.037632
Average total loss: 0.064367
tensor(0.0351, device='cuda:0') tensor(0.2648, device='cuda:0') tensor(-7.1401e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.026361
Average KL loss: 0.037618
Average total loss: 0.063979
tensor(0.0351, device='cuda:0') tensor(0.2648, device='cuda:0') tensor(-2.0571e-11, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.026366
Average KL loss: 0.037605
Average total loss: 0.063971
tensor(0.0351, device='cuda:0') tensor(0.2647, device='cuda:0') tensor(1.9089e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.026885
Average KL loss: 0.037590
Average total loss: 0.064476
tensor(0.0351, device='cuda:0') tensor(0.2646, device='cuda:0') tensor(-9.5123e-11, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.026685
Average KL loss: 0.037579
Average total loss: 0.064263
tensor(0.0351, device='cuda:0') tensor(0.2646, device='cuda:0') tensor(4.7070e-11, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.026347
Average KL loss: 0.037564
Average total loss: 0.063911
tensor(0.0351, device='cuda:0') tensor(0.2645, device='cuda:0') tensor(-1.1472e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.026572
Average KL loss: 0.037553
Average total loss: 0.064125
tensor(0.0351, device='cuda:0') tensor(0.2645, device='cuda:0') tensor(-1.2549e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.026526
Average KL loss: 0.037540
Average total loss: 0.064066
tensor(0.0350, device='cuda:0') tensor(0.2644, device='cuda:0') tensor(-7.5913e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.026485
Average KL loss: 0.037529
Average total loss: 0.064014
tensor(0.0350, device='cuda:0') tensor(0.2643, device='cuda:0') tensor(-4.0837e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.027274
Average KL loss: 0.037517
Average total loss: 0.064791
tensor(0.0350, device='cuda:0') tensor(0.2643, device='cuda:0') tensor(1.7676e-11, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.026648
Average KL loss: 0.037509
Average total loss: 0.064156
tensor(0.0350, device='cuda:0') tensor(0.2642, device='cuda:0') tensor(-1.6437e-11, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.026472
Average KL loss: 0.037497
Average total loss: 0.063969
tensor(0.0350, device='cuda:0') tensor(0.2642, device='cuda:0') tensor(3.6810e-12, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.026780
Average KL loss: 0.037487
Average total loss: 0.064267
tensor(0.0350, device='cuda:0') tensor(0.2641, device='cuda:0') tensor(-4.5508e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.026618
Average KL loss: 0.037477
Average total loss: 0.064095
tensor(0.0350, device='cuda:0') tensor(0.2641, device='cuda:0') tensor(2.9541e-12, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.026615
Average KL loss: 0.037466
Average total loss: 0.064082
tensor(0.0350, device='cuda:0') tensor(0.2640, device='cuda:0') tensor(-3.9961e-12, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.026550
Average KL loss: 0.037455
Average total loss: 0.064005
tensor(0.0350, device='cuda:0') tensor(0.2639, device='cuda:0') tensor(-2.7805e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.026749
Average KL loss: 0.037446
Average total loss: 0.064195
tensor(0.0350, device='cuda:0') tensor(0.2639, device='cuda:0') tensor(-2.6767e-11, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.026817
Average KL loss: 0.037440
Average total loss: 0.064258
tensor(0.0350, device='cuda:0') tensor(0.2639, device='cuda:0') tensor(-1.9041e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.026487
Average KL loss: 0.037439
Average total loss: 0.063926
tensor(0.0350, device='cuda:0') tensor(0.2639, device='cuda:0') tensor(-1.2908e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.026278
Average KL loss: 0.037437
Average total loss: 0.063715
tensor(0.0350, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(-6.2465e-11, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.026311
Average KL loss: 0.037436
Average total loss: 0.063747
tensor(0.0350, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(-1.1647e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.026346
Average KL loss: 0.037434
Average total loss: 0.063780
tensor(0.0350, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(-4.1936e-11, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.026310
Average KL loss: 0.037432
Average total loss: 0.063743
tensor(0.0350, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(-5.7628e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.026279
Average KL loss: 0.037431
Average total loss: 0.063710
tensor(0.0350, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(-3.9039e-11, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.026403
Average KL loss: 0.037429
Average total loss: 0.063832
tensor(0.0350, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(-5.9348e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.027092
Average KL loss: 0.037428
Average total loss: 0.064519
tensor(0.0350, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(2.8670e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.026491
Average KL loss: 0.037426
Average total loss: 0.063917
tensor(0.0350, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(-2.4641e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.026701
Average KL loss: 0.037425
Average total loss: 0.064126
tensor(0.0350, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(-3.6263e-11, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.026510
Average KL loss: 0.037423
Average total loss: 0.063933
 Percentile value: 9.246145629882813
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =      82 /    1728             (  4.75%) | total_pruned =    1646 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      41 /   36864             (  0.11%) | total_pruned =   36823 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      76 /   36864             (  0.21%) | total_pruned =   36788 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     257 /   36864             (  0.70%) | total_pruned =   36607 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     398 /   36864             (  1.08%) | total_pruned =   36466 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     921 /   73728             (  1.25%) | total_pruned =   72807 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1599 /  147456             (  1.08%) | total_pruned =  145857 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     211 /    8192             (  2.58%) | total_pruned =    7981 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     795 /  147456             (  0.54%) | total_pruned =  146661 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     718 /  147456             (  0.49%) | total_pruned =  146738 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3181 /  294912             (  1.08%) | total_pruned =  291731 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     139 /     256             ( 54.30%) | total_pruned =     117 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3598 /  589824             (  0.61%) | total_pruned =  586226 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      44 /     256             ( 17.19%) | total_pruned =     212 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     337 /   32768             (  1.03%) | total_pruned =   32431 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      76 /     256             ( 29.69%) | total_pruned =     180 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2276 /  589824             (  0.39%) | total_pruned =  587548 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     129 /     256             ( 50.39%) | total_pruned =     127 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1839 /  589824             (  0.31%) | total_pruned =  587985 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      99 /     256             ( 38.67%) | total_pruned =     157 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      43 /     256             ( 16.80%) | total_pruned =     213 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    3398 / 1179648             (  0.29%) | total_pruned = 1176250 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     288 /     512             ( 56.25%) | total_pruned =     224 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2293 / 2359296             (  0.10%) | total_pruned = 2357003 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     169 /     512             ( 33.01%) | total_pruned =     343 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     119 /     512             ( 23.24%) | total_pruned =     393 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      47 /  131072             (  0.04%) | total_pruned =  131025 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     112 /     512             ( 21.88%) | total_pruned =     400 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1138 / 2359296             (  0.05%) | total_pruned = 2358158 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      79 /     512             ( 15.43%) | total_pruned =     433 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1033 / 2359296             (  0.04%) | total_pruned = 2358263 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     196 /     512             ( 38.28%) | total_pruned =     316 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     107 /     512             ( 20.90%) | total_pruned =     405 | shape = torch.Size([512])
linear.weight        | nonzeros =     629 /    5120             ( 12.29%) | total_pruned =    4491 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 178/200 Loss: 0.167946 Accuracy: 78.37 98.99 % Best test Accuracy: 81.54%
tensor(0.0350, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(-2.3513e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.101994
Average KL loss: 0.031076
Average total loss: 0.133070
tensor(0.0220, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(-3.1163e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.131290
Average KL loss: 0.019020
Average total loss: 0.150310
tensor(0.0157, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-5.2511e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.184749
Average KL loss: 0.015924
Average total loss: 0.200673
tensor(0.0139, device='cuda:0') tensor(0.1045, device='cuda:0') tensor(-7.6208e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.205995
Average KL loss: 0.015095
Average total loss: 0.221091
tensor(0.0131, device='cuda:0') tensor(0.0955, device='cuda:0') tensor(-1.3491e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.200419
Average KL loss: 0.014719
Average total loss: 0.215138
tensor(0.0126, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(-4.7150e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.183285
Average KL loss: 0.014543
Average total loss: 0.197828
tensor(0.0124, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-6.5018e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.190084
Average KL loss: 0.014468
Average total loss: 0.204552
tensor(0.0123, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-4.5815e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.176010
Average KL loss: 0.014432
Average total loss: 0.190442
tensor(0.0122, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-4.6405e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.166718
Average KL loss: 0.014416
Average total loss: 0.181134
tensor(0.0122, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-6.2657e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.167815
Average KL loss: 0.014425
Average total loss: 0.182240
tensor(0.0122, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-6.6993e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.155444
Average KL loss: 0.014443
Average total loss: 0.169887
tensor(0.0123, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-2.5119e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.149150
Average KL loss: 0.014475
Average total loss: 0.163626
tensor(0.0124, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(-3.0247e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.150314
Average KL loss: 0.014487
Average total loss: 0.164802
tensor(0.0124, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-3.5555e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.143328
Average KL loss: 0.014490
Average total loss: 0.157817
tensor(0.0124, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-7.3698e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.143679
Average KL loss: 0.014494
Average total loss: 0.158173
tensor(0.0124, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-5.0249e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.143285
Average KL loss: 0.014498
Average total loss: 0.157783
tensor(0.0124, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(-3.8592e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.143012
Average KL loss: 0.014502
Average total loss: 0.157515
tensor(0.0124, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(-1.6625e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.149458
Average KL loss: 0.014505
Average total loss: 0.163963
tensor(0.0124, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(-2.5898e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.137025
Average KL loss: 0.014507
Average total loss: 0.151532
tensor(0.0124, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-1.3204e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.138295
Average KL loss: 0.014509
Average total loss: 0.152805
tensor(0.0124, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-4.3278e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.144510
Average KL loss: 0.014511
Average total loss: 0.159021
tensor(0.0124, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(-2.7393e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.147274
Average KL loss: 0.014514
Average total loss: 0.161788
tensor(0.0124, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(-2.0608e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.130014
Average KL loss: 0.014517
Average total loss: 0.144531
tensor(0.0125, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-5.0450e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.144848
Average KL loss: 0.014519
Average total loss: 0.159366
tensor(0.0125, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-1.9144e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.135433
Average KL loss: 0.014519
Average total loss: 0.149953
tensor(0.0125, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-1.7634e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.131021
Average KL loss: 0.014520
Average total loss: 0.145540
tensor(0.0125, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-2.8705e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.130132
Average KL loss: 0.014520
Average total loss: 0.144652
tensor(0.0125, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-2.1118e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.140548
Average KL loss: 0.014520
Average total loss: 0.155068
tensor(0.0125, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-2.1263e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.141118
Average KL loss: 0.014521
Average total loss: 0.155639
tensor(0.0125, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-2.3891e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.135797
Average KL loss: 0.014521
Average total loss: 0.150318
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.7658e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.132267
Average KL loss: 0.014522
Average total loss: 0.146788
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-1.7618e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.132572
Average KL loss: 0.014522
Average total loss: 0.147094
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-9.3982e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.137613
Average KL loss: 0.014523
Average total loss: 0.152135
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.0642e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.139466
Average KL loss: 0.014523
Average total loss: 0.153989
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-5.0827e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.135412
Average KL loss: 0.014523
Average total loss: 0.149935
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-3.8133e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.133410
Average KL loss: 0.014523
Average total loss: 0.147933
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.1458e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.143090
Average KL loss: 0.014523
Average total loss: 0.157613
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-1.9858e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.144791
Average KL loss: 0.014523
Average total loss: 0.159314
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-5.5601e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.141405
Average KL loss: 0.014524
Average total loss: 0.155928
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-1.8636e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.133742
Average KL loss: 0.014524
Average total loss: 0.148266
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-1.9863e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.136673
Average KL loss: 0.014524
Average total loss: 0.151197
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-7.6274e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.139319
Average KL loss: 0.014524
Average total loss: 0.153843
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-1.1143e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.137469
Average KL loss: 0.014524
Average total loss: 0.151993
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.3701e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.131214
Average KL loss: 0.014524
Average total loss: 0.145738
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-1.6021e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.133108
Average KL loss: 0.014524
Average total loss: 0.147632
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.2814e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.136914
Average KL loss: 0.014524
Average total loss: 0.151438
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-4.1079e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.138447
Average KL loss: 0.014524
Average total loss: 0.152971
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.1535e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.134950
Average KL loss: 0.014524
Average total loss: 0.149473
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.3674e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.135219
Average KL loss: 0.014524
Average total loss: 0.149743
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.3616e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.133945
Average KL loss: 0.014524
Average total loss: 0.148469
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-3.1098e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.132822
Average KL loss: 0.014524
Average total loss: 0.147346
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-1.4857e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.139796
Average KL loss: 0.014524
Average total loss: 0.154320
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.9006e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.140227
Average KL loss: 0.014524
Average total loss: 0.154751
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-1.3021e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.139661
Average KL loss: 0.014524
Average total loss: 0.154185
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-3.3791e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.129939
Average KL loss: 0.014524
Average total loss: 0.144463
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.1470e-09, device='cuda:0')
 Percentile value: 8.733054256439207
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =      48 /    1728             (  2.78%) | total_pruned =    1680 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      19 /   36864             (  0.05%) | total_pruned =   36845 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      42 /   36864             (  0.11%) | total_pruned =   36822 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     116 /   36864             (  0.31%) | total_pruned =   36748 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     144 /   36864             (  0.39%) | total_pruned =   36720 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     314 /   73728             (  0.43%) | total_pruned =   73414 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     524 /  147456             (  0.36%) | total_pruned =  146932 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      70 /    8192             (  0.85%) | total_pruned =    8122 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     278 /  147456             (  0.19%) | total_pruned =  147178 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     239 /  147456             (  0.16%) | total_pruned =  147217 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     928 /  294912             (  0.31%) | total_pruned =  293984 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1031 /  589824             (  0.17%) | total_pruned =  588793 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      72 /     256             ( 28.12%) | total_pruned =     184 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      86 /   32768             (  0.26%) | total_pruned =   32682 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     611 /  589824             (  0.10%) | total_pruned =  589213 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     472 /  589824             (  0.08%) | total_pruned =  589352 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      58 /     256             ( 22.66%) | total_pruned =     198 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     831 / 1179648             (  0.07%) | total_pruned = 1178817 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     157 /     512             ( 30.66%) | total_pruned =     355 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     531 / 2359296             (  0.02%) | total_pruned = 2358765 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      68 /     512             ( 13.28%) | total_pruned =     444 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      36 /     512             (  7.03%) | total_pruned =     476 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       8 /  131072             (  0.01%) | total_pruned =  131064 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     256 / 2359296             (  0.01%) | total_pruned = 2359040 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     213 / 2359296             (  0.01%) | total_pruned = 2359083 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      90 /     512             ( 17.58%) | total_pruned =     422 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
linear.weight        | nonzeros =     209 /    5120             (  4.08%) | total_pruned =    4911 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 170/200 Loss: 1.247427 Accuracy: 57.90 61.06 % Best test Accuracy: 58.15%
