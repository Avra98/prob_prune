Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1415e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.115130
Average KL loss: 0.162172
Average total loss: 1.277302
tensor(0.0052, device='cuda:0') tensor(0.2023, device='cuda:0') tensor(-6.0353e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.579908
Average KL loss: 0.289912
Average total loss: 0.869820
tensor(0.0094, device='cuda:0') tensor(0.2583, device='cuda:0') tensor(-4.4945e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.385923
Average KL loss: 0.330535
Average total loss: 0.716458
tensor(0.0124, device='cuda:0') tensor(0.2923, device='cuda:0') tensor(-2.5800e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.278584
Average KL loss: 0.352281
Average total loss: 0.630864
tensor(0.0147, device='cuda:0') tensor(0.3193, device='cuda:0') tensor(-3.0140e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.206983
Average KL loss: 0.366437
Average total loss: 0.573419
tensor(0.0166, device='cuda:0') tensor(0.3292, device='cuda:0') tensor(-1.9881e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.151148
Average KL loss: 0.363048
Average total loss: 0.514196
tensor(0.0178, device='cuda:0') tensor(0.3306, device='cuda:0') tensor(-1.9555e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.114745
Average KL loss: 0.354465
Average total loss: 0.469210
tensor(0.0188, device='cuda:0') tensor(0.3231, device='cuda:0') tensor(-1.7855e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.089863
Average KL loss: 0.344032
Average total loss: 0.433896
tensor(0.0192, device='cuda:0') tensor(0.3157, device='cuda:0') tensor(-1.0513e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.071134
Average KL loss: 0.324995
Average total loss: 0.396128
tensor(0.0194, device='cuda:0') tensor(0.3001, device='cuda:0') tensor(-8.9101e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.059705
Average KL loss: 0.311764
Average total loss: 0.371468
tensor(0.0196, device='cuda:0') tensor(0.2881, device='cuda:0') tensor(-9.4679e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.051460
Average KL loss: 0.297679
Average total loss: 0.349138
tensor(0.0195, device='cuda:0') tensor(0.2791, device='cuda:0') tensor(-4.3315e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.045788
Average KL loss: 0.286875
Average total loss: 0.332664
tensor(0.0196, device='cuda:0') tensor(0.2700, device='cuda:0') tensor(-5.6506e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.040536
Average KL loss: 0.278868
Average total loss: 0.319403
tensor(0.0196, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(-1.8885e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.037579
Average KL loss: 0.270243
Average total loss: 0.307822
tensor(0.0194, device='cuda:0') tensor(0.2567, device='cuda:0') tensor(-3.8787e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.036975
Average KL loss: 0.263908
Average total loss: 0.300883
tensor(0.0194, device='cuda:0') tensor(0.2544, device='cuda:0') tensor(-1.9591e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.030634
Average KL loss: 0.259936
Average total loss: 0.290570
tensor(0.0192, device='cuda:0') tensor(0.2448, device='cuda:0') tensor(-4.0532e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.023945
Average KL loss: 0.243589
Average total loss: 0.267534
tensor(0.0188, device='cuda:0') tensor(0.2275, device='cuda:0') tensor(-2.5928e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.025729
Average KL loss: 0.230920
Average total loss: 0.256649
tensor(0.0186, device='cuda:0') tensor(0.2216, device='cuda:0') tensor(-3.3545e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.025524
Average KL loss: 0.227740
Average total loss: 0.253264
tensor(0.0186, device='cuda:0') tensor(0.2205, device='cuda:0') tensor(-3.6391e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.024124
Average KL loss: 0.226628
Average total loss: 0.250752
tensor(0.0185, device='cuda:0') tensor(0.2174, device='cuda:0') tensor(-2.0510e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.023229
Average KL loss: 0.223850
Average total loss: 0.247079
tensor(0.0184, device='cuda:0') tensor(0.2175, device='cuda:0') tensor(-3.3624e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.018995
Average KL loss: 0.220124
Average total loss: 0.239119
tensor(0.0182, device='cuda:0') tensor(0.2078, device='cuda:0') tensor(-2.0693e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.021122
Average KL loss: 0.216240
Average total loss: 0.237362
tensor(0.0183, device='cuda:0') tensor(0.2118, device='cuda:0') tensor(-1.1850e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.017740
Average KL loss: 0.215198
Average total loss: 0.232938
tensor(0.0182, device='cuda:0') tensor(0.2028, device='cuda:0') tensor(6.4816e-11, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.017537
Average KL loss: 0.205315
Average total loss: 0.222852
tensor(0.0177, device='cuda:0') tensor(0.1988, device='cuda:0') tensor(-1.0489e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.017877
Average KL loss: 0.201843
Average total loss: 0.219720
tensor(0.0178, device='cuda:0') tensor(0.1965, device='cuda:0') tensor(-6.1906e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.019004
Average KL loss: 0.208724
Average total loss: 0.227728
tensor(0.0178, device='cuda:0') tensor(0.2039, device='cuda:0') tensor(-4.4978e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.017210
Average KL loss: 0.210344
Average total loss: 0.227554
tensor(0.0177, device='cuda:0') tensor(0.2016, device='cuda:0') tensor(-1.1631e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.016803
Average KL loss: 0.209439
Average total loss: 0.226242
tensor(0.0179, device='cuda:0') tensor(0.2035, device='cuda:0') tensor(-1.5337e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.016244
Average KL loss: 0.210051
Average total loss: 0.226295
tensor(0.0179, device='cuda:0') tensor(0.2037, device='cuda:0') tensor(-1.8117e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.014710
Average KL loss: 0.205435
Average total loss: 0.220146
tensor(0.0177, device='cuda:0') tensor(0.1957, device='cuda:0') tensor(-4.1334e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.014152
Average KL loss: 0.201429
Average total loss: 0.215582
tensor(0.0175, device='cuda:0') tensor(0.1947, device='cuda:0') tensor(5.1569e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.014730
Average KL loss: 0.197820
Average total loss: 0.212550
tensor(0.0176, device='cuda:0') tensor(0.1948, device='cuda:0') tensor(-5.6607e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.014976
Average KL loss: 0.200757
Average total loss: 0.215733
tensor(0.0176, device='cuda:0') tensor(0.1993, device='cuda:0') tensor(-9.0034e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.015545
Average KL loss: 0.207917
Average total loss: 0.223462
tensor(0.0178, device='cuda:0') tensor(0.2073, device='cuda:0') tensor(-7.0660e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.014984
Average KL loss: 0.216250
Average total loss: 0.231234
tensor(0.0179, device='cuda:0') tensor(0.2130, device='cuda:0') tensor(1.6821e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.012374
Average KL loss: 0.210183
Average total loss: 0.222556
tensor(0.0176, device='cuda:0') tensor(0.2061, device='cuda:0') tensor(-2.8724e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.012776
Average KL loss: 0.202920
Average total loss: 0.215696
tensor(0.0175, device='cuda:0') tensor(0.2001, device='cuda:0') tensor(-1.7816e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.013598
Average KL loss: 0.206159
Average total loss: 0.219756
tensor(0.0177, device='cuda:0') tensor(0.2055, device='cuda:0') tensor(1.5664e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.011330
Average KL loss: 0.205564
Average total loss: 0.216893
tensor(0.0172, device='cuda:0') tensor(0.1993, device='cuda:0') tensor(-9.7712e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.011113
Average KL loss: 0.194845
Average total loss: 0.205958
tensor(0.0171, device='cuda:0') tensor(0.1919, device='cuda:0') tensor(-2.2933e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.010465
Average KL loss: 0.192005
Average total loss: 0.202470
tensor(0.0170, device='cuda:0') tensor(0.1888, device='cuda:0') tensor(7.1265e-11, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.011231
Average KL loss: 0.187022
Average total loss: 0.198253
tensor(0.0168, device='cuda:0') tensor(0.1935, device='cuda:0') tensor(-5.5370e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.012118
Average KL loss: 0.197398
Average total loss: 0.209516
tensor(0.0171, device='cuda:0') tensor(0.2003, device='cuda:0') tensor(8.5354e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.012002
Average KL loss: 0.208989
Average total loss: 0.220991
tensor(0.0172, device='cuda:0') tensor(0.2091, device='cuda:0') tensor(-2.6440e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.011377
Average KL loss: 0.206535
Average total loss: 0.217912
tensor(0.0173, device='cuda:0') tensor(0.2034, device='cuda:0') tensor(-2.9927e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.012470
Average KL loss: 0.207278
Average total loss: 0.219749
tensor(0.0172, device='cuda:0') tensor(0.2114, device='cuda:0') tensor(4.5553e-11, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.011954
Average KL loss: 0.219162
Average total loss: 0.231116
tensor(0.0174, device='cuda:0') tensor(0.2219, device='cuda:0') tensor(3.4859e-12, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.011196
Average KL loss: 0.216928
Average total loss: 0.228124
tensor(0.0173, device='cuda:0') tensor(0.2158, device='cuda:0') tensor(1.9756e-11, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.010371
Average KL loss: 0.210567
Average total loss: 0.220939
tensor(0.0174, device='cuda:0') tensor(0.2122, device='cuda:0') tensor(-2.2540e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.009955
Average KL loss: 0.206922
Average total loss: 0.216877
tensor(0.0174, device='cuda:0') tensor(0.2102, device='cuda:0') tensor(4.8846e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.010411
Average KL loss: 0.203463
Average total loss: 0.213874
tensor(0.0173, device='cuda:0') tensor(0.2090, device='cuda:0') tensor(6.6736e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.010681
Average KL loss: 0.209250
Average total loss: 0.219931
tensor(0.0174, device='cuda:0') tensor(0.2142, device='cuda:0') tensor(-1.1703e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.010245
Average KL loss: 0.206866
Average total loss: 0.217111
tensor(0.0174, device='cuda:0') tensor(0.2120, device='cuda:0') tensor(-1.0240e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.007151
Average KL loss: 0.200633
Average total loss: 0.207783
tensor(0.0173, device='cuda:0') tensor(0.1986, device='cuda:0') tensor(4.7482e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.005793
Average KL loss: 0.184097
Average total loss: 0.189890
tensor(0.0172, device='cuda:0') tensor(0.1865, device='cuda:0') tensor(1.0391e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.004327
Average KL loss: 0.171250
Average total loss: 0.175577
tensor(0.0170, device='cuda:0') tensor(0.1767, device='cuda:0') tensor(1.0201e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.004480
Average KL loss: 0.160748
Average total loss: 0.165228
tensor(0.0168, device='cuda:0') tensor(0.1684, device='cuda:0') tensor(1.2421e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.004479
Average KL loss: 0.152037
Average total loss: 0.156517
tensor(0.0166, device='cuda:0') tensor(0.1613, device='cuda:0') tensor(7.1754e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.003485
Average KL loss: 0.144242
Average total loss: 0.147727
tensor(0.0164, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(8.8603e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.003858
Average KL loss: 0.137311
Average total loss: 0.141169
tensor(0.0162, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(1.3485e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.003877
Average KL loss: 0.131247
Average total loss: 0.135124
tensor(0.0161, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(5.2663e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.003423
Average KL loss: 0.125668
Average total loss: 0.129090
tensor(0.0159, device='cuda:0') tensor(0.1388, device='cuda:0') tensor(1.1794e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.003881
Average KL loss: 0.120542
Average total loss: 0.124424
tensor(0.0158, device='cuda:0') tensor(0.1344, device='cuda:0') tensor(1.0588e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.003559
Average KL loss: 0.115893
Average total loss: 0.119452
tensor(0.0156, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(5.7461e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.003661
Average KL loss: 0.111517
Average total loss: 0.115177
tensor(0.0154, device='cuda:0') tensor(0.1263, device='cuda:0') tensor(3.8897e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.003894
Average KL loss: 0.107564
Average total loss: 0.111458
tensor(0.0153, device='cuda:0') tensor(0.1227, device='cuda:0') tensor(4.1849e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.004121
Average KL loss: 0.104064
Average total loss: 0.108185
tensor(0.0152, device='cuda:0') tensor(0.1195, device='cuda:0') tensor(1.0329e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.003356
Average KL loss: 0.100627
Average total loss: 0.103983
tensor(0.0150, device='cuda:0') tensor(0.1162, device='cuda:0') tensor(8.7790e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.003873
Average KL loss: 0.097329
Average total loss: 0.101202
tensor(0.0149, device='cuda:0') tensor(0.1133, device='cuda:0') tensor(8.8487e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.003786
Average KL loss: 0.094369
Average total loss: 0.098155
tensor(0.0148, device='cuda:0') tensor(0.1104, device='cuda:0') tensor(9.4101e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.003167
Average KL loss: 0.091330
Average total loss: 0.094497
tensor(0.0146, device='cuda:0') tensor(0.1075, device='cuda:0') tensor(1.1799e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.003192
Average KL loss: 0.088392
Average total loss: 0.091584
tensor(0.0145, device='cuda:0') tensor(0.1047, device='cuda:0') tensor(1.1945e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.003672
Average KL loss: 0.085867
Average total loss: 0.089539
tensor(0.0144, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(8.6920e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.003706
Average KL loss: 0.083486
Average total loss: 0.087193
tensor(0.0143, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(4.0746e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.003218
Average KL loss: 0.081277
Average total loss: 0.084495
tensor(0.0141, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(-6.5022e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.003427
Average KL loss: 0.078936
Average total loss: 0.082362
tensor(0.0140, device='cuda:0') tensor(0.0955, device='cuda:0') tensor(1.2481e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.003482
Average KL loss: 0.076773
Average total loss: 0.080255
tensor(0.0139, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-3.5792e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.004316
Average KL loss: 0.074904
Average total loss: 0.079220
tensor(0.0138, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(1.1360e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.003902
Average KL loss: 0.073397
Average total loss: 0.077300
tensor(0.0137, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(9.9321e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.003396
Average KL loss: 0.071719
Average total loss: 0.075115
tensor(0.0136, device='cuda:0') tensor(0.0882, device='cuda:0') tensor(-1.0899e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.003859
Average KL loss: 0.069976
Average total loss: 0.073835
tensor(0.0135, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(1.0175e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.003339
Average KL loss: 0.068276
Average total loss: 0.071615
tensor(0.0134, device='cuda:0') tensor(0.0846, device='cuda:0') tensor(-3.4096e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.003909
Average KL loss: 0.066843
Average total loss: 0.070752
tensor(0.0133, device='cuda:0') tensor(0.0833, device='cuda:0') tensor(6.6688e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.004100
Average KL loss: 0.065548
Average total loss: 0.069648
tensor(0.0132, device='cuda:0') tensor(0.0818, device='cuda:0') tensor(7.4226e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.004002
Average KL loss: 0.064268
Average total loss: 0.068270
tensor(0.0131, device='cuda:0') tensor(0.0805, device='cuda:0') tensor(1.0904e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.004058
Average KL loss: 0.063070
Average total loss: 0.067129
tensor(0.0130, device='cuda:0') tensor(0.0792, device='cuda:0') tensor(7.1586e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.004063
Average KL loss: 0.061867
Average total loss: 0.065930
tensor(0.0129, device='cuda:0') tensor(0.0779, device='cuda:0') tensor(6.6623e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.003989
Average KL loss: 0.060781
Average total loss: 0.064770
tensor(0.0128, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(8.2724e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.004094
Average KL loss: 0.059910
Average total loss: 0.064004
tensor(0.0128, device='cuda:0') tensor(0.0756, device='cuda:0') tensor(8.2124e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.004409
Average KL loss: 0.058932
Average total loss: 0.063341
tensor(0.0127, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(1.6023e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.004584
Average KL loss: 0.058157
Average total loss: 0.062741
tensor(0.0126, device='cuda:0') tensor(0.0736, device='cuda:0') tensor(-1.2344e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.003963
Average KL loss: 0.057192
Average total loss: 0.061155
tensor(0.0125, device='cuda:0') tensor(0.0724, device='cuda:0') tensor(6.5836e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.004246
Average KL loss: 0.056218
Average total loss: 0.060465
tensor(0.0124, device='cuda:0') tensor(0.0714, device='cuda:0') tensor(1.4648e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.004304
Average KL loss: 0.055359
Average total loss: 0.059663
tensor(0.0124, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(7.2068e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.004373
Average KL loss: 0.054600
Average total loss: 0.058974
tensor(0.0123, device='cuda:0') tensor(0.0696, device='cuda:0') tensor(-2.8291e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.004691
Average KL loss: 0.054015
Average total loss: 0.058706
tensor(0.0123, device='cuda:0') tensor(0.0687, device='cuda:0') tensor(5.4826e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.004443
Average KL loss: 0.053307
Average total loss: 0.057751
tensor(0.0122, device='cuda:0') tensor(0.0679, device='cuda:0') tensor(-2.1705e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.003848
Average KL loss: 0.052572
Average total loss: 0.056420
tensor(0.0121, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(5.5937e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.004492
Average KL loss: 0.051762
Average total loss: 0.056254
tensor(0.0120, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(8.0191e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.004243
Average KL loss: 0.051240
Average total loss: 0.055484
tensor(0.0120, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(5.2670e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.004071
Average KL loss: 0.050665
Average total loss: 0.054736
tensor(0.0119, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(3.0366e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.004467
Average KL loss: 0.050057
Average total loss: 0.054524
tensor(0.0118, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-1.5458e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.004311
Average KL loss: 0.049571
Average total loss: 0.053882
tensor(0.0118, device='cuda:0') tensor(0.0633, device='cuda:0') tensor(5.6272e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.005046
Average KL loss: 0.048960
Average total loss: 0.054006
tensor(0.0117, device='cuda:0') tensor(0.0629, device='cuda:0') tensor(-4.5889e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.004675
Average KL loss: 0.048836
Average total loss: 0.053511
tensor(0.0117, device='cuda:0') tensor(0.0624, device='cuda:0') tensor(-3.0300e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.004271
Average KL loss: 0.048341
Average total loss: 0.052612
tensor(0.0117, device='cuda:0') tensor(0.0615, device='cuda:0') tensor(5.1820e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.004637
Average KL loss: 0.047544
Average total loss: 0.052180
tensor(0.0116, device='cuda:0') tensor(0.0608, device='cuda:0') tensor(-5.3538e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.005057
Average KL loss: 0.047328
Average total loss: 0.052385
tensor(0.0116, device='cuda:0') tensor(0.0607, device='cuda:0') tensor(3.3108e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.004561
Average KL loss: 0.047141
Average total loss: 0.051702
tensor(0.0115, device='cuda:0') tensor(0.0600, device='cuda:0') tensor(-1.6897e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.004318
Average KL loss: 0.046532
Average total loss: 0.050850
tensor(0.0115, device='cuda:0') tensor(0.0592, device='cuda:0') tensor(-1.2000e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.004417
Average KL loss: 0.045753
Average total loss: 0.050170
tensor(0.0114, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(-3.2498e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.004282
Average KL loss: 0.045429
Average total loss: 0.049711
tensor(0.0114, device='cuda:0') tensor(0.0581, device='cuda:0') tensor(-1.7784e-11, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.004892
Average KL loss: 0.045114
Average total loss: 0.050006
tensor(0.0114, device='cuda:0') tensor(0.0578, device='cuda:0') tensor(2.0587e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.004699
Average KL loss: 0.044766
Average total loss: 0.049465
tensor(0.0114, device='cuda:0') tensor(0.0573, device='cuda:0') tensor(4.6143e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.004683
Average KL loss: 0.044549
Average total loss: 0.049232
tensor(0.0113, device='cuda:0') tensor(0.0569, device='cuda:0') tensor(8.1576e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.004331
Average KL loss: 0.044009
Average total loss: 0.048340
tensor(0.0112, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(-1.5324e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.003998
Average KL loss: 0.043349
Average total loss: 0.047347
tensor(0.0112, device='cuda:0') tensor(0.0554, device='cuda:0') tensor(6.6329e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.004609
Average KL loss: 0.042846
Average total loss: 0.047455
tensor(0.0111, device='cuda:0') tensor(0.0551, device='cuda:0') tensor(1.0255e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.004364
Average KL loss: 0.042610
Average total loss: 0.046974
tensor(0.0111, device='cuda:0') tensor(0.0547, device='cuda:0') tensor(6.1067e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.005095
Average KL loss: 0.042505
Average total loss: 0.047600
tensor(0.0111, device='cuda:0') tensor(0.0545, device='cuda:0') tensor(2.8798e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.004454
Average KL loss: 0.042421
Average total loss: 0.046875
tensor(0.0111, device='cuda:0') tensor(0.0541, device='cuda:0') tensor(-2.6766e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.004635
Average KL loss: 0.041919
Average total loss: 0.046554
tensor(0.0110, device='cuda:0') tensor(0.0535, device='cuda:0') tensor(8.9527e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.003894
Average KL loss: 0.041468
Average total loss: 0.045362
tensor(0.0110, device='cuda:0') tensor(0.0529, device='cuda:0') tensor(7.7512e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.004742
Average KL loss: 0.041093
Average total loss: 0.045835
tensor(0.0110, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(-7.8785e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.004313
Average KL loss: 0.041083
Average total loss: 0.045396
tensor(0.0109, device='cuda:0') tensor(0.0522, device='cuda:0') tensor(-6.7673e-11, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.004216
Average KL loss: 0.040405
Average total loss: 0.044621
tensor(0.0109, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(2.6217e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.004558
Average KL loss: 0.040265
Average total loss: 0.044822
tensor(0.0108, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(-9.0320e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.004501
Average KL loss: 0.040079
Average total loss: 0.044580
tensor(0.0108, device='cuda:0') tensor(0.0513, device='cuda:0') tensor(-2.5817e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.004877
Average KL loss: 0.039878
Average total loss: 0.044755
tensor(0.0108, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(1.1232e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.005026
Average KL loss: 0.039897
Average total loss: 0.044924
tensor(0.0108, device='cuda:0') tensor(0.0509, device='cuda:0') tensor(-8.5659e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.004867
Average KL loss: 0.039880
Average total loss: 0.044747
tensor(0.0108, device='cuda:0') tensor(0.0507, device='cuda:0') tensor(5.0738e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.004025
Average KL loss: 0.039595
Average total loss: 0.043620
tensor(0.0108, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-2.1777e-12, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.004240
Average KL loss: 0.039011
Average total loss: 0.043251
tensor(0.0107, device='cuda:0') tensor(0.0496, device='cuda:0') tensor(7.0551e-12, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.004421
Average KL loss: 0.038620
Average total loss: 0.043041
tensor(0.0107, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(3.8746e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.005629
Average KL loss: 0.039013
Average total loss: 0.044642
tensor(0.0107, device='cuda:0') tensor(0.0497, device='cuda:0') tensor(-2.6522e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.004948
Average KL loss: 0.039263
Average total loss: 0.044211
tensor(0.0107, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-8.8097e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.004786
Average KL loss: 0.039133
Average total loss: 0.043919
tensor(0.0107, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(-2.1113e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.005460
Average KL loss: 0.039021
Average total loss: 0.044482
tensor(0.0106, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(3.6784e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.004606
Average KL loss: 0.039080
Average total loss: 0.043686
tensor(0.0106, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(6.4880e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.004657
Average KL loss: 0.038647
Average total loss: 0.043304
tensor(0.0106, device='cuda:0') tensor(0.0486, device='cuda:0') tensor(1.8934e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.005109
Average KL loss: 0.038543
Average total loss: 0.043653
tensor(0.0106, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-8.6461e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.004973
Average KL loss: 0.038295
Average total loss: 0.043268
tensor(0.0105, device='cuda:0') tensor(0.0482, device='cuda:0') tensor(-7.7243e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.004800
Average KL loss: 0.038116
Average total loss: 0.042916
tensor(0.0105, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-3.3460e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.004783
Average KL loss: 0.038028
Average total loss: 0.042811
tensor(0.0105, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(2.7025e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.004169
Average KL loss: 0.037587
Average total loss: 0.041756
tensor(0.0104, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-4.3200e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.003829
Average KL loss: 0.037036
Average total loss: 0.040865
tensor(0.0104, device='cuda:0') tensor(0.0466, device='cuda:0') tensor(6.6876e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.004408
Average KL loss: 0.036453
Average total loss: 0.040861
tensor(0.0104, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-6.8077e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.004687
Average KL loss: 0.036589
Average total loss: 0.041276
tensor(0.0104, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-5.3483e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.004874
Average KL loss: 0.036453
Average total loss: 0.041327
tensor(0.0103, device='cuda:0') tensor(0.0461, device='cuda:0') tensor(-1.5486e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.005331
Average KL loss: 0.036674
Average total loss: 0.042006
tensor(0.0104, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-1.1666e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.005004
Average KL loss: 0.036931
Average total loss: 0.041935
tensor(0.0104, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(4.5838e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.004507
Average KL loss: 0.036756
Average total loss: 0.041264
tensor(0.0103, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(-3.4294e-11, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.003919
Average KL loss: 0.036147
Average total loss: 0.040066
tensor(0.0103, device='cuda:0') tensor(0.0454, device='cuda:0') tensor(-2.8177e-11, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.005030
Average KL loss: 0.035804
Average total loss: 0.040834
tensor(0.0103, device='cuda:0') tensor(0.0454, device='cuda:0') tensor(-3.2643e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.004026
Average KL loss: 0.035947
Average total loss: 0.039973
tensor(0.0102, device='cuda:0') tensor(0.0450, device='cuda:0') tensor(-3.8578e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.004672
Average KL loss: 0.035523
Average total loss: 0.040195
tensor(0.0103, device='cuda:0') tensor(0.0449, device='cuda:0') tensor(-6.4134e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.004866
Average KL loss: 0.035705
Average total loss: 0.040571
tensor(0.0103, device='cuda:0') tensor(0.0449, device='cuda:0') tensor(-2.3606e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.004593
Average KL loss: 0.035434
Average total loss: 0.040027
tensor(0.0102, device='cuda:0') tensor(0.0445, device='cuda:0') tensor(-4.0822e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.004776
Average KL loss: 0.035385
Average total loss: 0.040161
tensor(0.0102, device='cuda:0') tensor(0.0445, device='cuda:0') tensor(1.1799e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.004224
Average KL loss: 0.035125
Average total loss: 0.039349
tensor(0.0102, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(1.0497e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.004911
Average KL loss: 0.034856
Average total loss: 0.039767
tensor(0.0102, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(1.2387e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.004944
Average KL loss: 0.035136
Average total loss: 0.040079
tensor(0.0102, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-2.0191e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.004568
Average KL loss: 0.034999
Average total loss: 0.039566
tensor(0.0102, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-8.6522e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.004397
Average KL loss: 0.034756
Average total loss: 0.039153
tensor(0.0102, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(-1.2045e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.004813
Average KL loss: 0.034649
Average total loss: 0.039462
tensor(0.0102, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(6.5496e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.005664
Average KL loss: 0.034624
Average total loss: 0.040288
tensor(0.0102, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(6.0220e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.004179
Average KL loss: 0.034865
Average total loss: 0.039044
tensor(0.0102, device='cuda:0') tensor(0.0434, device='cuda:0') tensor(4.6699e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.004259
Average KL loss: 0.034280
Average total loss: 0.038540
tensor(0.0101, device='cuda:0') tensor(0.0431, device='cuda:0') tensor(-9.8059e-11, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.004929
Average KL loss: 0.034252
Average total loss: 0.039181
tensor(0.0101, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(7.7488e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.004853
Average KL loss: 0.034410
Average total loss: 0.039263
tensor(0.0101, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(-1.7894e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.004103
Average KL loss: 0.033975
Average total loss: 0.038078
tensor(0.0100, device='cuda:0') tensor(0.0426, device='cuda:0') tensor(6.0173e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.004445
Average KL loss: 0.033469
Average total loss: 0.037914
tensor(0.0100, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-5.3472e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.004620
Average KL loss: 0.033322
Average total loss: 0.037942
tensor(0.0100, device='cuda:0') tensor(0.0423, device='cuda:0') tensor(-6.6298e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.004356
Average KL loss: 0.033325
Average total loss: 0.037682
tensor(0.0100, device='cuda:0') tensor(0.0421, device='cuda:0') tensor(-3.2636e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.004850
Average KL loss: 0.033439
Average total loss: 0.038289
tensor(0.0100, device='cuda:0') tensor(0.0423, device='cuda:0') tensor(-9.7209e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.004675
Average KL loss: 0.033489
Average total loss: 0.038164
tensor(0.0100, device='cuda:0') tensor(0.0423, device='cuda:0') tensor(4.0907e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.004828
Average KL loss: 0.033382
Average total loss: 0.038210
tensor(0.0100, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-1.5076e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.004985
Average KL loss: 0.033762
Average total loss: 0.038747
tensor(0.0099, device='cuda:0') tensor(0.0423, device='cuda:0') tensor(2.4743e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.004587
Average KL loss: 0.033737
Average total loss: 0.038324
tensor(0.0099, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-5.7480e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.004576
Average KL loss: 0.033331
Average total loss: 0.037907
tensor(0.0099, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-3.4404e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.004198
Average KL loss: 0.033020
Average total loss: 0.037218
tensor(0.0099, device='cuda:0') tensor(0.0417, device='cuda:0') tensor(5.4492e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.004611
Average KL loss: 0.033014
Average total loss: 0.037624
tensor(0.0099, device='cuda:0') tensor(0.0417, device='cuda:0') tensor(2.8515e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.004881
Average KL loss: 0.033079
Average total loss: 0.037960
tensor(0.0099, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(-6.5870e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.004595
Average KL loss: 0.033138
Average total loss: 0.037732
tensor(0.0099, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(3.1805e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.004481
Average KL loss: 0.032924
Average total loss: 0.037405
tensor(0.0099, device='cuda:0') tensor(0.0414, device='cuda:0') tensor(-8.0229e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.004586
Average KL loss: 0.032739
Average total loss: 0.037324
tensor(0.0099, device='cuda:0') tensor(0.0413, device='cuda:0') tensor(-3.7490e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.004188
Average KL loss: 0.032705
Average total loss: 0.036893
tensor(0.0098, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(2.4744e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.004530
Average KL loss: 0.032560
Average total loss: 0.037090
tensor(0.0098, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(3.1368e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.004660
Average KL loss: 0.032560
Average total loss: 0.037220
tensor(0.0099, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(4.7046e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.003692
Average KL loss: 0.032257
Average total loss: 0.035949
tensor(0.0098, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(-2.1222e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.004367
Average KL loss: 0.031784
Average total loss: 0.036151
tensor(0.0098, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(4.4515e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.004245
Average KL loss: 0.031790
Average total loss: 0.036035
tensor(0.0098, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-5.8458e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.004870
Average KL loss: 0.031801
Average total loss: 0.036671
tensor(0.0098, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(1.8213e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.004236
Average KL loss: 0.031836
Average total loss: 0.036072
tensor(0.0098, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-2.6406e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.005443
Average KL loss: 0.031823
Average total loss: 0.037266
tensor(0.0098, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(3.7954e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.004048
Average KL loss: 0.032218
Average total loss: 0.036266
tensor(0.0098, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(5.7590e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.004441
Average KL loss: 0.031688
Average total loss: 0.036129
tensor(0.0098, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-1.7230e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.004682
Average KL loss: 0.031895
Average total loss: 0.036577
tensor(0.0098, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(1.0515e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.004842
Average KL loss: 0.031987
Average total loss: 0.036830
 Percentile value: 0.1197976931929588
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1216 /    1728             ( 70.37%) | total_pruned =     512 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   17968 /   36864             ( 48.74%) | total_pruned =   18896 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   18851 /   36864             ( 51.14%) | total_pruned =   18013 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   17965 /   36864             ( 48.73%) | total_pruned =   18899 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18427 /   36864             ( 49.99%) | total_pruned =   18437 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   35714 /   73728             ( 48.44%) | total_pruned =   38014 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   69545 /  147456             ( 47.16%) | total_pruned =   77911 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5043 /    8192             ( 61.56%) | total_pruned =    3149 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   64190 /  147456             ( 43.53%) | total_pruned =   83266 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   64826 /  147456             ( 43.96%) | total_pruned =   82630 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  136011 /  294912             ( 46.12%) | total_pruned =  158901 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  262681 /  589824             ( 44.54%) | total_pruned =  327143 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18504 /   32768             ( 56.47%) | total_pruned =   14264 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  221197 /  589824             ( 37.50%) | total_pruned =  368627 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  220766 /  589824             ( 37.43%) | total_pruned =  369058 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     224 /     256             ( 87.50%) | total_pruned =      32 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  496645 / 1179648             ( 42.10%) | total_pruned =  683003 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     486 /     512             ( 94.92%) | total_pruned =      26 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  796380 / 2359296             ( 33.75%) | total_pruned = 1562916 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     385 /     512             ( 75.20%) | total_pruned =     127 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   60069 /  131072             ( 45.83%) | total_pruned =   71003 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     477 /     512             ( 93.16%) | total_pruned =      35 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  515992 / 2359296             ( 21.87%) | total_pruned = 1843304 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     370 /     512             ( 72.27%) | total_pruned =     142 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  299329 / 2359296             ( 12.69%) | total_pruned = 2059967 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
linear.weight        | nonzeros =    4261 /    5120             ( 83.22%) | total_pruned =     859 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 32/200 Loss: 0.000709 Accuracy: 86.38 100.00 % Best test Accuracy: 86.54%
tensor(0.0098, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.0375e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.082568
Average KL loss: 0.088564
Average total loss: 0.171132
tensor(0.0260, device='cuda:0') tensor(0.1211, device='cuda:0') tensor(-5.6060e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.050754
Average KL loss: 0.156318
Average total loss: 0.207071
tensor(0.0268, device='cuda:0') tensor(0.1544, device='cuda:0') tensor(-7.9275e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.039076
Average KL loss: 0.177145
Average total loss: 0.216221
tensor(0.0274, device='cuda:0') tensor(0.1739, device='cuda:0') tensor(-3.7982e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.029392
Average KL loss: 0.185044
Average total loss: 0.214436
tensor(0.0274, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-5.1292e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.026407
Average KL loss: 0.188673
Average total loss: 0.215079
tensor(0.0275, device='cuda:0') tensor(0.1886, device='cuda:0') tensor(-3.3424e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.022424
Average KL loss: 0.190631
Average total loss: 0.213055
tensor(0.0274, device='cuda:0') tensor(0.1920, device='cuda:0') tensor(-1.3080e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.021183
Average KL loss: 0.190652
Average total loss: 0.211835
tensor(0.0273, device='cuda:0') tensor(0.1971, device='cuda:0') tensor(2.3166e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.018254
Average KL loss: 0.192405
Average total loss: 0.210659
tensor(0.0273, device='cuda:0') tensor(0.1983, device='cuda:0') tensor(-1.6483e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.018314
Average KL loss: 0.191534
Average total loss: 0.209849
tensor(0.0272, device='cuda:0') tensor(0.2018, device='cuda:0') tensor(-3.8189e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.017475
Average KL loss: 0.193524
Average total loss: 0.210998
tensor(0.0272, device='cuda:0') tensor(0.2057, device='cuda:0') tensor(-3.5345e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.015363
Average KL loss: 0.194027
Average total loss: 0.209389
tensor(0.0270, device='cuda:0') tensor(0.2064, device='cuda:0') tensor(2.3457e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.015499
Average KL loss: 0.192417
Average total loss: 0.207916
tensor(0.0269, device='cuda:0') tensor(0.2097, device='cuda:0') tensor(-2.1731e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.011981
Average KL loss: 0.191686
Average total loss: 0.203668
tensor(0.0268, device='cuda:0') tensor(0.2047, device='cuda:0') tensor(1.4384e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.010875
Average KL loss: 0.185416
Average total loss: 0.196291
tensor(0.0267, device='cuda:0') tensor(0.1990, device='cuda:0') tensor(8.6223e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.009197
Average KL loss: 0.179526
Average total loss: 0.188723
tensor(0.0266, device='cuda:0') tensor(0.1937, device='cuda:0') tensor(-1.3759e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.008683
Average KL loss: 0.174048
Average total loss: 0.182732
tensor(0.0265, device='cuda:0') tensor(0.1887, device='cuda:0') tensor(8.7225e-11, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.008916
Average KL loss: 0.168963
Average total loss: 0.177879
tensor(0.0264, device='cuda:0') tensor(0.1841, device='cuda:0') tensor(1.6361e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.008048
Average KL loss: 0.164205
Average total loss: 0.172252
tensor(0.0263, device='cuda:0') tensor(0.1796, device='cuda:0') tensor(-3.0373e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.007670
Average KL loss: 0.159684
Average total loss: 0.167354
tensor(0.0262, device='cuda:0') tensor(0.1753, device='cuda:0') tensor(1.4132e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.008402
Average KL loss: 0.155382
Average total loss: 0.163784
tensor(0.0260, device='cuda:0') tensor(0.1713, device='cuda:0') tensor(-3.3012e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.007344
Average KL loss: 0.151341
Average total loss: 0.158685
tensor(0.0259, device='cuda:0') tensor(0.1674, device='cuda:0') tensor(1.6030e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.006499
Average KL loss: 0.147393
Average total loss: 0.153892
tensor(0.0258, device='cuda:0') tensor(0.1635, device='cuda:0') tensor(-6.6093e-11, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.006882
Average KL loss: 0.143587
Average total loss: 0.150469
tensor(0.0256, device='cuda:0') tensor(0.1598, device='cuda:0') tensor(1.0810e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.006914
Average KL loss: 0.139947
Average total loss: 0.146860
tensor(0.0255, device='cuda:0') tensor(0.1563, device='cuda:0') tensor(8.4587e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.006409
Average KL loss: 0.136448
Average total loss: 0.142857
tensor(0.0253, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(1.3595e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.006814
Average KL loss: 0.133032
Average total loss: 0.139847
tensor(0.0252, device='cuda:0') tensor(0.1495, device='cuda:0') tensor(9.3203e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.006859
Average KL loss: 0.129890
Average total loss: 0.136748
tensor(0.0250, device='cuda:0') tensor(0.1464, device='cuda:0') tensor(1.2119e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.006381
Average KL loss: 0.126773
Average total loss: 0.133154
tensor(0.0249, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-1.1487e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.006062
Average KL loss: 0.123745
Average total loss: 0.129806
tensor(0.0247, device='cuda:0') tensor(0.1403, device='cuda:0') tensor(1.0003e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.006195
Average KL loss: 0.120822
Average total loss: 0.127018
tensor(0.0246, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(-1.8391e-14, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.007001
Average KL loss: 0.118058
Average total loss: 0.125060
tensor(0.0244, device='cuda:0') tensor(0.1347, device='cuda:0') tensor(1.3621e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.006651
Average KL loss: 0.115443
Average total loss: 0.122093
tensor(0.0243, device='cuda:0') tensor(0.1321, device='cuda:0') tensor(1.7542e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.006904
Average KL loss: 0.112968
Average total loss: 0.119872
tensor(0.0242, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(1.0963e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.006090
Average KL loss: 0.110516
Average total loss: 0.116606
tensor(0.0240, device='cuda:0') tensor(0.1270, device='cuda:0') tensor(5.8315e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.005824
Average KL loss: 0.108044
Average total loss: 0.113868
tensor(0.0239, device='cuda:0') tensor(0.1245, device='cuda:0') tensor(6.3958e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.005834
Average KL loss: 0.105636
Average total loss: 0.111470
tensor(0.0237, device='cuda:0') tensor(0.1221, device='cuda:0') tensor(4.9625e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.006195
Average KL loss: 0.103356
Average total loss: 0.109552
tensor(0.0236, device='cuda:0') tensor(0.1198, device='cuda:0') tensor(7.5977e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.006565
Average KL loss: 0.101268
Average total loss: 0.107832
tensor(0.0234, device='cuda:0') tensor(0.1177, device='cuda:0') tensor(1.1219e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.006373
Average KL loss: 0.099306
Average total loss: 0.105680
tensor(0.0233, device='cuda:0') tensor(0.1156, device='cuda:0') tensor(8.5841e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.005752
Average KL loss: 0.097261
Average total loss: 0.103013
tensor(0.0232, device='cuda:0') tensor(0.1135, device='cuda:0') tensor(-6.8222e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.006395
Average KL loss: 0.095264
Average total loss: 0.101659
tensor(0.0230, device='cuda:0') tensor(0.1115, device='cuda:0') tensor(-4.2938e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.006614
Average KL loss: 0.093403
Average total loss: 0.100017
tensor(0.0229, device='cuda:0') tensor(0.1096, device='cuda:0') tensor(7.1419e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.006792
Average KL loss: 0.091695
Average total loss: 0.098487
tensor(0.0228, device='cuda:0') tensor(0.1079, device='cuda:0') tensor(8.1364e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.006187
Average KL loss: 0.090026
Average total loss: 0.096212
tensor(0.0226, device='cuda:0') tensor(0.1061, device='cuda:0') tensor(7.3729e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.006688
Average KL loss: 0.088370
Average total loss: 0.095058
tensor(0.0225, device='cuda:0') tensor(0.1044, device='cuda:0') tensor(9.7464e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.006412
Average KL loss: 0.086848
Average total loss: 0.093260
tensor(0.0224, device='cuda:0') tensor(0.1028, device='cuda:0') tensor(8.6904e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.006261
Average KL loss: 0.085284
Average total loss: 0.091545
tensor(0.0223, device='cuda:0') tensor(0.1011, device='cuda:0') tensor(-3.5442e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.007288
Average KL loss: 0.083843
Average total loss: 0.091131
tensor(0.0222, device='cuda:0') tensor(0.0997, device='cuda:0') tensor(1.7511e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.005598
Average KL loss: 0.082458
Average total loss: 0.088057
tensor(0.0220, device='cuda:0') tensor(0.0981, device='cuda:0') tensor(9.9178e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.006566
Average KL loss: 0.080955
Average total loss: 0.087521
tensor(0.0219, device='cuda:0') tensor(0.0966, device='cuda:0') tensor(-1.4711e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.006210
Average KL loss: 0.079611
Average total loss: 0.085822
tensor(0.0218, device='cuda:0') tensor(0.0952, device='cuda:0') tensor(-1.5349e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.006550
Average KL loss: 0.078330
Average total loss: 0.084880
tensor(0.0217, device='cuda:0') tensor(0.0939, device='cuda:0') tensor(1.2399e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.006215
Average KL loss: 0.077103
Average total loss: 0.083318
tensor(0.0215, device='cuda:0') tensor(0.0926, device='cuda:0') tensor(3.2802e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.006113
Average KL loss: 0.075807
Average total loss: 0.081921
tensor(0.0214, device='cuda:0') tensor(0.0912, device='cuda:0') tensor(4.6228e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.006833
Average KL loss: 0.074642
Average total loss: 0.081475
tensor(0.0213, device='cuda:0') tensor(0.0901, device='cuda:0') tensor(7.6938e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.006614
Average KL loss: 0.073666
Average total loss: 0.080279
tensor(0.0212, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(1.1889e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.006755
Average KL loss: 0.072697
Average total loss: 0.079452
tensor(0.0211, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(1.0219e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.006506
Average KL loss: 0.071731
Average total loss: 0.078237
tensor(0.0210, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(3.6516e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.006462
Average KL loss: 0.070753
Average total loss: 0.077215
tensor(0.0209, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-4.8663e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.006580
Average KL loss: 0.069814
Average total loss: 0.076394
tensor(0.0208, device='cuda:0') tensor(0.0849, device='cuda:0') tensor(5.0401e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.005922
Average KL loss: 0.068829
Average total loss: 0.074750
tensor(0.0207, device='cuda:0') tensor(0.0838, device='cuda:0') tensor(2.0166e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.006629
Average KL loss: 0.067864
Average total loss: 0.074493
tensor(0.0206, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(1.3240e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.006921
Average KL loss: 0.066991
Average total loss: 0.073912
tensor(0.0205, device='cuda:0') tensor(0.0820, device='cuda:0') tensor(3.2840e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.006175
Average KL loss: 0.066210
Average total loss: 0.072385
tensor(0.0204, device='cuda:0') tensor(0.0810, device='cuda:0') tensor(-2.9660e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.006629
Average KL loss: 0.065344
Average total loss: 0.071973
tensor(0.0203, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(1.6083e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.006268
Average KL loss: 0.064586
Average total loss: 0.070854
tensor(0.0202, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(4.5328e-11, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.006017
Average KL loss: 0.063794
Average total loss: 0.069811
tensor(0.0201, device='cuda:0') tensor(0.0785, device='cuda:0') tensor(-1.7201e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.007288
Average KL loss: 0.063133
Average total loss: 0.070420
tensor(0.0201, device='cuda:0') tensor(0.0779, device='cuda:0') tensor(-2.1760e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.007362
Average KL loss: 0.062536
Average total loss: 0.069898
tensor(0.0200, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(6.1497e-11, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.006710
Average KL loss: 0.061983
Average total loss: 0.068693
tensor(0.0199, device='cuda:0') tensor(0.0765, device='cuda:0') tensor(-4.4335e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.007133
Average KL loss: 0.061336
Average total loss: 0.068468
tensor(0.0199, device='cuda:0') tensor(0.0759, device='cuda:0') tensor(-1.4547e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.006817
Average KL loss: 0.060758
Average total loss: 0.067575
tensor(0.0198, device='cuda:0') tensor(0.0754, device='cuda:0') tensor(1.5580e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.007034
Average KL loss: 0.060234
Average total loss: 0.067268
tensor(0.0197, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(-1.0634e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.007042
Average KL loss: 0.059725
Average total loss: 0.066766
tensor(0.0197, device='cuda:0') tensor(0.0742, device='cuda:0') tensor(1.5355e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.007091
Average KL loss: 0.059214
Average total loss: 0.066305
tensor(0.0196, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(1.2769e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.006085
Average KL loss: 0.058651
Average total loss: 0.064735
tensor(0.0195, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(-7.7361e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.006293
Average KL loss: 0.057948
Average total loss: 0.064241
tensor(0.0195, device='cuda:0') tensor(0.0723, device='cuda:0') tensor(-2.9501e-11, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.006788
Average KL loss: 0.057380
Average total loss: 0.064168
tensor(0.0194, device='cuda:0') tensor(0.0717, device='cuda:0') tensor(-4.2163e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.006523
Average KL loss: 0.056792
Average total loss: 0.063315
tensor(0.0193, device='cuda:0') tensor(0.0712, device='cuda:0') tensor(9.0663e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.006614
Average KL loss: 0.056345
Average total loss: 0.062959
tensor(0.0193, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(3.1879e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.006821
Average KL loss: 0.055932
Average total loss: 0.062753
tensor(0.0192, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(1.1185e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.006742
Average KL loss: 0.055451
Average total loss: 0.062193
tensor(0.0192, device='cuda:0') tensor(0.0697, device='cuda:0') tensor(8.6713e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.006731
Average KL loss: 0.055030
Average total loss: 0.061761
tensor(0.0191, device='cuda:0') tensor(0.0693, device='cuda:0') tensor(3.7802e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.006543
Average KL loss: 0.054660
Average total loss: 0.061203
tensor(0.0190, device='cuda:0') tensor(0.0689, device='cuda:0') tensor(8.5360e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.006480
Average KL loss: 0.054203
Average total loss: 0.060683
tensor(0.0190, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(1.0406e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.006908
Average KL loss: 0.053778
Average total loss: 0.060687
tensor(0.0189, device='cuda:0') tensor(0.0680, device='cuda:0') tensor(1.9328e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.006951
Average KL loss: 0.053476
Average total loss: 0.060427
tensor(0.0189, device='cuda:0') tensor(0.0677, device='cuda:0') tensor(1.5017e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.006722
Average KL loss: 0.053059
Average total loss: 0.059780
tensor(0.0188, device='cuda:0') tensor(0.0672, device='cuda:0') tensor(1.2053e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.007023
Average KL loss: 0.052674
Average total loss: 0.059697
tensor(0.0187, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-5.0144e-11, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.006979
Average KL loss: 0.052398
Average total loss: 0.059376
tensor(0.0187, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(2.4755e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.006743
Average KL loss: 0.052081
Average total loss: 0.058823
tensor(0.0186, device='cuda:0') tensor(0.0661, device='cuda:0') tensor(-2.7827e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.006728
Average KL loss: 0.051812
Average total loss: 0.058540
tensor(0.0186, device='cuda:0') tensor(0.0658, device='cuda:0') tensor(1.6891e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.006265
Average KL loss: 0.051392
Average total loss: 0.057657
tensor(0.0185, device='cuda:0') tensor(0.0654, device='cuda:0') tensor(-2.0224e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.007300
Average KL loss: 0.050919
Average total loss: 0.058219
tensor(0.0185, device='cuda:0') tensor(0.0650, device='cuda:0') tensor(3.6570e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.006694
Average KL loss: 0.050697
Average total loss: 0.057391
tensor(0.0185, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-8.7722e-11, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.006445
Average KL loss: 0.050370
Average total loss: 0.056815
tensor(0.0184, device='cuda:0') tensor(0.0643, device='cuda:0') tensor(-2.6664e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.006720
Average KL loss: 0.049985
Average total loss: 0.056705
tensor(0.0184, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(1.3384e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.006806
Average KL loss: 0.049669
Average total loss: 0.056475
tensor(0.0183, device='cuda:0') tensor(0.0637, device='cuda:0') tensor(-3.3848e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.007300
Average KL loss: 0.049501
Average total loss: 0.056802
tensor(0.0183, device='cuda:0') tensor(0.0635, device='cuda:0') tensor(1.8379e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.007020
Average KL loss: 0.049375
Average total loss: 0.056395
tensor(0.0183, device='cuda:0') tensor(0.0634, device='cuda:0') tensor(-2.9339e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.006921
Average KL loss: 0.049109
Average total loss: 0.056030
tensor(0.0182, device='cuda:0') tensor(0.0630, device='cuda:0') tensor(4.3106e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.007212
Average KL loss: 0.048832
Average total loss: 0.056043
tensor(0.0182, device='cuda:0') tensor(0.0628, device='cuda:0') tensor(-1.3414e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.006694
Average KL loss: 0.048656
Average total loss: 0.055350
tensor(0.0181, device='cuda:0') tensor(0.0626, device='cuda:0') tensor(-8.4861e-11, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.007563
Average KL loss: 0.048543
Average total loss: 0.056105
tensor(0.0181, device='cuda:0') tensor(0.0625, device='cuda:0') tensor(9.2206e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.006664
Average KL loss: 0.048342
Average total loss: 0.055006
tensor(0.0181, device='cuda:0') tensor(0.0622, device='cuda:0') tensor(1.0082e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.006608
Average KL loss: 0.047950
Average total loss: 0.054558
tensor(0.0181, device='cuda:0') tensor(0.0618, device='cuda:0') tensor(8.0878e-11, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.006358
Average KL loss: 0.047598
Average total loss: 0.053956
tensor(0.0181, device='cuda:0') tensor(0.0615, device='cuda:0') tensor(4.5994e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.006399
Average KL loss: 0.047235
Average total loss: 0.053634
tensor(0.0180, device='cuda:0') tensor(0.0611, device='cuda:0') tensor(-1.8453e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.006462
Average KL loss: 0.046967
Average total loss: 0.053429
tensor(0.0179, device='cuda:0') tensor(0.0608, device='cuda:0') tensor(3.7145e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.007282
Average KL loss: 0.046830
Average total loss: 0.054112
tensor(0.0179, device='cuda:0') tensor(0.0607, device='cuda:0') tensor(1.0449e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.006906
Average KL loss: 0.046591
Average total loss: 0.053497
tensor(0.0179, device='cuda:0') tensor(0.0604, device='cuda:0') tensor(1.0438e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.005977
Average KL loss: 0.046294
Average total loss: 0.052271
tensor(0.0178, device='cuda:0') tensor(0.0601, device='cuda:0') tensor(1.5372e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.006621
Average KL loss: 0.045987
Average total loss: 0.052608
tensor(0.0178, device='cuda:0') tensor(0.0599, device='cuda:0') tensor(4.2683e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.006337
Average KL loss: 0.045819
Average total loss: 0.052156
tensor(0.0178, device='cuda:0') tensor(0.0597, device='cuda:0') tensor(9.5971e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.006270
Average KL loss: 0.045582
Average total loss: 0.051852
tensor(0.0177, device='cuda:0') tensor(0.0594, device='cuda:0') tensor(-5.4412e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.007065
Average KL loss: 0.045320
Average total loss: 0.052385
tensor(0.0177, device='cuda:0') tensor(0.0593, device='cuda:0') tensor(-3.3217e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.007298
Average KL loss: 0.045308
Average total loss: 0.052606
tensor(0.0177, device='cuda:0') tensor(0.0593, device='cuda:0') tensor(1.3520e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.007561
Average KL loss: 0.045327
Average total loss: 0.052888
tensor(0.0177, device='cuda:0') tensor(0.0592, device='cuda:0') tensor(2.8435e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.006579
Average KL loss: 0.045259
Average total loss: 0.051838
tensor(0.0177, device='cuda:0') tensor(0.0590, device='cuda:0') tensor(5.5075e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.008266
Average KL loss: 0.045110
Average total loss: 0.053376
tensor(0.0177, device='cuda:0') tensor(0.0590, device='cuda:0') tensor(1.1237e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.007173
Average KL loss: 0.045182
Average total loss: 0.052355
tensor(0.0176, device='cuda:0') tensor(0.0590, device='cuda:0') tensor(-1.6273e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.007098
Average KL loss: 0.045121
Average total loss: 0.052219
tensor(0.0176, device='cuda:0') tensor(0.0589, device='cuda:0') tensor(-5.5334e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.006543
Average KL loss: 0.044958
Average total loss: 0.051501
tensor(0.0176, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-7.0602e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.006834
Average KL loss: 0.044712
Average total loss: 0.051546
tensor(0.0176, device='cuda:0') tensor(0.0584, device='cuda:0') tensor(6.5592e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.005985
Average KL loss: 0.044396
Average total loss: 0.050381
tensor(0.0175, device='cuda:0') tensor(0.0581, device='cuda:0') tensor(-5.2074e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.007131
Average KL loss: 0.044115
Average total loss: 0.051247
tensor(0.0175, device='cuda:0') tensor(0.0580, device='cuda:0') tensor(1.7626e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.006253
Average KL loss: 0.043951
Average total loss: 0.050203
tensor(0.0175, device='cuda:0') tensor(0.0577, device='cuda:0') tensor(-2.9304e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.006591
Average KL loss: 0.043736
Average total loss: 0.050327
tensor(0.0174, device='cuda:0') tensor(0.0576, device='cuda:0') tensor(-4.0836e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.006511
Average KL loss: 0.043647
Average total loss: 0.050158
tensor(0.0174, device='cuda:0') tensor(0.0575, device='cuda:0') tensor(-1.5702e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.006299
Average KL loss: 0.043392
Average total loss: 0.049692
tensor(0.0174, device='cuda:0') tensor(0.0572, device='cuda:0') tensor(6.0387e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.006241
Average KL loss: 0.043163
Average total loss: 0.049404
tensor(0.0174, device='cuda:0') tensor(0.0570, device='cuda:0') tensor(1.4377e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.006812
Average KL loss: 0.042986
Average total loss: 0.049798
tensor(0.0173, device='cuda:0') tensor(0.0569, device='cuda:0') tensor(2.2398e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.006303
Average KL loss: 0.042939
Average total loss: 0.049242
tensor(0.0173, device='cuda:0') tensor(0.0568, device='cuda:0') tensor(-1.3873e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.006976
Average KL loss: 0.042791
Average total loss: 0.049767
tensor(0.0173, device='cuda:0') tensor(0.0567, device='cuda:0') tensor(1.1727e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.007641
Average KL loss: 0.042758
Average total loss: 0.050399
tensor(0.0173, device='cuda:0') tensor(0.0568, device='cuda:0') tensor(1.3361e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.006973
Average KL loss: 0.042814
Average total loss: 0.049786
tensor(0.0173, device='cuda:0') tensor(0.0567, device='cuda:0') tensor(-7.3195e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.006641
Average KL loss: 0.042777
Average total loss: 0.049418
tensor(0.0172, device='cuda:0') tensor(0.0566, device='cuda:0') tensor(8.5415e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.007102
Average KL loss: 0.042720
Average total loss: 0.049822
tensor(0.0172, device='cuda:0') tensor(0.0566, device='cuda:0') tensor(-4.8067e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.007261
Average KL loss: 0.042686
Average total loss: 0.049948
tensor(0.0172, device='cuda:0') tensor(0.0565, device='cuda:0') tensor(1.2118e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.007313
Average KL loss: 0.042656
Average total loss: 0.049969
tensor(0.0172, device='cuda:0') tensor(0.0566, device='cuda:0') tensor(-4.5388e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.006894
Average KL loss: 0.042687
Average total loss: 0.049581
tensor(0.0172, device='cuda:0') tensor(0.0565, device='cuda:0') tensor(4.4865e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.006931
Average KL loss: 0.042500
Average total loss: 0.049432
tensor(0.0172, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-7.6145e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.006926
Average KL loss: 0.042412
Average total loss: 0.049338
tensor(0.0172, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(2.4252e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.007123
Average KL loss: 0.042360
Average total loss: 0.049484
tensor(0.0172, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(2.9235e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.006447
Average KL loss: 0.042286
Average total loss: 0.048733
tensor(0.0172, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(9.2674e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.005503
Average KL loss: 0.042120
Average total loss: 0.047624
tensor(0.0172, device='cuda:0') tensor(0.0560, device='cuda:0') tensor(-1.2866e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.005944
Average KL loss: 0.041953
Average total loss: 0.047896
tensor(0.0171, device='cuda:0') tensor(0.0558, device='cuda:0') tensor(-1.6221e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.006294
Average KL loss: 0.041792
Average total loss: 0.048086
tensor(0.0171, device='cuda:0') tensor(0.0557, device='cuda:0') tensor(-8.6430e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.005718
Average KL loss: 0.041635
Average total loss: 0.047353
tensor(0.0171, device='cuda:0') tensor(0.0556, device='cuda:0') tensor(2.1978e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.005663
Average KL loss: 0.041481
Average total loss: 0.047144
tensor(0.0171, device='cuda:0') tensor(0.0555, device='cuda:0') tensor(-7.1655e-11, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.005986
Average KL loss: 0.041328
Average total loss: 0.047315
tensor(0.0171, device='cuda:0') tensor(0.0554, device='cuda:0') tensor(-8.0545e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.005991
Average KL loss: 0.041183
Average total loss: 0.047174
tensor(0.0171, device='cuda:0') tensor(0.0552, device='cuda:0') tensor(-1.2139e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.006033
Average KL loss: 0.041040
Average total loss: 0.047073
tensor(0.0171, device='cuda:0') tensor(0.0551, device='cuda:0') tensor(-1.3354e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.006338
Average KL loss: 0.040902
Average total loss: 0.047240
tensor(0.0171, device='cuda:0') tensor(0.0550, device='cuda:0') tensor(-2.7977e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.006874
Average KL loss: 0.040769
Average total loss: 0.047643
tensor(0.0171, device='cuda:0') tensor(0.0549, device='cuda:0') tensor(1.5127e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.005796
Average KL loss: 0.040637
Average total loss: 0.046434
tensor(0.0171, device='cuda:0') tensor(0.0548, device='cuda:0') tensor(1.2513e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.005989
Average KL loss: 0.040505
Average total loss: 0.046494
tensor(0.0171, device='cuda:0') tensor(0.0547, device='cuda:0') tensor(1.7009e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.005639
Average KL loss: 0.040375
Average total loss: 0.046014
tensor(0.0171, device='cuda:0') tensor(0.0546, device='cuda:0') tensor(1.4933e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.006018
Average KL loss: 0.040245
Average total loss: 0.046263
tensor(0.0171, device='cuda:0') tensor(0.0545, device='cuda:0') tensor(6.9644e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.006824
Average KL loss: 0.040120
Average total loss: 0.046944
tensor(0.0171, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-6.2881e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.005775
Average KL loss: 0.040001
Average total loss: 0.045776
tensor(0.0171, device='cuda:0') tensor(0.0543, device='cuda:0') tensor(3.3819e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.006783
Average KL loss: 0.039880
Average total loss: 0.046663
tensor(0.0171, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(1.5189e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.006098
Average KL loss: 0.039765
Average total loss: 0.045864
tensor(0.0171, device='cuda:0') tensor(0.0541, device='cuda:0') tensor(7.9817e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.007181
Average KL loss: 0.039651
Average total loss: 0.046832
tensor(0.0171, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(1.4503e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.006010
Average KL loss: 0.039541
Average total loss: 0.045551
tensor(0.0171, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(1.3987e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.005890
Average KL loss: 0.039428
Average total loss: 0.045317
tensor(0.0171, device='cuda:0') tensor(0.0539, device='cuda:0') tensor(2.0828e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.005219
Average KL loss: 0.039314
Average total loss: 0.044533
tensor(0.0171, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(1.3032e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.006081
Average KL loss: 0.039201
Average total loss: 0.045282
tensor(0.0171, device='cuda:0') tensor(0.0537, device='cuda:0') tensor(6.7607e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.005478
Average KL loss: 0.039093
Average total loss: 0.044570
tensor(0.0171, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(2.0473e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.005268
Average KL loss: 0.038981
Average total loss: 0.044249
tensor(0.0170, device='cuda:0') tensor(0.0535, device='cuda:0') tensor(1.3563e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.005186
Average KL loss: 0.038871
Average total loss: 0.044057
tensor(0.0170, device='cuda:0') tensor(0.0534, device='cuda:0') tensor(3.7584e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.005004
Average KL loss: 0.038762
Average total loss: 0.043766
tensor(0.0170, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(1.4028e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.006289
Average KL loss: 0.038654
Average total loss: 0.044943
tensor(0.0170, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(8.9211e-11, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.005915
Average KL loss: 0.038552
Average total loss: 0.044467
tensor(0.0170, device='cuda:0') tensor(0.0532, device='cuda:0') tensor(1.8412e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.005767
Average KL loss: 0.038450
Average total loss: 0.044217
tensor(0.0170, device='cuda:0') tensor(0.0531, device='cuda:0') tensor(8.1514e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.005708
Average KL loss: 0.038348
Average total loss: 0.044056
tensor(0.0170, device='cuda:0') tensor(0.0530, device='cuda:0') tensor(-4.0497e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.006014
Average KL loss: 0.038249
Average total loss: 0.044263
tensor(0.0170, device='cuda:0') tensor(0.0529, device='cuda:0') tensor(1.1382e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.006000
Average KL loss: 0.038153
Average total loss: 0.044154
tensor(0.0170, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(1.4302e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.006414
Average KL loss: 0.038057
Average total loss: 0.044471
tensor(0.0170, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(5.7093e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.005407
Average KL loss: 0.037963
Average total loss: 0.043370
tensor(0.0170, device='cuda:0') tensor(0.0527, device='cuda:0') tensor(-9.2660e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.005974
Average KL loss: 0.037869
Average total loss: 0.043843
tensor(0.0170, device='cuda:0') tensor(0.0526, device='cuda:0') tensor(-6.5891e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.006265
Average KL loss: 0.037778
Average total loss: 0.044044
tensor(0.0170, device='cuda:0') tensor(0.0526, device='cuda:0') tensor(-7.8721e-11, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.006557
Average KL loss: 0.037690
Average total loss: 0.044247
tensor(0.0170, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(-1.0983e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.005354
Average KL loss: 0.037602
Average total loss: 0.042956
tensor(0.0170, device='cuda:0') tensor(0.0524, device='cuda:0') tensor(6.2471e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.006017
Average KL loss: 0.037510
Average total loss: 0.043526
tensor(0.0170, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(6.0360e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.006055
Average KL loss: 0.037418
Average total loss: 0.043473
tensor(0.0170, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(9.8998e-11, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.006010
Average KL loss: 0.037334
Average total loss: 0.043344
tensor(0.0170, device='cuda:0') tensor(0.0522, device='cuda:0') tensor(8.0625e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.005970
Average KL loss: 0.037250
Average total loss: 0.043220
tensor(0.0170, device='cuda:0') tensor(0.0521, device='cuda:0') tensor(-5.4800e-11, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.005612
Average KL loss: 0.037165
Average total loss: 0.042777
tensor(0.0169, device='cuda:0') tensor(0.0521, device='cuda:0') tensor(-2.6767e-11, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.005324
Average KL loss: 0.037077
Average total loss: 0.042401
tensor(0.0169, device='cuda:0') tensor(0.0520, device='cuda:0') tensor(-5.1785e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.005727
Average KL loss: 0.036992
Average total loss: 0.042719
tensor(0.0169, device='cuda:0') tensor(0.0519, device='cuda:0') tensor(1.2669e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.004862
Average KL loss: 0.036905
Average total loss: 0.041767
tensor(0.0169, device='cuda:0') tensor(0.0518, device='cuda:0') tensor(1.1221e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.005048
Average KL loss: 0.036813
Average total loss: 0.041861
tensor(0.0169, device='cuda:0') tensor(0.0518, device='cuda:0') tensor(3.0812e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.005953
Average KL loss: 0.036728
Average total loss: 0.042681
tensor(0.0169, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(9.4778e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.006224
Average KL loss: 0.036647
Average total loss: 0.042871
tensor(0.0169, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-1.1699e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.005345
Average KL loss: 0.036567
Average total loss: 0.041912
tensor(0.0169, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-2.2635e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.005451
Average KL loss: 0.036485
Average total loss: 0.041937
tensor(0.0169, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(6.6503e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.005679
Average KL loss: 0.036404
Average total loss: 0.042084
tensor(0.0169, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(8.5220e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.005130
Average KL loss: 0.036324
Average total loss: 0.041453
tensor(0.0169, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(1.0351e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.006031
Average KL loss: 0.036244
Average total loss: 0.042275
 Percentile value: 0.2815840184688568
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =    1089 /    1728             ( 63.02%) | total_pruned =     639 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    8965 /   36864             ( 24.32%) | total_pruned =   27899 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    9784 /   36864             ( 26.54%) | total_pruned =   27080 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    8992 /   36864             ( 24.39%) | total_pruned =   27872 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9316 /   36864             ( 25.27%) | total_pruned =   27548 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   17421 /   73728             ( 23.63%) | total_pruned =   56307 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   32528 /  147456             ( 22.06%) | total_pruned =  114928 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3646 /    8192             ( 44.51%) | total_pruned =    4546 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   26281 /  147456             ( 17.82%) | total_pruned =  121175 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   26969 /  147456             ( 18.29%) | total_pruned =  120487 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   61656 /  294912             ( 20.91%) | total_pruned =  233256 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  110338 /  589824             ( 18.71%) | total_pruned =  479486 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     200 /     256             ( 78.12%) | total_pruned =      56 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   11644 /   32768             ( 35.53%) | total_pruned =   21124 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   71255 /  589824             ( 12.08%) | total_pruned =  518569 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   69916 /  589824             ( 11.85%) | total_pruned =  519908 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  186257 / 1179648             ( 15.79%) | total_pruned =  993391 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     474 /     512             ( 92.58%) | total_pruned =      38 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  199293 / 2359296             (  8.45%) | total_pruned = 2160003 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     316 /     512             ( 61.72%) | total_pruned =     196 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   25444 /  131072             ( 19.41%) | total_pruned =  105628 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     306 /     512             ( 59.77%) | total_pruned =     206 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   84374 / 2359296             (  3.58%) | total_pruned = 2274922 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     354 /     512             ( 69.14%) | total_pruned =     158 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     225 /     512             ( 43.95%) | total_pruned =     287 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   29688 / 2359296             (  1.26%) | total_pruned = 2329608 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
linear.weight        | nonzeros =    3680 /    5120             ( 71.88%) | total_pruned =    1440 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 26/200 Loss: 0.000461 Accuracy: 86.74 100.00 % Best test Accuracy: 86.82%
tensor(0.0169, device='cuda:0') tensor(0.0513, device='cuda:0') tensor(-1.7046e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.093543
Average KL loss: 0.050581
Average total loss: 0.144124
tensor(0.0262, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(-1.5622e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.073342
Average KL loss: 0.082933
Average total loss: 0.156275
tensor(0.0278, device='cuda:0') tensor(0.1000, device='cuda:0') tensor(-8.6324e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.056712
Average KL loss: 0.100982
Average total loss: 0.157694
tensor(0.0290, device='cuda:0') tensor(0.1184, device='cuda:0') tensor(-3.5492e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.050334
Average KL loss: 0.112976
Average total loss: 0.163310
tensor(0.0300, device='cuda:0') tensor(0.1339, device='cuda:0') tensor(-5.3991e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.040611
Average KL loss: 0.122010
Average total loss: 0.162621
tensor(0.0307, device='cuda:0') tensor(0.1454, device='cuda:0') tensor(-5.9471e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.035828
Average KL loss: 0.127678
Average total loss: 0.163506
tensor(0.0313, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(-5.9100e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.029164
Average KL loss: 0.131709
Average total loss: 0.160873
tensor(0.0318, device='cuda:0') tensor(0.1610, device='cuda:0') tensor(-6.2957e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.028533
Average KL loss: 0.134572
Average total loss: 0.163105
tensor(0.0322, device='cuda:0') tensor(0.1672, device='cuda:0') tensor(-3.2542e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.024769
Average KL loss: 0.137321
Average total loss: 0.162090
tensor(0.0325, device='cuda:0') tensor(0.1731, device='cuda:0') tensor(-1.7030e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.023260
Average KL loss: 0.139464
Average total loss: 0.162724
tensor(0.0327, device='cuda:0') tensor(0.1779, device='cuda:0') tensor(-5.1497e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.022189
Average KL loss: 0.141370
Average total loss: 0.163559
tensor(0.0329, device='cuda:0') tensor(0.1828, device='cuda:0') tensor(-1.1926e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.020676
Average KL loss: 0.143353
Average total loss: 0.164028
tensor(0.0331, device='cuda:0') tensor(0.1871, device='cuda:0') tensor(-4.3264e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.017799
Average KL loss: 0.143365
Average total loss: 0.161164
tensor(0.0331, device='cuda:0') tensor(0.1859, device='cuda:0') tensor(1.0419e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.015566
Average KL loss: 0.142057
Average total loss: 0.157623
tensor(0.0331, device='cuda:0') tensor(0.1844, device='cuda:0') tensor(-2.2717e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.014252
Average KL loss: 0.140704
Average total loss: 0.154955
tensor(0.0330, device='cuda:0') tensor(0.1828, device='cuda:0') tensor(7.1707e-11, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.015527
Average KL loss: 0.139362
Average total loss: 0.154889
tensor(0.0330, device='cuda:0') tensor(0.1813, device='cuda:0') tensor(-2.3405e-11, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.013382
Average KL loss: 0.138043
Average total loss: 0.151425
tensor(0.0330, device='cuda:0') tensor(0.1798, device='cuda:0') tensor(-1.8604e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.014084
Average KL loss: 0.136712
Average total loss: 0.150796
tensor(0.0329, device='cuda:0') tensor(0.1782, device='cuda:0') tensor(-4.4452e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.013129
Average KL loss: 0.135386
Average total loss: 0.148516
tensor(0.0329, device='cuda:0') tensor(0.1767, device='cuda:0') tensor(-1.5854e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.012574
Average KL loss: 0.134054
Average total loss: 0.146628
tensor(0.0329, device='cuda:0') tensor(0.1751, device='cuda:0') tensor(9.2638e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.012706
Average KL loss: 0.132736
Average total loss: 0.145442
tensor(0.0328, device='cuda:0') tensor(0.1736, device='cuda:0') tensor(-1.5162e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.012447
Average KL loss: 0.131420
Average total loss: 0.143867
tensor(0.0328, device='cuda:0') tensor(0.1720, device='cuda:0') tensor(-4.3542e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.013158
Average KL loss: 0.130115
Average total loss: 0.143273
tensor(0.0327, device='cuda:0') tensor(0.1705, device='cuda:0') tensor(-1.9661e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.013046
Average KL loss: 0.128849
Average total loss: 0.141895
tensor(0.0327, device='cuda:0') tensor(0.1690, device='cuda:0') tensor(3.5305e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.011480
Average KL loss: 0.127559
Average total loss: 0.139040
tensor(0.0326, device='cuda:0') tensor(0.1675, device='cuda:0') tensor(-1.3099e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.012801
Average KL loss: 0.126277
Average total loss: 0.139078
tensor(0.0326, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(-1.7135e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.011900
Average KL loss: 0.125018
Average total loss: 0.136918
tensor(0.0325, device='cuda:0') tensor(0.1645, device='cuda:0') tensor(-7.1962e-12, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.011367
Average KL loss: 0.123752
Average total loss: 0.135119
tensor(0.0325, device='cuda:0') tensor(0.1630, device='cuda:0') tensor(-1.1426e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.010662
Average KL loss: 0.122493
Average total loss: 0.133154
tensor(0.0324, device='cuda:0') tensor(0.1615, device='cuda:0') tensor(-1.2851e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.011574
Average KL loss: 0.121228
Average total loss: 0.132802
tensor(0.0323, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(-1.5075e-11, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.011548
Average KL loss: 0.120004
Average total loss: 0.131552
tensor(0.0323, device='cuda:0') tensor(0.1585, device='cuda:0') tensor(-2.2821e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.011259
Average KL loss: 0.118795
Average total loss: 0.130053
tensor(0.0322, device='cuda:0') tensor(0.1571, device='cuda:0') tensor(-9.8880e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.010709
Average KL loss: 0.117579
Average total loss: 0.128288
tensor(0.0322, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(2.7074e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.010952
Average KL loss: 0.116373
Average total loss: 0.127325
tensor(0.0321, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(3.7792e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.010093
Average KL loss: 0.115161
Average total loss: 0.125255
tensor(0.0320, device='cuda:0') tensor(0.1527, device='cuda:0') tensor(-3.6795e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.010715
Average KL loss: 0.113975
Average total loss: 0.124690
tensor(0.0319, device='cuda:0') tensor(0.1513, device='cuda:0') tensor(5.1889e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.009142
Average KL loss: 0.112791
Average total loss: 0.121933
tensor(0.0319, device='cuda:0') tensor(0.1499, device='cuda:0') tensor(2.6561e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.009613
Average KL loss: 0.111597
Average total loss: 0.121210
tensor(0.0318, device='cuda:0') tensor(0.1485, device='cuda:0') tensor(-2.1509e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.010415
Average KL loss: 0.110434
Average total loss: 0.120849
tensor(0.0317, device='cuda:0') tensor(0.1471, device='cuda:0') tensor(-1.4946e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.010068
Average KL loss: 0.109309
Average total loss: 0.119377
tensor(0.0316, device='cuda:0') tensor(0.1458, device='cuda:0') tensor(5.0738e-11, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.010373
Average KL loss: 0.108198
Average total loss: 0.118571
tensor(0.0315, device='cuda:0') tensor(0.1445, device='cuda:0') tensor(-1.6053e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.009480
Average KL loss: 0.107092
Average total loss: 0.116571
tensor(0.0315, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-1.7051e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.010470
Average KL loss: 0.105990
Average total loss: 0.116460
tensor(0.0314, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(9.0240e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.010036
Average KL loss: 0.104928
Average total loss: 0.114964
tensor(0.0313, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(-1.2139e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.009820
Average KL loss: 0.103849
Average total loss: 0.113670
tensor(0.0312, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(2.6025e-12, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.009847
Average KL loss: 0.102819
Average total loss: 0.112666
tensor(0.0311, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(-1.3739e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.009748
Average KL loss: 0.101782
Average total loss: 0.111530
tensor(0.0311, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-2.7112e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.010596
Average KL loss: 0.100758
Average total loss: 0.111354
tensor(0.0310, device='cuda:0') tensor(0.1356, device='cuda:0') tensor(9.1735e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.008817
Average KL loss: 0.099796
Average total loss: 0.108613
tensor(0.0309, device='cuda:0') tensor(0.1344, device='cuda:0') tensor(1.1354e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.009524
Average KL loss: 0.098777
Average total loss: 0.108301
tensor(0.0308, device='cuda:0') tensor(0.1332, device='cuda:0') tensor(4.4779e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.010114
Average KL loss: 0.097798
Average total loss: 0.107911
tensor(0.0307, device='cuda:0') tensor(0.1321, device='cuda:0') tensor(5.1101e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.009342
Average KL loss: 0.096857
Average total loss: 0.106199
tensor(0.0307, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-4.8075e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.009596
Average KL loss: 0.095891
Average total loss: 0.105486
tensor(0.0306, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.1240e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.009431
Average KL loss: 0.094946
Average total loss: 0.104377
tensor(0.0305, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(9.0658e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.008663
Average KL loss: 0.094025
Average total loss: 0.102688
tensor(0.0304, device='cuda:0') tensor(0.1276, device='cuda:0') tensor(-1.7099e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.008970
Average KL loss: 0.093098
Average total loss: 0.102068
tensor(0.0303, device='cuda:0') tensor(0.1265, device='cuda:0') tensor(1.5340e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.009793
Average KL loss: 0.092176
Average total loss: 0.101969
tensor(0.0302, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-1.0419e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.009820
Average KL loss: 0.091353
Average total loss: 0.101173
tensor(0.0301, device='cuda:0') tensor(0.1244, device='cuda:0') tensor(7.2793e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.010038
Average KL loss: 0.090517
Average total loss: 0.100555
tensor(0.0301, device='cuda:0') tensor(0.1234, device='cuda:0') tensor(1.5084e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.009175
Average KL loss: 0.089723
Average total loss: 0.098897
tensor(0.0300, device='cuda:0') tensor(0.1225, device='cuda:0') tensor(-1.0607e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.008961
Average KL loss: 0.088903
Average total loss: 0.097864
tensor(0.0299, device='cuda:0') tensor(0.1215, device='cuda:0') tensor(4.0525e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.010643
Average KL loss: 0.088103
Average total loss: 0.098745
tensor(0.0298, device='cuda:0') tensor(0.1206, device='cuda:0') tensor(3.3975e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.008805
Average KL loss: 0.087331
Average total loss: 0.096136
tensor(0.0298, device='cuda:0') tensor(0.1196, device='cuda:0') tensor(1.0741e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.009527
Average KL loss: 0.086521
Average total loss: 0.096048
tensor(0.0297, device='cuda:0') tensor(0.1187, device='cuda:0') tensor(-3.1881e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.009535
Average KL loss: 0.085774
Average total loss: 0.095309
tensor(0.0296, device='cuda:0') tensor(0.1178, device='cuda:0') tensor(1.9408e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.009164
Average KL loss: 0.085017
Average total loss: 0.094181
tensor(0.0295, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-8.7310e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.009674
Average KL loss: 0.084293
Average total loss: 0.093967
tensor(0.0295, device='cuda:0') tensor(0.1160, device='cuda:0') tensor(6.9730e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.009895
Average KL loss: 0.083603
Average total loss: 0.093498
tensor(0.0294, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.5487e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.009270
Average KL loss: 0.082947
Average total loss: 0.092217
tensor(0.0293, device='cuda:0') tensor(0.1144, device='cuda:0') tensor(7.1530e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.010262
Average KL loss: 0.082284
Average total loss: 0.092546
tensor(0.0293, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(1.5456e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.009748
Average KL loss: 0.081658
Average total loss: 0.091405
tensor(0.0292, device='cuda:0') tensor(0.1129, device='cuda:0') tensor(2.8408e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.009109
Average KL loss: 0.081003
Average total loss: 0.090112
tensor(0.0291, device='cuda:0') tensor(0.1121, device='cuda:0') tensor(1.2353e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.009187
Average KL loss: 0.080340
Average total loss: 0.089527
tensor(0.0290, device='cuda:0') tensor(0.1114, device='cuda:0') tensor(6.0467e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.008730
Average KL loss: 0.079703
Average total loss: 0.088433
tensor(0.0289, device='cuda:0') tensor(0.1106, device='cuda:0') tensor(-9.1981e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.009425
Average KL loss: 0.079045
Average total loss: 0.088470
tensor(0.0289, device='cuda:0') tensor(0.1099, device='cuda:0') tensor(-5.0758e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.009202
Average KL loss: 0.078427
Average total loss: 0.087629
tensor(0.0288, device='cuda:0') tensor(0.1091, device='cuda:0') tensor(4.2038e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.009352
Average KL loss: 0.077804
Average total loss: 0.087156
tensor(0.0287, device='cuda:0') tensor(0.1084, device='cuda:0') tensor(7.3776e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.008829
Average KL loss: 0.077219
Average total loss: 0.086048
tensor(0.0287, device='cuda:0') tensor(0.1077, device='cuda:0') tensor(1.0885e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.009399
Average KL loss: 0.076621
Average total loss: 0.086020
tensor(0.0286, device='cuda:0') tensor(0.1070, device='cuda:0') tensor(-1.1345e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.009507
Average KL loss: 0.076087
Average total loss: 0.085594
tensor(0.0285, device='cuda:0') tensor(0.1064, device='cuda:0') tensor(3.2694e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.009601
Average KL loss: 0.075550
Average total loss: 0.085151
tensor(0.0284, device='cuda:0') tensor(0.1058, device='cuda:0') tensor(-1.0390e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.009494
Average KL loss: 0.075007
Average total loss: 0.084501
tensor(0.0284, device='cuda:0') tensor(0.1051, device='cuda:0') tensor(7.3664e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.008609
Average KL loss: 0.074482
Average total loss: 0.083092
tensor(0.0283, device='cuda:0') tensor(0.1045, device='cuda:0') tensor(-1.0230e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.009255
Average KL loss: 0.073969
Average total loss: 0.083224
tensor(0.0282, device='cuda:0') tensor(0.1039, device='cuda:0') tensor(-8.3863e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.009247
Average KL loss: 0.073448
Average total loss: 0.082694
tensor(0.0282, device='cuda:0') tensor(0.1033, device='cuda:0') tensor(8.5060e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.009862
Average KL loss: 0.072952
Average total loss: 0.082813
tensor(0.0281, device='cuda:0') tensor(0.1027, device='cuda:0') tensor(5.3808e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.010122
Average KL loss: 0.072477
Average total loss: 0.082599
tensor(0.0281, device='cuda:0') tensor(0.1022, device='cuda:0') tensor(1.0511e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.010251
Average KL loss: 0.072063
Average total loss: 0.082314
tensor(0.0280, device='cuda:0') tensor(0.1017, device='cuda:0') tensor(1.5942e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.009813
Average KL loss: 0.071635
Average total loss: 0.081448
tensor(0.0280, device='cuda:0') tensor(0.1012, device='cuda:0') tensor(-2.7333e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.009591
Average KL loss: 0.071204
Average total loss: 0.080796
tensor(0.0279, device='cuda:0') tensor(0.1007, device='cuda:0') tensor(1.4237e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.008959
Average KL loss: 0.070766
Average total loss: 0.079725
tensor(0.0279, device='cuda:0') tensor(0.1002, device='cuda:0') tensor(1.3541e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.008924
Average KL loss: 0.070297
Average total loss: 0.079220
tensor(0.0278, device='cuda:0') tensor(0.0996, device='cuda:0') tensor(-2.9215e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.009929
Average KL loss: 0.069848
Average total loss: 0.079777
tensor(0.0277, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(1.2369e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.008942
Average KL loss: 0.069452
Average total loss: 0.078394
tensor(0.0277, device='cuda:0') tensor(0.0987, device='cuda:0') tensor(1.1310e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.008586
Average KL loss: 0.068996
Average total loss: 0.077582
tensor(0.0276, device='cuda:0') tensor(0.0982, device='cuda:0') tensor(1.1917e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.009265
Average KL loss: 0.068585
Average total loss: 0.077850
tensor(0.0276, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(1.4757e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.009264
Average KL loss: 0.068185
Average total loss: 0.077450
tensor(0.0275, device='cuda:0') tensor(0.0972, device='cuda:0') tensor(5.0410e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.009420
Average KL loss: 0.067761
Average total loss: 0.077181
tensor(0.0274, device='cuda:0') tensor(0.0968, device='cuda:0') tensor(-1.0141e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.008133
Average KL loss: 0.067393
Average total loss: 0.075526
tensor(0.0274, device='cuda:0') tensor(0.0963, device='cuda:0') tensor(6.3821e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.009692
Average KL loss: 0.066967
Average total loss: 0.076659
tensor(0.0273, device='cuda:0') tensor(0.0958, device='cuda:0') tensor(1.0468e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.008192
Average KL loss: 0.066585
Average total loss: 0.074777
tensor(0.0273, device='cuda:0') tensor(0.0954, device='cuda:0') tensor(1.9654e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.008564
Average KL loss: 0.066179
Average total loss: 0.074742
tensor(0.0272, device='cuda:0') tensor(0.0949, device='cuda:0') tensor(7.8509e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.009173
Average KL loss: 0.065796
Average total loss: 0.074969
tensor(0.0271, device='cuda:0') tensor(0.0945, device='cuda:0') tensor(3.4195e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.009027
Average KL loss: 0.065448
Average total loss: 0.074476
tensor(0.0271, device='cuda:0') tensor(0.0941, device='cuda:0') tensor(-1.1632e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.009722
Average KL loss: 0.065133
Average total loss: 0.074855
tensor(0.0270, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(-6.3323e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.009633
Average KL loss: 0.064837
Average total loss: 0.074470
tensor(0.0270, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(3.0960e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.008800
Average KL loss: 0.064512
Average total loss: 0.073312
tensor(0.0270, device='cuda:0') tensor(0.0930, device='cuda:0') tensor(9.1607e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.008761
Average KL loss: 0.064153
Average total loss: 0.072914
tensor(0.0269, device='cuda:0') tensor(0.0926, device='cuda:0') tensor(2.4992e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.009108
Average KL loss: 0.063850
Average total loss: 0.072958
tensor(0.0268, device='cuda:0') tensor(0.0922, device='cuda:0') tensor(1.2163e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.009211
Average KL loss: 0.063527
Average total loss: 0.072737
tensor(0.0268, device='cuda:0') tensor(0.0919, device='cuda:0') tensor(-7.6746e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.009682
Average KL loss: 0.063256
Average total loss: 0.072938
tensor(0.0268, device='cuda:0') tensor(0.0916, device='cuda:0') tensor(-8.9081e-11, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.008802
Average KL loss: 0.062975
Average total loss: 0.071778
tensor(0.0267, device='cuda:0') tensor(0.0912, device='cuda:0') tensor(9.3203e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.008444
Average KL loss: 0.062645
Average total loss: 0.071089
tensor(0.0267, device='cuda:0') tensor(0.0909, device='cuda:0') tensor(1.1053e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.008629
Average KL loss: 0.062314
Average total loss: 0.070943
tensor(0.0266, device='cuda:0') tensor(0.0905, device='cuda:0') tensor(-1.3544e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.008892
Average KL loss: 0.062030
Average total loss: 0.070921
tensor(0.0266, device='cuda:0') tensor(0.0901, device='cuda:0') tensor(-4.3171e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.009731
Average KL loss: 0.061737
Average total loss: 0.071468
tensor(0.0265, device='cuda:0') tensor(0.0898, device='cuda:0') tensor(-1.9057e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.009020
Average KL loss: 0.061471
Average total loss: 0.070492
tensor(0.0264, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-4.4353e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.009207
Average KL loss: 0.061195
Average total loss: 0.070402
tensor(0.0264, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(4.9496e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.008716
Average KL loss: 0.060899
Average total loss: 0.069615
tensor(0.0263, device='cuda:0') tensor(0.0889, device='cuda:0') tensor(1.1954e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.009342
Average KL loss: 0.060637
Average total loss: 0.069979
tensor(0.0263, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(7.2620e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.008934
Average KL loss: 0.060370
Average total loss: 0.069304
tensor(0.0262, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(6.1393e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.009795
Average KL loss: 0.060119
Average total loss: 0.069914
tensor(0.0262, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(1.3771e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.008987
Average KL loss: 0.059899
Average total loss: 0.068886
tensor(0.0262, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-1.3559e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.009762
Average KL loss: 0.059670
Average total loss: 0.069432
tensor(0.0261, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(5.3753e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.009200
Average KL loss: 0.059458
Average total loss: 0.068658
tensor(0.0261, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(1.4412e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.009781
Average KL loss: 0.059236
Average total loss: 0.069016
tensor(0.0261, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(5.5199e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.008493
Average KL loss: 0.059059
Average total loss: 0.067552
tensor(0.0260, device='cuda:0') tensor(0.0868, device='cuda:0') tensor(-4.8224e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.009548
Average KL loss: 0.058819
Average total loss: 0.068367
tensor(0.0260, device='cuda:0') tensor(0.0866, device='cuda:0') tensor(1.4047e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.009123
Average KL loss: 0.058662
Average total loss: 0.067786
tensor(0.0259, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-4.8184e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.009285
Average KL loss: 0.058452
Average total loss: 0.067737
tensor(0.0259, device='cuda:0') tensor(0.0861, device='cuda:0') tensor(1.8481e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.009800
Average KL loss: 0.058226
Average total loss: 0.068026
tensor(0.0259, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-2.9756e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.009374
Average KL loss: 0.058057
Average total loss: 0.067431
tensor(0.0259, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(1.5674e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.008894
Average KL loss: 0.057867
Average total loss: 0.066761
tensor(0.0258, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-5.4405e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.009431
Average KL loss: 0.057663
Average total loss: 0.067094
tensor(0.0258, device='cuda:0') tensor(0.0852, device='cuda:0') tensor(-4.6503e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.009670
Average KL loss: 0.057473
Average total loss: 0.067143
tensor(0.0258, device='cuda:0') tensor(0.0850, device='cuda:0') tensor(2.6557e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.009721
Average KL loss: 0.057292
Average total loss: 0.067014
tensor(0.0257, device='cuda:0') tensor(0.0848, device='cuda:0') tensor(1.8817e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.009357
Average KL loss: 0.057118
Average total loss: 0.066475
tensor(0.0257, device='cuda:0') tensor(0.0846, device='cuda:0') tensor(-2.1852e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.010417
Average KL loss: 0.056936
Average total loss: 0.067353
tensor(0.0257, device='cuda:0') tensor(0.0844, device='cuda:0') tensor(-4.5834e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.008529
Average KL loss: 0.056762
Average total loss: 0.065291
tensor(0.0256, device='cuda:0') tensor(0.0842, device='cuda:0') tensor(6.9242e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.010025
Average KL loss: 0.056578
Average total loss: 0.066603
tensor(0.0256, device='cuda:0') tensor(0.0840, device='cuda:0') tensor(-5.8942e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.008553
Average KL loss: 0.056420
Average total loss: 0.064973
tensor(0.0256, device='cuda:0') tensor(0.0838, device='cuda:0') tensor(6.9082e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.009705
Average KL loss: 0.056205
Average total loss: 0.065910
tensor(0.0255, device='cuda:0') tensor(0.0837, device='cuda:0') tensor(1.4058e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.009352
Average KL loss: 0.056055
Average total loss: 0.065407
tensor(0.0255, device='cuda:0') tensor(0.0835, device='cuda:0') tensor(-1.5640e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.008914
Average KL loss: 0.055905
Average total loss: 0.064818
tensor(0.0255, device='cuda:0') tensor(0.0833, device='cuda:0') tensor(-5.5016e-11, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.008791
Average KL loss: 0.055698
Average total loss: 0.064489
tensor(0.0254, device='cuda:0') tensor(0.0831, device='cuda:0') tensor(-4.1305e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.009119
Average KL loss: 0.055523
Average total loss: 0.064643
tensor(0.0254, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(-2.7570e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.009875
Average KL loss: 0.055370
Average total loss: 0.065245
tensor(0.0254, device='cuda:0') tensor(0.0827, device='cuda:0') tensor(-6.2931e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.009338
Average KL loss: 0.055235
Average total loss: 0.064573
tensor(0.0254, device='cuda:0') tensor(0.0826, device='cuda:0') tensor(-3.3433e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.008710
Average KL loss: 0.055082
Average total loss: 0.063792
tensor(0.0253, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(3.6238e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.008942
Average KL loss: 0.054895
Average total loss: 0.063837
tensor(0.0253, device='cuda:0') tensor(0.0822, device='cuda:0') tensor(1.3350e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.010057
Average KL loss: 0.054755
Average total loss: 0.064812
tensor(0.0253, device='cuda:0') tensor(0.0821, device='cuda:0') tensor(1.3182e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.009232
Average KL loss: 0.054651
Average total loss: 0.063883
tensor(0.0253, device='cuda:0') tensor(0.0819, device='cuda:0') tensor(1.1255e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.008268
Average KL loss: 0.054482
Average total loss: 0.062751
tensor(0.0253, device='cuda:0') tensor(0.0817, device='cuda:0') tensor(1.2059e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.009935
Average KL loss: 0.054271
Average total loss: 0.064206
tensor(0.0252, device='cuda:0') tensor(0.0815, device='cuda:0') tensor(4.6962e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.009251
Average KL loss: 0.054176
Average total loss: 0.063427
tensor(0.0252, device='cuda:0') tensor(0.0814, device='cuda:0') tensor(6.9611e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.009515
Average KL loss: 0.054027
Average total loss: 0.063542
tensor(0.0252, device='cuda:0') tensor(0.0813, device='cuda:0') tensor(5.1735e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.008881
Average KL loss: 0.053899
Average total loss: 0.062780
tensor(0.0251, device='cuda:0') tensor(0.0811, device='cuda:0') tensor(1.8536e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.009111
Average KL loss: 0.053727
Average total loss: 0.062838
tensor(0.0251, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-4.9259e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.008907
Average KL loss: 0.053612
Average total loss: 0.062519
tensor(0.0251, device='cuda:0') tensor(0.0808, device='cuda:0') tensor(5.3922e-11, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.008789
Average KL loss: 0.053467
Average total loss: 0.062256
tensor(0.0251, device='cuda:0') tensor(0.0806, device='cuda:0') tensor(9.7190e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.009613
Average KL loss: 0.053298
Average total loss: 0.062911
tensor(0.0250, device='cuda:0') tensor(0.0805, device='cuda:0') tensor(4.5199e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.009005
Average KL loss: 0.053174
Average total loss: 0.062178
tensor(0.0250, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(2.9926e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.009153
Average KL loss: 0.053065
Average total loss: 0.062217
tensor(0.0250, device='cuda:0') tensor(0.0802, device='cuda:0') tensor(-6.5308e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.009118
Average KL loss: 0.052932
Average total loss: 0.062050
tensor(0.0249, device='cuda:0') tensor(0.0801, device='cuda:0') tensor(7.6032e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.009348
Average KL loss: 0.052813
Average total loss: 0.062162
tensor(0.0249, device='cuda:0') tensor(0.0800, device='cuda:0') tensor(-3.5464e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.010095
Average KL loss: 0.052707
Average total loss: 0.062801
tensor(0.0249, device='cuda:0') tensor(0.0798, device='cuda:0') tensor(6.4564e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.010308
Average KL loss: 0.052636
Average total loss: 0.062943
tensor(0.0249, device='cuda:0') tensor(0.0798, device='cuda:0') tensor(-4.0446e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.009468
Average KL loss: 0.052564
Average total loss: 0.062032
tensor(0.0249, device='cuda:0') tensor(0.0796, device='cuda:0') tensor(4.1664e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.009600
Average KL loss: 0.052467
Average total loss: 0.062067
tensor(0.0249, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(4.9419e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.009824
Average KL loss: 0.052369
Average total loss: 0.062193
tensor(0.0249, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(5.4919e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.008118
Average KL loss: 0.052243
Average total loss: 0.060361
tensor(0.0248, device='cuda:0') tensor(0.0793, device='cuda:0') tensor(1.2032e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.009367
Average KL loss: 0.052087
Average total loss: 0.061454
tensor(0.0248, device='cuda:0') tensor(0.0791, device='cuda:0') tensor(-1.1943e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.009037
Average KL loss: 0.051970
Average total loss: 0.061007
tensor(0.0248, device='cuda:0') tensor(0.0790, device='cuda:0') tensor(-1.1265e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.009548
Average KL loss: 0.051871
Average total loss: 0.061419
tensor(0.0248, device='cuda:0') tensor(0.0789, device='cuda:0') tensor(6.7464e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.009072
Average KL loss: 0.051790
Average total loss: 0.060862
tensor(0.0248, device='cuda:0') tensor(0.0788, device='cuda:0') tensor(-2.4121e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.009995
Average KL loss: 0.051709
Average total loss: 0.061704
tensor(0.0247, device='cuda:0') tensor(0.0788, device='cuda:0') tensor(6.4562e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.009870
Average KL loss: 0.051670
Average total loss: 0.061540
tensor(0.0247, device='cuda:0') tensor(0.0787, device='cuda:0') tensor(3.5809e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.009430
Average KL loss: 0.051578
Average total loss: 0.061008
tensor(0.0247, device='cuda:0') tensor(0.0786, device='cuda:0') tensor(1.0522e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.008686
Average KL loss: 0.051443
Average total loss: 0.060129
tensor(0.0247, device='cuda:0') tensor(0.0784, device='cuda:0') tensor(-3.9697e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.008528
Average KL loss: 0.051291
Average total loss: 0.059819
tensor(0.0247, device='cuda:0') tensor(0.0783, device='cuda:0') tensor(1.4152e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.008620
Average KL loss: 0.051151
Average total loss: 0.059771
tensor(0.0246, device='cuda:0') tensor(0.0781, device='cuda:0') tensor(1.2125e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.009114
Average KL loss: 0.051011
Average total loss: 0.060125
tensor(0.0246, device='cuda:0') tensor(0.0780, device='cuda:0') tensor(-1.6355e-11, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.009992
Average KL loss: 0.050929
Average total loss: 0.060921
tensor(0.0246, device='cuda:0') tensor(0.0780, device='cuda:0') tensor(-2.3688e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.008625
Average KL loss: 0.050843
Average total loss: 0.059467
tensor(0.0246, device='cuda:0') tensor(0.0778, device='cuda:0') tensor(1.6430e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.008872
Average KL loss: 0.050715
Average total loss: 0.059586
tensor(0.0245, device='cuda:0') tensor(0.0777, device='cuda:0') tensor(7.1209e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.008405
Average KL loss: 0.050595
Average total loss: 0.059000
tensor(0.0245, device='cuda:0') tensor(0.0776, device='cuda:0') tensor(3.2693e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.008874
Average KL loss: 0.050488
Average total loss: 0.059362
tensor(0.0245, device='cuda:0') tensor(0.0775, device='cuda:0') tensor(-1.4448e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.008715
Average KL loss: 0.050358
Average total loss: 0.059073
tensor(0.0245, device='cuda:0') tensor(0.0773, device='cuda:0') tensor(1.0773e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.009722
Average KL loss: 0.050257
Average total loss: 0.059979
tensor(0.0245, device='cuda:0') tensor(0.0773, device='cuda:0') tensor(-7.1476e-12, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.008360
Average KL loss: 0.050198
Average total loss: 0.058558
tensor(0.0244, device='cuda:0') tensor(0.0771, device='cuda:0') tensor(-4.5731e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.009028
Average KL loss: 0.050090
Average total loss: 0.059118
tensor(0.0244, device='cuda:0') tensor(0.0771, device='cuda:0') tensor(-3.9573e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.008528
Average KL loss: 0.050001
Average total loss: 0.058528
tensor(0.0244, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(4.4729e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.008836
Average KL loss: 0.049901
Average total loss: 0.058738
tensor(0.0244, device='cuda:0') tensor(0.0769, device='cuda:0') tensor(-1.4728e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.008779
Average KL loss: 0.049812
Average total loss: 0.058592
tensor(0.0244, device='cuda:0') tensor(0.0768, device='cuda:0') tensor(8.4025e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.009028
Average KL loss: 0.049734
Average total loss: 0.058763
tensor(0.0244, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(-5.6479e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.009860
Average KL loss: 0.049688
Average total loss: 0.059548
tensor(0.0244, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(-1.0488e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.008594
Average KL loss: 0.049663
Average total loss: 0.058257
tensor(0.0243, device='cuda:0') tensor(0.0766, device='cuda:0') tensor(-4.1264e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.009692
Average KL loss: 0.049589
Average total loss: 0.059281
tensor(0.0243, device='cuda:0') tensor(0.0765, device='cuda:0') tensor(-6.4495e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.008761
Average KL loss: 0.049491
Average total loss: 0.058253
tensor(0.0243, device='cuda:0') tensor(0.0764, device='cuda:0') tensor(2.9772e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.008564
Average KL loss: 0.049412
Average total loss: 0.057976
 Percentile value: 1.075037360191345
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =     987 /    1728             ( 57.12%) | total_pruned =     741 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4086 /   36864             ( 11.08%) | total_pruned =   32778 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4679 /   36864             ( 12.69%) | total_pruned =   32185 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4097 /   36864             ( 11.11%) | total_pruned =   32767 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4355 /   36864             ( 11.81%) | total_pruned =   32509 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    7668 /   73728             ( 10.40%) | total_pruned =   66060 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   13281 /  147456             (  9.01%) | total_pruned =  134175 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2691 /    8192             ( 32.85%) | total_pruned =    5501 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8975 /  147456             (  6.09%) | total_pruned =  138481 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    9269 /  147456             (  6.29%) | total_pruned =  138187 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   23809 /  294912             (  8.07%) | total_pruned =  271103 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   37193 /  589824             (  6.31%) | total_pruned =  552631 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     181 /     256             ( 70.70%) | total_pruned =      75 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    7288 /   32768             ( 22.24%) | total_pruned =   25480 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   18848 /  589824             (  3.20%) | total_pruned =  570976 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   18103 /  589824             (  3.07%) | total_pruned =  571721 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   52872 / 1179648             (  4.48%) | total_pruned = 1126776 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     463 /     512             ( 90.43%) | total_pruned =      49 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   39465 / 2359296             (  1.67%) | total_pruned = 2319831 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     228 /     512             ( 44.53%) | total_pruned =     284 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    9726 /  131072             (  7.42%) | total_pruned =  121346 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     464 /     512             ( 90.62%) | total_pruned =      48 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     236 /     512             ( 46.09%) | total_pruned =     276 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   17438 / 2359296             (  0.74%) | total_pruned = 2341858 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     329 /     512             ( 64.26%) | total_pruned =     183 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     137 /     512             ( 26.76%) | total_pruned =     375 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    6793 / 2359296             (  0.29%) | total_pruned = 2352503 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
linear.weight        | nonzeros =    3115 /    5120             ( 60.84%) | total_pruned =    2005 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 24/200 Loss: 0.000466 Accuracy: 86.00 100.00 % Best test Accuracy: 86.35%
tensor(0.0243, device='cuda:0') tensor(0.0764, device='cuda:0') tensor(-1.2585e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.129247
Average KL loss: 0.042487
Average total loss: 0.171734
tensor(0.0273, device='cuda:0') tensor(0.0638, device='cuda:0') tensor(-1.1055e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.117961
Average KL loss: 0.050487
Average total loss: 0.168448
tensor(0.0284, device='cuda:0') tensor(0.0759, device='cuda:0') tensor(-1.0851e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.106414
Average KL loss: 0.057322
Average total loss: 0.163736
tensor(0.0294, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(-7.9985e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.086305
Average KL loss: 0.062481
Average total loss: 0.148786
tensor(0.0302, device='cuda:0') tensor(0.0966, device='cuda:0') tensor(-8.3605e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.078508
Average KL loss: 0.066543
Average total loss: 0.145051
tensor(0.0310, device='cuda:0') tensor(0.1051, device='cuda:0') tensor(-8.4333e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.069267
Average KL loss: 0.069992
Average total loss: 0.139259
tensor(0.0317, device='cuda:0') tensor(0.1128, device='cuda:0') tensor(-1.3081e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.063663
Average KL loss: 0.073002
Average total loss: 0.136665
tensor(0.0324, device='cuda:0') tensor(0.1199, device='cuda:0') tensor(-6.2084e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.053979
Average KL loss: 0.075642
Average total loss: 0.129621
tensor(0.0329, device='cuda:0') tensor(0.1263, device='cuda:0') tensor(-5.0829e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.046372
Average KL loss: 0.077733
Average total loss: 0.124105
tensor(0.0334, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-5.3816e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.045248
Average KL loss: 0.079548
Average total loss: 0.124796
tensor(0.0338, device='cuda:0') tensor(0.1369, device='cuda:0') tensor(-8.3753e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.041792
Average KL loss: 0.081189
Average total loss: 0.122981
tensor(0.0342, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-7.8220e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.039451
Average KL loss: 0.082620
Average total loss: 0.122072
tensor(0.0346, device='cuda:0') tensor(0.1463, device='cuda:0') tensor(-1.4060e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.035137
Average KL loss: 0.084051
Average total loss: 0.119188
tensor(0.0349, device='cuda:0') tensor(0.1507, device='cuda:0') tensor(-4.5584e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.034390
Average KL loss: 0.085271
Average total loss: 0.119660
tensor(0.0352, device='cuda:0') tensor(0.1549, device='cuda:0') tensor(-8.0077e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.030091
Average KL loss: 0.086474
Average total loss: 0.116565
tensor(0.0355, device='cuda:0') tensor(0.1587, device='cuda:0') tensor(-3.4197e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.029250
Average KL loss: 0.087446
Average total loss: 0.116695
tensor(0.0358, device='cuda:0') tensor(0.1622, device='cuda:0') tensor(-1.4975e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.029978
Average KL loss: 0.088368
Average total loss: 0.118346
tensor(0.0360, device='cuda:0') tensor(0.1659, device='cuda:0') tensor(-4.0340e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.026766
Average KL loss: 0.089343
Average total loss: 0.116108
tensor(0.0362, device='cuda:0') tensor(0.1694, device='cuda:0') tensor(-2.2516e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.025352
Average KL loss: 0.090162
Average total loss: 0.115514
tensor(0.0365, device='cuda:0') tensor(0.1728, device='cuda:0') tensor(-3.3839e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.023572
Average KL loss: 0.090997
Average total loss: 0.114569
tensor(0.0367, device='cuda:0') tensor(0.1759, device='cuda:0') tensor(-1.3108e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.024363
Average KL loss: 0.091729
Average total loss: 0.116093
tensor(0.0368, device='cuda:0') tensor(0.1791, device='cuda:0') tensor(-1.2708e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.022153
Average KL loss: 0.092420
Average total loss: 0.114573
tensor(0.0370, device='cuda:0') tensor(0.1820, device='cuda:0') tensor(-3.2908e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.020553
Average KL loss: 0.093031
Average total loss: 0.113584
tensor(0.0372, device='cuda:0') tensor(0.1848, device='cuda:0') tensor(-1.6918e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.020335
Average KL loss: 0.093502
Average total loss: 0.113837
tensor(0.0373, device='cuda:0') tensor(0.1872, device='cuda:0') tensor(-2.6395e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.018312
Average KL loss: 0.093978
Average total loss: 0.112290
tensor(0.0374, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-1.0933e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.017253
Average KL loss: 0.094431
Average total loss: 0.111684
tensor(0.0375, device='cuda:0') tensor(0.1920, device='cuda:0') tensor(-1.4905e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.017282
Average KL loss: 0.094755
Average total loss: 0.112037
tensor(0.0376, device='cuda:0') tensor(0.1941, device='cuda:0') tensor(-2.8013e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.016371
Average KL loss: 0.095083
Average total loss: 0.111454
tensor(0.0377, device='cuda:0') tensor(0.1962, device='cuda:0') tensor(2.2614e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.016587
Average KL loss: 0.095360
Average total loss: 0.111947
tensor(0.0377, device='cuda:0') tensor(0.1985, device='cuda:0') tensor(-2.1405e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.016730
Average KL loss: 0.095861
Average total loss: 0.112591
tensor(0.0379, device='cuda:0') tensor(0.2011, device='cuda:0') tensor(-6.5351e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.016551
Average KL loss: 0.096367
Average total loss: 0.112919
tensor(0.0379, device='cuda:0') tensor(0.2036, device='cuda:0') tensor(-1.4416e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.015919
Average KL loss: 0.096795
Average total loss: 0.112714
tensor(0.0380, device='cuda:0') tensor(0.2059, device='cuda:0') tensor(-1.1673e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.015904
Average KL loss: 0.097262
Average total loss: 0.113166
tensor(0.0381, device='cuda:0') tensor(0.2086, device='cuda:0') tensor(-1.4974e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.016672
Average KL loss: 0.097847
Average total loss: 0.114519
tensor(0.0382, device='cuda:0') tensor(0.2118, device='cuda:0') tensor(-1.5587e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.014471
Average KL loss: 0.098481
Average total loss: 0.112951
tensor(0.0384, device='cuda:0') tensor(0.2143, device='cuda:0') tensor(-7.1845e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.014336
Average KL loss: 0.098769
Average total loss: 0.113106
tensor(0.0384, device='cuda:0') tensor(0.2165, device='cuda:0') tensor(-2.0538e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.014296
Average KL loss: 0.099102
Average total loss: 0.113398
tensor(0.0385, device='cuda:0') tensor(0.2186, device='cuda:0') tensor(-1.2676e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.012635
Average KL loss: 0.099289
Average total loss: 0.111924
tensor(0.0385, device='cuda:0') tensor(0.2204, device='cuda:0') tensor(-7.1365e-11, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.012283
Average KL loss: 0.099414
Average total loss: 0.111697
tensor(0.0385, device='cuda:0') tensor(0.2219, device='cuda:0') tensor(-9.5454e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.012066
Average KL loss: 0.099406
Average total loss: 0.111471
tensor(0.0386, device='cuda:0') tensor(0.2217, device='cuda:0') tensor(-1.0961e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.010428
Average KL loss: 0.099219
Average total loss: 0.109648
tensor(0.0386, device='cuda:0') tensor(0.2214, device='cuda:0') tensor(9.4469e-11, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.011331
Average KL loss: 0.099025
Average total loss: 0.110355
tensor(0.0386, device='cuda:0') tensor(0.2211, device='cuda:0') tensor(-1.1877e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.011803
Average KL loss: 0.098832
Average total loss: 0.110635
tensor(0.0386, device='cuda:0') tensor(0.2208, device='cuda:0') tensor(3.4222e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.010463
Average KL loss: 0.098636
Average total loss: 0.109100
tensor(0.0386, device='cuda:0') tensor(0.2205, device='cuda:0') tensor(-4.2392e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.011049
Average KL loss: 0.098440
Average total loss: 0.109489
tensor(0.0386, device='cuda:0') tensor(0.2202, device='cuda:0') tensor(-5.5053e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.010230
Average KL loss: 0.098244
Average total loss: 0.108474
tensor(0.0385, device='cuda:0') tensor(0.2198, device='cuda:0') tensor(5.2052e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.010169
Average KL loss: 0.098047
Average total loss: 0.108216
tensor(0.0385, device='cuda:0') tensor(0.2195, device='cuda:0') tensor(-1.0983e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.010400
Average KL loss: 0.097847
Average total loss: 0.108247
tensor(0.0385, device='cuda:0') tensor(0.2192, device='cuda:0') tensor(-9.2182e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.009099
Average KL loss: 0.097646
Average total loss: 0.106745
tensor(0.0385, device='cuda:0') tensor(0.2188, device='cuda:0') tensor(-2.2875e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.009599
Average KL loss: 0.097446
Average total loss: 0.107045
tensor(0.0385, device='cuda:0') tensor(0.2184, device='cuda:0') tensor(-1.2307e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.009982
Average KL loss: 0.097243
Average total loss: 0.107225
tensor(0.0385, device='cuda:0') tensor(0.2181, device='cuda:0') tensor(7.2465e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.009391
Average KL loss: 0.097041
Average total loss: 0.106432
tensor(0.0385, device='cuda:0') tensor(0.2177, device='cuda:0') tensor(2.8207e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.008839
Average KL loss: 0.096839
Average total loss: 0.105678
tensor(0.0385, device='cuda:0') tensor(0.2174, device='cuda:0') tensor(1.9780e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.010030
Average KL loss: 0.096630
Average total loss: 0.106659
tensor(0.0385, device='cuda:0') tensor(0.2170, device='cuda:0') tensor(-2.0183e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.009229
Average KL loss: 0.096424
Average total loss: 0.105653
tensor(0.0385, device='cuda:0') tensor(0.2166, device='cuda:0') tensor(-3.2846e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.009793
Average KL loss: 0.096221
Average total loss: 0.106015
tensor(0.0385, device='cuda:0') tensor(0.2163, device='cuda:0') tensor(-4.1571e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.010002
Average KL loss: 0.096015
Average total loss: 0.106018
tensor(0.0384, device='cuda:0') tensor(0.2159, device='cuda:0') tensor(1.8704e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.008810
Average KL loss: 0.095805
Average total loss: 0.104615
tensor(0.0384, device='cuda:0') tensor(0.2155, device='cuda:0') tensor(-4.8938e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.009294
Average KL loss: 0.095598
Average total loss: 0.104892
tensor(0.0384, device='cuda:0') tensor(0.2151, device='cuda:0') tensor(1.1376e-12, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.008792
Average KL loss: 0.095388
Average total loss: 0.104181
tensor(0.0384, device='cuda:0') tensor(0.2147, device='cuda:0') tensor(-4.4945e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.008935
Average KL loss: 0.095175
Average total loss: 0.104110
tensor(0.0384, device='cuda:0') tensor(0.2144, device='cuda:0') tensor(-1.1593e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.008744
Average KL loss: 0.094955
Average total loss: 0.103699
tensor(0.0384, device='cuda:0') tensor(0.2139, device='cuda:0') tensor(-1.2224e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.008220
Average KL loss: 0.094737
Average total loss: 0.102957
tensor(0.0384, device='cuda:0') tensor(0.2135, device='cuda:0') tensor(-8.4717e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.008090
Average KL loss: 0.094516
Average total loss: 0.102607
tensor(0.0383, device='cuda:0') tensor(0.2131, device='cuda:0') tensor(-8.6361e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.008991
Average KL loss: 0.094302
Average total loss: 0.103293
tensor(0.0383, device='cuda:0') tensor(0.2127, device='cuda:0') tensor(2.2530e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.007814
Average KL loss: 0.094085
Average total loss: 0.101899
tensor(0.0383, device='cuda:0') tensor(0.2123, device='cuda:0') tensor(-2.6210e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.008258
Average KL loss: 0.093851
Average total loss: 0.102109
tensor(0.0383, device='cuda:0') tensor(0.2119, device='cuda:0') tensor(1.4408e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.008456
Average KL loss: 0.093626
Average total loss: 0.102083
tensor(0.0383, device='cuda:0') tensor(0.2115, device='cuda:0') tensor(4.8831e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.008878
Average KL loss: 0.093412
Average total loss: 0.102290
tensor(0.0382, device='cuda:0') tensor(0.2111, device='cuda:0') tensor(-1.3991e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.008235
Average KL loss: 0.093186
Average total loss: 0.101421
tensor(0.0382, device='cuda:0') tensor(0.2106, device='cuda:0') tensor(-1.1525e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.007941
Average KL loss: 0.092956
Average total loss: 0.100897
tensor(0.0382, device='cuda:0') tensor(0.2102, device='cuda:0') tensor(-3.7285e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.008040
Average KL loss: 0.092728
Average total loss: 0.100769
tensor(0.0382, device='cuda:0') tensor(0.2097, device='cuda:0') tensor(-9.4062e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.007929
Average KL loss: 0.092497
Average total loss: 0.100427
tensor(0.0381, device='cuda:0') tensor(0.2093, device='cuda:0') tensor(4.5984e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.008589
Average KL loss: 0.092261
Average total loss: 0.100849
tensor(0.0381, device='cuda:0') tensor(0.2089, device='cuda:0') tensor(1.4559e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.008381
Average KL loss: 0.092040
Average total loss: 0.100421
tensor(0.0381, device='cuda:0') tensor(0.2084, device='cuda:0') tensor(-1.1139e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.007996
Average KL loss: 0.091816
Average total loss: 0.099812
tensor(0.0381, device='cuda:0') tensor(0.2080, device='cuda:0') tensor(2.8511e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.007569
Average KL loss: 0.091584
Average total loss: 0.099154
tensor(0.0380, device='cuda:0') tensor(0.2075, device='cuda:0') tensor(3.1536e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.008089
Average KL loss: 0.091341
Average total loss: 0.099430
tensor(0.0380, device='cuda:0') tensor(0.2071, device='cuda:0') tensor(4.2592e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.007619
Average KL loss: 0.091104
Average total loss: 0.098723
tensor(0.0380, device='cuda:0') tensor(0.2066, device='cuda:0') tensor(2.4481e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.007349
Average KL loss: 0.090870
Average total loss: 0.098218
tensor(0.0380, device='cuda:0') tensor(0.2061, device='cuda:0') tensor(7.5421e-11, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.007911
Average KL loss: 0.090635
Average total loss: 0.098546
tensor(0.0379, device='cuda:0') tensor(0.2057, device='cuda:0') tensor(-6.2970e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.008650
Average KL loss: 0.090408
Average total loss: 0.099058
tensor(0.0379, device='cuda:0') tensor(0.2053, device='cuda:0') tensor(-9.8259e-11, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.007510
Average KL loss: 0.090179
Average total loss: 0.097689
tensor(0.0379, device='cuda:0') tensor(0.2048, device='cuda:0') tensor(-1.8305e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.008471
Average KL loss: 0.089942
Average total loss: 0.098413
tensor(0.0378, device='cuda:0') tensor(0.2044, device='cuda:0') tensor(2.2563e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.007675
Average KL loss: 0.089704
Average total loss: 0.097378
tensor(0.0378, device='cuda:0') tensor(0.2039, device='cuda:0') tensor(-4.2548e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.007891
Average KL loss: 0.089464
Average total loss: 0.097354
tensor(0.0378, device='cuda:0') tensor(0.2034, device='cuda:0') tensor(-1.2308e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.007689
Average KL loss: 0.089229
Average total loss: 0.096918
tensor(0.0378, device='cuda:0') tensor(0.2030, device='cuda:0') tensor(9.4550e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.007278
Average KL loss: 0.088991
Average total loss: 0.096269
tensor(0.0377, device='cuda:0') tensor(0.2025, device='cuda:0') tensor(-1.0765e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.007691
Average KL loss: 0.088747
Average total loss: 0.096438
tensor(0.0377, device='cuda:0') tensor(0.2020, device='cuda:0') tensor(3.2640e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.007759
Average KL loss: 0.088520
Average total loss: 0.096279
tensor(0.0377, device='cuda:0') tensor(0.2016, device='cuda:0') tensor(1.5454e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.008288
Average KL loss: 0.088300
Average total loss: 0.096588
tensor(0.0376, device='cuda:0') tensor(0.2012, device='cuda:0') tensor(8.6695e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.007961
Average KL loss: 0.088080
Average total loss: 0.096042
tensor(0.0376, device='cuda:0') tensor(0.2008, device='cuda:0') tensor(8.9101e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.007734
Average KL loss: 0.087848
Average total loss: 0.095582
tensor(0.0376, device='cuda:0') tensor(0.2003, device='cuda:0') tensor(-1.5781e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.007035
Average KL loss: 0.087607
Average total loss: 0.094642
tensor(0.0375, device='cuda:0') tensor(0.1998, device='cuda:0') tensor(7.3553e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.007449
Average KL loss: 0.087362
Average total loss: 0.094811
tensor(0.0375, device='cuda:0') tensor(0.1994, device='cuda:0') tensor(1.1460e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.007178
Average KL loss: 0.087137
Average total loss: 0.094315
tensor(0.0375, device='cuda:0') tensor(0.1989, device='cuda:0') tensor(-3.1988e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.007492
Average KL loss: 0.086902
Average total loss: 0.094394
tensor(0.0374, device='cuda:0') tensor(0.1984, device='cuda:0') tensor(-4.2144e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.007538
Average KL loss: 0.086659
Average total loss: 0.094197
tensor(0.0374, device='cuda:0') tensor(0.1980, device='cuda:0') tensor(-4.0917e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.007529
Average KL loss: 0.086429
Average total loss: 0.093957
tensor(0.0374, device='cuda:0') tensor(0.1975, device='cuda:0') tensor(2.0592e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.007766
Average KL loss: 0.086195
Average total loss: 0.093961
tensor(0.0373, device='cuda:0') tensor(0.1970, device='cuda:0') tensor(-1.9904e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.007520
Average KL loss: 0.085963
Average total loss: 0.093483
tensor(0.0373, device='cuda:0') tensor(0.1966, device='cuda:0') tensor(-8.9187e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.008058
Average KL loss: 0.085747
Average total loss: 0.093805
tensor(0.0373, device='cuda:0') tensor(0.1961, device='cuda:0') tensor(7.2566e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.007814
Average KL loss: 0.085530
Average total loss: 0.093344
tensor(0.0372, device='cuda:0') tensor(0.1957, device='cuda:0') tensor(-2.2039e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.007523
Average KL loss: 0.085306
Average total loss: 0.092828
tensor(0.0372, device='cuda:0') tensor(0.1952, device='cuda:0') tensor(-9.6893e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.007393
Average KL loss: 0.085082
Average total loss: 0.092475
tensor(0.0372, device='cuda:0') tensor(0.1948, device='cuda:0') tensor(-7.8078e-11, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.007159
Average KL loss: 0.084853
Average total loss: 0.092012
tensor(0.0371, device='cuda:0') tensor(0.1943, device='cuda:0') tensor(2.0307e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.007122
Average KL loss: 0.084620
Average total loss: 0.091742
tensor(0.0371, device='cuda:0') tensor(0.1938, device='cuda:0') tensor(7.7716e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.008019
Average KL loss: 0.084393
Average total loss: 0.092412
tensor(0.0370, device='cuda:0') tensor(0.1933, device='cuda:0') tensor(9.7884e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.008195
Average KL loss: 0.084168
Average total loss: 0.092363
tensor(0.0370, device='cuda:0') tensor(0.1929, device='cuda:0') tensor(1.8183e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.007775
Average KL loss: 0.083946
Average total loss: 0.091720
tensor(0.0370, device='cuda:0') tensor(0.1925, device='cuda:0') tensor(6.7716e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.006862
Average KL loss: 0.083722
Average total loss: 0.090583
tensor(0.0369, device='cuda:0') tensor(0.1920, device='cuda:0') tensor(4.2465e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.007077
Average KL loss: 0.083499
Average total loss: 0.090576
tensor(0.0369, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(3.3106e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.006285
Average KL loss: 0.083262
Average total loss: 0.089547
tensor(0.0368, device='cuda:0') tensor(0.1911, device='cuda:0') tensor(-2.7652e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.007399
Average KL loss: 0.083027
Average total loss: 0.090427
tensor(0.0368, device='cuda:0') tensor(0.1906, device='cuda:0') tensor(1.9840e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.007929
Average KL loss: 0.082804
Average total loss: 0.090733
tensor(0.0368, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(6.6480e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.006827
Average KL loss: 0.082589
Average total loss: 0.089416
tensor(0.0367, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(2.2022e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.006842
Average KL loss: 0.082356
Average total loss: 0.089197
tensor(0.0367, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(-6.9009e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.007651
Average KL loss: 0.082141
Average total loss: 0.089793
tensor(0.0366, device='cuda:0') tensor(0.1888, device='cuda:0') tensor(1.0244e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.007288
Average KL loss: 0.081926
Average total loss: 0.089214
tensor(0.0366, device='cuda:0') tensor(0.1884, device='cuda:0') tensor(-4.3152e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.007649
Average KL loss: 0.081714
Average total loss: 0.089363
tensor(0.0366, device='cuda:0') tensor(0.1879, device='cuda:0') tensor(-9.0241e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.007639
Average KL loss: 0.081504
Average total loss: 0.089144
tensor(0.0365, device='cuda:0') tensor(0.1875, device='cuda:0') tensor(2.7734e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.007084
Average KL loss: 0.081299
Average total loss: 0.088383
tensor(0.0365, device='cuda:0') tensor(0.1871, device='cuda:0') tensor(1.0051e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.006950
Average KL loss: 0.081092
Average total loss: 0.088042
tensor(0.0364, device='cuda:0') tensor(0.1866, device='cuda:0') tensor(-5.9077e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.007740
Average KL loss: 0.080889
Average total loss: 0.088629
tensor(0.0364, device='cuda:0') tensor(0.1862, device='cuda:0') tensor(-6.7966e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.007687
Average KL loss: 0.080693
Average total loss: 0.088380
tensor(0.0364, device='cuda:0') tensor(0.1858, device='cuda:0') tensor(-5.5107e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.007560
Average KL loss: 0.080479
Average total loss: 0.088040
tensor(0.0363, device='cuda:0') tensor(0.1854, device='cuda:0') tensor(-4.3511e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.007380
Average KL loss: 0.080284
Average total loss: 0.087664
tensor(0.0363, device='cuda:0') tensor(0.1850, device='cuda:0') tensor(-8.9125e-11, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.006615
Average KL loss: 0.080082
Average total loss: 0.086696
tensor(0.0363, device='cuda:0') tensor(0.1845, device='cuda:0') tensor(-7.9961e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.007813
Average KL loss: 0.079875
Average total loss: 0.087688
tensor(0.0362, device='cuda:0') tensor(0.1841, device='cuda:0') tensor(-9.7184e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.007069
Average KL loss: 0.079681
Average total loss: 0.086750
tensor(0.0362, device='cuda:0') tensor(0.1837, device='cuda:0') tensor(6.1206e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.007130
Average KL loss: 0.079472
Average total loss: 0.086602
tensor(0.0361, device='cuda:0') tensor(0.1833, device='cuda:0') tensor(9.4407e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.007766
Average KL loss: 0.079274
Average total loss: 0.087040
tensor(0.0361, device='cuda:0') tensor(0.1829, device='cuda:0') tensor(1.0230e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.008459
Average KL loss: 0.079093
Average total loss: 0.087553
tensor(0.0361, device='cuda:0') tensor(0.1825, device='cuda:0') tensor(-3.3701e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.007061
Average KL loss: 0.078915
Average total loss: 0.085976
tensor(0.0360, device='cuda:0') tensor(0.1821, device='cuda:0') tensor(-4.8812e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.007534
Average KL loss: 0.078711
Average total loss: 0.086245
tensor(0.0360, device='cuda:0') tensor(0.1817, device='cuda:0') tensor(5.5819e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.008218
Average KL loss: 0.078524
Average total loss: 0.086742
tensor(0.0359, device='cuda:0') tensor(0.1813, device='cuda:0') tensor(3.6378e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.007414
Average KL loss: 0.078335
Average total loss: 0.085749
tensor(0.0359, device='cuda:0') tensor(0.1809, device='cuda:0') tensor(4.4025e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.007047
Average KL loss: 0.078137
Average total loss: 0.085185
tensor(0.0359, device='cuda:0') tensor(0.1805, device='cuda:0') tensor(3.0027e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.007492
Average KL loss: 0.077953
Average total loss: 0.085445
tensor(0.0358, device='cuda:0') tensor(0.1801, device='cuda:0') tensor(2.0423e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.007523
Average KL loss: 0.077764
Average total loss: 0.085287
tensor(0.0358, device='cuda:0') tensor(0.1797, device='cuda:0') tensor(-1.0779e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.007771
Average KL loss: 0.077586
Average total loss: 0.085357
tensor(0.0358, device='cuda:0') tensor(0.1794, device='cuda:0') tensor(6.5023e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.007297
Average KL loss: 0.077408
Average total loss: 0.084704
tensor(0.0357, device='cuda:0') tensor(0.1790, device='cuda:0') tensor(2.0661e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.007451
Average KL loss: 0.077222
Average total loss: 0.084672
tensor(0.0357, device='cuda:0') tensor(0.1786, device='cuda:0') tensor(3.7387e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.007385
Average KL loss: 0.077050
Average total loss: 0.084436
tensor(0.0356, device='cuda:0') tensor(0.1782, device='cuda:0') tensor(3.1050e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.006994
Average KL loss: 0.076866
Average total loss: 0.083860
tensor(0.0356, device='cuda:0') tensor(0.1779, device='cuda:0') tensor(3.3571e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.008001
Average KL loss: 0.076692
Average total loss: 0.084692
tensor(0.0356, device='cuda:0') tensor(0.1775, device='cuda:0') tensor(-1.4344e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.007592
Average KL loss: 0.076535
Average total loss: 0.084127
tensor(0.0355, device='cuda:0') tensor(0.1772, device='cuda:0') tensor(2.6339e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.007104
Average KL loss: 0.076358
Average total loss: 0.083462
tensor(0.0355, device='cuda:0') tensor(0.1768, device='cuda:0') tensor(7.3442e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.007389
Average KL loss: 0.076178
Average total loss: 0.083568
tensor(0.0354, device='cuda:0') tensor(0.1764, device='cuda:0') tensor(5.1164e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.007278
Average KL loss: 0.076005
Average total loss: 0.083283
tensor(0.0354, device='cuda:0') tensor(0.1761, device='cuda:0') tensor(9.8802e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.007424
Average KL loss: 0.075837
Average total loss: 0.083262
tensor(0.0354, device='cuda:0') tensor(0.1757, device='cuda:0') tensor(-6.1412e-11, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.007394
Average KL loss: 0.075675
Average total loss: 0.083069
tensor(0.0354, device='cuda:0') tensor(0.1754, device='cuda:0') tensor(8.8743e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.007630
Average KL loss: 0.075502
Average total loss: 0.083131
tensor(0.0353, device='cuda:0') tensor(0.1750, device='cuda:0') tensor(2.2275e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.007723
Average KL loss: 0.075333
Average total loss: 0.083055
tensor(0.0353, device='cuda:0') tensor(0.1747, device='cuda:0') tensor(2.5053e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.008268
Average KL loss: 0.075176
Average total loss: 0.083444
tensor(0.0352, device='cuda:0') tensor(0.1743, device='cuda:0') tensor(2.8603e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.007980
Average KL loss: 0.075025
Average total loss: 0.083005
tensor(0.0352, device='cuda:0') tensor(0.1740, device='cuda:0') tensor(-4.1347e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.007450
Average KL loss: 0.074874
Average total loss: 0.082324
tensor(0.0352, device='cuda:0') tensor(0.1737, device='cuda:0') tensor(7.2409e-11, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.007173
Average KL loss: 0.074702
Average total loss: 0.081875
tensor(0.0351, device='cuda:0') tensor(0.1733, device='cuda:0') tensor(-6.4982e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.007855
Average KL loss: 0.074541
Average total loss: 0.082396
tensor(0.0351, device='cuda:0') tensor(0.1730, device='cuda:0') tensor(-5.6326e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.008194
Average KL loss: 0.074379
Average total loss: 0.082574
tensor(0.0351, device='cuda:0') tensor(0.1727, device='cuda:0') tensor(-9.4483e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.007273
Average KL loss: 0.074229
Average total loss: 0.081502
tensor(0.0350, device='cuda:0') tensor(0.1723, device='cuda:0') tensor(-6.4076e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.006889
Average KL loss: 0.074067
Average total loss: 0.080956
tensor(0.0350, device='cuda:0') tensor(0.1720, device='cuda:0') tensor(1.8485e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.007985
Average KL loss: 0.073906
Average total loss: 0.081891
tensor(0.0350, device='cuda:0') tensor(0.1717, device='cuda:0') tensor(-4.2462e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.007568
Average KL loss: 0.073764
Average total loss: 0.081332
tensor(0.0349, device='cuda:0') tensor(0.1714, device='cuda:0') tensor(8.6848e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.007961
Average KL loss: 0.073619
Average total loss: 0.081579
tensor(0.0349, device='cuda:0') tensor(0.1711, device='cuda:0') tensor(7.8931e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.007851
Average KL loss: 0.073480
Average total loss: 0.081331
tensor(0.0349, device='cuda:0') tensor(0.1708, device='cuda:0') tensor(-4.1617e-11, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.006664
Average KL loss: 0.073339
Average total loss: 0.080002
tensor(0.0348, device='cuda:0') tensor(0.1705, device='cuda:0') tensor(2.0925e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.007401
Average KL loss: 0.073179
Average total loss: 0.080580
tensor(0.0348, device='cuda:0') tensor(0.1701, device='cuda:0') tensor(6.6145e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.007632
Average KL loss: 0.073024
Average total loss: 0.080656
tensor(0.0348, device='cuda:0') tensor(0.1698, device='cuda:0') tensor(6.6838e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.007410
Average KL loss: 0.072871
Average total loss: 0.080282
tensor(0.0347, device='cuda:0') tensor(0.1695, device='cuda:0') tensor(1.4378e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.008464
Average KL loss: 0.072725
Average total loss: 0.081189
tensor(0.0347, device='cuda:0') tensor(0.1692, device='cuda:0') tensor(-1.0643e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.007639
Average KL loss: 0.072593
Average total loss: 0.080233
tensor(0.0347, device='cuda:0') tensor(0.1689, device='cuda:0') tensor(4.3384e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.006922
Average KL loss: 0.072450
Average total loss: 0.079372
tensor(0.0346, device='cuda:0') tensor(0.1686, device='cuda:0') tensor(-3.0892e-11, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.007752
Average KL loss: 0.072301
Average total loss: 0.080053
tensor(0.0346, device='cuda:0') tensor(0.1683, device='cuda:0') tensor(4.7791e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.007760
Average KL loss: 0.072167
Average total loss: 0.079928
tensor(0.0346, device='cuda:0') tensor(0.1680, device='cuda:0') tensor(4.4888e-11, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.007411
Average KL loss: 0.072020
Average total loss: 0.079432
tensor(0.0345, device='cuda:0') tensor(0.1677, device='cuda:0') tensor(1.8878e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.007610
Average KL loss: 0.071884
Average total loss: 0.079495
tensor(0.0345, device='cuda:0') tensor(0.1674, device='cuda:0') tensor(6.4422e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.007341
Average KL loss: 0.071746
Average total loss: 0.079087
tensor(0.0345, device='cuda:0') tensor(0.1671, device='cuda:0') tensor(-1.3149e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.007549
Average KL loss: 0.071596
Average total loss: 0.079145
tensor(0.0344, device='cuda:0') tensor(0.1668, device='cuda:0') tensor(6.3725e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.007651
Average KL loss: 0.071462
Average total loss: 0.079114
tensor(0.0344, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(9.9253e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.008309
Average KL loss: 0.071335
Average total loss: 0.079645
tensor(0.0344, device='cuda:0') tensor(0.1663, device='cuda:0') tensor(5.5637e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.007743
Average KL loss: 0.071210
Average total loss: 0.078953
tensor(0.0343, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(-5.0667e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.007397
Average KL loss: 0.071087
Average total loss: 0.078484
tensor(0.0343, device='cuda:0') tensor(0.1658, device='cuda:0') tensor(8.2012e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.007554
Average KL loss: 0.070956
Average total loss: 0.078509
tensor(0.0343, device='cuda:0') tensor(0.1655, device='cuda:0') tensor(3.1539e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.007660
Average KL loss: 0.070830
Average total loss: 0.078490
tensor(0.0342, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(8.2169e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.007163
Average KL loss: 0.070692
Average total loss: 0.077855
tensor(0.0342, device='cuda:0') tensor(0.1649, device='cuda:0') tensor(7.7335e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.008239
Average KL loss: 0.070556
Average total loss: 0.078795
tensor(0.0342, device='cuda:0') tensor(0.1646, device='cuda:0') tensor(1.2974e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.007721
Average KL loss: 0.070440
Average total loss: 0.078162
tensor(0.0341, device='cuda:0') tensor(0.1644, device='cuda:0') tensor(6.5053e-11, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.008189
Average KL loss: 0.070310
Average total loss: 0.078499
tensor(0.0341, device='cuda:0') tensor(0.1641, device='cuda:0') tensor(-1.2959e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.008095
Average KL loss: 0.070191
Average total loss: 0.078285
tensor(0.0341, device='cuda:0') tensor(0.1639, device='cuda:0') tensor(7.3925e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.007704
Average KL loss: 0.070077
Average total loss: 0.077781
tensor(0.0341, device='cuda:0') tensor(0.1636, device='cuda:0') tensor(4.3273e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.007604
Average KL loss: 0.069962
Average total loss: 0.077566
tensor(0.0340, device='cuda:0') tensor(0.1634, device='cuda:0') tensor(-1.0424e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.007855
Average KL loss: 0.069828
Average total loss: 0.077683
tensor(0.0340, device='cuda:0') tensor(0.1631, device='cuda:0') tensor(-5.7505e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.007609
Average KL loss: 0.069704
Average total loss: 0.077313
tensor(0.0340, device='cuda:0') tensor(0.1628, device='cuda:0') tensor(-3.9641e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.007402
Average KL loss: 0.069576
Average total loss: 0.076978
tensor(0.0339, device='cuda:0') tensor(0.1626, device='cuda:0') tensor(9.3494e-11, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.008664
Average KL loss: 0.069456
Average total loss: 0.078120
tensor(0.0339, device='cuda:0') tensor(0.1623, device='cuda:0') tensor(-8.3894e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.008079
Average KL loss: 0.069351
Average total loss: 0.077430
tensor(0.0339, device='cuda:0') tensor(0.1621, device='cuda:0') tensor(2.7347e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.007426
Average KL loss: 0.069233
Average total loss: 0.076659
tensor(0.0339, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(1.6595e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.008073
Average KL loss: 0.069107
Average total loss: 0.077181
tensor(0.0338, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(1.4082e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.007549
Average KL loss: 0.068990
Average total loss: 0.076539
 Percentile value: 4.473031139373779
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =     890 /    1728             ( 51.50%) | total_pruned =     838 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1810 /   36864             (  4.91%) | total_pruned =   35054 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2122 /   36864             (  5.76%) | total_pruned =   34742 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1859 /   36864             (  5.04%) | total_pruned =   35005 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1945 /   36864             (  5.28%) | total_pruned =   34919 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3177 /   73728             (  4.31%) | total_pruned =   70551 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4840 /  147456             (  3.28%) | total_pruned =  142616 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1867 /    8192             ( 22.79%) | total_pruned =    6325 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2952 /  147456             (  2.00%) | total_pruned =  144504 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2908 /  147456             (  1.97%) | total_pruned =  144548 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8194 /  294912             (  2.78%) | total_pruned =  286718 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     199 /     256             ( 77.73%) | total_pruned =      57 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   10638 /  589824             (  1.80%) | total_pruned =  579186 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4046 /   32768             ( 12.35%) | total_pruned =   28722 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     155 /     256             ( 60.55%) | total_pruned =     101 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    4211 /  589824             (  0.71%) | total_pruned =  585613 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     147 /     256             ( 57.42%) | total_pruned =     109 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3962 /  589824             (  0.67%) | total_pruned =  585862 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   11882 / 1179648             (  1.01%) | total_pruned = 1167766 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     421 /     512             ( 82.23%) | total_pruned =      91 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    6508 / 2359296             (  0.28%) | total_pruned = 2352788 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     136 /     512             ( 26.56%) | total_pruned =     376 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3133 /  131072             (  2.39%) | total_pruned =  127939 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     449 /     512             ( 87.70%) | total_pruned =      63 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     131 /     512             ( 25.59%) | total_pruned =     381 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3449 / 2359296             (  0.15%) | total_pruned = 2355847 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     275 /     512             ( 53.71%) | total_pruned =     237 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1217 / 2359296             (  0.05%) | total_pruned = 2358079 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
linear.weight        | nonzeros =    2536 /    5120             ( 49.53%) | total_pruned =    2584 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 26/200 Loss: 0.000946 Accuracy: 83.34 100.00 % Best test Accuracy: 83.52%
tensor(0.0338, device='cuda:0') tensor(0.1614, device='cuda:0') tensor(-4.1325e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.080769
Average KL loss: 0.047823
Average total loss: 0.128592
tensor(0.0258, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-1.8050e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.132286
Average KL loss: 0.042690
Average total loss: 0.174975
tensor(0.0257, device='cuda:0') tensor(0.0969, device='cuda:0') tensor(-1.7803e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.147213
Average KL loss: 0.042907
Average total loss: 0.190119
tensor(0.0262, device='cuda:0') tensor(0.1026, device='cuda:0') tensor(-1.8530e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.129982
Average KL loss: 0.043326
Average total loss: 0.173309
tensor(0.0267, device='cuda:0') tensor(0.1085, device='cuda:0') tensor(-9.2778e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.128745
Average KL loss: 0.043775
Average total loss: 0.172520
tensor(0.0272, device='cuda:0') tensor(0.1140, device='cuda:0') tensor(-7.7668e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.122925
Average KL loss: 0.044264
Average total loss: 0.167189
tensor(0.0276, device='cuda:0') tensor(0.1192, device='cuda:0') tensor(-1.7451e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.107463
Average KL loss: 0.044719
Average total loss: 0.152183
tensor(0.0280, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-7.7719e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.101441
Average KL loss: 0.045154
Average total loss: 0.146595
tensor(0.0285, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-9.0896e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.092341
Average KL loss: 0.045570
Average total loss: 0.137911
tensor(0.0289, device='cuda:0') tensor(0.1332, device='cuda:0') tensor(-8.7594e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.086785
Average KL loss: 0.045962
Average total loss: 0.132747
tensor(0.0292, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(-7.1978e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.081561
Average KL loss: 0.046374
Average total loss: 0.127935
tensor(0.0296, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-1.0851e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.075640
Average KL loss: 0.046732
Average total loss: 0.122372
tensor(0.0299, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-9.5002e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.074031
Average KL loss: 0.047075
Average total loss: 0.121107
tensor(0.0303, device='cuda:0') tensor(0.1489, device='cuda:0') tensor(-6.4624e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.065093
Average KL loss: 0.047397
Average total loss: 0.112490
tensor(0.0306, device='cuda:0') tensor(0.1523, device='cuda:0') tensor(-7.6582e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.058871
Average KL loss: 0.047679
Average total loss: 0.106551
tensor(0.0308, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-8.8731e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.059289
Average KL loss: 0.047942
Average total loss: 0.107231
tensor(0.0311, device='cuda:0') tensor(0.1583, device='cuda:0') tensor(-8.6815e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.056446
Average KL loss: 0.048224
Average total loss: 0.104670
tensor(0.0314, device='cuda:0') tensor(0.1614, device='cuda:0') tensor(-6.9497e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.053016
Average KL loss: 0.048497
Average total loss: 0.101513
tensor(0.0316, device='cuda:0') tensor(0.1645, device='cuda:0') tensor(-4.7861e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.049588
Average KL loss: 0.048762
Average total loss: 0.098350
tensor(0.0319, device='cuda:0') tensor(0.1673, device='cuda:0') tensor(-4.2838e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.048035
Average KL loss: 0.048998
Average total loss: 0.097033
tensor(0.0321, device='cuda:0') tensor(0.1701, device='cuda:0') tensor(-5.5563e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.044613
Average KL loss: 0.049207
Average total loss: 0.093819
tensor(0.0323, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-4.3482e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.044844
Average KL loss: 0.049412
Average total loss: 0.094256
tensor(0.0326, device='cuda:0') tensor(0.1755, device='cuda:0') tensor(-1.6323e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.039601
Average KL loss: 0.049606
Average total loss: 0.089206
tensor(0.0328, device='cuda:0') tensor(0.1779, device='cuda:0') tensor(-1.6861e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.037197
Average KL loss: 0.049765
Average total loss: 0.086962
tensor(0.0330, device='cuda:0') tensor(0.1802, device='cuda:0') tensor(-4.7994e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.034345
Average KL loss: 0.049941
Average total loss: 0.084286
tensor(0.0332, device='cuda:0') tensor(0.1825, device='cuda:0') tensor(-1.9479e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.035098
Average KL loss: 0.050106
Average total loss: 0.085204
tensor(0.0334, device='cuda:0') tensor(0.1848, device='cuda:0') tensor(-2.3738e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.033246
Average KL loss: 0.050280
Average total loss: 0.083526
tensor(0.0335, device='cuda:0') tensor(0.1871, device='cuda:0') tensor(-3.3183e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.031207
Average KL loss: 0.050447
Average total loss: 0.081654
tensor(0.0337, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(-1.3118e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.028722
Average KL loss: 0.050601
Average total loss: 0.079323
tensor(0.0339, device='cuda:0') tensor(0.1913, device='cuda:0') tensor(-2.9705e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.027405
Average KL loss: 0.050753
Average total loss: 0.078158
tensor(0.0341, device='cuda:0') tensor(0.1933, device='cuda:0') tensor(-2.8485e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.026783
Average KL loss: 0.050883
Average total loss: 0.077665
tensor(0.0342, device='cuda:0') tensor(0.1952, device='cuda:0') tensor(-2.0869e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.027016
Average KL loss: 0.051003
Average total loss: 0.078020
tensor(0.0344, device='cuda:0') tensor(0.1972, device='cuda:0') tensor(-5.3451e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.026758
Average KL loss: 0.051124
Average total loss: 0.077882
tensor(0.0345, device='cuda:0') tensor(0.1993, device='cuda:0') tensor(-1.5266e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.025279
Average KL loss: 0.051263
Average total loss: 0.076542
tensor(0.0347, device='cuda:0') tensor(0.2011, device='cuda:0') tensor(-2.4444e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.024239
Average KL loss: 0.051369
Average total loss: 0.075608
tensor(0.0348, device='cuda:0') tensor(0.2030, device='cuda:0') tensor(-1.4016e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.024280
Average KL loss: 0.051466
Average total loss: 0.075746
tensor(0.0350, device='cuda:0') tensor(0.2048, device='cuda:0') tensor(-1.9672e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.022567
Average KL loss: 0.051554
Average total loss: 0.074121
tensor(0.0351, device='cuda:0') tensor(0.2066, device='cuda:0') tensor(-1.4397e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.021755
Average KL loss: 0.051635
Average total loss: 0.073390
tensor(0.0352, device='cuda:0') tensor(0.2082, device='cuda:0') tensor(-7.5402e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.021777
Average KL loss: 0.051728
Average total loss: 0.073504
tensor(0.0354, device='cuda:0') tensor(0.2099, device='cuda:0') tensor(-1.4889e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.020455
Average KL loss: 0.051816
Average total loss: 0.072271
tensor(0.0355, device='cuda:0') tensor(0.2114, device='cuda:0') tensor(-1.3723e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.019279
Average KL loss: 0.051894
Average total loss: 0.071172
tensor(0.0356, device='cuda:0') tensor(0.2131, device='cuda:0') tensor(-9.2327e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.019791
Average KL loss: 0.051992
Average total loss: 0.071783
tensor(0.0357, device='cuda:0') tensor(0.2149, device='cuda:0') tensor(-2.4125e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.020018
Average KL loss: 0.052099
Average total loss: 0.072117
tensor(0.0359, device='cuda:0') tensor(0.2167, device='cuda:0') tensor(-1.3013e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.018611
Average KL loss: 0.052195
Average total loss: 0.070805
tensor(0.0360, device='cuda:0') tensor(0.2184, device='cuda:0') tensor(-5.1103e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.017397
Average KL loss: 0.052272
Average total loss: 0.069668
tensor(0.0361, device='cuda:0') tensor(0.2199, device='cuda:0') tensor(-1.3339e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.017244
Average KL loss: 0.052335
Average total loss: 0.069579
tensor(0.0362, device='cuda:0') tensor(0.2214, device='cuda:0') tensor(-7.3747e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.016712
Average KL loss: 0.052376
Average total loss: 0.069088
tensor(0.0363, device='cuda:0') tensor(0.2229, device='cuda:0') tensor(-4.4653e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.016176
Average KL loss: 0.052457
Average total loss: 0.068632
tensor(0.0364, device='cuda:0') tensor(0.2245, device='cuda:0') tensor(-1.7248e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.015788
Average KL loss: 0.052530
Average total loss: 0.068318
tensor(0.0365, device='cuda:0') tensor(0.2259, device='cuda:0') tensor(-2.1960e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.015832
Average KL loss: 0.052591
Average total loss: 0.068423
tensor(0.0366, device='cuda:0') tensor(0.2274, device='cuda:0') tensor(-6.5451e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.015179
Average KL loss: 0.052658
Average total loss: 0.067837
tensor(0.0368, device='cuda:0') tensor(0.2289, device='cuda:0') tensor(-5.5335e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.015084
Average KL loss: 0.052724
Average total loss: 0.067809
tensor(0.0368, device='cuda:0') tensor(0.2302, device='cuda:0') tensor(-6.5383e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.014353
Average KL loss: 0.052773
Average total loss: 0.067125
tensor(0.0369, device='cuda:0') tensor(0.2317, device='cuda:0') tensor(-9.6074e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.013346
Average KL loss: 0.052812
Average total loss: 0.066158
tensor(0.0370, device='cuda:0') tensor(0.2329, device='cuda:0') tensor(-1.5021e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.013301
Average KL loss: 0.052845
Average total loss: 0.066146
tensor(0.0371, device='cuda:0') tensor(0.2341, device='cuda:0') tensor(-9.3878e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.012706
Average KL loss: 0.052879
Average total loss: 0.065586
tensor(0.0372, device='cuda:0') tensor(0.2353, device='cuda:0') tensor(-5.0123e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.014269
Average KL loss: 0.052920
Average total loss: 0.067189
tensor(0.0373, device='cuda:0') tensor(0.2367, device='cuda:0') tensor(-2.0123e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.013097
Average KL loss: 0.052962
Average total loss: 0.066059
tensor(0.0374, device='cuda:0') tensor(0.2382, device='cuda:0') tensor(-3.2460e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.013566
Average KL loss: 0.053014
Average total loss: 0.066580
tensor(0.0374, device='cuda:0') tensor(0.2395, device='cuda:0') tensor(-8.1945e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.012444
Average KL loss: 0.053052
Average total loss: 0.065496
tensor(0.0375, device='cuda:0') tensor(0.2408, device='cuda:0') tensor(-4.1257e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.012509
Average KL loss: 0.053105
Average total loss: 0.065613
tensor(0.0376, device='cuda:0') tensor(0.2422, device='cuda:0') tensor(-6.9884e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.012347
Average KL loss: 0.053141
Average total loss: 0.065488
tensor(0.0377, device='cuda:0') tensor(0.2436, device='cuda:0') tensor(-3.6479e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.012900
Average KL loss: 0.053185
Average total loss: 0.066084
tensor(0.0378, device='cuda:0') tensor(0.2450, device='cuda:0') tensor(-1.9646e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.012243
Average KL loss: 0.053228
Average total loss: 0.065471
tensor(0.0379, device='cuda:0') tensor(0.2462, device='cuda:0') tensor(-5.2114e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.012103
Average KL loss: 0.053272
Average total loss: 0.065374
tensor(0.0380, device='cuda:0') tensor(0.2477, device='cuda:0') tensor(-1.2202e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.011575
Average KL loss: 0.053321
Average total loss: 0.064897
tensor(0.0381, device='cuda:0') tensor(0.2491, device='cuda:0') tensor(-4.9111e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.010934
Average KL loss: 0.053362
Average total loss: 0.064296
tensor(0.0381, device='cuda:0') tensor(0.2503, device='cuda:0') tensor(-2.4392e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.010688
Average KL loss: 0.053365
Average total loss: 0.064053
tensor(0.0382, device='cuda:0') tensor(0.2513, device='cuda:0') tensor(-8.3001e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.011333
Average KL loss: 0.053397
Average total loss: 0.064730
tensor(0.0383, device='cuda:0') tensor(0.2527, device='cuda:0') tensor(-1.2184e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.011065
Average KL loss: 0.053426
Average total loss: 0.064492
tensor(0.0384, device='cuda:0') tensor(0.2540, device='cuda:0') tensor(-1.0559e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.010516
Average KL loss: 0.053444
Average total loss: 0.063960
tensor(0.0384, device='cuda:0') tensor(0.2551, device='cuda:0') tensor(-2.7666e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.010492
Average KL loss: 0.053441
Average total loss: 0.063932
tensor(0.0385, device='cuda:0') tensor(0.2564, device='cuda:0') tensor(-4.3307e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.010217
Average KL loss: 0.053467
Average total loss: 0.063684
tensor(0.0386, device='cuda:0') tensor(0.2577, device='cuda:0') tensor(-8.6866e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.010179
Average KL loss: 0.053526
Average total loss: 0.063704
tensor(0.0387, device='cuda:0') tensor(0.2592, device='cuda:0') tensor(-1.1717e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.009805
Average KL loss: 0.053567
Average total loss: 0.063371
tensor(0.0388, device='cuda:0') tensor(0.2604, device='cuda:0') tensor(-1.8869e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.009539
Average KL loss: 0.053599
Average total loss: 0.063138
tensor(0.0388, device='cuda:0') tensor(0.2615, device='cuda:0') tensor(-9.9867e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.009180
Average KL loss: 0.053625
Average total loss: 0.062805
tensor(0.0389, device='cuda:0') tensor(0.2626, device='cuda:0') tensor(-4.6365e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.010313
Average KL loss: 0.053647
Average total loss: 0.063960
tensor(0.0390, device='cuda:0') tensor(0.2639, device='cuda:0') tensor(-8.9703e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.009325
Average KL loss: 0.053686
Average total loss: 0.063011
tensor(0.0390, device='cuda:0') tensor(0.2650, device='cuda:0') tensor(-5.2795e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.009177
Average KL loss: 0.053718
Average total loss: 0.062895
tensor(0.0391, device='cuda:0') tensor(0.2663, device='cuda:0') tensor(-9.1839e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.009104
Average KL loss: 0.053746
Average total loss: 0.062851
tensor(0.0392, device='cuda:0') tensor(0.2676, device='cuda:0') tensor(-6.5606e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.008996
Average KL loss: 0.053795
Average total loss: 0.062791
tensor(0.0392, device='cuda:0') tensor(0.2688, device='cuda:0') tensor(-1.0600e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.009044
Average KL loss: 0.053819
Average total loss: 0.062863
tensor(0.0393, device='cuda:0') tensor(0.2702, device='cuda:0') tensor(-5.0040e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.009594
Average KL loss: 0.053838
Average total loss: 0.063431
tensor(0.0394, device='cuda:0') tensor(0.2715, device='cuda:0') tensor(-4.4792e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.008780
Average KL loss: 0.053853
Average total loss: 0.062633
tensor(0.0395, device='cuda:0') tensor(0.2727, device='cuda:0') tensor(-2.4540e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.009313
Average KL loss: 0.053882
Average total loss: 0.063196
tensor(0.0395, device='cuda:0') tensor(0.2741, device='cuda:0') tensor(-2.4207e-11, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.009091
Average KL loss: 0.053924
Average total loss: 0.063015
tensor(0.0396, device='cuda:0') tensor(0.2755, device='cuda:0') tensor(-1.9142e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.009535
Average KL loss: 0.053945
Average total loss: 0.063480
tensor(0.0397, device='cuda:0') tensor(0.2768, device='cuda:0') tensor(-1.3234e-11, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.008903
Average KL loss: 0.053970
Average total loss: 0.062873
tensor(0.0397, device='cuda:0') tensor(0.2782, device='cuda:0') tensor(-9.2826e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.009113
Average KL loss: 0.053998
Average total loss: 0.063110
tensor(0.0398, device='cuda:0') tensor(0.2796, device='cuda:0') tensor(-1.0461e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.008793
Average KL loss: 0.054051
Average total loss: 0.062843
tensor(0.0399, device='cuda:0') tensor(0.2811, device='cuda:0') tensor(1.4250e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.008290
Average KL loss: 0.054084
Average total loss: 0.062373
tensor(0.0400, device='cuda:0') tensor(0.2822, device='cuda:0') tensor(-9.7045e-11, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.008605
Average KL loss: 0.054094
Average total loss: 0.062699
tensor(0.0400, device='cuda:0') tensor(0.2836, device='cuda:0') tensor(-1.2907e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.008664
Average KL loss: 0.054124
Average total loss: 0.062788
tensor(0.0401, device='cuda:0') tensor(0.2850, device='cuda:0') tensor(8.6747e-11, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.008811
Average KL loss: 0.054166
Average total loss: 0.062977
tensor(0.0402, device='cuda:0') tensor(0.2864, device='cuda:0') tensor(-6.3546e-11, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.007777
Average KL loss: 0.054210
Average total loss: 0.061987
tensor(0.0403, device='cuda:0') tensor(0.2877, device='cuda:0') tensor(-2.2463e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.008667
Average KL loss: 0.054220
Average total loss: 0.062887
tensor(0.0403, device='cuda:0') tensor(0.2891, device='cuda:0') tensor(-3.2840e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.008701
Average KL loss: 0.054253
Average total loss: 0.062955
tensor(0.0404, device='cuda:0') tensor(0.2908, device='cuda:0') tensor(-2.5105e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.007739
Average KL loss: 0.054294
Average total loss: 0.062033
tensor(0.0405, device='cuda:0') tensor(0.2920, device='cuda:0') tensor(-4.1298e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.007883
Average KL loss: 0.054306
Average total loss: 0.062189
tensor(0.0406, device='cuda:0') tensor(0.2932, device='cuda:0') tensor(-1.3793e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.007749
Average KL loss: 0.054325
Average total loss: 0.062074
tensor(0.0406, device='cuda:0') tensor(0.2944, device='cuda:0') tensor(-6.2997e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.008246
Average KL loss: 0.054357
Average total loss: 0.062603
tensor(0.0407, device='cuda:0') tensor(0.2958, device='cuda:0') tensor(-4.9880e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.007950
Average KL loss: 0.054379
Average total loss: 0.062329
tensor(0.0407, device='cuda:0') tensor(0.2971, device='cuda:0') tensor(-1.4609e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.007640
Average KL loss: 0.054409
Average total loss: 0.062049
tensor(0.0408, device='cuda:0') tensor(0.2984, device='cuda:0') tensor(-4.2597e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.007828
Average KL loss: 0.054424
Average total loss: 0.062252
tensor(0.0409, device='cuda:0') tensor(0.2997, device='cuda:0') tensor(-1.5798e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.008111
Average KL loss: 0.054433
Average total loss: 0.062544
tensor(0.0409, device='cuda:0') tensor(0.3010, device='cuda:0') tensor(-1.5737e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.007991
Average KL loss: 0.054444
Average total loss: 0.062435
tensor(0.0410, device='cuda:0') tensor(0.3024, device='cuda:0') tensor(-1.8281e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.007581
Average KL loss: 0.054443
Average total loss: 0.062024
tensor(0.0410, device='cuda:0') tensor(0.3024, device='cuda:0') tensor(-1.0689e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.007179
Average KL loss: 0.054434
Average total loss: 0.061613
tensor(0.0410, device='cuda:0') tensor(0.3024, device='cuda:0') tensor(-3.2487e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.007133
Average KL loss: 0.054425
Average total loss: 0.061558
tensor(0.0410, device='cuda:0') tensor(0.3025, device='cuda:0') tensor(-5.6326e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.007415
Average KL loss: 0.054417
Average total loss: 0.061832
tensor(0.0410, device='cuda:0') tensor(0.3025, device='cuda:0') tensor(-1.0681e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.007462
Average KL loss: 0.054409
Average total loss: 0.061871
tensor(0.0410, device='cuda:0') tensor(0.3025, device='cuda:0') tensor(-4.2329e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.007231
Average KL loss: 0.054401
Average total loss: 0.061632
tensor(0.0410, device='cuda:0') tensor(0.3025, device='cuda:0') tensor(1.4572e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.006767
Average KL loss: 0.054393
Average total loss: 0.061160
tensor(0.0410, device='cuda:0') tensor(0.3025, device='cuda:0') tensor(1.1923e-11, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.006769
Average KL loss: 0.054384
Average total loss: 0.061154
tensor(0.0411, device='cuda:0') tensor(0.3025, device='cuda:0') tensor(-2.8258e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.007128
Average KL loss: 0.054375
Average total loss: 0.061502
tensor(0.0411, device='cuda:0') tensor(0.3025, device='cuda:0') tensor(-6.1799e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.007310
Average KL loss: 0.054366
Average total loss: 0.061676
tensor(0.0411, device='cuda:0') tensor(0.3025, device='cuda:0') tensor(-4.1007e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.006720
Average KL loss: 0.054357
Average total loss: 0.061076
tensor(0.0411, device='cuda:0') tensor(0.3025, device='cuda:0') tensor(1.2285e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.006953
Average KL loss: 0.054347
Average total loss: 0.061300
tensor(0.0411, device='cuda:0') tensor(0.3025, device='cuda:0') tensor(-2.9691e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.006422
Average KL loss: 0.054337
Average total loss: 0.060759
tensor(0.0411, device='cuda:0') tensor(0.3025, device='cuda:0') tensor(-1.9273e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.006441
Average KL loss: 0.054327
Average total loss: 0.060768
tensor(0.0411, device='cuda:0') tensor(0.3025, device='cuda:0') tensor(-1.3385e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.006430
Average KL loss: 0.054319
Average total loss: 0.060750
tensor(0.0411, device='cuda:0') tensor(0.3024, device='cuda:0') tensor(-9.0367e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.006263
Average KL loss: 0.054308
Average total loss: 0.060571
tensor(0.0411, device='cuda:0') tensor(0.3024, device='cuda:0') tensor(-1.3006e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.006673
Average KL loss: 0.054298
Average total loss: 0.060971
tensor(0.0411, device='cuda:0') tensor(0.3024, device='cuda:0') tensor(-5.9507e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.006296
Average KL loss: 0.054289
Average total loss: 0.060585
tensor(0.0411, device='cuda:0') tensor(0.3024, device='cuda:0') tensor(-2.9199e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.006459
Average KL loss: 0.054278
Average total loss: 0.060737
tensor(0.0411, device='cuda:0') tensor(0.3024, device='cuda:0') tensor(-2.4945e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.006354
Average KL loss: 0.054269
Average total loss: 0.060623
tensor(0.0411, device='cuda:0') tensor(0.3024, device='cuda:0') tensor(1.2338e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.006394
Average KL loss: 0.054259
Average total loss: 0.060653
tensor(0.0411, device='cuda:0') tensor(0.3024, device='cuda:0') tensor(-5.0548e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.006340
Average KL loss: 0.054249
Average total loss: 0.060589
tensor(0.0411, device='cuda:0') tensor(0.3024, device='cuda:0') tensor(-1.8008e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.006051
Average KL loss: 0.054237
Average total loss: 0.060288
tensor(0.0411, device='cuda:0') tensor(0.3023, device='cuda:0') tensor(-4.5735e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.006061
Average KL loss: 0.054228
Average total loss: 0.060289
tensor(0.0411, device='cuda:0') tensor(0.3023, device='cuda:0') tensor(-1.1980e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.006079
Average KL loss: 0.054218
Average total loss: 0.060297
tensor(0.0411, device='cuda:0') tensor(0.3023, device='cuda:0') tensor(-2.0450e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.006390
Average KL loss: 0.054207
Average total loss: 0.060597
tensor(0.0411, device='cuda:0') tensor(0.3023, device='cuda:0') tensor(-5.5450e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.006309
Average KL loss: 0.054198
Average total loss: 0.060508
tensor(0.0411, device='cuda:0') tensor(0.3023, device='cuda:0') tensor(-6.9840e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.006034
Average KL loss: 0.054189
Average total loss: 0.060223
tensor(0.0411, device='cuda:0') tensor(0.3023, device='cuda:0') tensor(-7.3619e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.006041
Average KL loss: 0.054179
Average total loss: 0.060220
tensor(0.0411, device='cuda:0') tensor(0.3023, device='cuda:0') tensor(-3.3572e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.006192
Average KL loss: 0.054170
Average total loss: 0.060362
tensor(0.0411, device='cuda:0') tensor(0.3023, device='cuda:0') tensor(-7.8871e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.005811
Average KL loss: 0.054160
Average total loss: 0.059971
tensor(0.0411, device='cuda:0') tensor(0.3022, device='cuda:0') tensor(1.5510e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.005970
Average KL loss: 0.054149
Average total loss: 0.060119
tensor(0.0411, device='cuda:0') tensor(0.3022, device='cuda:0') tensor(-2.1717e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.005938
Average KL loss: 0.054139
Average total loss: 0.060077
tensor(0.0411, device='cuda:0') tensor(0.3022, device='cuda:0') tensor(-1.2995e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.005948
Average KL loss: 0.054128
Average total loss: 0.060076
tensor(0.0411, device='cuda:0') tensor(0.3021, device='cuda:0') tensor(2.6526e-11, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.005691
Average KL loss: 0.054117
Average total loss: 0.059808
tensor(0.0411, device='cuda:0') tensor(0.3021, device='cuda:0') tensor(-2.4340e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.006078
Average KL loss: 0.054104
Average total loss: 0.060181
tensor(0.0411, device='cuda:0') tensor(0.3021, device='cuda:0') tensor(-4.4550e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.005880
Average KL loss: 0.054092
Average total loss: 0.059972
tensor(0.0411, device='cuda:0') tensor(0.3021, device='cuda:0') tensor(9.1259e-11, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.005978
Average KL loss: 0.054081
Average total loss: 0.060059
tensor(0.0411, device='cuda:0') tensor(0.3021, device='cuda:0') tensor(-4.8030e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.005964
Average KL loss: 0.054071
Average total loss: 0.060035
tensor(0.0411, device='cuda:0') tensor(0.3021, device='cuda:0') tensor(-5.1903e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.005769
Average KL loss: 0.054059
Average total loss: 0.059828
tensor(0.0411, device='cuda:0') tensor(0.3020, device='cuda:0') tensor(-3.5370e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.005907
Average KL loss: 0.054047
Average total loss: 0.059954
tensor(0.0411, device='cuda:0') tensor(0.3020, device='cuda:0') tensor(-1.5125e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.005711
Average KL loss: 0.054035
Average total loss: 0.059746
tensor(0.0411, device='cuda:0') tensor(0.3020, device='cuda:0') tensor(-4.0086e-11, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.005793
Average KL loss: 0.054023
Average total loss: 0.059816
tensor(0.0411, device='cuda:0') tensor(0.3019, device='cuda:0') tensor(-2.4380e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.005666
Average KL loss: 0.054013
Average total loss: 0.059678
tensor(0.0411, device='cuda:0') tensor(0.3019, device='cuda:0') tensor(-2.2077e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.005784
Average KL loss: 0.054002
Average total loss: 0.059785
tensor(0.0411, device='cuda:0') tensor(0.3019, device='cuda:0') tensor(-1.2451e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.005791
Average KL loss: 0.053989
Average total loss: 0.059779
tensor(0.0411, device='cuda:0') tensor(0.3018, device='cuda:0') tensor(-1.7506e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.005451
Average KL loss: 0.053978
Average total loss: 0.059429
tensor(0.0411, device='cuda:0') tensor(0.3018, device='cuda:0') tensor(-2.9407e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.005420
Average KL loss: 0.053965
Average total loss: 0.059385
tensor(0.0411, device='cuda:0') tensor(0.3017, device='cuda:0') tensor(1.3548e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.005280
Average KL loss: 0.053953
Average total loss: 0.059234
tensor(0.0411, device='cuda:0') tensor(0.3017, device='cuda:0') tensor(-1.8750e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.005655
Average KL loss: 0.053940
Average total loss: 0.059595
tensor(0.0411, device='cuda:0') tensor(0.3017, device='cuda:0') tensor(-8.4772e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.005209
Average KL loss: 0.053927
Average total loss: 0.059137
tensor(0.0411, device='cuda:0') tensor(0.3016, device='cuda:0') tensor(-2.1865e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.005366
Average KL loss: 0.053918
Average total loss: 0.059283
tensor(0.0411, device='cuda:0') tensor(0.3016, device='cuda:0') tensor(-1.5056e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.005197
Average KL loss: 0.053907
Average total loss: 0.059104
tensor(0.0411, device='cuda:0') tensor(0.3016, device='cuda:0') tensor(3.3165e-11, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.005213
Average KL loss: 0.053891
Average total loss: 0.059104
tensor(0.0411, device='cuda:0') tensor(0.3015, device='cuda:0') tensor(1.4393e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.005300
Average KL loss: 0.053878
Average total loss: 0.059178
tensor(0.0411, device='cuda:0') tensor(0.3015, device='cuda:0') tensor(1.0558e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.005560
Average KL loss: 0.053866
Average total loss: 0.059427
tensor(0.0411, device='cuda:0') tensor(0.3014, device='cuda:0') tensor(-1.3713e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.005576
Average KL loss: 0.053853
Average total loss: 0.059430
tensor(0.0411, device='cuda:0') tensor(0.3014, device='cuda:0') tensor(-1.9679e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.005334
Average KL loss: 0.053843
Average total loss: 0.059177
tensor(0.0411, device='cuda:0') tensor(0.3013, device='cuda:0') tensor(1.1303e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.005456
Average KL loss: 0.053828
Average total loss: 0.059284
tensor(0.0411, device='cuda:0') tensor(0.3013, device='cuda:0') tensor(-3.9817e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.005124
Average KL loss: 0.053814
Average total loss: 0.058938
tensor(0.0411, device='cuda:0') tensor(0.3012, device='cuda:0') tensor(1.5726e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.005346
Average KL loss: 0.053800
Average total loss: 0.059147
tensor(0.0411, device='cuda:0') tensor(0.3012, device='cuda:0') tensor(-1.6435e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.005087
Average KL loss: 0.053787
Average total loss: 0.058874
tensor(0.0411, device='cuda:0') tensor(0.3011, device='cuda:0') tensor(-4.0792e-11, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.005075
Average KL loss: 0.053772
Average total loss: 0.058847
tensor(0.0411, device='cuda:0') tensor(0.3010, device='cuda:0') tensor(-2.4821e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.005266
Average KL loss: 0.053757
Average total loss: 0.059023
tensor(0.0411, device='cuda:0') tensor(0.3010, device='cuda:0') tensor(-7.5437e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.005253
Average KL loss: 0.053744
Average total loss: 0.058997
tensor(0.0411, device='cuda:0') tensor(0.3009, device='cuda:0') tensor(-2.9690e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.005237
Average KL loss: 0.053732
Average total loss: 0.058968
tensor(0.0411, device='cuda:0') tensor(0.3009, device='cuda:0') tensor(-1.6261e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.005163
Average KL loss: 0.053718
Average total loss: 0.058881
tensor(0.0411, device='cuda:0') tensor(0.3008, device='cuda:0') tensor(-9.8186e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.004997
Average KL loss: 0.053704
Average total loss: 0.058701
tensor(0.0411, device='cuda:0') tensor(0.3007, device='cuda:0') tensor(-4.4359e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.005241
Average KL loss: 0.053689
Average total loss: 0.058930
tensor(0.0411, device='cuda:0') tensor(0.3007, device='cuda:0') tensor(-3.4167e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.005095
Average KL loss: 0.053675
Average total loss: 0.058770
tensor(0.0411, device='cuda:0') tensor(0.3006, device='cuda:0') tensor(1.6401e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.005205
Average KL loss: 0.053661
Average total loss: 0.058866
tensor(0.0411, device='cuda:0') tensor(0.3006, device='cuda:0') tensor(-2.9790e-11, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.005284
Average KL loss: 0.053644
Average total loss: 0.058929
tensor(0.0411, device='cuda:0') tensor(0.3005, device='cuda:0') tensor(-9.0717e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.005163
Average KL loss: 0.053628
Average total loss: 0.058791
tensor(0.0411, device='cuda:0') tensor(0.3004, device='cuda:0') tensor(4.6490e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.005206
Average KL loss: 0.053612
Average total loss: 0.058818
tensor(0.0411, device='cuda:0') tensor(0.3003, device='cuda:0') tensor(-4.7533e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.005181
Average KL loss: 0.053600
Average total loss: 0.058781
tensor(0.0411, device='cuda:0') tensor(0.3003, device='cuda:0') tensor(-2.3862e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.004985
Average KL loss: 0.053586
Average total loss: 0.058572
tensor(0.0411, device='cuda:0') tensor(0.3002, device='cuda:0') tensor(1.7024e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.004972
Average KL loss: 0.053570
Average total loss: 0.058542
tensor(0.0411, device='cuda:0') tensor(0.3001, device='cuda:0') tensor(7.0324e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.004735
Average KL loss: 0.053554
Average total loss: 0.058289
tensor(0.0411, device='cuda:0') tensor(0.3000, device='cuda:0') tensor(-1.0592e-12, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.004810
Average KL loss: 0.053537
Average total loss: 0.058347
tensor(0.0411, device='cuda:0') tensor(0.2999, device='cuda:0') tensor(-3.8899e-11, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.004876
Average KL loss: 0.053519
Average total loss: 0.058395
tensor(0.0411, device='cuda:0') tensor(0.2999, device='cuda:0') tensor(-3.2925e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.004919
Average KL loss: 0.053505
Average total loss: 0.058425
tensor(0.0411, device='cuda:0') tensor(0.2998, device='cuda:0') tensor(-2.0924e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.004926
Average KL loss: 0.053491
Average total loss: 0.058416
tensor(0.0410, device='cuda:0') tensor(0.2997, device='cuda:0') tensor(-1.2450e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.004911
Average KL loss: 0.053476
Average total loss: 0.058387
tensor(0.0410, device='cuda:0') tensor(0.2996, device='cuda:0') tensor(7.9080e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.004866
Average KL loss: 0.053460
Average total loss: 0.058326
tensor(0.0410, device='cuda:0') tensor(0.2995, device='cuda:0') tensor(-8.5626e-11, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.004870
Average KL loss: 0.053442
Average total loss: 0.058313
tensor(0.0410, device='cuda:0') tensor(0.2994, device='cuda:0') tensor(-2.6645e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.004979
Average KL loss: 0.053427
Average total loss: 0.058406
tensor(0.0410, device='cuda:0') tensor(0.2993, device='cuda:0') tensor(-9.6614e-11, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.004854
Average KL loss: 0.053413
Average total loss: 0.058267
tensor(0.0410, device='cuda:0') tensor(0.2993, device='cuda:0') tensor(-7.4450e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.005433
Average KL loss: 0.053399
Average total loss: 0.058832
tensor(0.0410, device='cuda:0') tensor(0.2992, device='cuda:0') tensor(-2.4426e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.004847
Average KL loss: 0.053384
Average total loss: 0.058231
tensor(0.0410, device='cuda:0') tensor(0.2991, device='cuda:0') tensor(-3.2645e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.005031
Average KL loss: 0.053368
Average total loss: 0.058399
tensor(0.0410, device='cuda:0') tensor(0.2990, device='cuda:0') tensor(-2.5753e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.004635
Average KL loss: 0.053351
Average total loss: 0.057987
tensor(0.0410, device='cuda:0') tensor(0.2989, device='cuda:0') tensor(-1.4321e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.004655
Average KL loss: 0.053335
Average total loss: 0.057989
tensor(0.0410, device='cuda:0') tensor(0.2988, device='cuda:0') tensor(9.8349e-12, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.004546
Average KL loss: 0.053316
Average total loss: 0.057862
 Percentile value: 8.556967735290527
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     685 /    1728             ( 39.64%) | total_pruned =    1043 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     645 /   36864             (  1.75%) | total_pruned =   36219 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     704 /   36864             (  1.91%) | total_pruned =   36160 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     601 /   36864             (  1.63%) | total_pruned =   36263 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     658 /   36864             (  1.78%) | total_pruned =   36206 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1000 /   73728             (  1.36%) | total_pruned =   72728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1423 /  147456             (  0.97%) | total_pruned =  146033 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     842 /    8192             ( 10.28%) | total_pruned =    7350 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     902 /  147456             (  0.61%) | total_pruned =  146554 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     802 /  147456             (  0.54%) | total_pruned =  146654 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2174 /  294912             (  0.74%) | total_pruned =  292738 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     131 /     256             ( 51.17%) | total_pruned =     125 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2488 /  589824             (  0.42%) | total_pruned =  587336 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      63 /     256             ( 24.61%) | total_pruned =     193 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1312 /   32768             (  4.00%) | total_pruned =   31456 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1010 /  589824             (  0.17%) | total_pruned =  588814 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     178 /     256             ( 69.53%) | total_pruned =      78 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      54 /     256             ( 21.09%) | total_pruned =     202 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     936 /  589824             (  0.16%) | total_pruned =  588888 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      61 /     256             ( 23.83%) | total_pruned =     195 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2393 / 1179648             (  0.20%) | total_pruned = 1177255 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     174 /     512             ( 33.98%) | total_pruned =     338 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1341 / 2359296             (  0.06%) | total_pruned = 2357955 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     349 /     512             ( 68.16%) | total_pruned =     163 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     739 /  131072             (  0.56%) | total_pruned =  130333 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     296 /     512             ( 57.81%) | total_pruned =     216 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     805 / 2359296             (  0.03%) | total_pruned = 2358491 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     140 /     512             ( 27.34%) | total_pruned =     372 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     264 / 2359296             (  0.01%) | total_pruned = 2359032 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     310 /     512             ( 60.55%) | total_pruned =     202 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
linear.weight        | nonzeros =    1108 /    5120             ( 21.64%) | total_pruned =    4012 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 199/200 Loss: 0.239608 Accuracy: 70.82 98.37 % Best test Accuracy: 73.16%
tensor(0.0410, device='cuda:0') tensor(0.2987, device='cuda:0') tensor(-6.0101e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.145586
Average KL loss: 0.041676
Average total loss: 0.187261
tensor(0.0208, device='cuda:0') tensor(0.1348, device='cuda:0') tensor(-6.5669e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.359827
Average KL loss: 0.018818
Average total loss: 0.378645
tensor(0.0139, device='cuda:0') tensor(0.0940, device='cuda:0') tensor(-2.0111e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.536329
Average KL loss: 0.015751
Average total loss: 0.552081
tensor(0.0127, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(-6.7716e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.540249
Average KL loss: 0.015281
Average total loss: 0.555530
tensor(0.0124, device='cuda:0') tensor(0.0806, device='cuda:0') tensor(-2.1234e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.554993
Average KL loss: 0.015150
Average total loss: 0.570143
tensor(0.0123, device='cuda:0') tensor(0.0797, device='cuda:0') tensor(-2.9104e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.535212
Average KL loss: 0.015119
Average total loss: 0.550331
tensor(0.0123, device='cuda:0') tensor(0.0799, device='cuda:0') tensor(-1.8480e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.465693
Average KL loss: 0.015136
Average total loss: 0.480829
tensor(0.0124, device='cuda:0') tensor(0.0806, device='cuda:0') tensor(-3.3535e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.426176
Average KL loss: 0.015177
Average total loss: 0.441353
tensor(0.0125, device='cuda:0') tensor(0.0817, device='cuda:0') tensor(-1.2156e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.411317
Average KL loss: 0.015237
Average total loss: 0.426555
tensor(0.0126, device='cuda:0') tensor(0.0831, device='cuda:0') tensor(-2.0315e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.361839
Average KL loss: 0.015290
Average total loss: 0.377130
tensor(0.0127, device='cuda:0') tensor(0.0846, device='cuda:0') tensor(-1.5706e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.332321
Average KL loss: 0.015346
Average total loss: 0.347666
tensor(0.0128, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-1.6723e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.321564
Average KL loss: 0.015391
Average total loss: 0.336955
tensor(0.0130, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-2.4047e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.285534
Average KL loss: 0.015417
Average total loss: 0.300952
tensor(0.0130, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(-4.7680e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.288146
Average KL loss: 0.015428
Average total loss: 0.303574
tensor(0.0130, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(-1.9993e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.288256
Average KL loss: 0.015437
Average total loss: 0.303694
tensor(0.0130, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(-2.1295e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.281615
Average KL loss: 0.015445
Average total loss: 0.297061
tensor(0.0130, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(-2.0501e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.279267
Average KL loss: 0.015453
Average total loss: 0.294719
tensor(0.0130, device='cuda:0') tensor(0.0884, device='cuda:0') tensor(-1.0359e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.270936
Average KL loss: 0.015460
Average total loss: 0.286396
tensor(0.0131, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-1.1317e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.277907
Average KL loss: 0.015466
Average total loss: 0.293374
tensor(0.0131, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-1.9116e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.266558
Average KL loss: 0.015474
Average total loss: 0.282032
tensor(0.0131, device='cuda:0') tensor(0.0888, device='cuda:0') tensor(-1.1987e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.259968
Average KL loss: 0.015481
Average total loss: 0.275448
tensor(0.0131, device='cuda:0') tensor(0.0889, device='cuda:0') tensor(-9.5202e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.263283
Average KL loss: 0.015487
Average total loss: 0.278770
tensor(0.0131, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(-1.1672e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.247140
Average KL loss: 0.015494
Average total loss: 0.262634
tensor(0.0131, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(-1.3133e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.273585
Average KL loss: 0.015498
Average total loss: 0.289083
tensor(0.0131, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(-6.9109e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.266113
Average KL loss: 0.015499
Average total loss: 0.281612
tensor(0.0131, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(-6.9589e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.251144
Average KL loss: 0.015499
Average total loss: 0.266643
tensor(0.0131, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(-1.2347e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.244373
Average KL loss: 0.015500
Average total loss: 0.259873
tensor(0.0131, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(-8.0393e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.250073
Average KL loss: 0.015501
Average total loss: 0.265574
tensor(0.0131, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(-1.4325e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.267412
Average KL loss: 0.015502
Average total loss: 0.282914
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-9.3713e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.268811
Average KL loss: 0.015502
Average total loss: 0.284314
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.4154e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.251498
Average KL loss: 0.015503
Average total loss: 0.267001
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.5118e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.250304
Average KL loss: 0.015504
Average total loss: 0.265808
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.1048e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.254982
Average KL loss: 0.015505
Average total loss: 0.270487
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.0971e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.249598
Average KL loss: 0.015505
Average total loss: 0.265104
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-8.1579e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.247200
Average KL loss: 0.015506
Average total loss: 0.262706
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-7.9441e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.256782
Average KL loss: 0.015506
Average total loss: 0.272288
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.0392e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.255170
Average KL loss: 0.015506
Average total loss: 0.270676
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-8.8189e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.259332
Average KL loss: 0.015506
Average total loss: 0.274838
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-7.1793e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.248746
Average KL loss: 0.015506
Average total loss: 0.264252
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-9.5485e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.257031
Average KL loss: 0.015506
Average total loss: 0.272537
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.2010e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.240695
Average KL loss: 0.015506
Average total loss: 0.256201
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-6.2139e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.250190
Average KL loss: 0.015506
Average total loss: 0.265696
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-9.3707e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.268155
Average KL loss: 0.015507
Average total loss: 0.283662
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.2284e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.237802
Average KL loss: 0.015507
Average total loss: 0.253309
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-2.2803e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.248688
Average KL loss: 0.015507
Average total loss: 0.264195
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.2047e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.258271
Average KL loss: 0.015507
Average total loss: 0.273778
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-2.2520e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.269275
Average KL loss: 0.015507
Average total loss: 0.284782
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.0351e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.272132
Average KL loss: 0.015507
Average total loss: 0.287639
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-8.3567e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.251365
Average KL loss: 0.015507
Average total loss: 0.266871
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.2496e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.257455
Average KL loss: 0.015507
Average total loss: 0.272962
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.0393e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.260240
Average KL loss: 0.015507
Average total loss: 0.275747
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.3660e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.255767
Average KL loss: 0.015507
Average total loss: 0.271274
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-7.7897e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.246018
Average KL loss: 0.015507
Average total loss: 0.261525
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-9.8268e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.260255
Average KL loss: 0.015507
Average total loss: 0.275762
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.4711e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.238663
Average KL loss: 0.015507
Average total loss: 0.254170
tensor(0.0131, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.0821e-08, device='cuda:0')
 Percentile value: 8.421171188354492
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =     362 /    1728             ( 20.95%) | total_pruned =    1366 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
bn1.bias             | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     241 /   36864             (  0.65%) | total_pruned =   36623 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     277 /   36864             (  0.75%) | total_pruned =   36587 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     235 /   36864             (  0.64%) | total_pruned =   36629 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     242 /   36864             (  0.66%) | total_pruned =   36622 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     359 /   73728             (  0.49%) | total_pruned =   73369 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     473 /  147456             (  0.32%) | total_pruned =  146983 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     307 /    8192             (  3.75%) | total_pruned =    7885 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     276 /  147456             (  0.19%) | total_pruned =  147180 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     239 /  147456             (  0.16%) | total_pruned =  147217 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     579 /  294912             (  0.20%) | total_pruned =  294333 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     634 /  589824             (  0.11%) | total_pruned =  589190 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     131 /     256             ( 51.17%) | total_pruned =     125 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     335 /   32768             (  1.02%) | total_pruned =   32433 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     243 /  589824             (  0.04%) | total_pruned =  589581 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      74 /     256             ( 28.91%) | total_pruned =     182 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     216 /  589824             (  0.04%) | total_pruned =  589608 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      87 /     256             ( 33.98%) | total_pruned =     169 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     478 / 1179648             (  0.04%) | total_pruned = 1179170 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     126 /     512             ( 24.61%) | total_pruned =     386 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     256 / 2359296             (  0.01%) | total_pruned = 2359040 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     128 /     512             ( 25.00%) | total_pruned =     384 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     130 /  131072             (  0.10%) | total_pruned =  130942 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     153 / 2359296             (  0.01%) | total_pruned = 2359143 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      36 / 2359296             (  0.00%) | total_pruned = 2359260 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      62 /     512             ( 12.11%) | total_pruned =     450 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
linear.weight        | nonzeros =     320 /    5120             (  6.25%) | total_pruned =    4800 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 183/200 Loss: 1.308084 Accuracy: 49.83 52.10 % Best test Accuracy: 50.00%
