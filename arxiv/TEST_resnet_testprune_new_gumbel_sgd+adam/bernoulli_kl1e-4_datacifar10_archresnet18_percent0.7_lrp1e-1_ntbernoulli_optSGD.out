Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/200 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2827e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.289188
Average KL loss: 0.040061
Average total loss: 2.329249
tensor(-0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-5.6375e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.145351
Average KL loss: 0.716112
Average total loss: 1.861463
tensor(0.0026, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.6987e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.520145
Average KL loss: 0.869078
Average total loss: 1.389222
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4203e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.436012
Average KL loss: 0.737531
Average total loss: 1.173542
tensor(0.0030, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.0514e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.393579
Average KL loss: 0.672284
Average total loss: 1.065863
tensor(0.0030, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.8618e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.365791
Average KL loss: 0.643880
Average total loss: 1.009672
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.7083e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.349812
Average KL loss: 0.624357
Average total loss: 0.974169
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.1316e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.342791
Average KL loss: 0.614731
Average total loss: 0.957521
tensor(0.0031, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.0130e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.327976
Average KL loss: 0.607370
Average total loss: 0.935346
tensor(0.0032, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(6.2776e-11, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.322113
Average KL loss: 0.592123
Average total loss: 0.914237
tensor(0.0032, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.1023e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.315495
Average KL loss: 0.601501
Average total loss: 0.916996
tensor(0.0032, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-7.9388e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.316939
Average KL loss: 0.601162
Average total loss: 0.918102
tensor(0.0033, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(7.5680e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.311040
Average KL loss: 0.594276
Average total loss: 0.905316
tensor(0.0032, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.6640e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.305348
Average KL loss: 0.592750
Average total loss: 0.898098
tensor(0.0033, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.2241e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.303044
Average KL loss: 0.591958
Average total loss: 0.895001
tensor(0.0033, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-6.2300e-11, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.300768
Average KL loss: 0.592118
Average total loss: 0.892886
tensor(0.0034, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-2.1005e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.298350
Average KL loss: 0.591008
Average total loss: 0.889358
tensor(0.0033, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.3174e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.296021
Average KL loss: 0.590456
Average total loss: 0.886477
tensor(0.0033, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(3.2389e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.296012
Average KL loss: 0.587378
Average total loss: 0.883390
tensor(0.0034, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.5852e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.293133
Average KL loss: 0.586416
Average total loss: 0.879549
tensor(0.0034, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.9136e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.294510
Average KL loss: 0.598474
Average total loss: 0.892984
tensor(0.0035, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(3.4036e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.291490
Average KL loss: 0.590085
Average total loss: 0.881575
tensor(0.0034, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-6.5500e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.292926
Average KL loss: 0.597935
Average total loss: 0.890861
tensor(0.0034, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(1.2215e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.293196
Average KL loss: 0.602090
Average total loss: 0.895286
tensor(0.0034, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-8.1202e-11, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.289223
Average KL loss: 0.591562
Average total loss: 0.880785
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.1455e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.287915
Average KL loss: 0.590299
Average total loss: 0.878213
tensor(0.0034, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.7765e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.287750
Average KL loss: 0.593464
Average total loss: 0.881214
tensor(0.0035, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.4809e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.287398
Average KL loss: 0.599637
Average total loss: 0.887035
tensor(0.0035, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.1226e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.288272
Average KL loss: 0.592196
Average total loss: 0.880468
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.3782e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.288941
Average KL loss: 0.603572
Average total loss: 0.892513
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(1.8468e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.285232
Average KL loss: 0.591297
Average total loss: 0.876529
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.6707e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.283630
Average KL loss: 0.594906
Average total loss: 0.878536
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.7173e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.282637
Average KL loss: 0.597022
Average total loss: 0.879659
tensor(0.0035, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-9.3485e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.284345
Average KL loss: 0.603096
Average total loss: 0.887441
tensor(0.0036, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.4137e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.283552
Average KL loss: 0.601586
Average total loss: 0.885138
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.3543e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.280423
Average KL loss: 0.596371
Average total loss: 0.876794
tensor(0.0035, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.8968e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.279555
Average KL loss: 0.595641
Average total loss: 0.875196
tensor(0.0035, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.3612e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.281942
Average KL loss: 0.591345
Average total loss: 0.873286
tensor(0.0036, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(1.7419e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.280336
Average KL loss: 0.596158
Average total loss: 0.876494
tensor(0.0036, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-7.4728e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.279741
Average KL loss: 0.600794
Average total loss: 0.880535
tensor(0.0035, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.8782e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.281878
Average KL loss: 0.607070
Average total loss: 0.888948
tensor(0.0036, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.8576e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.280916
Average KL loss: 0.608459
Average total loss: 0.889376
tensor(0.0036, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.1440e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.279586
Average KL loss: 0.596571
Average total loss: 0.876157
tensor(0.0036, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.1439e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.279823
Average KL loss: 0.605538
Average total loss: 0.885361
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(2.6532e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.280433
Average KL loss: 0.601775
Average total loss: 0.882209
tensor(0.0036, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.0647e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.278471
Average KL loss: 0.597348
Average total loss: 0.875819
tensor(0.0036, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(3.8983e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.282639
Average KL loss: 0.606591
Average total loss: 0.889230
tensor(0.0036, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.4308e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.279193
Average KL loss: 0.606841
Average total loss: 0.886035
tensor(0.0037, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.6042e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.277485
Average KL loss: 0.600798
Average total loss: 0.878282
tensor(0.0037, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-6.4209e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.271894
Average KL loss: 0.449773
Average total loss: 0.721667
tensor(0.0036, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(9.4432e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.271184
Average KL loss: 0.363186
Average total loss: 0.634370
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.7844e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.269213
Average KL loss: 0.351980
Average total loss: 0.621193
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.7114e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.272578
Average KL loss: 0.347834
Average total loss: 0.620412
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.4718e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.271190
Average KL loss: 0.346398
Average total loss: 0.617588
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.0560e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.268221
Average KL loss: 0.344081
Average total loss: 0.612302
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.6163e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.271276
Average KL loss: 0.343967
Average total loss: 0.615243
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.5653e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.269132
Average KL loss: 0.342558
Average total loss: 0.611690
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(4.2396e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.268553
Average KL loss: 0.340537
Average total loss: 0.609090
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.5950e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.271110
Average KL loss: 0.341577
Average total loss: 0.612687
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.6712e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.272191
Average KL loss: 0.341310
Average total loss: 0.613501
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.4696e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.271219
Average KL loss: 0.340490
Average total loss: 0.611709
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.7576e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.271893
Average KL loss: 0.340622
Average total loss: 0.612514
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.5418e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.268789
Average KL loss: 0.339926
Average total loss: 0.608715
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.4118e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.271087
Average KL loss: 0.339647
Average total loss: 0.610734
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(7.1512e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.268659
Average KL loss: 0.338979
Average total loss: 0.607638
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.6156e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.270476
Average KL loss: 0.338504
Average total loss: 0.608981
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.3648e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.268464
Average KL loss: 0.337886
Average total loss: 0.606351
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.7964e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.270993
Average KL loss: 0.338341
Average total loss: 0.609335
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.0074e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.269026
Average KL loss: 0.337357
Average total loss: 0.606382
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(9.9147e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.272694
Average KL loss: 0.338395
Average total loss: 0.611088
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.4319e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.270672
Average KL loss: 0.338209
Average total loss: 0.608881
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(5.5886e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.271898
Average KL loss: 0.337798
Average total loss: 0.609696
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(4.0450e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.270949
Average KL loss: 0.338143
Average total loss: 0.609092
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.7193e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.272001
Average KL loss: 0.337458
Average total loss: 0.609460
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.5165e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.272469
Average KL loss: 0.337656
Average total loss: 0.610125
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.5301e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.272097
Average KL loss: 0.337488
Average total loss: 0.609585
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.4703e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.272357
Average KL loss: 0.338043
Average total loss: 0.610401
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-8.1203e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.271037
Average KL loss: 0.337406
Average total loss: 0.608443
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.1240e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.269141
Average KL loss: 0.331855
Average total loss: 0.600997
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.5418e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.272343
Average KL loss: 0.324463
Average total loss: 0.596806
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.6435e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.272154
Average KL loss: 0.320922
Average total loss: 0.593077
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.7165e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.271464
Average KL loss: 0.318787
Average total loss: 0.590251
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(8.9344e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.271010
Average KL loss: 0.317344
Average total loss: 0.588354
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(9.7046e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.270711
Average KL loss: 0.316216
Average total loss: 0.586928
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-8.8630e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.268705
Average KL loss: 0.315405
Average total loss: 0.584109
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.5717e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.268831
Average KL loss: 0.314690
Average total loss: 0.583521
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.3749e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.270702
Average KL loss: 0.314149
Average total loss: 0.584850
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(6.8923e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.269703
Average KL loss: 0.313709
Average total loss: 0.583412
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-5.0028e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.269508
Average KL loss: 0.313398
Average total loss: 0.582906
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.6536e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.271513
Average KL loss: 0.313109
Average total loss: 0.584622
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.2293e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.271181
Average KL loss: 0.312880
Average total loss: 0.584061
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.5348e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.270304
Average KL loss: 0.312716
Average total loss: 0.583020
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.4021e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.270426
Average KL loss: 0.312437
Average total loss: 0.582863
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.1796e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.269492
Average KL loss: 0.312280
Average total loss: 0.581773
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.6573e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.269992
Average KL loss: 0.312101
Average total loss: 0.582094
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.1592e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.269585
Average KL loss: 0.311951
Average total loss: 0.581536
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.8611e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.272320
Average KL loss: 0.311872
Average total loss: 0.584192
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.0375e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.269830
Average KL loss: 0.311840
Average total loss: 0.581670
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.5501e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.269908
Average KL loss: 0.311730
Average total loss: 0.581637
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(6.4544e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.273199
Average KL loss: 0.311605
Average total loss: 0.584804
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.6949e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.269257
Average KL loss: 0.311460
Average total loss: 0.580717
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.8166e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.270426
Average KL loss: 0.311352
Average total loss: 0.581778
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.8417e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.269905
Average KL loss: 0.311301
Average total loss: 0.581206
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.3467e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.272018
Average KL loss: 0.311317
Average total loss: 0.583335
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.5260e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.269081
Average KL loss: 0.311327
Average total loss: 0.580407
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.9533e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.268958
Average KL loss: 0.311220
Average total loss: 0.580178
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.2278e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.268912
Average KL loss: 0.311117
Average total loss: 0.580029
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.8627e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.271023
Average KL loss: 0.311031
Average total loss: 0.582054
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.2708e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.271030
Average KL loss: 0.311067
Average total loss: 0.582096
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.7226e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.269253
Average KL loss: 0.310970
Average total loss: 0.580223
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.6293e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.267037
Average KL loss: 0.310789
Average total loss: 0.577826
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-4.4764e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.268357
Average KL loss: 0.310750
Average total loss: 0.579107
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(9.5635e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.270859
Average KL loss: 0.310715
Average total loss: 0.581574
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(5.3577e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.270783
Average KL loss: 0.310747
Average total loss: 0.581530
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-6.7875e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.270188
Average KL loss: 0.310722
Average total loss: 0.580909
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.9149e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.270247
Average KL loss: 0.310667
Average total loss: 0.580914
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.5039e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.270168
Average KL loss: 0.310562
Average total loss: 0.580730
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.7820e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.270089
Average KL loss: 0.310509
Average total loss: 0.580598
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.1400e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.268962
Average KL loss: 0.310455
Average total loss: 0.579418
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.3080e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.270493
Average KL loss: 0.310471
Average total loss: 0.580965
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.9410e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.273030
Average KL loss: 0.310421
Average total loss: 0.583451
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(7.8842e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.270977
Average KL loss: 0.310405
Average total loss: 0.581383
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.1945e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.272283
Average KL loss: 0.310283
Average total loss: 0.582566
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.3879e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.269290
Average KL loss: 0.310063
Average total loss: 0.579353
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.2730e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.271862
Average KL loss: 0.309897
Average total loss: 0.581759
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.0235e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.272585
Average KL loss: 0.309776
Average total loss: 0.582361
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.5149e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.271462
Average KL loss: 0.309671
Average total loss: 0.581133
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.5447e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.270280
Average KL loss: 0.309575
Average total loss: 0.579856
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.5462e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.271030
Average KL loss: 0.309481
Average total loss: 0.580511
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.1861e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.272432
Average KL loss: 0.309397
Average total loss: 0.581829
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.5286e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.271936
Average KL loss: 0.309329
Average total loss: 0.581265
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.0925e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.272890
Average KL loss: 0.309259
Average total loss: 0.582149
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.5547e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.271467
Average KL loss: 0.309186
Average total loss: 0.580652
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.6767e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.270396
Average KL loss: 0.309148
Average total loss: 0.579544
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.2447e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.271227
Average KL loss: 0.309139
Average total loss: 0.580366
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.7773e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.270415
Average KL loss: 0.309130
Average total loss: 0.579545
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.0413e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.272176
Average KL loss: 0.309121
Average total loss: 0.581297
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.9457e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.270587
Average KL loss: 0.309112
Average total loss: 0.579698
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.3219e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.270174
Average KL loss: 0.309102
Average total loss: 0.579276
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(7.2867e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.270311
Average KL loss: 0.309094
Average total loss: 0.579406
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.8223e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.270129
Average KL loss: 0.309086
Average total loss: 0.579215
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.4316e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.271030
Average KL loss: 0.309078
Average total loss: 0.580109
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.0891e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.273179
Average KL loss: 0.309071
Average total loss: 0.582250
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.0499e-09, device='cuda:0')
 Percentile value: 0.006939223408699034
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =     457 /    1728             ( 26.45%) | total_pruned =    1271 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
bn1.bias             | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5297 /   36864             ( 14.37%) | total_pruned =   31567 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   11949 /   36864             ( 32.41%) | total_pruned =   24915 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   11525 /   36864             ( 31.26%) | total_pruned =   25339 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   13847 /   36864             ( 37.56%) | total_pruned =   23017 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   35046 /   73728             ( 47.53%) | total_pruned =   38682 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   69173 /  147456             ( 46.91%) | total_pruned =   78283 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4508 /    8192             ( 55.03%) | total_pruned =    3684 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   49482 /  147456             ( 33.56%) | total_pruned =   97974 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   42916 /  147456             ( 29.10%) | total_pruned =  104540 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  141968 /  294912             ( 48.14%) | total_pruned =  152944 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     139 /     256             ( 54.30%) | total_pruned =     117 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  275875 /  589824             ( 46.77%) | total_pruned =  313949 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   16156 /   32768             ( 49.30%) | total_pruned =   16612 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      87 /     256             ( 33.98%) | total_pruned =     169 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  230530 /  589824             ( 39.08%) | total_pruned =  359294 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  180049 /  589824             ( 30.53%) | total_pruned =  409775 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  450269 / 1179648             ( 38.17%) | total_pruned =  729379 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      90 /     512             ( 17.58%) | total_pruned =     422 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  529768 / 2359296             ( 22.45%) | total_pruned = 1829528 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     486 /     512             ( 94.92%) | total_pruned =      26 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     281 /     512             ( 54.88%) | total_pruned =     231 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   27312 /  131072             ( 20.84%) | total_pruned =  103760 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  558224 / 2359296             ( 23.66%) | total_pruned = 1801072 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  687480 / 2359296             ( 29.14%) | total_pruned = 1671816 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5075 /    5120             ( 99.12%) | total_pruned =      45 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 51/200 Loss: 0.017382 Accuracy: 88.96 100.00 % Best test Accuracy: 89.01%
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.4830e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.636399
Average KL loss: 0.739534
Average total loss: 1.375932
tensor(0.0038, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.5207e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.539470
Average KL loss: 0.649516
Average total loss: 1.188986
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.1271e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.472569
Average KL loss: 0.641335
Average total loss: 1.113904
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.0630e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.433916
Average KL loss: 0.621016
Average total loss: 1.054933
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.5092e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.410970
Average KL loss: 0.625570
Average total loss: 1.036540
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.8577e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.392217
Average KL loss: 0.612043
Average total loss: 1.004260
tensor(0.0036, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.4036e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.382857
Average KL loss: 0.609110
Average total loss: 0.991966
tensor(0.0036, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(2.6156e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.379178
Average KL loss: 0.610567
Average total loss: 0.989745
tensor(0.0036, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-7.6682e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.370656
Average KL loss: 0.606067
Average total loss: 0.976722
tensor(0.0037, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.4918e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.365733
Average KL loss: 0.609136
Average total loss: 0.974870
tensor(0.0037, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-6.1699e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.364368
Average KL loss: 0.610458
Average total loss: 0.974825
tensor(0.0038, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-3.1200e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.353958
Average KL loss: 0.603931
Average total loss: 0.957889
tensor(0.0038, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-5.4796e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.357689
Average KL loss: 0.619893
Average total loss: 0.977582
tensor(0.0038, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(9.6416e-11, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.347173
Average KL loss: 0.607105
Average total loss: 0.954277
tensor(0.0037, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(3.4351e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.347047
Average KL loss: 0.604659
Average total loss: 0.951706
tensor(0.0038, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.3890e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.351431
Average KL loss: 0.604670
Average total loss: 0.956102
tensor(0.0037, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.7201e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.347297
Average KL loss: 0.618206
Average total loss: 0.965503
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(4.9748e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.342460
Average KL loss: 0.611329
Average total loss: 0.953789
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.7359e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.338124
Average KL loss: 0.603971
Average total loss: 0.942095
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.1930e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.341575
Average KL loss: 0.611376
Average total loss: 0.952951
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.3151e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.337895
Average KL loss: 0.610645
Average total loss: 0.948540
tensor(0.0039, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(9.9059e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.341523
Average KL loss: 0.613777
Average total loss: 0.955300
tensor(0.0039, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-9.3970e-11, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.335104
Average KL loss: 0.609827
Average total loss: 0.944931
tensor(0.0039, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.1136e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.334484
Average KL loss: 0.607502
Average total loss: 0.941987
tensor(0.0039, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.1493e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.335689
Average KL loss: 0.609039
Average total loss: 0.944728
tensor(0.0038, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-7.4988e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.334387
Average KL loss: 0.611961
Average total loss: 0.946349
tensor(0.0039, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-4.3392e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.335353
Average KL loss: 0.616223
Average total loss: 0.951575
tensor(0.0040, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(4.1272e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.335217
Average KL loss: 0.619848
Average total loss: 0.955066
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(4.5155e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.330180
Average KL loss: 0.615068
Average total loss: 0.945249
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(3.9416e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.329361
Average KL loss: 0.617131
Average total loss: 0.946493
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.7984e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.330600
Average KL loss: 0.616027
Average total loss: 0.946627
tensor(0.0040, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(3.4920e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.331110
Average KL loss: 0.616191
Average total loss: 0.947301
tensor(0.0040, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(6.0175e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.332666
Average KL loss: 0.615367
Average total loss: 0.948033
tensor(0.0040, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-4.9368e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.330454
Average KL loss: 0.616183
Average total loss: 0.946637
tensor(0.0040, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(2.0766e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.330781
Average KL loss: 0.614226
Average total loss: 0.945006
tensor(0.0040, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(2.0098e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.326879
Average KL loss: 0.521570
Average total loss: 0.848449
tensor(0.0040, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.1518e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.319447
Average KL loss: 0.426656
Average total loss: 0.746103
tensor(0.0040, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(1.8548e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.316975
Average KL loss: 0.399773
Average total loss: 0.716748
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.9712e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.318057
Average KL loss: 0.387798
Average total loss: 0.705855
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(2.8325e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.318113
Average KL loss: 0.380826
Average total loss: 0.698939
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-7.5324e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.320404
Average KL loss: 0.377137
Average total loss: 0.697541
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.9490e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.316808
Average KL loss: 0.374190
Average total loss: 0.690998
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(7.3617e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.318221
Average KL loss: 0.372076
Average total loss: 0.690298
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.2225e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.321894
Average KL loss: 0.370550
Average total loss: 0.692444
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.4350e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.319060
Average KL loss: 0.369651
Average total loss: 0.688711
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.3510e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.319547
Average KL loss: 0.367621
Average total loss: 0.687168
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.2819e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.319410
Average KL loss: 0.367633
Average total loss: 0.687043
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(7.7880e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.322624
Average KL loss: 0.367694
Average total loss: 0.690317
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.5609e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.319481
Average KL loss: 0.367124
Average total loss: 0.686605
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-9.7778e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.321510
Average KL loss: 0.366737
Average total loss: 0.688248
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(3.9175e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.317762
Average KL loss: 0.365817
Average total loss: 0.683579
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(3.9398e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.320575
Average KL loss: 0.365868
Average total loss: 0.686443
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-9.6628e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.318232
Average KL loss: 0.365691
Average total loss: 0.683923
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.8789e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.320576
Average KL loss: 0.365320
Average total loss: 0.685896
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(4.3242e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.317396
Average KL loss: 0.365071
Average total loss: 0.682467
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.3471e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.316309
Average KL loss: 0.364135
Average total loss: 0.680444
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.5208e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.322944
Average KL loss: 0.364029
Average total loss: 0.686973
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(5.7467e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.320953
Average KL loss: 0.364215
Average total loss: 0.685168
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.5951e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.318981
Average KL loss: 0.363601
Average total loss: 0.682582
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.9948e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.321499
Average KL loss: 0.363596
Average total loss: 0.685095
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(5.2823e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.320444
Average KL loss: 0.363302
Average total loss: 0.683746
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.9821e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.320995
Average KL loss: 0.363132
Average total loss: 0.684126
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.1382e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.318339
Average KL loss: 0.363422
Average total loss: 0.681761
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.9039e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.320683
Average KL loss: 0.362984
Average total loss: 0.683667
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.5586e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.316180
Average KL loss: 0.361648
Average total loss: 0.677828
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.8444e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.320578
Average KL loss: 0.362200
Average total loss: 0.682778
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.4099e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.321912
Average KL loss: 0.362065
Average total loss: 0.683977
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.4702e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.319623
Average KL loss: 0.362172
Average total loss: 0.681794
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-2.7570e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.319885
Average KL loss: 0.361622
Average total loss: 0.681507
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.8280e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.321461
Average KL loss: 0.361875
Average total loss: 0.683337
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-7.4009e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.319353
Average KL loss: 0.361479
Average total loss: 0.680833
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-2.0858e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.323938
Average KL loss: 0.361842
Average total loss: 0.685780
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-9.4660e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.320025
Average KL loss: 0.361446
Average total loss: 0.681470
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(5.7258e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.321403
Average KL loss: 0.361100
Average total loss: 0.682503
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-8.7234e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.321053
Average KL loss: 0.360787
Average total loss: 0.681841
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.0083e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.319307
Average KL loss: 0.360595
Average total loss: 0.679902
tensor(0.0039, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.0060e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.322058
Average KL loss: 0.357540
Average total loss: 0.679598
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-2.0187e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.322459
Average KL loss: 0.353365
Average total loss: 0.675824
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-2.3406e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.322254
Average KL loss: 0.350627
Average total loss: 0.672881
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.8875e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.319853
Average KL loss: 0.348632
Average total loss: 0.668485
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-6.4419e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.315501
Average KL loss: 0.347117
Average total loss: 0.662618
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.3291e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.321358
Average KL loss: 0.345920
Average total loss: 0.667278
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.9505e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.320512
Average KL loss: 0.344916
Average total loss: 0.665428
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-5.3886e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.319717
Average KL loss: 0.344084
Average total loss: 0.663800
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.6101e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.321733
Average KL loss: 0.343310
Average total loss: 0.665043
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.9525e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.322404
Average KL loss: 0.342696
Average total loss: 0.665100
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.5265e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.320893
Average KL loss: 0.342112
Average total loss: 0.663005
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(8.2150e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.315636
Average KL loss: 0.341619
Average total loss: 0.657255
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(4.6273e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.320741
Average KL loss: 0.341175
Average total loss: 0.661917
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(5.2805e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.319421
Average KL loss: 0.340709
Average total loss: 0.660130
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(5.5203e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.318910
Average KL loss: 0.340331
Average total loss: 0.659241
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.2272e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.317946
Average KL loss: 0.339940
Average total loss: 0.657886
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.3755e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.317446
Average KL loss: 0.339569
Average total loss: 0.657015
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-5.8124e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.317501
Average KL loss: 0.339344
Average total loss: 0.656846
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.2411e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.321209
Average KL loss: 0.339045
Average total loss: 0.660255
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.2681e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.319831
Average KL loss: 0.338891
Average total loss: 0.658721
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(8.2198e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.320824
Average KL loss: 0.338656
Average total loss: 0.659480
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(5.0926e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.319760
Average KL loss: 0.338493
Average total loss: 0.658254
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.6113e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.321295
Average KL loss: 0.338380
Average total loss: 0.659675
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.0548e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.318342
Average KL loss: 0.338132
Average total loss: 0.656474
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.0635e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.319980
Average KL loss: 0.337913
Average total loss: 0.657894
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.6360e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.324610
Average KL loss: 0.337834
Average total loss: 0.662444
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.0731e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.316672
Average KL loss: 0.337655
Average total loss: 0.654327
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.1889e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.318774
Average KL loss: 0.337468
Average total loss: 0.656242
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.5281e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.318739
Average KL loss: 0.337357
Average total loss: 0.656095
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.7550e-11, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.319860
Average KL loss: 0.337263
Average total loss: 0.657123
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.1313e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.313248
Average KL loss: 0.337197
Average total loss: 0.650445
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-7.7165e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.317504
Average KL loss: 0.337082
Average total loss: 0.654587
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.6404e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.319294
Average KL loss: 0.336911
Average total loss: 0.656205
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.2866e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.319030
Average KL loss: 0.336869
Average total loss: 0.655899
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.4023e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.316727
Average KL loss: 0.336709
Average total loss: 0.653436
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(5.1039e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.322950
Average KL loss: 0.336500
Average total loss: 0.659450
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.7804e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.319800
Average KL loss: 0.336452
Average total loss: 0.656252
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.4646e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.318872
Average KL loss: 0.336424
Average total loss: 0.655296
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.9931e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.317263
Average KL loss: 0.336329
Average total loss: 0.653591
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-7.3734e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.316725
Average KL loss: 0.336269
Average total loss: 0.652994
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.8703e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.320420
Average KL loss: 0.336173
Average total loss: 0.656593
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.4302e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.318711
Average KL loss: 0.336202
Average total loss: 0.654914
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.2953e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.320892
Average KL loss: 0.336151
Average total loss: 0.657042
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.1158e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.317412
Average KL loss: 0.336055
Average total loss: 0.653467
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.0926e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.319927
Average KL loss: 0.335975
Average total loss: 0.655903
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.1747e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.325342
Average KL loss: 0.335905
Average total loss: 0.661247
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.2146e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.318401
Average KL loss: 0.335836
Average total loss: 0.654237
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-5.9566e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.322961
Average KL loss: 0.335782
Average total loss: 0.658742
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(4.3491e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.320291
Average KL loss: 0.335729
Average total loss: 0.656020
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.6434e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.315825
Average KL loss: 0.335675
Average total loss: 0.651500
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.2343e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.324815
Average KL loss: 0.335624
Average total loss: 0.660439
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.3642e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.323908
Average KL loss: 0.335578
Average total loss: 0.659487
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.9370e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.318203
Average KL loss: 0.335536
Average total loss: 0.653739
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.9244e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.322930
Average KL loss: 0.335511
Average total loss: 0.658442
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.3870e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.320555
Average KL loss: 0.335506
Average total loss: 0.656061
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.1741e-12, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.319878
Average KL loss: 0.335501
Average total loss: 0.655378
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-8.9014e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.319250
Average KL loss: 0.335495
Average total loss: 0.654745
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.6243e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.320330
Average KL loss: 0.335490
Average total loss: 0.655819
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.1536e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.315806
Average KL loss: 0.335484
Average total loss: 0.651290
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.0881e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.317050
Average KL loss: 0.335479
Average total loss: 0.652530
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7653e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.319014
Average KL loss: 0.335475
Average total loss: 0.654489
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7591e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.319992
Average KL loss: 0.335470
Average total loss: 0.655461
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.0425e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.318511
Average KL loss: 0.335464
Average total loss: 0.653976
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.5624e-10, device='cuda:0')
 Percentile value: 0.026260040700435635
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =     283 /    1728             ( 16.38%) | total_pruned =    1445 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
bn1.bias             | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1360 /   36864             (  3.69%) | total_pruned =   35504 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2709 /   36864             (  7.35%) | total_pruned =   34155 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2399 /   36864             (  6.51%) | total_pruned =   34465 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3267 /   36864             (  8.86%) | total_pruned =   33597 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13345 /   73728             ( 18.10%) | total_pruned =   60383 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   24844 /  147456             ( 16.85%) | total_pruned =  122612 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2060 /    8192             ( 25.15%) | total_pruned =    6132 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   14734 /  147456             (  9.99%) | total_pruned =  132722 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   12171 /  147456             (  8.25%) | total_pruned =  135285 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   59136 /  294912             ( 20.05%) | total_pruned =  235776 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  106492 /  589824             ( 18.05%) | total_pruned =  483332 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6996 /   32768             ( 21.35%) | total_pruned =   25772 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      67 /     256             ( 26.17%) | total_pruned =     189 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   70468 /  589824             ( 11.95%) | total_pruned =  519356 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   43601 /  589824             (  7.39%) | total_pruned =  546223 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  157677 / 1179648             ( 13.37%) | total_pruned = 1021971 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     487 /     512             ( 95.12%) | total_pruned =      25 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  128238 / 2359296             (  5.44%) | total_pruned = 2231058 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     407 /     512             ( 79.49%) | total_pruned =     105 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     192 /     512             ( 37.50%) | total_pruned =     320 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    4210 /  131072             (  3.21%) | total_pruned =  126862 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     196 /     512             ( 38.28%) | total_pruned =     316 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  124676 / 2359296             (  5.28%) | total_pruned = 2234620 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     418 /     512             ( 81.64%) | total_pruned =      94 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  217458 / 2359296             (  9.22%) | total_pruned = 2141838 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     479 /     512             ( 93.55%) | total_pruned =      33 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     472 /     512             ( 92.19%) | total_pruned =      40 | shape = torch.Size([512])
linear.weight        | nonzeros =    4603 /    5120             ( 89.90%) | total_pruned =     517 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 55/200 Loss: 0.014313 Accuracy: 88.58 100.00 % Best test Accuracy: 88.67%
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1968e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.710806
Average KL loss: 0.647953
Average total loss: 1.358759
tensor(0.0013, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.1815e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.634971
Average KL loss: 0.639039
Average total loss: 1.274011
tensor(0.0033, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1427e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.552143
Average KL loss: 0.630267
Average total loss: 1.182410
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.0289e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.522285
Average KL loss: 0.634198
Average total loss: 1.156483
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.4498e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.488819
Average KL loss: 0.628039
Average total loss: 1.116858
tensor(0.0036, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.2250e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.464489
Average KL loss: 0.623058
Average total loss: 1.087547
tensor(0.0037, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.0220e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.455895
Average KL loss: 0.623336
Average total loss: 1.079231
tensor(0.0037, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-5.3850e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.446740
Average KL loss: 0.627953
Average total loss: 1.074693
tensor(0.0038, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(4.2737e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.440418
Average KL loss: 0.626234
Average total loss: 1.066652
tensor(0.0038, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.0166e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.436647
Average KL loss: 0.628591
Average total loss: 1.065238
tensor(0.0038, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.1894e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.432799
Average KL loss: 0.630697
Average total loss: 1.063496
tensor(0.0039, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.4543e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.423935
Average KL loss: 0.631906
Average total loss: 1.055841
tensor(0.0038, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-6.5112e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.425784
Average KL loss: 0.633862
Average total loss: 1.059647
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.3062e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.416047
Average KL loss: 0.623929
Average total loss: 1.039976
tensor(0.0039, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(3.5144e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.413771
Average KL loss: 0.630664
Average total loss: 1.044435
tensor(0.0039, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.3801e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.414985
Average KL loss: 0.637360
Average total loss: 1.052345
tensor(-0.0021, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.5128e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.413787
Average KL loss: 0.636819
Average total loss: 1.050606
tensor(0.0045, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.0902e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.411433
Average KL loss: 0.640448
Average total loss: 1.051881
tensor(0.0039, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.2474e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.407488
Average KL loss: 0.637572
Average total loss: 1.045060
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.1979e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.410435
Average KL loss: 0.637067
Average total loss: 1.047502
tensor(0.0041, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.4023e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.406875
Average KL loss: 0.643183
Average total loss: 1.050059
tensor(0.0050, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.6227e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.403113
Average KL loss: 0.632772
Average total loss: 1.035885
tensor(0.0040, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.3566e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.410634
Average KL loss: 0.633334
Average total loss: 1.043968
tensor(0.0040, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(7.5294e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.405551
Average KL loss: 0.636556
Average total loss: 1.042107
tensor(0.0039, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.0891e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.407085
Average KL loss: 0.641955
Average total loss: 1.049040
tensor(0.0005, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-9.0696e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.402648
Average KL loss: 0.641027
Average total loss: 1.043674
tensor(0.0045, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(9.8283e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.401103
Average KL loss: 0.638471
Average total loss: 1.039574
tensor(0.0041, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.6854e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.405078
Average KL loss: 0.639486
Average total loss: 1.044564
tensor(0.0043, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(3.7357e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.400333
Average KL loss: 0.641013
Average total loss: 1.041347
tensor(0.0031, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.6446e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.403643
Average KL loss: 0.651045
Average total loss: 1.054688
tensor(0.0042, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(8.8698e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.399836
Average KL loss: 0.645193
Average total loss: 1.045028
tensor(0.0042, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.2034e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.399530
Average KL loss: 0.646038
Average total loss: 1.045567
tensor(0.0042, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(4.1920e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.403570
Average KL loss: 0.646045
Average total loss: 1.049615
tensor(0.0042, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(3.0167e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.388244
Average KL loss: 0.593480
Average total loss: 0.981723
tensor(0.0042, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.8865e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.383323
Average KL loss: 0.510908
Average total loss: 0.894232
tensor(0.0041, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-4.9265e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.384896
Average KL loss: 0.475368
Average total loss: 0.860264
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.4448e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.382748
Average KL loss: 0.454897
Average total loss: 0.837645
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(1.2777e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.384417
Average KL loss: 0.441440
Average total loss: 0.825858
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.0199e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.392436
Average KL loss: 0.432782
Average total loss: 0.825218
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(5.1247e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.382854
Average KL loss: 0.426942
Average total loss: 0.809797
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.8937e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.386438
Average KL loss: 0.421339
Average total loss: 0.807777
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-4.6105e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.385864
Average KL loss: 0.417831
Average total loss: 0.803696
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.6203e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.391570
Average KL loss: 0.415072
Average total loss: 0.806642
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(3.7419e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.388175
Average KL loss: 0.412946
Average total loss: 0.801121
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-5.5637e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.390893
Average KL loss: 0.411495
Average total loss: 0.802388
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(3.1715e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.383235
Average KL loss: 0.409955
Average total loss: 0.793190
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(2.3566e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.390290
Average KL loss: 0.407962
Average total loss: 0.798253
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-2.2655e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.389008
Average KL loss: 0.407409
Average total loss: 0.796417
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(6.3416e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.388652
Average KL loss: 0.405735
Average total loss: 0.794387
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.7569e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.387061
Average KL loss: 0.404482
Average total loss: 0.791543
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(4.3586e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.390709
Average KL loss: 0.403522
Average total loss: 0.794231
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-2.9755e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.390760
Average KL loss: 0.403362
Average total loss: 0.794122
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.4807e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.387982
Average KL loss: 0.402751
Average total loss: 0.790733
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.6497e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.390534
Average KL loss: 0.401868
Average total loss: 0.792402
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.3006e-11, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.393459
Average KL loss: 0.402371
Average total loss: 0.795830
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-3.5534e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.389680
Average KL loss: 0.401373
Average total loss: 0.791052
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(5.0300e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.391445
Average KL loss: 0.400508
Average total loss: 0.791953
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-4.9750e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.391214
Average KL loss: 0.400097
Average total loss: 0.791311
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.6437e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.389948
Average KL loss: 0.400365
Average total loss: 0.790313
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.0134e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.387665
Average KL loss: 0.400341
Average total loss: 0.788007
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.1280e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.390957
Average KL loss: 0.399421
Average total loss: 0.790378
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-3.7851e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.391625
Average KL loss: 0.398977
Average total loss: 0.790602
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.1142e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.391132
Average KL loss: 0.398569
Average total loss: 0.789701
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.9203e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.391616
Average KL loss: 0.398233
Average total loss: 0.789849
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.4813e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.390063
Average KL loss: 0.397837
Average total loss: 0.787900
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.2116e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.392354
Average KL loss: 0.398000
Average total loss: 0.790355
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-6.3316e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.391005
Average KL loss: 0.398146
Average total loss: 0.789151
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-4.0068e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.390756
Average KL loss: 0.397639
Average total loss: 0.788395
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.9424e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.389925
Average KL loss: 0.397519
Average total loss: 0.787444
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.3176e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.390852
Average KL loss: 0.396580
Average total loss: 0.787432
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(7.8270e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.389087
Average KL loss: 0.396962
Average total loss: 0.786048
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-7.4343e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.388542
Average KL loss: 0.395955
Average total loss: 0.784497
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-6.1786e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.391599
Average KL loss: 0.396261
Average total loss: 0.787861
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-4.3201e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.390350
Average KL loss: 0.395492
Average total loss: 0.785842
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-2.5996e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.388721
Average KL loss: 0.395214
Average total loss: 0.783935
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-6.2377e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.391552
Average KL loss: 0.395593
Average total loss: 0.787145
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.4172e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.390302
Average KL loss: 0.396174
Average total loss: 0.786476
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.0173e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.393179
Average KL loss: 0.395360
Average total loss: 0.788538
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.0154e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.393207
Average KL loss: 0.395959
Average total loss: 0.789166
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.9201e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.389941
Average KL loss: 0.396232
Average total loss: 0.786173
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-7.3708e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.392693
Average KL loss: 0.395821
Average total loss: 0.788514
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-3.1675e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.390049
Average KL loss: 0.395839
Average total loss: 0.785888
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.0452e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.389726
Average KL loss: 0.395443
Average total loss: 0.785169
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.9040e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.392400
Average KL loss: 0.395056
Average total loss: 0.787456
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.6169e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.396434
Average KL loss: 0.395738
Average total loss: 0.792172
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-3.1276e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.391473
Average KL loss: 0.395821
Average total loss: 0.787294
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.1965e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.388579
Average KL loss: 0.394115
Average total loss: 0.782694
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-6.3365e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.388846
Average KL loss: 0.391675
Average total loss: 0.780521
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-4.5889e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.389904
Average KL loss: 0.389851
Average total loss: 0.779756
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(6.4054e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.392403
Average KL loss: 0.388390
Average total loss: 0.780793
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.0774e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.387602
Average KL loss: 0.387139
Average total loss: 0.774741
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.9579e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.387036
Average KL loss: 0.385947
Average total loss: 0.772984
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.0971e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.388281
Average KL loss: 0.384912
Average total loss: 0.773193
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(2.0612e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.391422
Average KL loss: 0.383950
Average total loss: 0.775371
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-8.1228e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.384983
Average KL loss: 0.383147
Average total loss: 0.768130
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(2.5434e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.392519
Average KL loss: 0.382490
Average total loss: 0.775009
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-8.1902e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.393221
Average KL loss: 0.381924
Average total loss: 0.775145
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.1219e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.390344
Average KL loss: 0.381365
Average total loss: 0.771710
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.2291e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.387559
Average KL loss: 0.380785
Average total loss: 0.768344
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(4.8561e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.388648
Average KL loss: 0.380259
Average total loss: 0.768907
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(5.6035e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.390872
Average KL loss: 0.379755
Average total loss: 0.770627
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.5672e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.384354
Average KL loss: 0.379406
Average total loss: 0.763761
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.4231e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.393479
Average KL loss: 0.378907
Average total loss: 0.772386
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.6477e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.387899
Average KL loss: 0.378536
Average total loss: 0.766436
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(3.3568e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.388144
Average KL loss: 0.378198
Average total loss: 0.766343
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.8920e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.389458
Average KL loss: 0.377814
Average total loss: 0.767272
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(2.1687e-11, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.391275
Average KL loss: 0.377461
Average total loss: 0.768736
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.7381e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.387451
Average KL loss: 0.377164
Average total loss: 0.764615
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.6981e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.392182
Average KL loss: 0.376982
Average total loss: 0.769165
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(3.2478e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.388076
Average KL loss: 0.376774
Average total loss: 0.764849
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.5271e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.388724
Average KL loss: 0.376520
Average total loss: 0.765244
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.9320e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.390578
Average KL loss: 0.376297
Average total loss: 0.766875
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.0366e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.386736
Average KL loss: 0.375987
Average total loss: 0.762723
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.8243e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.389332
Average KL loss: 0.375789
Average total loss: 0.765121
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.7429e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.392422
Average KL loss: 0.375470
Average total loss: 0.767892
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.4472e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.389384
Average KL loss: 0.375244
Average total loss: 0.764628
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.1792e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.391544
Average KL loss: 0.375113
Average total loss: 0.766658
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(5.8812e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.388111
Average KL loss: 0.374929
Average total loss: 0.763040
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(4.9082e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.389744
Average KL loss: 0.374799
Average total loss: 0.764544
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.7053e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.390422
Average KL loss: 0.374646
Average total loss: 0.765068
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.4127e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.392666
Average KL loss: 0.374535
Average total loss: 0.767201
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(4.7011e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.386380
Average KL loss: 0.374288
Average total loss: 0.760668
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.7651e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.391202
Average KL loss: 0.374122
Average total loss: 0.765324
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.0464e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.391922
Average KL loss: 0.374010
Average total loss: 0.765932
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.1938e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.392552
Average KL loss: 0.373861
Average total loss: 0.766413
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.1910e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.390094
Average KL loss: 0.373739
Average total loss: 0.763834
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.6485e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.389698
Average KL loss: 0.373581
Average total loss: 0.763279
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.7930e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.388210
Average KL loss: 0.373398
Average total loss: 0.761608
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-8.7534e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.391482
Average KL loss: 0.373317
Average total loss: 0.764798
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(4.4953e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.383957
Average KL loss: 0.373244
Average total loss: 0.757201
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.6665e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.392205
Average KL loss: 0.372989
Average total loss: 0.765194
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.9675e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.391096
Average KL loss: 0.372814
Average total loss: 0.763910
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(4.6305e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.391592
Average KL loss: 0.372741
Average total loss: 0.764334
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(9.7971e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.390952
Average KL loss: 0.372739
Average total loss: 0.763691
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.7299e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.390650
Average KL loss: 0.372677
Average total loss: 0.763327
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.2639e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.390008
Average KL loss: 0.372635
Average total loss: 0.762643
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.4768e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.388187
Average KL loss: 0.372579
Average total loss: 0.760766
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(5.2873e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.388924
Average KL loss: 0.372486
Average total loss: 0.761410
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.2671e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.389034
Average KL loss: 0.372359
Average total loss: 0.761393
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-9.3457e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.390319
Average KL loss: 0.372193
Average total loss: 0.762512
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.1627e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.393435
Average KL loss: 0.372138
Average total loss: 0.765573
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.9035e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.391543
Average KL loss: 0.372138
Average total loss: 0.763681
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.8935e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.387025
Average KL loss: 0.372099
Average total loss: 0.759124
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.5238e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.394867
Average KL loss: 0.372065
Average total loss: 0.766932
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.3908e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.388952
Average KL loss: 0.372026
Average total loss: 0.760979
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.7851e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.392646
Average KL loss: 0.371991
Average total loss: 0.764637
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(5.4734e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.388405
Average KL loss: 0.371963
Average total loss: 0.760368
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.5998e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.391746
Average KL loss: 0.371937
Average total loss: 0.763683
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.6440e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.391230
Average KL loss: 0.371904
Average total loss: 0.763134
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(6.8212e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.388586
Average KL loss: 0.371870
Average total loss: 0.760456
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.6639e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.391518
Average KL loss: 0.371840
Average total loss: 0.763358
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.3840e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.384388
Average KL loss: 0.371808
Average total loss: 0.756196
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.7043e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.391407
Average KL loss: 0.371776
Average total loss: 0.763183
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.3588e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.390156
Average KL loss: 0.371745
Average total loss: 0.761902
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.3450e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.389392
Average KL loss: 0.371716
Average total loss: 0.761108
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.6001e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.389536
Average KL loss: 0.371684
Average total loss: 0.761220
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.3819e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.389881
Average KL loss: 0.371660
Average total loss: 0.761541
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.8323e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.384415
Average KL loss: 0.371635
Average total loss: 0.756050
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.6243e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.393423
Average KL loss: 0.371613
Average total loss: 0.765036
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.8735e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.390337
Average KL loss: 0.371590
Average total loss: 0.761927
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.3321e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.391370
Average KL loss: 0.371564
Average total loss: 0.762934
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.7469e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.391569
Average KL loss: 0.371544
Average total loss: 0.763112
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.3002e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.392010
Average KL loss: 0.371529
Average total loss: 0.763539
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.8125e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.386186
Average KL loss: 0.371512
Average total loss: 0.757698
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(5.7653e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.389864
Average KL loss: 0.371494
Average total loss: 0.761357
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-7.0981e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.384515
Average KL loss: 0.371469
Average total loss: 0.755984
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.2735e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.393157
Average KL loss: 0.371448
Average total loss: 0.764605
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-8.4678e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.388814
Average KL loss: 0.371438
Average total loss: 0.760252
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(8.1346e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.389066
Average KL loss: 0.371422
Average total loss: 0.760488
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-7.9098e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.386393
Average KL loss: 0.371409
Average total loss: 0.757802
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-8.0606e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.387378
Average KL loss: 0.371406
Average total loss: 0.758784
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.7229e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.391302
Average KL loss: 0.371404
Average total loss: 0.762706
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.4625e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.387444
Average KL loss: 0.371401
Average total loss: 0.758845
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(4.3958e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.391406
Average KL loss: 0.371400
Average total loss: 0.762806
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.7126e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.389462
Average KL loss: 0.371398
Average total loss: 0.760860
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.7926e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.390919
Average KL loss: 0.371395
Average total loss: 0.762314
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(5.9264e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.395402
Average KL loss: 0.371392
Average total loss: 0.766793
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.0555e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.388027
Average KL loss: 0.371390
Average total loss: 0.759417
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.3560e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.390547
Average KL loss: 0.371388
Average total loss: 0.761935
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.6046e-09, device='cuda:0')
 Percentile value: 0.09573643952608107
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =     179 /    1728             ( 10.36%) | total_pruned =    1549 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
bn1.bias             | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     379 /   36864             (  1.03%) | total_pruned =   36485 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     664 /   36864             (  1.80%) | total_pruned =   36200 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     603 /   36864             (  1.64%) | total_pruned =   36261 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1040 /   36864             (  2.82%) | total_pruned =   35824 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4656 /   73728             (  6.32%) | total_pruned =   69072 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    8596 /  147456             (  5.83%) | total_pruned =  138860 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     888 /    8192             ( 10.84%) | total_pruned =    7304 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4736 /  147456             (  3.21%) | total_pruned =  142720 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3724 /  147456             (  2.53%) | total_pruned =  143732 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   23238 /  294912             (  7.88%) | total_pruned =  271674 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      62 /     256             ( 24.22%) | total_pruned =     194 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   37026 /  589824             (  6.28%) | total_pruned =  552798 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2441 /   32768             (  7.45%) | total_pruned =   30327 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     180 /     256             ( 70.31%) | total_pruned =      76 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   20989 /  589824             (  3.56%) | total_pruned =  568835 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   13720 /  589824             (  2.33%) | total_pruned =  576104 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   42872 / 1179648             (  3.63%) | total_pruned = 1136776 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     441 /     512             ( 86.13%) | total_pruned =      71 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      36 /     512             (  7.03%) | total_pruned =     476 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   32229 / 2359296             (  1.37%) | total_pruned = 2327067 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     292 /     512             ( 57.03%) | total_pruned =     220 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     167 /     512             ( 32.62%) | total_pruned =     345 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     759 /  131072             (  0.58%) | total_pruned =  130313 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     135 /     512             ( 26.37%) | total_pruned =     377 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     168 /     512             ( 32.81%) | total_pruned =     344 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   33381 / 2359296             (  1.41%) | total_pruned = 2325915 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     242 /     512             ( 47.27%) | total_pruned =     270 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   61691 / 2359296             (  2.61%) | total_pruned = 2297605 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     413 /     512             ( 80.66%) | total_pruned =      99 | shape = torch.Size([512])
linear.weight        | nonzeros =    3835 /    5120             ( 74.90%) | total_pruned =    1285 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 64/200 Loss: 0.017445 Accuracy: 87.97 100.00 % Best test Accuracy: 88.17%
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.6179e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.717476
Average KL loss: 0.523222
Average total loss: 1.240697
tensor(0.0002, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.4853e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.712044
Average KL loss: 0.562277
Average total loss: 1.274321
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.1627e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.589752
Average KL loss: 0.566516
Average total loss: 1.156268
tensor(0.0030, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-8.1483e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.557450
Average KL loss: 0.570158
Average total loss: 1.127609
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6345e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.535391
Average KL loss: 0.576463
Average total loss: 1.111855
tensor(0.0032, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.5845e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.510081
Average KL loss: 0.577140
Average total loss: 1.087220
tensor(0.0032, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.7192e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.496451
Average KL loss: 0.574852
Average total loss: 1.071304
tensor(0.0033, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.4261e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.490912
Average KL loss: 0.578972
Average total loss: 1.069884
tensor(0.0033, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.0559e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.482773
Average KL loss: 0.580981
Average total loss: 1.063753
tensor(0.0033, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.0931e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.487221
Average KL loss: 0.584214
Average total loss: 1.071434
tensor(0.0034, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.4147e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.472633
Average KL loss: 0.586296
Average total loss: 1.058929
tensor(0.0034, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.4126e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.469116
Average KL loss: 0.589064
Average total loss: 1.058180
tensor(0.0034, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.4943e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.466658
Average KL loss: 0.590920
Average total loss: 1.057578
tensor(0.0034, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(5.1015e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.468703
Average KL loss: 0.589676
Average total loss: 1.058379
tensor(0.0034, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.0138e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.463249
Average KL loss: 0.591406
Average total loss: 1.054655
tensor(0.0035, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-7.2970e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.455727
Average KL loss: 0.595827
Average total loss: 1.051554
tensor(-0.0042, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.9172e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.454864
Average KL loss: 0.597465
Average total loss: 1.052328
tensor(0.0041, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.1446e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.462585
Average KL loss: 0.597354
Average total loss: 1.059939
tensor(0.0035, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.1528e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.455861
Average KL loss: 0.599939
Average total loss: 1.055800
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-8.5739e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.453300
Average KL loss: 0.598568
Average total loss: 1.051868
tensor(0.0043, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.9973e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.451853
Average KL loss: 0.599371
Average total loss: 1.051225
tensor(0.0047, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.7635e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.453178
Average KL loss: 0.598888
Average total loss: 1.052065
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.8770e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.448435
Average KL loss: 0.603952
Average total loss: 1.052388
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.4632e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.449554
Average KL loss: 0.601472
Average total loss: 1.051026
tensor(0.0031, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.3534e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.445393
Average KL loss: 0.601692
Average total loss: 1.047085
tensor(-0.0005, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.0535e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.447883
Average KL loss: 0.604413
Average total loss: 1.052296
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(7.8500e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.448256
Average KL loss: 0.605567
Average total loss: 1.053823
tensor(0.0037, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.7331e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.445072
Average KL loss: 0.609254
Average total loss: 1.054326
tensor(0.0044, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(1.4854e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.439812
Average KL loss: 0.609109
Average total loss: 1.048921
tensor(0.0027, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.9031e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.446855
Average KL loss: 0.612992
Average total loss: 1.059847
tensor(0.0039, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.9190e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.442544
Average KL loss: 0.606567
Average total loss: 1.049111
tensor(0.0038, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.8875e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.444980
Average KL loss: 0.607124
Average total loss: 1.052104
tensor(0.0038, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-5.4043e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.440309
Average KL loss: 0.607114
Average total loss: 1.047423
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(3.8556e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.442666
Average KL loss: 0.606425
Average total loss: 1.049091
tensor(0.0038, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.9410e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.442338
Average KL loss: 0.609411
Average total loss: 1.051749
tensor(0.0007, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-7.6869e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.442699
Average KL loss: 0.611838
Average total loss: 1.054537
tensor(0.0041, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(8.4516e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.436990
Average KL loss: 0.584406
Average total loss: 1.021397
tensor(0.0038, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(3.9341e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.430814
Average KL loss: 0.539323
Average total loss: 0.970137
tensor(0.0038, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(6.0805e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.425722
Average KL loss: 0.511564
Average total loss: 0.937287
tensor(0.0038, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.7410e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.427293
Average KL loss: 0.493088
Average total loss: 0.920381
tensor(0.0038, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(4.7931e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.429440
Average KL loss: 0.478440
Average total loss: 0.907880
tensor(0.0038, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-4.1989e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.425329
Average KL loss: 0.467416
Average total loss: 0.892744
tensor(0.0037, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-2.2984e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.423424
Average KL loss: 0.458897
Average total loss: 0.882321
tensor(0.0037, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.3200e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.428048
Average KL loss: 0.451415
Average total loss: 0.879464
tensor(0.0037, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.5085e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.421163
Average KL loss: 0.445620
Average total loss: 0.866783
tensor(0.0037, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(5.9039e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.426466
Average KL loss: 0.440424
Average total loss: 0.866890
tensor(0.0037, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(3.6823e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.423821
Average KL loss: 0.436424
Average total loss: 0.860245
tensor(0.0037, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-5.7578e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.428959
Average KL loss: 0.433218
Average total loss: 0.862177
tensor(0.0037, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(8.6790e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.427807
Average KL loss: 0.430317
Average total loss: 0.858124
tensor(0.0037, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(7.6036e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.434535
Average KL loss: 0.427684
Average total loss: 0.862219
tensor(0.0037, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.7551e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.426711
Average KL loss: 0.425495
Average total loss: 0.852205
tensor(0.0037, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.1494e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.428815
Average KL loss: 0.423260
Average total loss: 0.852075
tensor(0.0037, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.8736e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.428276
Average KL loss: 0.421555
Average total loss: 0.849831
tensor(0.0037, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.6733e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.428874
Average KL loss: 0.419942
Average total loss: 0.848816
tensor(0.0037, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(7.8833e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.426561
Average KL loss: 0.418796
Average total loss: 0.845358
tensor(0.0037, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.5119e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.429872
Average KL loss: 0.417318
Average total loss: 0.847190
tensor(0.0037, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.5005e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.429628
Average KL loss: 0.416238
Average total loss: 0.845866
tensor(0.0037, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.6259e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.427320
Average KL loss: 0.415083
Average total loss: 0.842403
tensor(0.0037, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.1749e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.427891
Average KL loss: 0.413747
Average total loss: 0.841638
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.1559e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.430035
Average KL loss: 0.412644
Average total loss: 0.842678
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(4.3256e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.429940
Average KL loss: 0.411469
Average total loss: 0.841410
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(8.8973e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.431103
Average KL loss: 0.410842
Average total loss: 0.841946
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.1975e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.430552
Average KL loss: 0.409893
Average total loss: 0.840445
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(4.9046e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.432360
Average KL loss: 0.409177
Average total loss: 0.841537
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.1910e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.434214
Average KL loss: 0.408890
Average total loss: 0.843105
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.8556e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.431129
Average KL loss: 0.408138
Average total loss: 0.839268
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.4699e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.433971
Average KL loss: 0.407617
Average total loss: 0.841588
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.5941e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.431970
Average KL loss: 0.407092
Average total loss: 0.839062
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.5494e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.436431
Average KL loss: 0.406381
Average total loss: 0.842813
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.3032e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.435577
Average KL loss: 0.406132
Average total loss: 0.841709
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.3238e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.429533
Average KL loss: 0.405705
Average total loss: 0.835238
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.9078e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.431973
Average KL loss: 0.404729
Average total loss: 0.836702
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.7450e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.433641
Average KL loss: 0.403996
Average total loss: 0.837637
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.3911e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.433388
Average KL loss: 0.403664
Average total loss: 0.837051
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.6889e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.439508
Average KL loss: 0.403183
Average total loss: 0.842691
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.9259e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.433582
Average KL loss: 0.403389
Average total loss: 0.836971
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.2318e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.433136
Average KL loss: 0.403096
Average total loss: 0.836231
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.6498e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.435820
Average KL loss: 0.402698
Average total loss: 0.838518
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.2863e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.437747
Average KL loss: 0.402221
Average total loss: 0.839968
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(7.1371e-11, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.437159
Average KL loss: 0.402667
Average total loss: 0.839826
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.9003e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.433013
Average KL loss: 0.402330
Average total loss: 0.835343
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.6874e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.433759
Average KL loss: 0.401986
Average total loss: 0.835744
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.7054e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.435582
Average KL loss: 0.400849
Average total loss: 0.836430
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-5.7071e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.429722
Average KL loss: 0.399841
Average total loss: 0.829563
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.9773e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.438694
Average KL loss: 0.398985
Average total loss: 0.837678
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.1037e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.432351
Average KL loss: 0.398227
Average total loss: 0.830578
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.6200e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.430808
Average KL loss: 0.397552
Average total loss: 0.828360
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.5509e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.430714
Average KL loss: 0.396922
Average total loss: 0.827635
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.8481e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.432639
Average KL loss: 0.396305
Average total loss: 0.828944
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.5514e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.430716
Average KL loss: 0.395766
Average total loss: 0.826482
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-6.8176e-12, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.432935
Average KL loss: 0.395192
Average total loss: 0.828127
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7794e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.433808
Average KL loss: 0.394685
Average total loss: 0.828492
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-6.2367e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.434525
Average KL loss: 0.394230
Average total loss: 0.828755
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.4202e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.434665
Average KL loss: 0.393818
Average total loss: 0.828483
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(5.8017e-11, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.432879
Average KL loss: 0.393420
Average total loss: 0.826299
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.1081e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.430961
Average KL loss: 0.392980
Average total loss: 0.823941
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.3842e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.437339
Average KL loss: 0.392580
Average total loss: 0.829920
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.3565e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.429495
Average KL loss: 0.392274
Average total loss: 0.821768
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.9223e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.432949
Average KL loss: 0.391961
Average total loss: 0.824910
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-8.4183e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.430238
Average KL loss: 0.391619
Average total loss: 0.821856
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.3805e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.431980
Average KL loss: 0.391242
Average total loss: 0.823222
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.0911e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.431890
Average KL loss: 0.390913
Average total loss: 0.822803
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.5185e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.436105
Average KL loss: 0.390625
Average total loss: 0.826730
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.3937e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.435175
Average KL loss: 0.390361
Average total loss: 0.825537
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.1037e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.432815
Average KL loss: 0.390163
Average total loss: 0.822978
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.0831e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.432084
Average KL loss: 0.389963
Average total loss: 0.822046
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.9092e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.433842
Average KL loss: 0.389746
Average total loss: 0.823588
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.7585e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.428977
Average KL loss: 0.389558
Average total loss: 0.818535
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.5258e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.431962
Average KL loss: 0.389312
Average total loss: 0.821274
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.7000e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.429082
Average KL loss: 0.389094
Average total loss: 0.818176
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(5.6138e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.435325
Average KL loss: 0.388883
Average total loss: 0.824208
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(9.7487e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.430661
Average KL loss: 0.388670
Average total loss: 0.819331
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.8060e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.433964
Average KL loss: 0.388424
Average total loss: 0.822388
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.4742e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.433220
Average KL loss: 0.388240
Average total loss: 0.821460
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-8.9449e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.431299
Average KL loss: 0.388093
Average total loss: 0.819392
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.4018e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.436429
Average KL loss: 0.387930
Average total loss: 0.824359
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(6.5260e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.434836
Average KL loss: 0.387705
Average total loss: 0.822541
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(6.5533e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.432273
Average KL loss: 0.387523
Average total loss: 0.819796
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(4.9231e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.429937
Average KL loss: 0.387381
Average total loss: 0.817318
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(8.8731e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.434075
Average KL loss: 0.387202
Average total loss: 0.821277
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.2792e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.435038
Average KL loss: 0.387026
Average total loss: 0.822063
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.7445e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.433291
Average KL loss: 0.386883
Average total loss: 0.820174
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.2184e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.430311
Average KL loss: 0.386758
Average total loss: 0.817069
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.1978e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.436419
Average KL loss: 0.386622
Average total loss: 0.823041
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.1246e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.433316
Average KL loss: 0.386477
Average total loss: 0.819793
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.3199e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.431826
Average KL loss: 0.386280
Average total loss: 0.818106
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.0637e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.437234
Average KL loss: 0.386120
Average total loss: 0.823354
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.3126e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.433119
Average KL loss: 0.386012
Average total loss: 0.819132
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.8846e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.431778
Average KL loss: 0.385809
Average total loss: 0.817587
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.4552e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.431891
Average KL loss: 0.385634
Average total loss: 0.817525
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(6.7108e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.434775
Average KL loss: 0.385446
Average total loss: 0.820221
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.6874e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.433688
Average KL loss: 0.385355
Average total loss: 0.819043
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.8237e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.434700
Average KL loss: 0.385253
Average total loss: 0.819953
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.2593e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.434067
Average KL loss: 0.385157
Average total loss: 0.819224
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.3978e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.433397
Average KL loss: 0.385065
Average total loss: 0.818462
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.4378e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.429965
Average KL loss: 0.385044
Average total loss: 0.815009
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.8049e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.431311
Average KL loss: 0.385023
Average total loss: 0.816334
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.0028e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.435998
Average KL loss: 0.384995
Average total loss: 0.820994
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.3529e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.434026
Average KL loss: 0.384970
Average total loss: 0.818996
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.8589e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.434335
Average KL loss: 0.384947
Average total loss: 0.819281
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.1898e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.433653
Average KL loss: 0.384921
Average total loss: 0.818574
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.5729e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.433945
Average KL loss: 0.384898
Average total loss: 0.818843
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(5.8011e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.432150
Average KL loss: 0.384877
Average total loss: 0.817027
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.0873e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.434081
Average KL loss: 0.384845
Average total loss: 0.818926
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.2909e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.431852
Average KL loss: 0.384816
Average total loss: 0.816668
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-8.9026e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.437377
Average KL loss: 0.384794
Average total loss: 0.822171
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(9.6638e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.434267
Average KL loss: 0.384772
Average total loss: 0.819039
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.7691e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.433539
Average KL loss: 0.384759
Average total loss: 0.818298
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.0871e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.433460
Average KL loss: 0.384756
Average total loss: 0.818216
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.0269e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.434705
Average KL loss: 0.384754
Average total loss: 0.819458
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.3758e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.433252
Average KL loss: 0.384751
Average total loss: 0.818003
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.5188e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.430324
Average KL loss: 0.384748
Average total loss: 0.815072
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.9040e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.435895
Average KL loss: 0.384746
Average total loss: 0.820642
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.5723e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.436304
Average KL loss: 0.384744
Average total loss: 0.821049
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.1870e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.432222
Average KL loss: 0.384741
Average total loss: 0.816964
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.6586e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.433153
Average KL loss: 0.384739
Average total loss: 0.817892
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(5.4677e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.434359
Average KL loss: 0.384736
Average total loss: 0.819095
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.1319e-09, device='cuda:0')
 Percentile value: 0.2994674324989319
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =     122 /    1728             (  7.06%) | total_pruned =    1606 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     163 /   36864             (  0.44%) | total_pruned =   36701 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     274 /   36864             (  0.74%) | total_pruned =   36590 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     258 /   36864             (  0.70%) | total_pruned =   36606 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     458 /   36864             (  1.24%) | total_pruned =   36406 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1967 /   73728             (  2.67%) | total_pruned =   71761 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3662 /  147456             (  2.48%) | total_pruned =  143794 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     460 /    8192             (  5.62%) | total_pruned =    7732 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2045 /  147456             (  1.39%) | total_pruned =  145411 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1622 /  147456             (  1.10%) | total_pruned =  145834 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    9414 /  294912             (  3.19%) | total_pruned =  285498 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   13623 /  589824             (  2.31%) | total_pruned =  576201 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     198 /     256             ( 77.34%) | total_pruned =      58 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     793 /   32768             (  2.42%) | total_pruned =   31975 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     132 /     256             ( 51.56%) | total_pruned =     124 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    7249 /  589824             (  1.23%) | total_pruned =  582575 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    5019 /  589824             (  0.85%) | total_pruned =  584805 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     129 /     256             ( 50.39%) | total_pruned =     127 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   11580 / 1179648             (  0.98%) | total_pruned = 1168068 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     380 /     512             ( 74.22%) | total_pruned =     132 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      28 /     512             (  5.47%) | total_pruned =     484 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    8731 / 2359296             (  0.37%) | total_pruned = 2350565 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     188 /     512             ( 36.72%) | total_pruned =     324 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     128 /     512             ( 25.00%) | total_pruned =     384 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     146 /  131072             (  0.11%) | total_pruned =  130926 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     132 /     512             ( 25.78%) | total_pruned =     380 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    7346 / 2359296             (  0.31%) | total_pruned = 2351950 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     146 /     512             ( 28.52%) | total_pruned =     366 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   10398 / 2359296             (  0.44%) | total_pruned = 2348898 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     338 /     512             ( 66.02%) | total_pruned =     174 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
linear.weight        | nonzeros =    1972 /    5120             ( 38.52%) | total_pruned =    3148 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 64/200 Loss: 0.033727 Accuracy: 86.81 99.99 % Best test Accuracy: 87.42%
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-5.4421e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.805367
Average KL loss: 0.429946
Average total loss: 1.235313
tensor(-0.0004, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.0632e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.778734
Average KL loss: 0.475433
Average total loss: 1.254167
tensor(0.0023, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.4600e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.646634
Average KL loss: 0.490082
Average total loss: 1.136716
tensor(0.0026, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3886e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.614608
Average KL loss: 0.502326
Average total loss: 1.116934
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-7.1021e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.583484
Average KL loss: 0.512874
Average total loss: 1.096357
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.5751e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.564496
Average KL loss: 0.519221
Average total loss: 1.083716
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.0455e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.539520
Average KL loss: 0.525575
Average total loss: 1.065095
tensor(0.0029, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.1208e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.523265
Average KL loss: 0.531187
Average total loss: 1.054452
tensor(0.0029, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.1925e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.517777
Average KL loss: 0.533787
Average total loss: 1.051564
tensor(0.0030, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.0613e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.512994
Average KL loss: 0.538652
Average total loss: 1.051646
tensor(0.0030, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-2.8069e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.507847
Average KL loss: 0.538792
Average total loss: 1.046639
tensor(0.0030, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(4.4559e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.505725
Average KL loss: 0.543624
Average total loss: 1.049349
tensor(0.0030, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(1.8375e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.495043
Average KL loss: 0.547657
Average total loss: 1.042700
tensor(0.0031, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.3539e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.488571
Average KL loss: 0.550554
Average total loss: 1.039125
tensor(0.0031, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-3.3080e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.486310
Average KL loss: 0.552063
Average total loss: 1.038372
tensor(0.0031, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.0509e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.494642
Average KL loss: 0.556949
Average total loss: 1.051591
tensor(-0.0050, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.0825e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.476843
Average KL loss: 0.559732
Average total loss: 1.036576
tensor(0.0037, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(1.5682e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.473129
Average KL loss: 0.556428
Average total loss: 1.029557
tensor(0.0031, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.6007e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.476052
Average KL loss: 0.559842
Average total loss: 1.035894
tensor(0.0032, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.1026e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.474869
Average KL loss: 0.561900
Average total loss: 1.036769
tensor(0.0041, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.0097e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.479399
Average KL loss: 0.567096
Average total loss: 1.046495
tensor(0.0044, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.2040e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.473123
Average KL loss: 0.565229
Average total loss: 1.038352
tensor(0.0033, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.0776e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.462413
Average KL loss: 0.565174
Average total loss: 1.027587
tensor(0.0033, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.6701e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.463418
Average KL loss: 0.566541
Average total loss: 1.029959
tensor(0.0028, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.7383e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.465604
Average KL loss: 0.570221
Average total loss: 1.035824
tensor(-0.0010, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.1328e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.461477
Average KL loss: 0.569935
Average total loss: 1.031412
tensor(0.0037, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(9.8486e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.457328
Average KL loss: 0.566410
Average total loss: 1.023738
tensor(0.0034, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-5.4816e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.457532
Average KL loss: 0.568738
Average total loss: 1.026270
tensor(0.0042, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(1.3797e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.457622
Average KL loss: 0.572523
Average total loss: 1.030145
tensor(0.0023, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-3.0497e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.456025
Average KL loss: 0.573351
Average total loss: 1.029376
tensor(0.0035, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.9948e-11, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.454156
Average KL loss: 0.572121
Average total loss: 1.026278
tensor(0.0035, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-6.4244e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.456136
Average KL loss: 0.571223
Average total loss: 1.027358
tensor(0.0035, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(4.5025e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.458385
Average KL loss: 0.574086
Average total loss: 1.032470
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(6.7478e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.449085
Average KL loss: 0.575413
Average total loss: 1.024498
tensor(0.0035, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.8762e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.447070
Average KL loss: 0.578838
Average total loss: 1.025908
tensor(0.0002, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-8.3230e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.446876
Average KL loss: 0.576603
Average total loss: 1.023479
tensor(0.0039, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(9.8366e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.448493
Average KL loss: 0.578032
Average total loss: 1.026525
tensor(0.0039, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.0309e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.448334
Average KL loss: 0.577440
Average total loss: 1.025774
tensor(0.0035, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-5.7487e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.446913
Average KL loss: 0.578912
Average total loss: 1.025825
tensor(0.0031, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.6053e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.453805
Average KL loss: 0.583324
Average total loss: 1.037129
tensor(0.0031, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.0970e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.447180
Average KL loss: 0.579583
Average total loss: 1.026763
tensor(0.0043, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(1.8232e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.451788
Average KL loss: 0.579759
Average total loss: 1.031548
tensor(0.0037, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.0752e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.450295
Average KL loss: 0.581402
Average total loss: 1.031697
tensor(0.0036, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-4.6962e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.447374
Average KL loss: 0.582570
Average total loss: 1.029944
tensor(0.0116, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(1.9951e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.450619
Average KL loss: 0.582065
Average total loss: 1.032684
tensor(0.0043, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(2.2062e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.448514
Average KL loss: 0.577952
Average total loss: 1.026466
tensor(0.0019, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-4.0922e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.448697
Average KL loss: 0.582758
Average total loss: 1.031455
tensor(0.0037, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-4.2117e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.438728
Average KL loss: 0.576021
Average total loss: 1.014750
tensor(0.0036, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(1.9069e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.441605
Average KL loss: 0.557133
Average total loss: 0.998738
tensor(0.0036, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(3.5167e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.436238
Average KL loss: 0.542980
Average total loss: 0.979218
tensor(0.0036, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(2.6223e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.431818
Average KL loss: 0.531943
Average total loss: 0.963761
tensor(0.0036, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(2.3706e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.435578
Average KL loss: 0.523003
Average total loss: 0.958582
tensor(0.0036, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.8197e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.429275
Average KL loss: 0.515290
Average total loss: 0.944565
tensor(0.0036, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-4.9846e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.437115
Average KL loss: 0.508409
Average total loss: 0.945524
tensor(0.0036, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.6252e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.433545
Average KL loss: 0.502539
Average total loss: 0.936084
tensor(0.0036, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(2.4493e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.432046
Average KL loss: 0.497278
Average total loss: 0.929324
tensor(0.0035, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(4.1877e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.431919
Average KL loss: 0.492760
Average total loss: 0.924680
tensor(0.0035, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(3.8243e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.432033
Average KL loss: 0.488848
Average total loss: 0.920881
tensor(0.0035, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(2.7903e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.438729
Average KL loss: 0.485149
Average total loss: 0.923879
tensor(0.0035, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.9672e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.435673
Average KL loss: 0.481741
Average total loss: 0.917414
tensor(0.0035, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.7379e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.434246
Average KL loss: 0.478750
Average total loss: 0.912995
tensor(0.0035, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.0690e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.434550
Average KL loss: 0.475686
Average total loss: 0.910236
tensor(0.0035, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.9226e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.433698
Average KL loss: 0.472912
Average total loss: 0.906610
tensor(0.0035, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.0552e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.436889
Average KL loss: 0.470787
Average total loss: 0.907676
tensor(0.0035, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-7.6471e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.436947
Average KL loss: 0.469264
Average total loss: 0.906211
tensor(0.0035, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-8.9014e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.431858
Average KL loss: 0.467364
Average total loss: 0.899223
tensor(0.0035, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(2.8327e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.435577
Average KL loss: 0.465086
Average total loss: 0.900663
tensor(0.0035, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(2.3635e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.432297
Average KL loss: 0.463393
Average total loss: 0.895690
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-7.2185e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.436686
Average KL loss: 0.461487
Average total loss: 0.898173
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-8.2459e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.439455
Average KL loss: 0.459661
Average total loss: 0.899116
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(4.3979e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.436779
Average KL loss: 0.458325
Average total loss: 0.895104
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(4.7902e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.438911
Average KL loss: 0.457095
Average total loss: 0.896006
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.4217e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.436302
Average KL loss: 0.455777
Average total loss: 0.892079
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.5527e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.438935
Average KL loss: 0.454134
Average total loss: 0.893070
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(2.5743e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.437749
Average KL loss: 0.453401
Average total loss: 0.891150
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(3.2823e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.438174
Average KL loss: 0.452398
Average total loss: 0.890572
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(4.5933e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.432999
Average KL loss: 0.451434
Average total loss: 0.884433
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.9304e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.444786
Average KL loss: 0.450475
Average total loss: 0.895261
tensor(0.0035, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(6.2096e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.434458
Average KL loss: 0.449497
Average total loss: 0.883955
tensor(0.0035, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-3.0723e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.441566
Average KL loss: 0.448709
Average total loss: 0.890275
tensor(0.0035, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.0073e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.438260
Average KL loss: 0.447927
Average total loss: 0.886187
tensor(0.0035, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.0345e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.440432
Average KL loss: 0.447201
Average total loss: 0.887633
tensor(0.0034, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(5.4550e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.443363
Average KL loss: 0.446160
Average total loss: 0.889523
tensor(0.0034, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.7204e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.439290
Average KL loss: 0.445665
Average total loss: 0.884955
tensor(0.0034, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-3.4098e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.442671
Average KL loss: 0.444987
Average total loss: 0.887658
tensor(0.0034, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(5.8554e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.437913
Average KL loss: 0.444186
Average total loss: 0.882099
tensor(0.0034, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.4126e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.442517
Average KL loss: 0.443490
Average total loss: 0.886006
tensor(0.0034, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.1445e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.443101
Average KL loss: 0.442672
Average total loss: 0.885773
tensor(0.0034, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(2.9499e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.443758
Average KL loss: 0.441928
Average total loss: 0.885686
tensor(0.0034, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(8.8972e-11, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.441987
Average KL loss: 0.440960
Average total loss: 0.882947
tensor(0.0034, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(3.4033e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.439915
Average KL loss: 0.440245
Average total loss: 0.880159
tensor(0.0034, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.9639e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.446347
Average KL loss: 0.439638
Average total loss: 0.885985
tensor(0.0034, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(5.7762e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.443935
Average KL loss: 0.439587
Average total loss: 0.883523
tensor(0.0034, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(7.0785e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.451143
Average KL loss: 0.439016
Average total loss: 0.890159
tensor(0.0034, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-8.0092e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.442985
Average KL loss: 0.438621
Average total loss: 0.881606
tensor(0.0034, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.6933e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.442386
Average KL loss: 0.438130
Average total loss: 0.880516
tensor(0.0034, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.1327e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.441422
Average KL loss: 0.437856
Average total loss: 0.879278
tensor(0.0034, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(8.8508e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.443142
Average KL loss: 0.436745
Average total loss: 0.879887
tensor(0.0034, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.5983e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.445344
Average KL loss: 0.435976
Average total loss: 0.881320
tensor(0.0034, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-5.9428e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.443681
Average KL loss: 0.435726
Average total loss: 0.879407
tensor(0.0034, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(7.7069e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.448599
Average KL loss: 0.434764
Average total loss: 0.883364
tensor(0.0034, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(1.7439e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.450198
Average KL loss: 0.434377
Average total loss: 0.884575
tensor(0.0034, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.9963e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.444064
Average KL loss: 0.434283
Average total loss: 0.878347
tensor(0.0034, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(3.4906e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.444428
Average KL loss: 0.433793
Average total loss: 0.878221
tensor(0.0034, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.1265e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.445781
Average KL loss: 0.433080
Average total loss: 0.878860
tensor(0.0034, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.3433e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.446633
Average KL loss: 0.432806
Average total loss: 0.879439
tensor(0.0034, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-3.4525e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.447262
Average KL loss: 0.432473
Average total loss: 0.879735
tensor(0.0034, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(3.8532e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.451675
Average KL loss: 0.432157
Average total loss: 0.883832
tensor(0.0034, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-9.4498e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.445735
Average KL loss: 0.431881
Average total loss: 0.877615
tensor(0.0034, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(4.7617e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.446684
Average KL loss: 0.431320
Average total loss: 0.878004
tensor(0.0034, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(5.7521e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.443969
Average KL loss: 0.430981
Average total loss: 0.874950
tensor(0.0034, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.5071e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.449030
Average KL loss: 0.430552
Average total loss: 0.879582
tensor(0.0034, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.8242e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.439800
Average KL loss: 0.430640
Average total loss: 0.870439
tensor(0.0034, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(2.0174e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.457438
Average KL loss: 0.430244
Average total loss: 0.887682
tensor(0.0034, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(2.5940e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.445383
Average KL loss: 0.430207
Average total loss: 0.875590
tensor(0.0034, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-5.1958e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.447912
Average KL loss: 0.430166
Average total loss: 0.878079
tensor(0.0034, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.7352e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.446537
Average KL loss: 0.430263
Average total loss: 0.876800
tensor(0.0034, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-8.0957e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.449276
Average KL loss: 0.429754
Average total loss: 0.879030
tensor(0.0034, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.5886e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.446718
Average KL loss: 0.429399
Average total loss: 0.876116
tensor(0.0034, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(2.0082e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.449790
Average KL loss: 0.429093
Average total loss: 0.878883
tensor(0.0034, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.0443e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.445312
Average KL loss: 0.429101
Average total loss: 0.874412
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.2460e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.446438
Average KL loss: 0.428875
Average total loss: 0.875313
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.3014e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.444198
Average KL loss: 0.428846
Average total loss: 0.873044
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-5.1730e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.447944
Average KL loss: 0.428420
Average total loss: 0.876363
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.4294e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.450984
Average KL loss: 0.427776
Average total loss: 0.878760
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.8197e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.447642
Average KL loss: 0.427486
Average total loss: 0.875128
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.5777e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.448547
Average KL loss: 0.427153
Average total loss: 0.875699
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-6.7755e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.451049
Average KL loss: 0.426871
Average total loss: 0.877920
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.1458e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.452382
Average KL loss: 0.426614
Average total loss: 0.878996
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.1779e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.450934
Average KL loss: 0.426366
Average total loss: 0.877300
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.7080e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.451900
Average KL loss: 0.426111
Average total loss: 0.878011
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(4.4430e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.448548
Average KL loss: 0.425847
Average total loss: 0.874395
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(4.1851e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.444367
Average KL loss: 0.425628
Average total loss: 0.869995
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-4.3254e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.453038
Average KL loss: 0.425388
Average total loss: 0.878426
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(9.8624e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.444099
Average KL loss: 0.425159
Average total loss: 0.869258
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-8.8742e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.445000
Average KL loss: 0.424948
Average total loss: 0.869948
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.4463e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.455176
Average KL loss: 0.424748
Average total loss: 0.879924
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-8.9222e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.448921
Average KL loss: 0.424574
Average total loss: 0.873495
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4182e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.447784
Average KL loss: 0.424392
Average total loss: 0.872175
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(3.6230e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.446722
Average KL loss: 0.424226
Average total loss: 0.870948
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.4959e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.449846
Average KL loss: 0.424040
Average total loss: 0.873887
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.0631e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.450022
Average KL loss: 0.423873
Average total loss: 0.873895
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.8500e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.451896
Average KL loss: 0.423677
Average total loss: 0.875573
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.7265e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.449819
Average KL loss: 0.423538
Average total loss: 0.873357
tensor(0.0034, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3848e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.447078
Average KL loss: 0.423399
Average total loss: 0.870477
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(1.4446e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.445950
Average KL loss: 0.423245
Average total loss: 0.869195
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(5.6832e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.443499
Average KL loss: 0.423124
Average total loss: 0.866623
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(1.6812e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.447498
Average KL loss: 0.423098
Average total loss: 0.870596
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.7723e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.453517
Average KL loss: 0.423075
Average total loss: 0.876592
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-8.0360e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.443669
Average KL loss: 0.423055
Average total loss: 0.866724
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(2.4059e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.452304
Average KL loss: 0.423032
Average total loss: 0.875336
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-5.0693e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.449730
Average KL loss: 0.423014
Average total loss: 0.872744
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-4.3134e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.444838
Average KL loss: 0.422995
Average total loss: 0.867834
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(1.6673e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.442804
Average KL loss: 0.422976
Average total loss: 0.865780
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(2.1043e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.445932
Average KL loss: 0.422955
Average total loss: 0.868887
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.1714e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.446671
Average KL loss: 0.422930
Average total loss: 0.869600
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(8.0040e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.446939
Average KL loss: 0.422910
Average total loss: 0.869849
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(2.1512e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.452100
Average KL loss: 0.422893
Average total loss: 0.874993
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(1.5664e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.449762
Average KL loss: 0.422874
Average total loss: 0.872636
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(7.2695e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.449686
Average KL loss: 0.422851
Average total loss: 0.872537
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(2.2577e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.448504
Average KL loss: 0.422830
Average total loss: 0.871334
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-7.5621e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.449111
Average KL loss: 0.422813
Average total loss: 0.871923
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(9.0753e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.447644
Average KL loss: 0.422795
Average total loss: 0.870440
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(2.3725e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.446777
Average KL loss: 0.422781
Average total loss: 0.869558
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.6203e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.451442
Average KL loss: 0.422764
Average total loss: 0.874206
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(3.5399e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.450748
Average KL loss: 0.422755
Average total loss: 0.873503
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(2.3725e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.447967
Average KL loss: 0.422753
Average total loss: 0.870720
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(3.5887e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.448092
Average KL loss: 0.422751
Average total loss: 0.870843
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.2876e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.445927
Average KL loss: 0.422749
Average total loss: 0.868675
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(1.4699e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.453248
Average KL loss: 0.422747
Average total loss: 0.875995
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.2847e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.454329
Average KL loss: 0.422745
Average total loss: 0.877074
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(3.8349e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.444186
Average KL loss: 0.422744
Average total loss: 0.866930
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-7.1382e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.446581
Average KL loss: 0.422742
Average total loss: 0.869323
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(1.7429e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.447651
Average KL loss: 0.422740
Average total loss: 0.870391
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(6.4886e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.450808
Average KL loss: 0.422739
Average total loss: 0.873547
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.1912e-09, device='cuda:0')
 Percentile value: 0.9973897933959961
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     107 /    1728             (  6.19%) | total_pruned =    1621 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      91 /   36864             (  0.25%) | total_pruned =   36773 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     158 /   36864             (  0.43%) | total_pruned =   36706 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     145 /   36864             (  0.39%) | total_pruned =   36719 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     311 /   36864             (  0.84%) | total_pruned =   36553 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     907 /   73728             (  1.23%) | total_pruned =   72821 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1449 /  147456             (  0.98%) | total_pruned =  146007 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     255 /    8192             (  3.11%) | total_pruned =    7937 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     817 /  147456             (  0.55%) | total_pruned =  146639 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     697 /  147456             (  0.47%) | total_pruned =  146759 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3274 /  294912             (  1.11%) | total_pruned =  291638 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4322 /  589824             (  0.73%) | total_pruned =  585502 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     185 /     256             ( 72.27%) | total_pruned =      71 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     244 /   32768             (  0.74%) | total_pruned =   32524 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      90 /     256             ( 35.16%) | total_pruned =     166 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2312 /  589824             (  0.39%) | total_pruned =  587512 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     145 /     256             ( 56.64%) | total_pruned =     111 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1613 /  589824             (  0.27%) | total_pruned =  588211 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     102 /     256             ( 39.84%) | total_pruned =     154 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2686 / 1179648             (  0.23%) | total_pruned = 1176962 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     286 /     512             ( 55.86%) | total_pruned =     226 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2063 / 2359296             (  0.09%) | total_pruned = 2357233 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     129 /     512             ( 25.20%) | total_pruned =     383 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      35 /  131072             (  0.03%) | total_pruned =  131037 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      63 /     512             ( 12.30%) | total_pruned =     449 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1338 / 2359296             (  0.06%) | total_pruned = 2357958 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      90 /     512             ( 17.58%) | total_pruned =     422 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1472 / 2359296             (  0.06%) | total_pruned = 2357824 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     161 /     512             ( 31.45%) | total_pruned =     351 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     107 /     512             ( 20.90%) | total_pruned =     405 | shape = torch.Size([512])
linear.weight        | nonzeros =     584 /    5120             ( 11.41%) | total_pruned =    4536 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 152/200 Loss: 0.154209 Accuracy: 83.84 99.76 % Best test Accuracy: 85.31%
tensor(0.0034, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.2786e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.953160
Average KL loss: 0.375160
Average total loss: 1.328320
tensor(-0.0007, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.2241e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.939684
Average KL loss: 0.382191
Average total loss: 1.321876
tensor(0.0019, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.5176e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.830665
Average KL loss: 0.411390
Average total loss: 1.242055
tensor(0.0023, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.0409e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.719561
Average KL loss: 0.428282
Average total loss: 1.147843
tensor(0.0023, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.3859e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.674502
Average KL loss: 0.438246
Average total loss: 1.112748
tensor(0.0024, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6525e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.630202
Average KL loss: 0.447331
Average total loss: 1.077533
tensor(0.0024, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.5030e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.626237
Average KL loss: 0.454605
Average total loss: 1.080842
tensor(0.0025, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-7.8296e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.607517
Average KL loss: 0.462726
Average total loss: 1.070242
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.2498e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.573905
Average KL loss: 0.468921
Average total loss: 1.042826
tensor(0.0026, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-8.8985e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.566905
Average KL loss: 0.472946
Average total loss: 1.039851
tensor(0.0026, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-5.2230e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.546580
Average KL loss: 0.479891
Average total loss: 1.026470
tensor(0.0027, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-4.0714e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.533270
Average KL loss: 0.483962
Average total loss: 1.017232
tensor(0.0027, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-5.9801e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.534227
Average KL loss: 0.488493
Average total loss: 1.022721
tensor(0.0028, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-8.8722e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.519257
Average KL loss: 0.494039
Average total loss: 1.013296
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-5.6780e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.509676
Average KL loss: 0.497170
Average total loss: 1.006846
tensor(0.0029, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.4904e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.504591
Average KL loss: 0.504138
Average total loss: 1.008729
tensor(-0.0057, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.2088e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.498897
Average KL loss: 0.505131
Average total loss: 1.004028
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(1.6943e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.493896
Average KL loss: 0.505866
Average total loss: 0.999762
tensor(0.0029, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-6.3829e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.493402
Average KL loss: 0.509064
Average total loss: 1.002466
tensor(0.0030, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.1736e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.487787
Average KL loss: 0.513722
Average total loss: 1.001509
tensor(0.0030, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-6.0360e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.481452
Average KL loss: 0.520668
Average total loss: 1.002121
tensor(0.0045, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(3.1217e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.473899
Average KL loss: 0.518832
Average total loss: 0.992730
tensor(0.0031, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-9.2908e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.475820
Average KL loss: 0.521729
Average total loss: 0.997549
tensor(0.0031, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-5.2352e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.465769
Average KL loss: 0.523118
Average total loss: 0.988887
tensor(0.0031, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.8853e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.463238
Average KL loss: 0.528465
Average total loss: 0.991703
tensor(-0.0020, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.3086e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.458225
Average KL loss: 0.529208
Average total loss: 0.987433
tensor(0.0036, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(7.6967e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.449889
Average KL loss: 0.530529
Average total loss: 0.980418
tensor(0.0032, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-9.0152e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.455393
Average KL loss: 0.532673
Average total loss: 0.988066
tensor(0.0033, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.7194e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.445546
Average KL loss: 0.536462
Average total loss: 0.982008
tensor(0.0018, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-4.2848e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.446005
Average KL loss: 0.540527
Average total loss: 0.986532
tensor(0.0035, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-2.1788e-11, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.438418
Average KL loss: 0.538729
Average total loss: 0.977147
tensor(0.0034, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-7.6808e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.437368
Average KL loss: 0.540871
Average total loss: 0.978240
tensor(0.0034, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-1.4756e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.434562
Average KL loss: 0.543829
Average total loss: 0.978391
tensor(0.0034, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-8.1774e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.431111
Average KL loss: 0.545437
Average total loss: 0.976548
tensor(0.0034, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-4.1334e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.434445
Average KL loss: 0.549685
Average total loss: 0.984130
tensor(-0.0004, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-9.0351e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.429134
Average KL loss: 0.548647
Average total loss: 0.977781
tensor(0.0039, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(7.7991e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.429173
Average KL loss: 0.550947
Average total loss: 0.980120
tensor(0.0035, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-4.5532e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.422719
Average KL loss: 0.551211
Average total loss: 0.973930
tensor(0.0035, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-3.8045e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.420654
Average KL loss: 0.552526
Average total loss: 0.973181
tensor(0.0030, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.8228e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.418953
Average KL loss: 0.556760
Average total loss: 0.975713
tensor(0.0030, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.6316e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.420477
Average KL loss: 0.554724
Average total loss: 0.975201
tensor(0.0037, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(4.5812e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.416255
Average KL loss: 0.555764
Average total loss: 0.972018
tensor(0.0036, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-2.0830e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.413167
Average KL loss: 0.557125
Average total loss: 0.970292
tensor(0.0036, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-4.0454e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.410196
Average KL loss: 0.559583
Average total loss: 0.969779
tensor(0.0132, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(2.3994e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.411693
Average KL loss: 0.564019
Average total loss: 0.975712
tensor(0.0046, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(1.9255e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.406075
Average KL loss: 0.562464
Average total loss: 0.968539
tensor(0.0036, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-4.6270e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.408219
Average KL loss: 0.564984
Average total loss: 0.973203
tensor(0.0037, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(1.8587e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.404042
Average KL loss: 0.565905
Average total loss: 0.969946
tensor(0.0043, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(1.4627e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.401705
Average KL loss: 0.570587
Average total loss: 0.972292
tensor(0.0040, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(8.6795e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.400552
Average KL loss: 0.570309
Average total loss: 0.970860
tensor(0.0036, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-9.3391e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.396736
Average KL loss: 0.571679
Average total loss: 0.968414
tensor(0.0038, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.1688e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.395106
Average KL loss: 0.573805
Average total loss: 0.968911
tensor(0.0037, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-7.0956e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.388001
Average KL loss: 0.578658
Average total loss: 0.966660
tensor(0.0064, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(6.3991e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.393152
Average KL loss: 0.575054
Average total loss: 0.968205
tensor(0.0040, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(3.6091e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.394975
Average KL loss: 0.573711
Average total loss: 0.968685
tensor(0.0038, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-4.7617e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.394067
Average KL loss: 0.574771
Average total loss: 0.968837
tensor(0.0039, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(1.3411e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.398080
Average KL loss: 0.574913
Average total loss: 0.972992
tensor(0.0099, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(1.4778e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.390512
Average KL loss: 0.577152
Average total loss: 0.967664
tensor(0.0030, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.1539e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.392556
Average KL loss: 0.575320
Average total loss: 0.967877
tensor(0.0040, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(1.9033e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.392660
Average KL loss: 0.575406
Average total loss: 0.968065
tensor(0.0039, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(4.8575e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.388945
Average KL loss: 0.575651
Average total loss: 0.964596
tensor(0.0048, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(1.6470e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.388551
Average KL loss: 0.582065
Average total loss: 0.970616
tensor(0.0048, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(1.8677e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.385187
Average KL loss: 0.578181
Average total loss: 0.963368
tensor(0.0040, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-3.3066e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.387113
Average KL loss: 0.578229
Average total loss: 0.965342
tensor(0.0039, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(7.0174e-12, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.384618
Average KL loss: 0.579232
Average total loss: 0.963850
tensor(0.0040, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(8.0263e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.380534
Average KL loss: 0.581143
Average total loss: 0.961677
tensor(-0.0030, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-1.7496e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.382300
Average KL loss: 0.581044
Average total loss: 0.963344
tensor(0.0037, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-7.8050e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.382865
Average KL loss: 0.584038
Average total loss: 0.966903
tensor(0.0041, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-4.2013e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.384581
Average KL loss: 0.585937
Average total loss: 0.970518
tensor(0.0040, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(1.3431e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.382251
Average KL loss: 0.586826
Average total loss: 0.969077
tensor(0.0048, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(1.8002e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.377734
Average KL loss: 0.591331
Average total loss: 0.969065
tensor(0.0058, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(4.0144e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.379740
Average KL loss: 0.588700
Average total loss: 0.968441
tensor(0.0041, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(2.7853e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.378587
Average KL loss: 0.588829
Average total loss: 0.967416
tensor(0.0041, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-6.0564e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.371439
Average KL loss: 0.588464
Average total loss: 0.959903
tensor(0.0041, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-5.4884e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.383807
Average KL loss: 0.590637
Average total loss: 0.974445
tensor(0.0046, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(9.9573e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.376446
Average KL loss: 0.589580
Average total loss: 0.966026
tensor(0.0049, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(1.5439e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.375174
Average KL loss: 0.590563
Average total loss: 0.965738
tensor(0.0042, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-2.1289e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.376257
Average KL loss: 0.591157
Average total loss: 0.967413
tensor(0.0042, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-4.9807e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.372398
Average KL loss: 0.592869
Average total loss: 0.965267
tensor(0.0042, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(2.6744e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.378558
Average KL loss: 0.594069
Average total loss: 0.972627
tensor(0.0033, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-2.5630e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.367281
Average KL loss: 0.598757
Average total loss: 0.966037
tensor(0.0030, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-3.2479e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.368533
Average KL loss: 0.594677
Average total loss: 0.963211
tensor(0.0044, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-4.3032e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.372643
Average KL loss: 0.595328
Average total loss: 0.967972
tensor(0.0042, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-6.6892e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.369763
Average KL loss: 0.597936
Average total loss: 0.967698
tensor(0.0041, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-8.9154e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.371500
Average KL loss: 0.600330
Average total loss: 0.971830
tensor(0.0044, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(7.7055e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.361432
Average KL loss: 0.595132
Average total loss: 0.956564
tensor(0.0043, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(5.7789e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.359511
Average KL loss: 0.590832
Average total loss: 0.950342
tensor(0.0043, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(4.2970e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.358690
Average KL loss: 0.587168
Average total loss: 0.945858
tensor(0.0043, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(2.5789e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.357545
Average KL loss: 0.583930
Average total loss: 0.941475
tensor(0.0043, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-2.6562e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.357062
Average KL loss: 0.581019
Average total loss: 0.938081
tensor(0.0043, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(3.8817e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.353772
Average KL loss: 0.578400
Average total loss: 0.932172
tensor(0.0043, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-3.0399e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.359069
Average KL loss: 0.576093
Average total loss: 0.935162
tensor(0.0043, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-5.5753e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.365908
Average KL loss: 0.574082
Average total loss: 0.939990
tensor(0.0042, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-2.6493e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.357479
Average KL loss: 0.572267
Average total loss: 0.929746
tensor(0.0042, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(1.5621e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.351351
Average KL loss: 0.570648
Average total loss: 0.921999
tensor(0.0042, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-4.0737e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.355636
Average KL loss: 0.568920
Average total loss: 0.924556
tensor(0.0042, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(2.5508e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.355323
Average KL loss: 0.567607
Average total loss: 0.922931
tensor(0.0042, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-5.1597e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.358956
Average KL loss: 0.566324
Average total loss: 0.925280
tensor(0.0042, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(1.4168e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.357557
Average KL loss: 0.565068
Average total loss: 0.922626
tensor(0.0042, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-1.6819e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.355956
Average KL loss: 0.563883
Average total loss: 0.919839
tensor(0.0042, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(1.3976e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.357679
Average KL loss: 0.562617
Average total loss: 0.920296
tensor(0.0042, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(2.8782e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.353807
Average KL loss: 0.561464
Average total loss: 0.915270
tensor(0.0042, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(1.3914e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.357936
Average KL loss: 0.560168
Average total loss: 0.918105
tensor(0.0042, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-9.9009e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.355436
Average KL loss: 0.559028
Average total loss: 0.914464
tensor(0.0042, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-4.6996e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.356492
Average KL loss: 0.557937
Average total loss: 0.914429
tensor(0.0042, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(1.7787e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.357225
Average KL loss: 0.556971
Average total loss: 0.914196
tensor(0.0042, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(1.8478e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.358491
Average KL loss: 0.555990
Average total loss: 0.914482
tensor(0.0042, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(3.4212e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.355471
Average KL loss: 0.555236
Average total loss: 0.910707
tensor(0.0042, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-2.1970e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.355337
Average KL loss: 0.554371
Average total loss: 0.909709
tensor(0.0042, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-4.5019e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.354104
Average KL loss: 0.553372
Average total loss: 0.907476
tensor(0.0042, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-1.3055e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.355889
Average KL loss: 0.552276
Average total loss: 0.908165
tensor(0.0042, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-1.3749e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.361134
Average KL loss: 0.551306
Average total loss: 0.912441
tensor(0.0042, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.1919e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.353520
Average KL loss: 0.550663
Average total loss: 0.904184
tensor(0.0042, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(1.2763e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.359650
Average KL loss: 0.550074
Average total loss: 0.909724
tensor(0.0042, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(5.2594e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.354236
Average KL loss: 0.549410
Average total loss: 0.903646
tensor(0.0042, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.6870e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.359768
Average KL loss: 0.548474
Average total loss: 0.908241
tensor(0.0042, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(5.8986e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.359214
Average KL loss: 0.547428
Average total loss: 0.906642
tensor(0.0042, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(1.2721e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.358869
Average KL loss: 0.546843
Average total loss: 0.905712
tensor(0.0042, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.7139e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.365805
Average KL loss: 0.546149
Average total loss: 0.911955
tensor(0.0042, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(8.1471e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.361791
Average KL loss: 0.545452
Average total loss: 0.907244
tensor(0.0042, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-7.6004e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.362459
Average KL loss: 0.544883
Average total loss: 0.907342
tensor(0.0042, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(1.1068e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.358102
Average KL loss: 0.544325
Average total loss: 0.902427
tensor(0.0042, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(4.8627e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.356055
Average KL loss: 0.543471
Average total loss: 0.899526
tensor(0.0041, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(5.8895e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.362664
Average KL loss: 0.542639
Average total loss: 0.905303
tensor(0.0041, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.1569e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.358256
Average KL loss: 0.541849
Average total loss: 0.900105
tensor(0.0041, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-2.4342e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.359093
Average KL loss: 0.541152
Average total loss: 0.900244
tensor(0.0041, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-8.6718e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.359763
Average KL loss: 0.540470
Average total loss: 0.900232
tensor(0.0041, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-8.3530e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.359597
Average KL loss: 0.539597
Average total loss: 0.899194
tensor(0.0041, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-4.7873e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.357747
Average KL loss: 0.538794
Average total loss: 0.896540
tensor(0.0041, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(7.2456e-12, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.359498
Average KL loss: 0.538019
Average total loss: 0.897517
tensor(0.0041, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-1.1747e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.358026
Average KL loss: 0.537577
Average total loss: 0.895604
tensor(0.0041, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(1.3005e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.365338
Average KL loss: 0.537082
Average total loss: 0.902420
tensor(0.0041, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(1.5518e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.363874
Average KL loss: 0.536796
Average total loss: 0.900670
tensor(0.0041, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(4.8716e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.360896
Average KL loss: 0.536503
Average total loss: 0.897399
tensor(0.0041, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-1.2808e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.364565
Average KL loss: 0.535969
Average total loss: 0.900533
tensor(0.0041, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-2.0840e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.361988
Average KL loss: 0.535281
Average total loss: 0.897269
tensor(0.0041, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.0883e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.362203
Average KL loss: 0.534875
Average total loss: 0.897077
tensor(0.0041, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-4.2612e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.367248
Average KL loss: 0.534342
Average total loss: 0.901590
tensor(0.0041, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(1.2219e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.361825
Average KL loss: 0.534126
Average total loss: 0.895952
tensor(0.0041, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(2.7967e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.366849
Average KL loss: 0.533858
Average total loss: 0.900707
tensor(0.0041, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-6.5526e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.361035
Average KL loss: 0.533332
Average total loss: 0.894367
tensor(0.0041, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(9.0814e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.363225
Average KL loss: 0.532700
Average total loss: 0.895924
tensor(0.0041, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.9690e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.365882
Average KL loss: 0.532468
Average total loss: 0.898350
tensor(0.0041, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-3.7590e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.362289
Average KL loss: 0.532160
Average total loss: 0.894449
tensor(0.0041, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-4.3310e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.370491
Average KL loss: 0.531670
Average total loss: 0.902161
tensor(0.0041, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-1.3926e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.359715
Average KL loss: 0.531213
Average total loss: 0.890929
tensor(0.0041, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-6.1027e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.363539
Average KL loss: 0.530636
Average total loss: 0.894175
tensor(0.0041, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(5.9572e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.362891
Average KL loss: 0.530222
Average total loss: 0.893112
tensor(0.0041, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.4093e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.367386
Average KL loss: 0.529854
Average total loss: 0.897240
tensor(0.0041, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(3.0357e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.367751
Average KL loss: 0.529291
Average total loss: 0.897042
tensor(0.0041, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-7.9954e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.365303
Average KL loss: 0.528959
Average total loss: 0.894262
tensor(0.0041, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-2.0248e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.366951
Average KL loss: 0.528546
Average total loss: 0.895497
tensor(0.0041, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-2.9489e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.367730
Average KL loss: 0.528310
Average total loss: 0.896040
tensor(0.0041, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(1.7798e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.360898
Average KL loss: 0.528032
Average total loss: 0.888930
tensor(0.0041, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(1.0392e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.374411
Average KL loss: 0.527477
Average total loss: 0.901887
tensor(0.0040, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-2.9644e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.371792
Average KL loss: 0.527169
Average total loss: 0.898961
tensor(0.0040, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-3.3303e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.367245
Average KL loss: 0.526927
Average total loss: 0.894173
tensor(0.0040, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-2.5660e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.368830
Average KL loss: 0.526694
Average total loss: 0.895524
tensor(0.0040, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.6366e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.369469
Average KL loss: 0.526605
Average total loss: 0.896074
tensor(0.0040, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-2.2891e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.368453
Average KL loss: 0.526268
Average total loss: 0.894721
tensor(0.0040, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(1.4657e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.368120
Average KL loss: 0.526124
Average total loss: 0.894244
tensor(0.0040, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(1.5962e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.365573
Average KL loss: 0.525656
Average total loss: 0.891229
tensor(0.0040, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(3.4624e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.369548
Average KL loss: 0.525272
Average total loss: 0.894820
tensor(0.0040, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(8.0878e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.367537
Average KL loss: 0.525076
Average total loss: 0.892613
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-3.8933e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.368428
Average KL loss: 0.524789
Average total loss: 0.893216
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(5.3155e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.368464
Average KL loss: 0.524629
Average total loss: 0.893093
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(4.4755e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.367364
Average KL loss: 0.524545
Average total loss: 0.891909
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(9.2814e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.372690
Average KL loss: 0.524455
Average total loss: 0.897145
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(2.2820e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.367205
Average KL loss: 0.524370
Average total loss: 0.891575
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(2.6173e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.366135
Average KL loss: 0.524283
Average total loss: 0.890418
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(6.7730e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.373524
Average KL loss: 0.524181
Average total loss: 0.897705
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(5.0575e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.368121
Average KL loss: 0.524094
Average total loss: 0.892215
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.6850e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.366374
Average KL loss: 0.524004
Average total loss: 0.890379
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(3.6830e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.366530
Average KL loss: 0.523916
Average total loss: 0.890447
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(2.8747e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.369147
Average KL loss: 0.523842
Average total loss: 0.892989
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(2.8717e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.369061
Average KL loss: 0.523795
Average total loss: 0.892855
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(4.1209e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.366297
Average KL loss: 0.523776
Average total loss: 0.890073
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(2.4774e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.364751
Average KL loss: 0.523766
Average total loss: 0.888517
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-2.5724e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.362792
Average KL loss: 0.523758
Average total loss: 0.886549
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-2.7510e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.366402
Average KL loss: 0.523750
Average total loss: 0.890152
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(1.6938e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.364376
Average KL loss: 0.523741
Average total loss: 0.888117
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(4.4977e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.368001
Average KL loss: 0.523734
Average total loss: 0.891736
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(1.1420e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.370464
Average KL loss: 0.523727
Average total loss: 0.894191
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-8.6962e-11, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.368404
Average KL loss: 0.523717
Average total loss: 0.892121
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-3.2665e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.362720
Average KL loss: 0.523711
Average total loss: 0.886430
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-3.9957e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.361989
Average KL loss: 0.523701
Average total loss: 0.885690
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(1.3180e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.367401
Average KL loss: 0.523691
Average total loss: 0.891092
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(5.9491e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.367439
Average KL loss: 0.523680
Average total loss: 0.891119
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(2.0199e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.368666
Average KL loss: 0.523671
Average total loss: 0.892337
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(1.2821e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.365154
Average KL loss: 0.523662
Average total loss: 0.888816
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-4.2498e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.372119
Average KL loss: 0.523655
Average total loss: 0.895774
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-8.3532e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.365973
Average KL loss: 0.523646
Average total loss: 0.889619
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-4.0798e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.365455
Average KL loss: 0.523636
Average total loss: 0.889091
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(2.3328e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.368098
Average KL loss: 0.523629
Average total loss: 0.891727
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.3786e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.363752
Average KL loss: 0.523621
Average total loss: 0.887373
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(8.7375e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.368574
Average KL loss: 0.523612
Average total loss: 0.892187
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(3.3517e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.372168
Average KL loss: 0.523603
Average total loss: 0.895771
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(2.3272e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.371995
Average KL loss: 0.523597
Average total loss: 0.895592
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(2.0889e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.365565
Average KL loss: 0.523596
Average total loss: 0.889161
tensor(0.0040, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-2.3182e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.371123
Average KL loss: 0.523595
Average total loss: 0.894719
 Percentile value: 6.303319549560546
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =      93 /    1728             (  5.38%) | total_pruned =    1635 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      57 /   36864             (  0.15%) | total_pruned =   36807 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      97 /   36864             (  0.26%) | total_pruned =   36767 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      92 /   36864             (  0.25%) | total_pruned =   36772 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     189 /   36864             (  0.51%) | total_pruned =   36675 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     391 /   73728             (  0.53%) | total_pruned =   73337 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     552 /  147456             (  0.37%) | total_pruned =  146904 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     133 /    8192             (  1.62%) | total_pruned =    8059 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     351 /  147456             (  0.24%) | total_pruned =  147105 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     291 /  147456             (  0.20%) | total_pruned =  147165 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     889 /  294912             (  0.30%) | total_pruned =  294023 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     179 /     256             ( 69.92%) | total_pruned =      77 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1025 /  589824             (  0.17%) | total_pruned =  588799 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     160 /     256             ( 62.50%) | total_pruned =      96 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      43 /   32768             (  0.13%) | total_pruned =   32725 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     676 /  589824             (  0.11%) | total_pruned =  589148 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     122 /     256             ( 47.66%) | total_pruned =     134 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     505 /  589824             (  0.09%) | total_pruned =  589319 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      73 /     256             ( 28.52%) | total_pruned =     183 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     473 / 1179648             (  0.04%) | total_pruned = 1179175 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     158 /     512             ( 30.86%) | total_pruned =     354 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     328 / 2359296             (  0.01%) | total_pruned = 2358968 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      69 /     512             ( 13.48%) | total_pruned =     443 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       7 /  131072             (  0.01%) | total_pruned =  131065 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     213 / 2359296             (  0.01%) | total_pruned = 2359083 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     180 / 2359296             (  0.01%) | total_pruned = 2359116 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      38 /     512             (  7.42%) | total_pruned =     474 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
linear.weight        | nonzeros =     100 /    5120             (  1.95%) | total_pruned =    5020 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 152/200 Loss: 0.671658 Accuracy: 72.40 77.51 % Best test Accuracy: 72.68%
