Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/200 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-8.0686e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302788
Average KL loss: 0.441791
Average total loss: 2.744578
tensor(0.0031, device='cuda:0') tensor(5.8303e-06, device='cuda:0') tensor(7.6596e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.303113
Average KL loss: 0.027942
Average total loss: 2.331054
tensor(0.0003, device='cuda:0') tensor(1.4247e-06, device='cuda:0') tensor(7.2811e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.302928
Average KL loss: 0.025010
Average total loss: 2.327938
tensor(1.0438e-05, device='cuda:0') tensor(1.7058e-06, device='cuda:0') tensor(2.5072e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.302966
Average KL loss: 0.025191
Average total loss: 2.328157
tensor(-8.4142e-07, device='cuda:0') tensor(2.1558e-06, device='cuda:0') tensor(-5.1419e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.303227
Average KL loss: 0.025122
Average total loss: 2.328349
tensor(-2.8155e-07, device='cuda:0') tensor(1.7906e-06, device='cuda:0') tensor(-2.9579e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.303055
Average KL loss: 0.025038
Average total loss: 2.328093
tensor(-4.9273e-07, device='cuda:0') tensor(1.7427e-06, device='cuda:0') tensor(5.9514e-12, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.302783
Average KL loss: 0.025284
Average total loss: 2.328067
tensor(4.1568e-07, device='cuda:0') tensor(2.2715e-06, device='cuda:0') tensor(-6.1164e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.302771
Average KL loss: 0.025594
Average total loss: 2.328365
tensor(-1.0560e-06, device='cuda:0') tensor(1.9645e-06, device='cuda:0') tensor(-1.9232e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.302952
Average KL loss: 0.025627
Average total loss: 2.328579
tensor(6.1147e-08, device='cuda:0') tensor(2.3245e-06, device='cuda:0') tensor(-1.9937e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.302720
Average KL loss: 0.025761
Average total loss: 2.328481
tensor(9.6638e-07, device='cuda:0') tensor(2.0226e-06, device='cuda:0') tensor(1.7291e-12, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.303013
Average KL loss: 0.025841
Average total loss: 2.328854
tensor(2.8196e-06, device='cuda:0') tensor(3.2798e-06, device='cuda:0') tensor(2.2351e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.302824
Average KL loss: 0.026027
Average total loss: 2.328851
tensor(-2.8432e-08, device='cuda:0') tensor(2.3330e-06, device='cuda:0') tensor(-4.3845e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.302751
Average KL loss: 0.026186
Average total loss: 2.328936
tensor(1.5990e-06, device='cuda:0') tensor(2.6944e-06, device='cuda:0') tensor(5.3461e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.302752
Average KL loss: 0.026060
Average total loss: 2.328812
tensor(5.5542e-07, device='cuda:0') tensor(2.7034e-06, device='cuda:0') tensor(1.4112e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.302933
Average KL loss: 0.023544
Average total loss: 2.326478
tensor(6.8801e-07, device='cuda:0') tensor(2.1064e-07, device='cuda:0') tensor(-3.4327e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.302854
Average KL loss: 0.022991
Average total loss: 2.325845
tensor(4.2911e-07, device='cuda:0') tensor(2.0384e-07, device='cuda:0') tensor(1.3322e-11, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.302971
Average KL loss: 0.022920
Average total loss: 2.325890
tensor(1.0285e-07, device='cuda:0') tensor(2.1392e-07, device='cuda:0') tensor(-1.2567e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.302661
Average KL loss: 0.022976
Average total loss: 2.325637
tensor(1.9638e-08, device='cuda:0') tensor(2.3064e-07, device='cuda:0') tensor(3.3618e-11, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.302676
Average KL loss: 0.023021
Average total loss: 2.325697
tensor(1.1057e-06, device='cuda:0') tensor(2.8023e-07, device='cuda:0') tensor(1.3186e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.302865
Average KL loss: 0.023022
Average total loss: 2.325887
tensor(1.5159e-06, device='cuda:0') tensor(2.5315e-07, device='cuda:0') tensor(3.9220e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.302496
Average KL loss: 0.023009
Average total loss: 2.325506
tensor(1.6866e-07, device='cuda:0') tensor(2.5666e-07, device='cuda:0') tensor(-5.3494e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.302934
Average KL loss: 0.023006
Average total loss: 2.325940
tensor(4.6537e-07, device='cuda:0') tensor(2.3567e-07, device='cuda:0') tensor(-5.0720e-11, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.302884
Average KL loss: 0.022985
Average total loss: 2.325869
tensor(9.6487e-07, device='cuda:0') tensor(3.0360e-07, device='cuda:0') tensor(-1.7478e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.303033
Average KL loss: 0.023018
Average total loss: 2.326051
tensor(7.4285e-07, device='cuda:0') tensor(2.8153e-07, device='cuda:0') tensor(1.1854e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.302880
Average KL loss: 0.022985
Average total loss: 2.325865
tensor(9.2083e-07, device='cuda:0') tensor(2.4561e-07, device='cuda:0') tensor(5.5007e-11, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.302625
Average KL loss: 0.023016
Average total loss: 2.325641
tensor(9.8679e-07, device='cuda:0') tensor(2.6715e-07, device='cuda:0') tensor(1.0569e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.303028
Average KL loss: 0.022999
Average total loss: 2.326028
tensor(9.1234e-07, device='cuda:0') tensor(2.0916e-07, device='cuda:0') tensor(1.5023e-11, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.303036
Average KL loss: 0.023026
Average total loss: 2.326062
tensor(9.0272e-07, device='cuda:0') tensor(2.6077e-07, device='cuda:0') tensor(3.9760e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.302822
Average KL loss: 0.023044
Average total loss: 2.325866
tensor(9.0162e-07, device='cuda:0') tensor(2.3917e-07, device='cuda:0') tensor(-1.8461e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.303066
Average KL loss: 0.022997
Average total loss: 2.326063
tensor(7.0749e-08, device='cuda:0') tensor(2.0708e-07, device='cuda:0') tensor(6.8378e-13, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.302720
Average KL loss: 0.023095
Average total loss: 2.325816
tensor(1.0612e-06, device='cuda:0') tensor(3.5084e-07, device='cuda:0') tensor(-2.7945e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.302737
Average KL loss: 0.023056
Average total loss: 2.325792
tensor(5.9505e-07, device='cuda:0') tensor(2.6864e-07, device='cuda:0') tensor(-1.3957e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 2.303005
Average KL loss: 0.022855
Average total loss: 2.325860
tensor(8.9430e-07, device='cuda:0') tensor(9.4658e-08, device='cuda:0') tensor(1.8312e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 2.303296
Average KL loss: 0.022763
Average total loss: 2.326059
tensor(7.7528e-07, device='cuda:0') tensor(7.0308e-08, device='cuda:0') tensor(-1.5747e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 2.303009
Average KL loss: 0.022741
Average total loss: 2.325750
tensor(6.1655e-07, device='cuda:0') tensor(5.7212e-08, device='cuda:0') tensor(6.5371e-11, device='cuda:0')
Epoch 36
Average batch original loss after noise: 2.302900
Average KL loss: 0.022729
Average total loss: 2.325630
tensor(5.3432e-07, device='cuda:0') tensor(4.9657e-08, device='cuda:0') tensor(-3.7565e-11, device='cuda:0')
Epoch 37
Average batch original loss after noise: 2.302802
Average KL loss: 0.022726
Average total loss: 2.325528
tensor(8.6123e-07, device='cuda:0') tensor(5.4878e-08, device='cuda:0') tensor(2.3807e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 2.302692
Average KL loss: 0.022730
Average total loss: 2.325421
tensor(1.1905e-06, device='cuda:0') tensor(5.7041e-08, device='cuda:0') tensor(2.3304e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 2.302696
Average KL loss: 0.022724
Average total loss: 2.325420
tensor(5.0714e-07, device='cuda:0') tensor(4.6530e-08, device='cuda:0') tensor(-1.8288e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 2.302547
Average KL loss: 0.022728
Average total loss: 2.325275
tensor(4.4992e-07, device='cuda:0') tensor(5.2608e-08, device='cuda:0') tensor(9.4578e-11, device='cuda:0')
Epoch 41
Average batch original loss after noise: 2.302765
Average KL loss: 0.022721
Average total loss: 2.325486
tensor(6.7611e-07, device='cuda:0') tensor(4.3776e-08, device='cuda:0') tensor(1.4174e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 2.303095
Average KL loss: 0.022723
Average total loss: 2.325818
tensor(6.0460e-07, device='cuda:0') tensor(5.7119e-08, device='cuda:0') tensor(4.4634e-12, device='cuda:0')
Epoch 43
Average batch original loss after noise: 2.303050
Average KL loss: 0.022725
Average total loss: 2.325775
tensor(5.5078e-07, device='cuda:0') tensor(4.9689e-08, device='cuda:0') tensor(-3.5380e-11, device='cuda:0')
Epoch 44
Average batch original loss after noise: 2.302945
Average KL loss: 0.022713
Average total loss: 2.325658
tensor(4.1596e-07, device='cuda:0') tensor(3.6826e-08, device='cuda:0') tensor(-4.4486e-11, device='cuda:0')
Epoch 45
Average batch original loss after noise: 2.302746
Average KL loss: 0.022704
Average total loss: 2.325450
tensor(5.6449e-07, device='cuda:0') tensor(3.4522e-08, device='cuda:0') tensor(-9.9333e-11, device='cuda:0')
Epoch 46
Average batch original loss after noise: 2.302479
Average KL loss: 0.022702
Average total loss: 2.325181
tensor(6.5109e-07, device='cuda:0') tensor(3.3825e-08, device='cuda:0') tensor(1.5089e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 2.302741
Average KL loss: 0.022701
Average total loss: 2.325442
tensor(6.8335e-07, device='cuda:0') tensor(3.3089e-08, device='cuda:0') tensor(5.4612e-11, device='cuda:0')
Epoch 48
Average batch original loss after noise: 2.302966
Average KL loss: 0.022701
Average total loss: 2.325667
tensor(6.3619e-07, device='cuda:0') tensor(3.3225e-08, device='cuda:0') tensor(3.1210e-11, device='cuda:0')
Epoch 49
Average batch original loss after noise: 2.302871
Average KL loss: 0.022700
Average total loss: 2.325572
tensor(5.6805e-07, device='cuda:0') tensor(3.2463e-08, device='cuda:0') tensor(3.2694e-11, device='cuda:0')
Epoch 50
Average batch original loss after noise: 2.302886
Average KL loss: 0.022699
Average total loss: 2.325585
tensor(5.7555e-07, device='cuda:0') tensor(3.1707e-08, device='cuda:0') tensor(-3.1384e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 2.302650
Average KL loss: 0.022699
Average total loss: 2.325349
tensor(6.4225e-07, device='cuda:0') tensor(3.1238e-08, device='cuda:0') tensor(5.7759e-11, device='cuda:0')
Epoch 52
Average batch original loss after noise: 2.302745
Average KL loss: 0.022698
Average total loss: 2.325443
tensor(5.4297e-07, device='cuda:0') tensor(3.0816e-08, device='cuda:0') tensor(2.7274e-11, device='cuda:0')
Epoch 53
Average batch original loss after noise: 2.302884
Average KL loss: 0.022698
Average total loss: 2.325582
tensor(5.1413e-07, device='cuda:0') tensor(3.0777e-08, device='cuda:0') tensor(-8.9722e-11, device='cuda:0')
Epoch 54
Average batch original loss after noise: 2.302762
Average KL loss: 0.022697
Average total loss: 2.325459
tensor(6.1415e-07, device='cuda:0') tensor(3.0138e-08, device='cuda:0') tensor(1.6758e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 2.302777
Average KL loss: 0.022697
Average total loss: 2.325474
tensor(6.3772e-07, device='cuda:0') tensor(3.0707e-08, device='cuda:0') tensor(2.1456e-12, device='cuda:0')
Epoch 56
Average batch original loss after noise: 2.302868
Average KL loss: 0.022697
Average total loss: 2.325565
tensor(6.5177e-07, device='cuda:0') tensor(3.0491e-08, device='cuda:0') tensor(3.0623e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 2.302963
Average KL loss: 0.022697
Average total loss: 2.325660
tensor(7.2568e-07, device='cuda:0') tensor(3.0681e-08, device='cuda:0') tensor(2.0369e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 2.302999
Average KL loss: 0.022697
Average total loss: 2.325696
tensor(6.7894e-07, device='cuda:0') tensor(3.0053e-08, device='cuda:0') tensor(1.3193e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 2.302829
Average KL loss: 0.022696
Average total loss: 2.325525
tensor(6.4601e-07, device='cuda:0') tensor(2.9591e-08, device='cuda:0') tensor(3.0737e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 2.302762
Average KL loss: 0.022696
Average total loss: 2.325457
tensor(6.5559e-07, device='cuda:0') tensor(2.9384e-08, device='cuda:0') tensor(-3.8128e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 2.303046
Average KL loss: 0.022695
Average total loss: 2.325742
tensor(6.4899e-07, device='cuda:0') tensor(2.9194e-08, device='cuda:0') tensor(1.6652e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 2.302991
Average KL loss: 0.022695
Average total loss: 2.325686
tensor(6.4341e-07, device='cuda:0') tensor(2.9083e-08, device='cuda:0') tensor(3.8711e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 2.303030
Average KL loss: 0.022695
Average total loss: 2.325725
tensor(6.2870e-07, device='cuda:0') tensor(2.8960e-08, device='cuda:0') tensor(3.8933e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 2.302739
Average KL loss: 0.022695
Average total loss: 2.325434
tensor(6.3626e-07, device='cuda:0') tensor(2.8895e-08, device='cuda:0') tensor(-6.8446e-12, device='cuda:0')
Epoch 65
Average batch original loss after noise: 2.302807
Average KL loss: 0.022695
Average total loss: 2.325502
tensor(6.5921e-07, device='cuda:0') tensor(2.8850e-08, device='cuda:0') tensor(-3.1109e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 2.302947
Average KL loss: 0.022695
Average total loss: 2.325642
tensor(6.4863e-07, device='cuda:0') tensor(2.8803e-08, device='cuda:0') tensor(3.3315e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 2.302891
Average KL loss: 0.022695
Average total loss: 2.325586
tensor(6.6877e-07, device='cuda:0') tensor(2.8781e-08, device='cuda:0') tensor(9.0530e-11, device='cuda:0')
 Percentile value: 5.036090533394599e-06
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =     332 /    1728             ( 19.21%) | total_pruned =    1396 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
bn1.bias             | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5480 /   36864             ( 14.87%) | total_pruned =   31384 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   12864 /   36864             ( 34.90%) | total_pruned =   24000 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   12295 /   36864             ( 33.35%) | total_pruned =   24569 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   15066 /   36864             ( 40.87%) | total_pruned =   21798 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   37441 /   73728             ( 50.78%) | total_pruned =   36287 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   73846 /  147456             ( 50.08%) | total_pruned =   73610 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4268 /    8192             ( 52.10%) | total_pruned =    3924 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   47792 /  147456             ( 32.41%) | total_pruned =   99664 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   43979 /  147456             ( 29.83%) | total_pruned =  103477 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  145723 /  294912             ( 49.41%) | total_pruned =  149189 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  272829 /  589824             ( 46.26%) | total_pruned =  316995 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   15338 /   32768             ( 46.81%) | total_pruned =   17430 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  175958 /  589824             ( 29.83%) | total_pruned =  413866 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     151 /     256             ( 58.98%) | total_pruned =     105 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  133202 /  589824             ( 22.58%) | total_pruned =  456622 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     147 /     256             ( 57.42%) | total_pruned =     109 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      44 /     256             ( 17.19%) | total_pruned =     212 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  463068 / 1179648             ( 39.25%) | total_pruned =  716580 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     370 /     512             ( 72.27%) | total_pruned =     142 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     126 /     512             ( 24.61%) | total_pruned =     386 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  692291 / 2359296             ( 29.34%) | total_pruned = 1667005 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     139 /     512             ( 27.15%) | total_pruned =     373 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   45780 /  131072             ( 34.93%) | total_pruned =   85292 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     358 /     512             ( 69.92%) | total_pruned =     154 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     131 /     512             ( 25.59%) | total_pruned =     381 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  598212 / 2359296             ( 25.36%) | total_pruned = 1761084 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     381 /     512             ( 74.41%) | total_pruned =     131 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     169 /     512             ( 33.01%) | total_pruned =     343 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  550284 / 2359296             ( 23.32%) | total_pruned = 1809012 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     420 /     512             ( 82.03%) | total_pruned =      92 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     236 /     512             ( 46.09%) | total_pruned =     276 | shape = torch.Size([512])
linear.weight        | nonzeros =    2667 /    5120             ( 52.09%) | total_pruned =    2453 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       6 /      10             ( 60.00%) | total_pruned =       4 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 73/200 Loss: 0.012489 Accuracy: 89.77 100.00 % Best test Accuracy: 89.77%
tensor(6.7578e-07, device='cuda:0') tensor(2.8746e-08, device='cuda:0') tensor(-3.1062e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.292197
Average KL loss: 0.637851
Average total loss: 2.930048
tensor(0.0012, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(2.8106e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.235288
Average KL loss: 0.293396
Average total loss: 2.528684
tensor(0.0002, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(3.2042e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.046901
Average KL loss: 0.667744
Average total loss: 2.714646
tensor(0.0002, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.5998e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.757644
Average KL loss: 1.065038
Average total loss: 2.822681
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.2336e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.488584
Average KL loss: 1.249347
Average total loss: 2.737932
tensor(0.0005, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-4.6569e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.337738
Average KL loss: 1.320192
Average total loss: 2.657929
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-2.3780e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.220292
Average KL loss: 1.346626
Average total loss: 2.566919
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.2145e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.164638
Average KL loss: 1.410513
Average total loss: 2.575151
tensor(0.0006, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(7.1989e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.088800
Average KL loss: 1.387820
Average total loss: 2.476620
tensor(0.0006, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(2.0631e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.057657
Average KL loss: 1.409053
Average total loss: 2.466711
tensor(0.0006, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(3.3098e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.050480
Average KL loss: 1.377137
Average total loss: 2.427617
tensor(0.0006, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.5537e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.010852
Average KL loss: 1.403763
Average total loss: 2.414615
tensor(0.0007, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(2.9368e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.988647
Average KL loss: 1.369444
Average total loss: 2.358090
tensor(0.0007, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.4571e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.993785
Average KL loss: 1.369318
Average total loss: 2.363104
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.1132e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.975372
Average KL loss: 1.406659
Average total loss: 2.382030
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.0572e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.959627
Average KL loss: 1.381761
Average total loss: 2.341388
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(8.4323e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.965257
Average KL loss: 1.387901
Average total loss: 2.353158
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.5053e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.935880
Average KL loss: 1.372984
Average total loss: 2.308864
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(4.6989e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.946664
Average KL loss: 1.382692
Average total loss: 2.329357
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.5286e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.932598
Average KL loss: 1.370127
Average total loss: 2.302725
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(7.5863e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.931779
Average KL loss: 1.356411
Average total loss: 2.288190
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.6224e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.923752
Average KL loss: 1.356750
Average total loss: 2.280503
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(1.5463e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.935470
Average KL loss: 1.368770
Average total loss: 2.304241
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-5.6529e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.920555
Average KL loss: 1.369401
Average total loss: 2.289957
tensor(0.0008, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(2.2065e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.909661
Average KL loss: 1.380030
Average total loss: 2.289690
tensor(-0.0001, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.2734e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.918400
Average KL loss: 1.362167
Average total loss: 2.280567
tensor(0.0008, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(3.2507e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.927266
Average KL loss: 1.365886
Average total loss: 2.293151
tensor(0.0007, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.0346e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.918216
Average KL loss: 1.351673
Average total loss: 2.269889
tensor(0.0007, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.1056e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.920126
Average KL loss: 1.376982
Average total loss: 2.297109
tensor(0.0006, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.0007e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.926166
Average KL loss: 1.379840
Average total loss: 2.306006
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(3.0044e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.930300
Average KL loss: 1.391538
Average total loss: 2.321838
tensor(0.0005, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-3.7917e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.921151
Average KL loss: 1.374765
Average total loss: 2.295916
tensor(0.0007, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.0794e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.906981
Average KL loss: 1.365577
Average total loss: 2.272558
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(2.5035e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.911674
Average KL loss: 1.366643
Average total loss: 2.278317
tensor(9.4404e-05, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.7649e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.912640
Average KL loss: 1.375473
Average total loss: 2.288114
tensor(0.0010, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(8.0001e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.909420
Average KL loss: 1.371335
Average total loss: 2.280755
tensor(0.0007, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.7325e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.909674
Average KL loss: 1.367145
Average total loss: 2.276819
tensor(0.0007, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.7592e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.917355
Average KL loss: 1.382780
Average total loss: 2.300135
tensor(0.0009, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.7817e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.901748
Average KL loss: 1.356193
Average total loss: 2.257941
tensor(0.0007, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.0254e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.911177
Average KL loss: 1.377521
Average total loss: 2.288698
tensor(0.0007, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.7858e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.908713
Average KL loss: 1.376055
Average total loss: 2.284768
tensor(0.0009, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.5221e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.900299
Average KL loss: 1.377484
Average total loss: 2.277783
tensor(0.0005, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-6.9047e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.908652
Average KL loss: 1.380408
Average total loss: 2.289060
tensor(0.0006, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.9329e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.909068
Average KL loss: 1.371352
Average total loss: 2.280421
tensor(0.0007, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-5.1512e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.905930
Average KL loss: 1.378594
Average total loss: 2.284524
tensor(0.0005, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-5.8879e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.919921
Average KL loss: 1.392743
Average total loss: 2.312664
tensor(0.0008, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(4.7670e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.909693
Average KL loss: 1.391948
Average total loss: 2.301641
tensor(0.0007, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-6.4927e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.902212
Average KL loss: 1.356347
Average total loss: 2.258560
tensor(0.0007, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.4439e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.890522
Average KL loss: 1.363552
Average total loss: 2.254074
tensor(-0.0002, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.5752e-07, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.893418
Average KL loss: 1.397271
Average total loss: 2.290689
tensor(0.0009, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(4.0156e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.879000
Average KL loss: 1.397378
Average total loss: 2.276378
tensor(0.0009, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(2.0335e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.864213
Average KL loss: 1.377465
Average total loss: 2.241678
tensor(0.0007, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.4624e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.885233
Average KL loss: 1.397323
Average total loss: 2.282556
tensor(0.0007, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.0322e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.871647
Average KL loss: 1.402136
Average total loss: 2.273783
tensor(0.0008, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(1.4303e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.866738
Average KL loss: 1.416151
Average total loss: 2.282889
tensor(0.0002, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.6090e-07, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.872535
Average KL loss: 1.426080
Average total loss: 2.298615
tensor(0.0008, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(2.9155e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.858718
Average KL loss: 1.404502
Average total loss: 2.263221
tensor(0.0008, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-7.6836e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.855280
Average KL loss: 1.407989
Average total loss: 2.263270
tensor(0.0009, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(3.9703e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.854890
Average KL loss: 1.413746
Average total loss: 2.268637
tensor(0.0008, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(1.5662e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.853509
Average KL loss: 1.394328
Average total loss: 2.247837
tensor(0.0008, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.0331e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.867448
Average KL loss: 1.407625
Average total loss: 2.275074
tensor(0.0009, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(1.5624e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.851869
Average KL loss: 1.392250
Average total loss: 2.244120
tensor(0.0010, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(3.7937e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.862672
Average KL loss: 1.401316
Average total loss: 2.263989
tensor(0.0006, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.6729e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.852759
Average KL loss: 1.082218
Average total loss: 1.934977
tensor(0.0008, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.0368e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.839880
Average KL loss: 0.911244
Average total loss: 1.751125
tensor(0.0008, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.6229e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.842224
Average KL loss: 0.885601
Average total loss: 1.727824
tensor(0.0008, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(9.4043e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.840031
Average KL loss: 0.875213
Average total loss: 1.715245
tensor(0.0008, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(7.8689e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.834408
Average KL loss: 0.867453
Average total loss: 1.701861
tensor(0.0008, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.7688e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.845583
Average KL loss: 0.864558
Average total loss: 1.710140
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(2.5349e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.827582
Average KL loss: 0.861816
Average total loss: 1.689398
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-4.5098e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.845955
Average KL loss: 0.859825
Average total loss: 1.705780
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(5.1408e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.831009
Average KL loss: 0.856814
Average total loss: 1.687823
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-3.3459e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.848405
Average KL loss: 0.853664
Average total loss: 1.702069
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-3.3916e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.845808
Average KL loss: 0.855225
Average total loss: 1.701033
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-4.6407e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.841302
Average KL loss: 0.852197
Average total loss: 1.693499
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-5.9659e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.840797
Average KL loss: 0.849465
Average total loss: 1.690262
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-4.5239e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.851700
Average KL loss: 0.851339
Average total loss: 1.703039
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(5.6133e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.833545
Average KL loss: 0.847676
Average total loss: 1.681222
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(6.2611e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.847168
Average KL loss: 0.846596
Average total loss: 1.693765
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(1.2363e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.841406
Average KL loss: 0.844760
Average total loss: 1.686165
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(1.9723e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.848862
Average KL loss: 0.845358
Average total loss: 1.694220
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.1965e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.848565
Average KL loss: 0.844886
Average total loss: 1.693451
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.8823e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.848545
Average KL loss: 0.841504
Average total loss: 1.690050
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(5.3619e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.856279
Average KL loss: 0.844996
Average total loss: 1.701275
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(9.4638e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.853206
Average KL loss: 0.843595
Average total loss: 1.696802
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(2.3452e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.844579
Average KL loss: 0.845294
Average total loss: 1.689873
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(9.2217e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.834259
Average KL loss: 0.842719
Average total loss: 1.676978
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-5.4785e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.841150
Average KL loss: 0.840995
Average total loss: 1.682145
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(4.8473e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.848933
Average KL loss: 0.844401
Average total loss: 1.693333
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(9.6412e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.847852
Average KL loss: 0.841107
Average total loss: 1.688958
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(2.0660e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.848490
Average KL loss: 0.841476
Average total loss: 1.689966
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.3489e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.846941
Average KL loss: 0.841443
Average total loss: 1.688384
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(1.8265e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.837077
Average KL loss: 0.841007
Average total loss: 1.678083
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(1.1611e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.849683
Average KL loss: 0.838654
Average total loss: 1.688337
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-8.7224e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.843977
Average KL loss: 0.838508
Average total loss: 1.682485
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(1.4395e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.854667
Average KL loss: 0.839089
Average total loss: 1.693755
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.8546e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.850462
Average KL loss: 0.839605
Average total loss: 1.690067
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(3.4055e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.849601
Average KL loss: 0.837777
Average total loss: 1.687377
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(2.4558e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.853034
Average KL loss: 0.827809
Average total loss: 1.680843
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(4.6088e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.854346
Average KL loss: 0.810370
Average total loss: 1.664715
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(3.4607e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.852345
Average KL loss: 0.802468
Average total loss: 1.654814
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.8953e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.850372
Average KL loss: 0.797591
Average total loss: 1.647963
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.2016e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.854954
Average KL loss: 0.794446
Average total loss: 1.649400
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(3.6548e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.845221
Average KL loss: 0.792567
Average total loss: 1.637788
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-6.4888e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.845701
Average KL loss: 0.790953
Average total loss: 1.636654
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.8363e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.845211
Average KL loss: 0.789732
Average total loss: 1.634943
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.3788e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.850109
Average KL loss: 0.788554
Average total loss: 1.638663
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(2.8958e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.846003
Average KL loss: 0.787812
Average total loss: 1.633815
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(3.6014e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.842632
Average KL loss: 0.786975
Average total loss: 1.629606
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.2888e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.853950
Average KL loss: 0.786375
Average total loss: 1.640324
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.9268e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.840370
Average KL loss: 0.785923
Average total loss: 1.626293
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-4.5909e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.844086
Average KL loss: 0.785043
Average total loss: 1.629129
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-7.4480e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.854140
Average KL loss: 0.784764
Average total loss: 1.638904
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(9.0804e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.844515
Average KL loss: 0.784709
Average total loss: 1.629223
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(8.1961e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.852440
Average KL loss: 0.784451
Average total loss: 1.636891
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-6.4039e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.836002
Average KL loss: 0.784029
Average total loss: 1.620031
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-6.1500e-11, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.836440
Average KL loss: 0.783450
Average total loss: 1.619890
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(4.8434e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.844653
Average KL loss: 0.783363
Average total loss: 1.628016
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.2281e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.844071
Average KL loss: 0.783228
Average total loss: 1.627299
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.0175e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.845724
Average KL loss: 0.782923
Average total loss: 1.628647
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(2.8585e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.848049
Average KL loss: 0.782488
Average total loss: 1.630537
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(8.3154e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.846490
Average KL loss: 0.782198
Average total loss: 1.628689
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.7763e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.840020
Average KL loss: 0.781899
Average total loss: 1.621918
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.2265e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.839866
Average KL loss: 0.781381
Average total loss: 1.621248
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.5081e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.844776
Average KL loss: 0.781220
Average total loss: 1.625995
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.2252e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.840876
Average KL loss: 0.780962
Average total loss: 1.621838
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(4.0086e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.847687
Average KL loss: 0.780804
Average total loss: 1.628491
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(8.2711e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.858278
Average KL loss: 0.780341
Average total loss: 1.638620
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.0558e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.856752
Average KL loss: 0.779929
Average total loss: 1.636681
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.0870e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.848936
Average KL loss: 0.779596
Average total loss: 1.628531
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(2.3072e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.840655
Average KL loss: 0.779296
Average total loss: 1.619951
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.7725e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.858289
Average KL loss: 0.779028
Average total loss: 1.637317
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.8170e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.862771
Average KL loss: 0.778830
Average total loss: 1.641601
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.6259e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.845741
Average KL loss: 0.778642
Average total loss: 1.624382
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-5.5043e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.841717
Average KL loss: 0.778445
Average total loss: 1.620162
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(7.0337e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.833285
Average KL loss: 0.778228
Average total loss: 1.611512
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.5409e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.841869
Average KL loss: 0.778061
Average total loss: 1.619930
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-7.4567e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.847004
Average KL loss: 0.777893
Average total loss: 1.624897
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-8.0921e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.844243
Average KL loss: 0.777741
Average total loss: 1.621984
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-4.4602e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.846702
Average KL loss: 0.777597
Average total loss: 1.624299
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.4695e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.850369
Average KL loss: 0.777471
Average total loss: 1.627840
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.8716e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.855039
Average KL loss: 0.777369
Average total loss: 1.632408
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.9571e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.838069
Average KL loss: 0.777283
Average total loss: 1.615352
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-4.5146e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.850026
Average KL loss: 0.777188
Average total loss: 1.627214
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.0703e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.858223
Average KL loss: 0.777134
Average total loss: 1.635357
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.5264e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.846906
Average KL loss: 0.777086
Average total loss: 1.623992
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(9.9943e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.840195
Average KL loss: 0.776987
Average total loss: 1.617182
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-5.5635e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.846446
Average KL loss: 0.776918
Average total loss: 1.623365
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-7.7941e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.850995
Average KL loss: 0.776907
Average total loss: 1.627902
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.8011e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.851919
Average KL loss: 0.776899
Average total loss: 1.628818
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(3.0976e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.846335
Average KL loss: 0.776886
Average total loss: 1.623221
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.6876e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.851869
Average KL loss: 0.776873
Average total loss: 1.628742
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-5.4990e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.856251
Average KL loss: 0.776861
Average total loss: 1.633112
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.5236e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.845433
Average KL loss: 0.776845
Average total loss: 1.622278
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.1199e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.848970
Average KL loss: 0.776828
Average total loss: 1.625798
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(4.8309e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.857512
Average KL loss: 0.776814
Average total loss: 1.634325
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(5.2640e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.846921
Average KL loss: 0.776803
Average total loss: 1.623725
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-4.5347e-09, device='cuda:0')
 Percentile value: 0.0036951213143765916
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =     127 /    1728             (  7.35%) | total_pruned =    1601 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
bn1.bias             | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1168 /   36864             (  3.17%) | total_pruned =   35696 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5116 /   36864             ( 13.88%) | total_pruned =   31748 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    5289 /   36864             ( 14.35%) | total_pruned =   31575 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    7149 /   36864             ( 19.39%) | total_pruned =   29715 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   19769 /   73728             ( 26.81%) | total_pruned =   53959 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   38720 /  147456             ( 26.26%) | total_pruned =  108736 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2145 /    8192             ( 26.18%) | total_pruned =    6047 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   14527 /  147456             (  9.85%) | total_pruned =  132929 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    7070 /  147456             (  4.79%) | total_pruned =  140386 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   72083 /  294912             ( 24.44%) | total_pruned =  222829 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  116014 /  589824             ( 19.67%) | total_pruned =  473810 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6299 /   32768             ( 19.22%) | total_pruned =   26469 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     161 /     256             ( 62.89%) | total_pruned =      95 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   53036 /  589824             (  8.99%) | total_pruned =  536788 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     147 /     256             ( 57.42%) | total_pruned =     109 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   26352 /  589824             (  4.47%) | total_pruned =  563472 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  173551 / 1179648             ( 14.71%) | total_pruned = 1006097 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     362 /     512             ( 70.70%) | total_pruned =     150 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      27 /     512             (  5.27%) | total_pruned =     485 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  181578 / 2359296             (  7.70%) | total_pruned = 2177718 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     254 /     512             ( 49.61%) | total_pruned =     258 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   13363 /  131072             ( 10.20%) | total_pruned =  117709 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     202 /     512             ( 39.45%) | total_pruned =     310 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  139893 / 2359296             (  5.93%) | total_pruned = 2219403 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     308 /     512             ( 60.16%) | total_pruned =     204 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  117971 / 2359296             (  5.00%) | total_pruned = 2241325 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     233 /     512             ( 45.51%) | total_pruned =     279 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     153 /     512             ( 29.88%) | total_pruned =     359 | shape = torch.Size([512])
linear.weight        | nonzeros =    1455 /    5120             ( 28.42%) | total_pruned =    3665 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 67/200 Loss: 0.023401 Accuracy: 87.87 100.00 % Best test Accuracy: 87.91%
tensor(0.0008, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(5.0328e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.622115
Average KL loss: 1.686582
Average total loss: 3.308698
tensor(0.0031, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(6.5266e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.505936
Average KL loss: 1.153924
Average total loss: 2.659860
tensor(0.0009, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(9.6979e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.344250
Average KL loss: 1.170631
Average total loss: 2.514881
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-8.9072e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.301885
Average KL loss: 1.216401
Average total loss: 2.518286
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-8.9543e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.214392
Average KL loss: 1.245925
Average total loss: 2.460317
tensor(0.0006, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.6594e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.197616
Average KL loss: 1.264951
Average total loss: 2.462567
tensor(0.0006, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.6765e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.166803
Average KL loss: 1.230560
Average total loss: 2.397363
tensor(0.0006, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.8580e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.158309
Average KL loss: 1.246871
Average total loss: 2.405180
tensor(0.0006, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-9.6619e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.133458
Average KL loss: 1.270036
Average total loss: 2.403494
tensor(0.0006, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.3282e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.126433
Average KL loss: 1.270581
Average total loss: 2.397013
tensor(0.0006, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.7908e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.109074
Average KL loss: 1.279807
Average total loss: 2.388881
tensor(0.0006, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.1121e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.095311
Average KL loss: 1.304790
Average total loss: 2.400101
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.8772e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.099328
Average KL loss: 1.306243
Average total loss: 2.405572
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.0206e-11, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.096639
Average KL loss: 1.307161
Average total loss: 2.403800
tensor(0.0007, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-5.4115e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.069148
Average KL loss: 1.301903
Average total loss: 2.371050
tensor(0.0007, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.9845e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.081406
Average KL loss: 1.312885
Average total loss: 2.394291
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.0144e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.055987
Average KL loss: 1.300980
Average total loss: 2.356967
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(9.3909e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.075017
Average KL loss: 1.314776
Average total loss: 2.389793
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.0583e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.058917
Average KL loss: 1.318530
Average total loss: 2.377446
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.4132e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.051796
Average KL loss: 1.330636
Average total loss: 2.382431
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.4379e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.045698
Average KL loss: 1.331423
Average total loss: 2.377121
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.4533e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.044332
Average KL loss: 1.325040
Average total loss: 2.369373
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.4450e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.039935
Average KL loss: 1.318686
Average total loss: 2.358621
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.1824e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.048348
Average KL loss: 1.339492
Average total loss: 2.387840
tensor(0.0007, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(3.9320e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.033357
Average KL loss: 1.396723
Average total loss: 2.430080
tensor(-0.0053, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.5080e-06, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.025631
Average KL loss: 1.341773
Average total loss: 2.367404
tensor(0.0012, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.2136e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.025182
Average KL loss: 1.295006
Average total loss: 2.320189
tensor(0.0007, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.1639e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.037756
Average KL loss: 1.320788
Average total loss: 2.358543
tensor(0.0007, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(9.1398e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.036866
Average KL loss: 1.315091
Average total loss: 2.351958
tensor(0.0007, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.7564e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.036876
Average KL loss: 1.324065
Average total loss: 2.360941
tensor(0.0007, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(1.5452e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.043965
Average KL loss: 1.334979
Average total loss: 2.378944
tensor(-2.2209e-05, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.0740e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.028366
Average KL loss: 1.344182
Average total loss: 2.372549
tensor(0.0006, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.1784e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.026844
Average KL loss: 1.335193
Average total loss: 2.362037
tensor(0.0007, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.6602e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.035868
Average KL loss: 1.324412
Average total loss: 2.360280
tensor(-0.0042, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.2279e-06, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.032315
Average KL loss: 1.358428
Average total loss: 2.390743
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.1926e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.028277
Average KL loss: 1.340958
Average total loss: 2.369235
tensor(0.0002, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.2257e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.029467
Average KL loss: 1.356724
Average total loss: 2.386191
tensor(0.0007, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.6216e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.025169
Average KL loss: 1.331921
Average total loss: 2.357090
tensor(0.0007, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(1.1876e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.010622
Average KL loss: 1.088679
Average total loss: 2.099301
tensor(0.0007, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(8.8853e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.015770
Average KL loss: 0.897343
Average total loss: 1.913113
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(8.5197e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.010460
Average KL loss: 0.861622
Average total loss: 1.872082
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(2.0715e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.013562
Average KL loss: 0.846136
Average total loss: 1.859698
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(8.0400e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.003968
Average KL loss: 0.836678
Average total loss: 1.840646
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-6.2687e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.001019
Average KL loss: 0.828523
Average total loss: 1.829542
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.9299e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.007142
Average KL loss: 0.826377
Average total loss: 1.833519
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-7.4417e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.020786
Average KL loss: 0.823842
Average total loss: 1.844628
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(6.0842e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.010001
Average KL loss: 0.822314
Average total loss: 1.832315
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(7.3461e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.009203
Average KL loss: 0.816885
Average total loss: 1.826088
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.1611e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.015573
Average KL loss: 0.814860
Average total loss: 1.830433
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(9.9471e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.015124
Average KL loss: 0.812599
Average total loss: 1.827724
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.4372e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.011077
Average KL loss: 0.812355
Average total loss: 1.823432
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.8213e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.011907
Average KL loss: 0.810450
Average total loss: 1.822358
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.1616e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.017861
Average KL loss: 0.808429
Average total loss: 1.826290
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(3.4233e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.011986
Average KL loss: 0.807252
Average total loss: 1.819238
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(6.2113e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.014165
Average KL loss: 0.806407
Average total loss: 1.820573
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.3607e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.020274
Average KL loss: 0.804543
Average total loss: 1.824817
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.2607e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.022595
Average KL loss: 0.804784
Average total loss: 1.827379
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.8487e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.021440
Average KL loss: 0.802753
Average total loss: 1.824193
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.6349e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.028925
Average KL loss: 0.801021
Average total loss: 1.829946
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(3.7006e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.018705
Average KL loss: 0.801469
Average total loss: 1.820174
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.9703e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.010889
Average KL loss: 0.800394
Average total loss: 1.811283
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-8.8354e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.014617
Average KL loss: 0.801092
Average total loss: 1.815709
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-7.4609e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.024488
Average KL loss: 0.799195
Average total loss: 1.823684
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.7360e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.021263
Average KL loss: 0.799045
Average total loss: 1.820308
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.8762e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.024440
Average KL loss: 0.800167
Average total loss: 1.824607
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.2970e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.010265
Average KL loss: 0.799746
Average total loss: 1.810011
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(7.5125e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.021785
Average KL loss: 0.793964
Average total loss: 1.815748
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(4.9471e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.030841
Average KL loss: 0.795747
Average total loss: 1.826588
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.2867e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.032896
Average KL loss: 0.795431
Average total loss: 1.828327
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.3650e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.025517
Average KL loss: 0.797156
Average total loss: 1.822673
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-5.9797e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.022741
Average KL loss: 0.797885
Average total loss: 1.820626
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.5251e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.022843
Average KL loss: 0.795307
Average total loss: 1.818151
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.9618e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.021813
Average KL loss: 0.793963
Average total loss: 1.815776
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.4274e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.025617
Average KL loss: 0.796104
Average total loss: 1.821721
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-6.5123e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.013677
Average KL loss: 0.794808
Average total loss: 1.808485
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.1935e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.025160
Average KL loss: 0.793622
Average total loss: 1.818782
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.2692e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.019997
Average KL loss: 0.793408
Average total loss: 1.813406
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.5231e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.025388
Average KL loss: 0.790737
Average total loss: 1.816125
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(3.3125e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.020001
Average KL loss: 0.792248
Average total loss: 1.812249
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(2.2203e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.034405
Average KL loss: 0.791526
Average total loss: 1.825931
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(5.9835e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.025561
Average KL loss: 0.790857
Average total loss: 1.816419
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-8.0218e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.023270
Average KL loss: 0.790228
Average total loss: 1.813498
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.0479e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.019320
Average KL loss: 0.787077
Average total loss: 1.806397
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.7508e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.035898
Average KL loss: 0.788452
Average total loss: 1.824350
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(3.6336e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.019846
Average KL loss: 0.788837
Average total loss: 1.808682
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-5.2807e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.028141
Average KL loss: 0.786409
Average total loss: 1.814550
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.6818e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.031161
Average KL loss: 0.787057
Average total loss: 1.818218
tensor(0.0007, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.8017e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.037534
Average KL loss: 0.786108
Average total loss: 1.823642
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-9.4602e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.034460
Average KL loss: 0.785430
Average total loss: 1.819890
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.1244e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.033683
Average KL loss: 0.784192
Average total loss: 1.817875
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.3509e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.036131
Average KL loss: 0.784619
Average total loss: 1.820750
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(4.8809e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.041622
Average KL loss: 0.784916
Average total loss: 1.826538
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.7442e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.023358
Average KL loss: 0.786086
Average total loss: 1.809444
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.1039e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.043188
Average KL loss: 0.785533
Average total loss: 1.828721
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.9588e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.036655
Average KL loss: 0.779098
Average total loss: 1.815754
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.9172e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.032976
Average KL loss: 0.765595
Average total loss: 1.798570
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2577e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.036823
Average KL loss: 0.757983
Average total loss: 1.794806
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.5144e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.034937
Average KL loss: 0.753100
Average total loss: 1.788037
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.7333e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.016216
Average KL loss: 0.749414
Average total loss: 1.765630
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.1177e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.036481
Average KL loss: 0.746474
Average total loss: 1.782955
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.7433e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.013214
Average KL loss: 0.744134
Average total loss: 1.757348
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-9.9161e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.022893
Average KL loss: 0.742263
Average total loss: 1.765156
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.3500e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.029861
Average KL loss: 0.740937
Average total loss: 1.770798
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.6488e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.033526
Average KL loss: 0.739663
Average total loss: 1.773189
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.8703e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.032226
Average KL loss: 0.738477
Average total loss: 1.770703
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.8609e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.037633
Average KL loss: 0.737296
Average total loss: 1.774929
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(5.7173e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.034608
Average KL loss: 0.736693
Average total loss: 1.771301
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-9.5525e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.028334
Average KL loss: 0.735894
Average total loss: 1.764228
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(7.6285e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.049435
Average KL loss: 0.735258
Average total loss: 1.784693
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.9966e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.053351
Average KL loss: 0.735076
Average total loss: 1.788426
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.8188e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.019365
Average KL loss: 0.734650
Average total loss: 1.754015
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.2736e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.040881
Average KL loss: 0.734572
Average total loss: 1.775453
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.9856e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.034956
Average KL loss: 0.734545
Average total loss: 1.769500
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.3693e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.030724
Average KL loss: 0.733928
Average total loss: 1.764653
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-8.7940e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.029663
Average KL loss: 0.733660
Average total loss: 1.763323
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.8434e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.045538
Average KL loss: 0.733697
Average total loss: 1.779235
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(5.0926e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.035569
Average KL loss: 0.733508
Average total loss: 1.769077
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.7007e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.023529
Average KL loss: 0.733186
Average total loss: 1.756715
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.1533e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.037596
Average KL loss: 0.732580
Average total loss: 1.770176
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(6.7636e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.029923
Average KL loss: 0.732020
Average total loss: 1.761942
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-6.3272e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.026696
Average KL loss: 0.731592
Average total loss: 1.758288
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-9.1263e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.039568
Average KL loss: 0.731271
Average total loss: 1.770839
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-7.0103e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.041748
Average KL loss: 0.731117
Average total loss: 1.772865
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2077e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.032667
Average KL loss: 0.730841
Average total loss: 1.763508
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.4188e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.024503
Average KL loss: 0.730598
Average total loss: 1.755101
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.1217e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.027955
Average KL loss: 0.730388
Average total loss: 1.758343
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(7.9326e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.039435
Average KL loss: 0.730218
Average total loss: 1.769653
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(6.5675e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.038363
Average KL loss: 0.730053
Average total loss: 1.768416
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.1988e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.029612
Average KL loss: 0.729883
Average total loss: 1.759496
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.0731e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.027323
Average KL loss: 0.729709
Average total loss: 1.757032
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.5072e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.027022
Average KL loss: 0.729526
Average total loss: 1.756548
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(9.8314e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.035352
Average KL loss: 0.729380
Average total loss: 1.764731
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(4.0216e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.031447
Average KL loss: 0.729268
Average total loss: 1.760715
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.5241e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.037362
Average KL loss: 0.729202
Average total loss: 1.766563
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.8901e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.034416
Average KL loss: 0.729186
Average total loss: 1.763602
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.6718e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.021168
Average KL loss: 0.729170
Average total loss: 1.750337
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.6152e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.033791
Average KL loss: 0.729154
Average total loss: 1.762945
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.6080e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.028344
Average KL loss: 0.729138
Average total loss: 1.757482
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-9.0235e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.025214
Average KL loss: 0.729123
Average total loss: 1.754337
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.8574e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.032211
Average KL loss: 0.729106
Average total loss: 1.761317
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(3.6871e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.032386
Average KL loss: 0.729089
Average total loss: 1.761474
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.1223e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.030486
Average KL loss: 0.729073
Average total loss: 1.759558
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2082e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.040980
Average KL loss: 0.729059
Average total loss: 1.770039
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-7.1391e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.036048
Average KL loss: 0.729048
Average total loss: 1.765097
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.4693e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.038625
Average KL loss: 0.729038
Average total loss: 1.767663
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(3.8995e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.036652
Average KL loss: 0.729023
Average total loss: 1.765675
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(6.8225e-09, device='cuda:0')
 Percentile value: 0.014859018847346302
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =      80 /    1728             (  4.63%) | total_pruned =    1648 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     435 /   36864             (  1.18%) | total_pruned =   36429 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1665 /   36864             (  4.52%) | total_pruned =   35199 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1211 /   36864             (  3.29%) | total_pruned =   35653 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2250 /   36864             (  6.10%) | total_pruned =   34614 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    9508 /   73728             ( 12.90%) | total_pruned =   64220 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   16076 /  147456             ( 10.90%) | total_pruned =  131380 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     901 /    8192             ( 11.00%) | total_pruned =    7291 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    5466 /  147456             (  3.71%) | total_pruned =  141990 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2481 /  147456             (  1.68%) | total_pruned =  144975 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   34409 /  294912             ( 11.67%) | total_pruned =  260503 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   54806 /  589824             (  9.29%) | total_pruned =  535018 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2475 /   32768             (  7.55%) | total_pruned =   30293 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   23028 /  589824             (  3.90%) | total_pruned =  566796 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    9097 /  589824             (  1.54%) | total_pruned =  580727 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      92 /     256             ( 35.94%) | total_pruned =     164 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   70146 / 1179648             (  5.95%) | total_pruned = 1109502 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     323 /     512             ( 63.09%) | total_pruned =     189 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   41921 / 2359296             (  1.78%) | total_pruned = 2317375 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     156 /     512             ( 30.47%) | total_pruned =     356 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2114 /  131072             (  1.61%) | total_pruned =  128958 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     112 /     512             ( 21.88%) | total_pruned =     400 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   14356 / 2359296             (  0.61%) | total_pruned = 2344940 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     187 /     512             ( 36.52%) | total_pruned =     325 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    6556 / 2359296             (  0.28%) | total_pruned = 2352740 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      90 /     512             ( 17.58%) | total_pruned =     422 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
linear.weight        | nonzeros =     375 /    5120             (  7.32%) | total_pruned =    4745 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 66/200 Loss: 0.027130 Accuracy: 87.28 100.00 % Best test Accuracy: 87.34%
tensor(0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.8512e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.640739
Average KL loss: 1.630962
Average total loss: 3.271701
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(2.7181e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.638466
Average KL loss: 0.992294
Average total loss: 2.630760
tensor(0.0008, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(6.8904e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.507771
Average KL loss: 1.006376
Average total loss: 2.514147
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-2.7387e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.461642
Average KL loss: 1.019404
Average total loss: 2.481046
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-2.6343e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.426552
Average KL loss: 1.075740
Average total loss: 2.502292
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.2652e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.384524
Average KL loss: 1.081689
Average total loss: 2.466212
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(8.4079e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.378652
Average KL loss: 1.083673
Average total loss: 2.462325
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.2159e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.364772
Average KL loss: 1.112823
Average total loss: 2.477595
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.4893e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.336343
Average KL loss: 1.109664
Average total loss: 2.446007
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.0109e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.304100
Average KL loss: 1.115012
Average total loss: 2.419112
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.3267e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.306980
Average KL loss: 1.127211
Average total loss: 2.434191
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.2730e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.297636
Average KL loss: 1.120623
Average total loss: 2.418259
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.0833e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.306344
Average KL loss: 1.115018
Average total loss: 2.421363
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.1909e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.286023
Average KL loss: 1.134992
Average total loss: 2.421016
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(6.1646e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.273459
Average KL loss: 1.132313
Average total loss: 2.405772
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(4.6001e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.278813
Average KL loss: 1.147245
Average total loss: 2.426059
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.4467e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.253945
Average KL loss: 1.166542
Average total loss: 2.420486
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(3.5233e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.258267
Average KL loss: 1.174710
Average total loss: 2.432976
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.3721e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.246440
Average KL loss: 1.179889
Average total loss: 2.426329
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.6405e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.245557
Average KL loss: 1.182454
Average total loss: 2.428011
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.7644e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.248719
Average KL loss: 1.169557
Average total loss: 2.418276
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.2210e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.240272
Average KL loss: 1.160411
Average total loss: 2.400683
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(4.2818e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.233632
Average KL loss: 1.180011
Average total loss: 2.413642
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(4.4664e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.240883
Average KL loss: 1.182099
Average total loss: 2.422982
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.4288e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.225829
Average KL loss: 1.200912
Average total loss: 2.426742
tensor(-0.0016, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-5.5852e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.236717
Average KL loss: 1.194001
Average total loss: 2.430718
tensor(0.0008, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(4.0176e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.232371
Average KL loss: 1.190585
Average total loss: 2.422956
tensor(0.0006, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.2056e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.237732
Average KL loss: 1.195241
Average total loss: 2.432973
tensor(0.0006, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-6.6231e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.233338
Average KL loss: 1.192496
Average total loss: 2.425835
tensor(0.0006, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.0440e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.226618
Average KL loss: 1.207371
Average total loss: 2.433989
tensor(0.0006, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(1.3408e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.224478
Average KL loss: 1.218061
Average total loss: 2.442539
tensor(-0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-7.5316e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.233425
Average KL loss: 1.184646
Average total loss: 2.418070
tensor(0.0004, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-4.7740e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.228925
Average KL loss: 1.198604
Average total loss: 2.427529
tensor(0.0006, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.4492e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.224999
Average KL loss: 1.025763
Average total loss: 2.250762
tensor(0.0006, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.0979e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.206076
Average KL loss: 0.865226
Average total loss: 2.071303
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.2012e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.217040
Average KL loss: 0.820333
Average total loss: 2.037373
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.0726e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.213732
Average KL loss: 0.800304
Average total loss: 2.014035
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.3274e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.204118
Average KL loss: 0.789500
Average total loss: 1.993619
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.3330e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.217808
Average KL loss: 0.782286
Average total loss: 2.000094
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(9.8645e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.208630
Average KL loss: 0.775256
Average total loss: 1.983886
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.8634e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.212315
Average KL loss: 0.769118
Average total loss: 1.981432
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2109e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.211544
Average KL loss: 0.765804
Average total loss: 1.977348
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.1786e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.207772
Average KL loss: 0.762312
Average total loss: 1.970084
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.1696e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.217668
Average KL loss: 0.761027
Average total loss: 1.978695
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.4929e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.211216
Average KL loss: 0.759991
Average total loss: 1.971207
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-6.8784e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.206787
Average KL loss: 0.760149
Average total loss: 1.966936
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.8031e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.201245
Average KL loss: 0.756478
Average total loss: 1.957722
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(7.0275e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.215139
Average KL loss: 0.755201
Average total loss: 1.970340
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.0931e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.214645
Average KL loss: 0.755954
Average total loss: 1.970599
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-7.6409e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.225816
Average KL loss: 0.753860
Average total loss: 1.979676
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.1760e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.214921
Average KL loss: 0.755176
Average total loss: 1.970097
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.0754e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.206773
Average KL loss: 0.752480
Average total loss: 1.959254
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.6508e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.214041
Average KL loss: 0.750963
Average total loss: 1.965004
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.2996e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.212738
Average KL loss: 0.749581
Average total loss: 1.962319
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.8001e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.214782
Average KL loss: 0.749096
Average total loss: 1.963878
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.6315e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.213518
Average KL loss: 0.748276
Average total loss: 1.961794
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.0898e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.201235
Average KL loss: 0.747434
Average total loss: 1.948669
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(4.5705e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.216175
Average KL loss: 0.747990
Average total loss: 1.964165
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.4892e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.210549
Average KL loss: 0.749661
Average total loss: 1.960210
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.9441e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.206998
Average KL loss: 0.747185
Average total loss: 1.954183
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.9907e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.217278
Average KL loss: 0.747289
Average total loss: 1.964567
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(5.2703e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.211748
Average KL loss: 0.746387
Average total loss: 1.958136
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.0805e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.207777
Average KL loss: 0.743096
Average total loss: 1.950873
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(5.1433e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.203985
Average KL loss: 0.744829
Average total loss: 1.948814
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.9595e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.202341
Average KL loss: 0.741783
Average total loss: 1.944123
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.3682e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.210032
Average KL loss: 0.741896
Average total loss: 1.951928
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-7.0049e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.222217
Average KL loss: 0.741871
Average total loss: 1.964089
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(6.8068e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.210633
Average KL loss: 0.740055
Average total loss: 1.950688
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.8736e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.237392
Average KL loss: 0.741412
Average total loss: 1.978804
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.9293e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.216353
Average KL loss: 0.740569
Average total loss: 1.956922
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.0711e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.216164
Average KL loss: 0.741252
Average total loss: 1.957417
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.0641e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.208150
Average KL loss: 0.738424
Average total loss: 1.946574
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.0320e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.220130
Average KL loss: 0.739788
Average total loss: 1.959917
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.8459e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.208050
Average KL loss: 0.740599
Average total loss: 1.948648
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.7514e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.223388
Average KL loss: 0.740701
Average total loss: 1.964089
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.0185e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.215911
Average KL loss: 0.740111
Average total loss: 1.956022
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-5.3721e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.219431
Average KL loss: 0.734679
Average total loss: 1.954110
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.9013e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.214960
Average KL loss: 0.727574
Average total loss: 1.942534
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-5.3389e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.219137
Average KL loss: 0.723070
Average total loss: 1.942207
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.0705e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.215092
Average KL loss: 0.719393
Average total loss: 1.934485
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.1533e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.209858
Average KL loss: 0.716546
Average total loss: 1.926404
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.3714e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.201960
Average KL loss: 0.713784
Average total loss: 1.915744
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.1412e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.214694
Average KL loss: 0.711674
Average total loss: 1.926368
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-5.9185e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.192859
Average KL loss: 0.710046
Average total loss: 1.902904
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-5.8687e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.228577
Average KL loss: 0.708201
Average total loss: 1.936779
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.0147e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.214124
Average KL loss: 0.707143
Average total loss: 1.921268
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(3.5114e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.225782
Average KL loss: 0.706490
Average total loss: 1.932272
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.0385e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.224406
Average KL loss: 0.705503
Average total loss: 1.929909
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-5.1406e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.217101
Average KL loss: 0.704497
Average total loss: 1.921598
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.0531e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.216878
Average KL loss: 0.703699
Average total loss: 1.920577
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.2434e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.225279
Average KL loss: 0.702971
Average total loss: 1.928251
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.1313e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.210148
Average KL loss: 0.702014
Average total loss: 1.912162
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.0542e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.212908
Average KL loss: 0.701200
Average total loss: 1.914108
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.1165e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.214666
Average KL loss: 0.700586
Average total loss: 1.915252
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.5970e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.217503
Average KL loss: 0.700246
Average total loss: 1.917748
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(3.9636e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.220740
Average KL loss: 0.700032
Average total loss: 1.920772
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-7.7146e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.215352
Average KL loss: 0.699862
Average total loss: 1.915214
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.2321e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.219209
Average KL loss: 0.699719
Average total loss: 1.918929
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(8.4405e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.222877
Average KL loss: 0.699586
Average total loss: 1.922463
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-9.2212e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.221403
Average KL loss: 0.699468
Average total loss: 1.920871
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-6.6223e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.212647
Average KL loss: 0.699339
Average total loss: 1.911986
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.1504e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.208233
Average KL loss: 0.699219
Average total loss: 1.907452
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.5965e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.223524
Average KL loss: 0.699123
Average total loss: 1.922647
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(7.6274e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.208291
Average KL loss: 0.699011
Average total loss: 1.907302
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(5.5133e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.229444
Average KL loss: 0.698883
Average total loss: 1.928327
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.5721e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.212638
Average KL loss: 0.698800
Average total loss: 1.911437
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(5.6576e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.212768
Average KL loss: 0.698733
Average total loss: 1.911501
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.7942e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.225181
Average KL loss: 0.698721
Average total loss: 1.923903
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.4478e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.212263
Average KL loss: 0.698711
Average total loss: 1.910973
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-8.9204e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.220046
Average KL loss: 0.698699
Average total loss: 1.918745
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.8713e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.215958
Average KL loss: 0.698687
Average total loss: 1.914645
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.1901e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.203589
Average KL loss: 0.698675
Average total loss: 1.902264
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.6685e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.220399
Average KL loss: 0.698663
Average total loss: 1.919062
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-9.3814e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.212959
Average KL loss: 0.698653
Average total loss: 1.911612
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(7.5455e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.226797
Average KL loss: 0.698641
Average total loss: 1.925438
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(3.3512e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.218775
Average KL loss: 0.698629
Average total loss: 1.917404
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-6.1716e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.226817
Average KL loss: 0.698619
Average total loss: 1.925436
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(3.5724e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.222347
Average KL loss: 0.698610
Average total loss: 1.920957
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.9108e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.211830
Average KL loss: 0.698602
Average total loss: 1.910432
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.7746e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.218295
Average KL loss: 0.698594
Average total loss: 1.916889
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(4.0967e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.224961
Average KL loss: 0.698584
Average total loss: 1.923545
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(8.2055e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.224191
Average KL loss: 0.698576
Average total loss: 1.922766
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-6.0942e-10, device='cuda:0')
 Percentile value: 0.04795579835772514
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =      61 /    1728             (  3.53%) | total_pruned =    1667 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     182 /   36864             (  0.49%) | total_pruned =   36682 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     501 /   36864             (  1.36%) | total_pruned =   36363 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     487 /   36864             (  1.32%) | total_pruned =   36377 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     980 /   36864             (  2.66%) | total_pruned =   35884 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3871 /   73728             (  5.25%) | total_pruned =   69857 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    6558 /  147456             (  4.45%) | total_pruned =  140898 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     323 /    8192             (  3.94%) | total_pruned =    7869 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1773 /  147456             (  1.20%) | total_pruned =  145683 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     767 /  147456             (  0.52%) | total_pruned =  146689 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   13207 /  294912             (  4.48%) | total_pruned =  281705 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   19425 /  589824             (  3.29%) | total_pruned =  570399 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     185 /     256             ( 72.27%) | total_pruned =      71 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     751 /   32768             (  2.29%) | total_pruned =   32017 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    7789 /  589824             (  1.32%) | total_pruned =  582035 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2613 /  589824             (  0.44%) | total_pruned =  587211 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      68 /     256             ( 26.56%) | total_pruned =     188 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   16650 / 1179648             (  1.41%) | total_pruned = 1162998 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     244 /     512             ( 47.66%) | total_pruned =     268 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    8630 / 2359296             (  0.37%) | total_pruned = 2350666 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      93 /     512             ( 18.16%) | total_pruned =     419 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     383 /  131072             (  0.29%) | total_pruned =  130689 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2399 / 2359296             (  0.10%) | total_pruned = 2356897 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     108 /     512             ( 21.09%) | total_pruned =     404 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1215 / 2359296             (  0.05%) | total_pruned = 2358081 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      27 /     512             (  5.27%) | total_pruned =     485 | shape = torch.Size([512])
linear.weight        | nonzeros =     155 /    5120             (  3.03%) | total_pruned =    4965 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 85/200 Loss: 0.028057 Accuracy: 85.01 99.98 % Best test Accuracy: 85.63%
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.9604e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.823274
Average KL loss: 1.318314
Average total loss: 3.141588
tensor(0.0032, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(7.3434e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.811018
Average KL loss: 0.823458
Average total loss: 2.634476
tensor(0.0007, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(9.9659e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.684312
Average KL loss: 0.816104
Average total loss: 2.500416
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.7271e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.619688
Average KL loss: 0.864289
Average total loss: 2.483977
tensor(0.0003, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.9124e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.575789
Average KL loss: 0.855505
Average total loss: 2.431294
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.4752e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.573660
Average KL loss: 0.849197
Average total loss: 2.422857
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(1.7606e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.547313
Average KL loss: 0.862590
Average total loss: 2.409903
tensor(0.0003, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.7549e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.547948
Average KL loss: 0.874968
Average total loss: 2.422917
tensor(0.0003, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(2.9705e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.521064
Average KL loss: 0.887228
Average total loss: 2.408292
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-2.5153e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.476196
Average KL loss: 0.892504
Average total loss: 2.368700
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(6.0020e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.478750
Average KL loss: 0.878497
Average total loss: 2.357247
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.1576e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.467441
Average KL loss: 0.902788
Average total loss: 2.370229
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(2.0433e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.482228
Average KL loss: 0.901645
Average total loss: 2.383873
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.1876e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.469182
Average KL loss: 0.901304
Average total loss: 2.370485
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.5242e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.463915
Average KL loss: 0.898632
Average total loss: 2.362547
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(6.3768e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.470878
Average KL loss: 0.900254
Average total loss: 2.371132
tensor(0.0004, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.3770e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.471942
Average KL loss: 0.901867
Average total loss: 2.373808
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.9508e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.454252
Average KL loss: 0.907026
Average total loss: 2.361278
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.6609e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.451376
Average KL loss: 0.908181
Average total loss: 2.359557
tensor(0.0004, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(5.1798e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.439236
Average KL loss: 0.902384
Average total loss: 2.341620
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.2679e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.442827
Average KL loss: 0.915082
Average total loss: 2.357909
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.5037e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.435759
Average KL loss: 0.918486
Average total loss: 2.354245
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.2017e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.440006
Average KL loss: 0.934321
Average total loss: 2.374328
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-6.0330e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.433903
Average KL loss: 0.909764
Average total loss: 2.343667
tensor(0.0004, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.0305e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.430506
Average KL loss: 0.960315
Average total loss: 2.390821
tensor(-0.0061, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.6317e-06, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.431008
Average KL loss: 0.930473
Average total loss: 2.361482
tensor(0.0010, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.5561e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.425296
Average KL loss: 0.934280
Average total loss: 2.359576
tensor(0.0004, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.7235e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.420779
Average KL loss: 0.927301
Average total loss: 2.348081
tensor(0.0004, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(9.7846e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.425389
Average KL loss: 0.936586
Average total loss: 2.361975
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.6179e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.430343
Average KL loss: 0.927710
Average total loss: 2.358053
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-6.6618e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.404999
Average KL loss: 0.932946
Average total loss: 2.337945
tensor(-0.0007, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.9415e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.417057
Average KL loss: 0.921062
Average total loss: 2.338119
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.0810e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.417585
Average KL loss: 0.933859
Average total loss: 2.351444
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(6.9007e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.413119
Average KL loss: 0.944190
Average total loss: 2.357309
tensor(-0.0049, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.3411e-06, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.407824
Average KL loss: 0.974670
Average total loss: 2.382494
tensor(0.0014, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(2.5161e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.403968
Average KL loss: 0.929370
Average total loss: 2.333338
tensor(-0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.7364e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.405328
Average KL loss: 0.941724
Average total loss: 2.347052
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-5.9229e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.397289
Average KL loss: 0.954517
Average total loss: 2.351806
tensor(0.0004, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-9.8470e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.409741
Average KL loss: 0.941256
Average total loss: 2.350997
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.3343e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.408989
Average KL loss: 0.953740
Average total loss: 2.362729
tensor(0.0004, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-6.5727e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.395073
Average KL loss: 0.959363
Average total loss: 2.354436
tensor(0.0013, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(2.1473e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.413505
Average KL loss: 0.995627
Average total loss: 2.409133
tensor(-0.0019, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-5.9026e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.409468
Average KL loss: 0.956132
Average total loss: 2.365600
tensor(0.0004, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(5.4022e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.404661
Average KL loss: 0.952836
Average total loss: 2.357497
tensor(0.0004, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.2691e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.398579
Average KL loss: 0.959856
Average total loss: 2.358435
tensor(-0.0027, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-7.8453e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.409873
Average KL loss: 0.945171
Average total loss: 2.355044
tensor(0.0007, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(5.8182e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.407344
Average KL loss: 0.948236
Average total loss: 2.355580
tensor(0.0005, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.6602e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.400867
Average KL loss: 0.897728
Average total loss: 2.298595
tensor(0.0004, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-8.5327e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.387898
Average KL loss: 0.795906
Average total loss: 2.183804
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.4302e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.383286
Average KL loss: 0.752862
Average total loss: 2.136148
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.3019e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.382704
Average KL loss: 0.727203
Average total loss: 2.109908
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(9.1016e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.373127
Average KL loss: 0.712095
Average total loss: 2.085222
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.3849e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.387105
Average KL loss: 0.699870
Average total loss: 2.086975
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(7.5929e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.394441
Average KL loss: 0.693877
Average total loss: 2.088318
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.3221e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.387086
Average KL loss: 0.687977
Average total loss: 2.075063
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.1511e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.397640
Average KL loss: 0.684754
Average total loss: 2.082394
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.4736e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.389708
Average KL loss: 0.681260
Average total loss: 2.070968
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(8.3578e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.392263
Average KL loss: 0.677382
Average total loss: 2.069645
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(4.9821e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.394467
Average KL loss: 0.674176
Average total loss: 2.068643
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.9362e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.384257
Average KL loss: 0.670981
Average total loss: 2.055238
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.0113e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.383041
Average KL loss: 0.669047
Average total loss: 2.052089
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.6124e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.385225
Average KL loss: 0.669559
Average total loss: 2.054784
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(8.3513e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.382086
Average KL loss: 0.665820
Average total loss: 2.047906
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(6.1412e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.382089
Average KL loss: 0.664458
Average total loss: 2.046547
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-6.6965e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.385431
Average KL loss: 0.663285
Average total loss: 2.048716
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-9.4571e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.386850
Average KL loss: 0.661678
Average total loss: 2.048528
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(5.8202e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.388859
Average KL loss: 0.661754
Average total loss: 2.050612
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-6.1395e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.389111
Average KL loss: 0.660901
Average total loss: 2.050012
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-9.5269e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.384387
Average KL loss: 0.657763
Average total loss: 2.042150
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.0083e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.388874
Average KL loss: 0.656613
Average total loss: 2.045486
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.1974e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.388808
Average KL loss: 0.655075
Average total loss: 2.043883
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.0755e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.384869
Average KL loss: 0.653187
Average total loss: 2.038056
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.4464e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.390913
Average KL loss: 0.654124
Average total loss: 2.045037
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.1340e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.408390
Average KL loss: 0.655523
Average total loss: 2.063913
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.9485e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.398257
Average KL loss: 0.656697
Average total loss: 2.054954
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(5.9731e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.398356
Average KL loss: 0.654568
Average total loss: 2.052924
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(4.0950e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.390643
Average KL loss: 0.654537
Average total loss: 2.045180
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(3.0099e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.383671
Average KL loss: 0.652566
Average total loss: 2.036237
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.4679e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.387905
Average KL loss: 0.651617
Average total loss: 2.039522
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-6.3525e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.389834
Average KL loss: 0.649047
Average total loss: 2.038881
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.0091e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.391138
Average KL loss: 0.647660
Average total loss: 2.038798
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(9.6829e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.394752
Average KL loss: 0.646776
Average total loss: 2.041528
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.7389e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.401929
Average KL loss: 0.648376
Average total loss: 2.050305
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.3336e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.389884
Average KL loss: 0.648621
Average total loss: 2.038506
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(6.6754e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.394453
Average KL loss: 0.648552
Average total loss: 2.043005
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.2815e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.404853
Average KL loss: 0.647614
Average total loss: 2.052467
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(9.1035e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.402688
Average KL loss: 0.646310
Average total loss: 2.048998
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.4805e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.401856
Average KL loss: 0.644666
Average total loss: 2.046522
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.2187e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.397418
Average KL loss: 0.644705
Average total loss: 2.042122
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.0610e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.402686
Average KL loss: 0.642895
Average total loss: 2.045582
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(4.8268e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.391425
Average KL loss: 0.639921
Average total loss: 2.031346
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.3604e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.400168
Average KL loss: 0.637678
Average total loss: 2.037845
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-7.8731e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.399953
Average KL loss: 0.635872
Average total loss: 2.035825
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.8835e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.402163
Average KL loss: 0.634117
Average total loss: 2.036279
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2377e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.403850
Average KL loss: 0.632798
Average total loss: 2.036648
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.2513e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.399505
Average KL loss: 0.631582
Average total loss: 2.031087
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.2110e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.408651
Average KL loss: 0.630492
Average total loss: 2.039144
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.3496e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.401414
Average KL loss: 0.629533
Average total loss: 2.030948
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(8.3269e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.388182
Average KL loss: 0.628573
Average total loss: 2.016755
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.0457e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.388532
Average KL loss: 0.627430
Average total loss: 2.015962
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.6158e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.401116
Average KL loss: 0.626717
Average total loss: 2.027832
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.8791e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.417738
Average KL loss: 0.626101
Average total loss: 2.043838
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.7027e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.399978
Average KL loss: 0.625558
Average total loss: 2.025536
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.5258e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.386461
Average KL loss: 0.624862
Average total loss: 2.011323
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.9521e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.402018
Average KL loss: 0.624229
Average total loss: 2.026248
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(4.1732e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.405701
Average KL loss: 0.623681
Average total loss: 2.029382
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.5178e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.402373
Average KL loss: 0.623264
Average total loss: 2.025637
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.1023e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.392223
Average KL loss: 0.622799
Average total loss: 2.015022
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.7263e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.396936
Average KL loss: 0.622175
Average total loss: 2.019112
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.5644e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.409243
Average KL loss: 0.621727
Average total loss: 2.030970
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.6197e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.413456
Average KL loss: 0.621355
Average total loss: 2.034811
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(3.5075e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.405300
Average KL loss: 0.620790
Average total loss: 2.026090
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(8.8471e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.403663
Average KL loss: 0.620533
Average total loss: 2.024196
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(5.5291e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.384533
Average KL loss: 0.620132
Average total loss: 2.004665
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.1617e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.400413
Average KL loss: 0.619551
Average total loss: 2.019964
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(8.3163e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.387161
Average KL loss: 0.619157
Average total loss: 2.006318
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.0427e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.403529
Average KL loss: 0.618713
Average total loss: 2.022242
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(5.5013e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.395031
Average KL loss: 0.618490
Average total loss: 2.013520
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-7.2092e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.415423
Average KL loss: 0.618274
Average total loss: 2.033697
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.6815e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.391356
Average KL loss: 0.618021
Average total loss: 2.009377
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.1674e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.405888
Average KL loss: 0.618008
Average total loss: 2.023895
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-6.7567e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.401116
Average KL loss: 0.618033
Average total loss: 2.019149
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(7.9722e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.398161
Average KL loss: 0.617689
Average total loss: 2.015851
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(8.8470e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.401459
Average KL loss: 0.617524
Average total loss: 2.018983
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.4473e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.407893
Average KL loss: 0.617324
Average total loss: 2.025217
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.1044e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.399772
Average KL loss: 0.617273
Average total loss: 2.017045
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.4081e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.397656
Average KL loss: 0.617208
Average total loss: 2.014863
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.2116e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.401207
Average KL loss: 0.617161
Average total loss: 2.018367
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(4.4950e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.400874
Average KL loss: 0.617145
Average total loss: 2.018019
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.0309e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.392479
Average KL loss: 0.617091
Average total loss: 2.009570
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.9779e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.400305
Average KL loss: 0.617024
Average total loss: 2.017329
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.1112e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.396842
Average KL loss: 0.616978
Average total loss: 2.013820
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-7.6902e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.399189
Average KL loss: 0.616934
Average total loss: 2.016123
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(7.9474e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.407573
Average KL loss: 0.616898
Average total loss: 2.024471
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-7.8226e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.384791
Average KL loss: 0.616833
Average total loss: 2.001624
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.3965e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.401825
Average KL loss: 0.616775
Average total loss: 2.018600
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.3459e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.390258
Average KL loss: 0.616722
Average total loss: 2.006981
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(8.8463e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.396279
Average KL loss: 0.616678
Average total loss: 2.012957
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(8.8260e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.407980
Average KL loss: 0.616637
Average total loss: 2.024617
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-7.6291e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.393849
Average KL loss: 0.616611
Average total loss: 2.010460
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.3714e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.400954
Average KL loss: 0.616575
Average total loss: 2.017529
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.4134e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.398570
Average KL loss: 0.616544
Average total loss: 2.015113
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.9137e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.400071
Average KL loss: 0.616503
Average total loss: 2.016574
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.6813e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.399244
Average KL loss: 0.616448
Average total loss: 2.015692
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-9.0614e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.404456
Average KL loss: 0.616395
Average total loss: 2.020851
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.2587e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.404759
Average KL loss: 0.616349
Average total loss: 2.021108
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-8.5388e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.393581
Average KL loss: 0.616329
Average total loss: 2.009909
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2259e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.403444
Average KL loss: 0.616324
Average total loss: 2.019768
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.4029e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.396039
Average KL loss: 0.616318
Average total loss: 2.012357
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.3166e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.400744
Average KL loss: 0.616313
Average total loss: 2.017057
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(7.4080e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.399455
Average KL loss: 0.616309
Average total loss: 2.015764
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-7.7168e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.396625
Average KL loss: 0.616303
Average total loss: 2.012928
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(4.0612e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.406141
Average KL loss: 0.616299
Average total loss: 2.022440
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.9068e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.415833
Average KL loss: 0.616297
Average total loss: 2.032130
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.0014e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.407771
Average KL loss: 0.616292
Average total loss: 2.024064
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.8006e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.391982
Average KL loss: 0.616289
Average total loss: 2.008271
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.8682e-09, device='cuda:0')
 Percentile value: 0.11085603386163712
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =      48 /    1728             (  2.78%) | total_pruned =    1680 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      74 /   36864             (  0.20%) | total_pruned =   36790 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     185 /   36864             (  0.50%) | total_pruned =   36679 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     230 /   36864             (  0.62%) | total_pruned =   36634 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     517 /   36864             (  1.40%) | total_pruned =   36347 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1587 /   73728             (  2.15%) | total_pruned =   72141 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2502 /  147456             (  1.70%) | total_pruned =  144954 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     132 /    8192             (  1.61%) | total_pruned =    8060 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     516 /  147456             (  0.35%) | total_pruned =  146940 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     196 /  147456             (  0.13%) | total_pruned =  147260 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    4427 /  294912             (  1.50%) | total_pruned =  290485 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    5962 /  589824             (  1.01%) | total_pruned =  583862 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     131 /     256             ( 51.17%) | total_pruned =     125 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     192 /   32768             (  0.59%) | total_pruned =   32576 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2202 /  589824             (  0.37%) | total_pruned =  587622 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      79 /     256             ( 30.86%) | total_pruned =     177 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     797 /  589824             (  0.14%) | total_pruned =  589027 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    3587 / 1179648             (  0.30%) | total_pruned = 1176061 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     144 /     512             ( 28.12%) | total_pruned =     368 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1918 / 2359296             (  0.08%) | total_pruned = 2357378 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      98 /  131072             (  0.07%) | total_pruned =  130974 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     533 / 2359296             (  0.02%) | total_pruned = 2358763 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      50 /     512             (  9.77%) | total_pruned =     462 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     253 / 2359296             (  0.01%) | total_pruned = 2359043 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
linear.weight        | nonzeros =      60 /    5120             (  1.17%) | total_pruned =    5060 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 165/200 Loss: 0.167143 Accuracy: 79.98 97.47 % Best test Accuracy: 82.16%
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-8.5317e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.967875
Average KL loss: 1.014049
Average total loss: 2.981924
tensor(0.0040, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(9.4814e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.977513
Average KL loss: 0.606590
Average total loss: 2.584103
tensor(0.0006, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(8.4220e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.892482
Average KL loss: 0.594900
Average total loss: 2.487382
tensor(0.0002, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.1874e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.797282
Average KL loss: 0.607010
Average total loss: 2.404292
tensor(0.0002, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.3163e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.731515
Average KL loss: 0.619501
Average total loss: 2.351016
tensor(0.0002, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-7.4732e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.692246
Average KL loss: 0.630478
Average total loss: 2.322724
tensor(0.0002, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-3.7066e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.651060
Average KL loss: 0.646981
Average total loss: 2.298041
tensor(0.0002, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(3.5542e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.613154
Average KL loss: 0.650889
Average total loss: 2.264043
tensor(0.0002, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.2004e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.610612
Average KL loss: 0.658464
Average total loss: 2.269076
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.8223e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.587278
Average KL loss: 0.669539
Average total loss: 2.256817
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(3.5509e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.591459
Average KL loss: 0.672983
Average total loss: 2.264442
tensor(0.0003, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.0588e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.566850
Average KL loss: 0.682466
Average total loss: 2.249316
tensor(0.0003, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.0756e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.561462
Average KL loss: 0.679293
Average total loss: 2.240756
tensor(0.0003, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(5.6272e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.540341
Average KL loss: 0.675971
Average total loss: 2.216312
tensor(0.0003, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-1.1923e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.550143
Average KL loss: 0.681143
Average total loss: 2.231286
tensor(0.0003, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-3.3969e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.536160
Average KL loss: 0.690645
Average total loss: 2.226806
tensor(0.0003, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(5.6960e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.535871
Average KL loss: 0.700291
Average total loss: 2.236161
tensor(0.0003, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(3.8216e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.524853
Average KL loss: 0.699805
Average total loss: 2.224658
tensor(0.0003, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.2558e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.512473
Average KL loss: 0.699552
Average total loss: 2.212025
tensor(0.0003, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.9329e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.503076
Average KL loss: 0.693918
Average total loss: 2.196994
tensor(0.0003, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(6.2673e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.501396
Average KL loss: 0.703365
Average total loss: 2.204760
tensor(0.0003, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.0435e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.483791
Average KL loss: 0.701066
Average total loss: 2.184856
tensor(0.0003, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.2395e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.493358
Average KL loss: 0.699213
Average total loss: 2.192572
tensor(0.0003, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-9.6093e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.494347
Average KL loss: 0.702065
Average total loss: 2.196412
tensor(0.0003, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-9.1328e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.480546
Average KL loss: 0.791714
Average total loss: 2.272261
tensor(-0.0086, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.2230e-06, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.484538
Average KL loss: 0.733746
Average total loss: 2.218284
tensor(0.0011, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.9096e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.491742
Average KL loss: 0.711898
Average total loss: 2.203640
tensor(0.0003, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.4619e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.479391
Average KL loss: 0.725848
Average total loss: 2.205239
tensor(0.0003, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.9384e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.468239
Average KL loss: 0.724981
Average total loss: 2.193219
tensor(0.0003, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.0753e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.476537
Average KL loss: 0.726833
Average total loss: 2.203370
tensor(0.0003, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-9.2295e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.469788
Average KL loss: 0.736682
Average total loss: 2.206471
tensor(0.0003, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-7.4864e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.463430
Average KL loss: 0.733587
Average total loss: 2.197017
tensor(0.0003, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.2062e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.453116
Average KL loss: 0.729529
Average total loss: 2.182645
tensor(0.0003, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(5.3124e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.458559
Average KL loss: 0.730412
Average total loss: 2.188971
tensor(-0.0070, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.8398e-06, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.468485
Average KL loss: 0.803897
Average total loss: 2.272381
tensor(0.0017, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(3.4431e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.449184
Average KL loss: 0.734517
Average total loss: 2.183701
tensor(0.0004, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(3.0582e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.444114
Average KL loss: 0.724528
Average total loss: 2.168641
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(3.8933e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.458839
Average KL loss: 0.727071
Average total loss: 2.185910
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.5679e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.447236
Average KL loss: 0.731002
Average total loss: 2.178237
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.0460e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.445272
Average KL loss: 0.733983
Average total loss: 2.179255
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.2252e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.461555
Average KL loss: 0.738138
Average total loss: 2.199693
tensor(0.0004, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.0304e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.442211
Average KL loss: 0.832620
Average total loss: 2.274832
tensor(-0.0027, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-7.7002e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.437432
Average KL loss: 0.757126
Average total loss: 2.194558
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.3073e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.431391
Average KL loss: 0.760317
Average total loss: 2.191709
tensor(0.0003, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(3.7912e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.424516
Average KL loss: 0.757128
Average total loss: 2.181645
tensor(0.0003, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-6.3497e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.433397
Average KL loss: 0.749921
Average total loss: 2.183317
tensor(0.0004, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-9.3437e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.423083
Average KL loss: 0.746741
Average total loss: 2.169825
tensor(0.0004, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(2.3287e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.442284
Average KL loss: 0.745141
Average total loss: 2.187425
tensor(0.0003, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(2.3680e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.440990
Average KL loss: 0.724520
Average total loss: 2.165510
tensor(0.0003, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.2885e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.435533
Average KL loss: 0.690795
Average total loss: 2.126327
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(9.9572e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.436873
Average KL loss: 0.671700
Average total loss: 2.108573
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.1175e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.424960
Average KL loss: 0.657937
Average total loss: 2.082897
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.9392e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.426373
Average KL loss: 0.646970
Average total loss: 2.073343
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(2.3334e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.435142
Average KL loss: 0.638831
Average total loss: 2.073972
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.1556e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.430984
Average KL loss: 0.632069
Average total loss: 2.063053
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.2748e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.423822
Average KL loss: 0.626986
Average total loss: 2.050808
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-6.8599e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.419737
Average KL loss: 0.621715
Average total loss: 2.041452
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.5215e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.422684
Average KL loss: 0.617266
Average total loss: 2.039950
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.1586e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.437864
Average KL loss: 0.614776
Average total loss: 2.052639
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.7537e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.427560
Average KL loss: 0.612713
Average total loss: 2.040273
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.7249e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.446961
Average KL loss: 0.610328
Average total loss: 2.057289
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-8.0860e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.434045
Average KL loss: 0.609219
Average total loss: 2.043265
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-8.8393e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.430472
Average KL loss: 0.608634
Average total loss: 2.039106
tensor(0.0003, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-5.1171e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.425853
Average KL loss: 0.607128
Average total loss: 2.032982
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.5559e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.439510
Average KL loss: 0.604722
Average total loss: 2.044232
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.6557e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.428207
Average KL loss: 0.603610
Average total loss: 2.031816
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-8.9961e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.431253
Average KL loss: 0.602371
Average total loss: 2.033624
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.4818e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.430915
Average KL loss: 0.600640
Average total loss: 2.031555
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.0169e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.430862
Average KL loss: 0.598579
Average total loss: 2.029440
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.9533e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.429467
Average KL loss: 0.596562
Average total loss: 2.026030
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(6.2412e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.434694
Average KL loss: 0.594640
Average total loss: 2.029334
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(9.7158e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.447728
Average KL loss: 0.594354
Average total loss: 2.042082
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.1721e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.442219
Average KL loss: 0.593906
Average total loss: 2.036125
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(5.9250e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.437735
Average KL loss: 0.592782
Average total loss: 2.030516
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.5925e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.447070
Average KL loss: 0.591093
Average total loss: 2.038163
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.7675e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.442377
Average KL loss: 0.590371
Average total loss: 2.032748
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.5828e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.442249
Average KL loss: 0.589216
Average total loss: 2.031465
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.2815e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.446553
Average KL loss: 0.588206
Average total loss: 2.034759
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2218e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.436565
Average KL loss: 0.587736
Average total loss: 2.024300
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(3.3285e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.448819
Average KL loss: 0.588185
Average total loss: 2.037004
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.6154e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.450982
Average KL loss: 0.589201
Average total loss: 2.040183
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.5403e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.435214
Average KL loss: 0.588118
Average total loss: 2.023332
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.2134e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.452940
Average KL loss: 0.586602
Average total loss: 2.039542
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(9.1829e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.456280
Average KL loss: 0.587032
Average total loss: 2.043312
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.0773e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.439654
Average KL loss: 0.587218
Average total loss: 2.026872
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-6.9844e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.445000
Average KL loss: 0.586600
Average total loss: 2.031600
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.1116e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.446160
Average KL loss: 0.585881
Average total loss: 2.032040
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-9.8407e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.438761
Average KL loss: 0.585497
Average total loss: 2.024258
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-7.6978e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.437697
Average KL loss: 0.584656
Average total loss: 2.022354
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.8897e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.438888
Average KL loss: 0.584479
Average total loss: 2.023367
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.0874e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.440728
Average KL loss: 0.583295
Average total loss: 2.024023
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.1489e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.424438
Average KL loss: 0.582334
Average total loss: 2.006773
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.5520e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.453493
Average KL loss: 0.581992
Average total loss: 2.035485
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.8288e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.439982
Average KL loss: 0.581563
Average total loss: 2.021545
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.5247e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.442647
Average KL loss: 0.580944
Average total loss: 2.023591
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.6424e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.441719
Average KL loss: 0.580743
Average total loss: 2.022463
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(6.3889e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.450761
Average KL loss: 0.580395
Average total loss: 2.031156
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(7.7436e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.447734
Average KL loss: 0.580822
Average total loss: 2.028556
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(3.2702e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.451910
Average KL loss: 0.580806
Average total loss: 2.032716
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.7580e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.453094
Average KL loss: 0.580536
Average total loss: 2.033630
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.1951e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.453878
Average KL loss: 0.580144
Average total loss: 2.034022
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.4412e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.436267
Average KL loss: 0.578910
Average total loss: 2.015177
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(9.0306e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.451617
Average KL loss: 0.577325
Average total loss: 2.028942
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.3423e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.443640
Average KL loss: 0.576637
Average total loss: 2.020276
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.0808e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.447409
Average KL loss: 0.575743
Average total loss: 2.023152
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-6.3995e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.444421
Average KL loss: 0.575104
Average total loss: 2.019524
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.0916e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.433274
Average KL loss: 0.574514
Average total loss: 2.007788
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(4.7126e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.452844
Average KL loss: 0.573986
Average total loss: 2.026831
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.0094e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.454822
Average KL loss: 0.573535
Average total loss: 2.028357
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(6.4269e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.453823
Average KL loss: 0.573151
Average total loss: 2.026974
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(3.3693e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.438289
Average KL loss: 0.572617
Average total loss: 2.010907
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(8.0507e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.445989
Average KL loss: 0.572181
Average total loss: 2.018169
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.3051e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.446186
Average KL loss: 0.571732
Average total loss: 2.017918
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(5.4271e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.448992
Average KL loss: 0.571417
Average total loss: 2.020409
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(6.8338e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.440093
Average KL loss: 0.571288
Average total loss: 2.011381
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.1566e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.446516
Average KL loss: 0.571256
Average total loss: 2.017772
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.1578e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.444264
Average KL loss: 0.571213
Average total loss: 2.015477
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.4142e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.440166
Average KL loss: 0.571170
Average total loss: 2.011335
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(4.7979e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.452687
Average KL loss: 0.571121
Average total loss: 2.023808
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(7.2156e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.454982
Average KL loss: 0.571082
Average total loss: 2.026064
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(5.3474e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.448080
Average KL loss: 0.571050
Average total loss: 2.019129
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(6.6650e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.459724
Average KL loss: 0.571025
Average total loss: 2.030748
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.3521e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.437661
Average KL loss: 0.570994
Average total loss: 2.008655
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.2065e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.449291
Average KL loss: 0.570958
Average total loss: 2.020250
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-7.8264e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.447244
Average KL loss: 0.570915
Average total loss: 2.018159
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.4363e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.449970
Average KL loss: 0.570896
Average total loss: 2.020866
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.4554e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.448413
Average KL loss: 0.570892
Average total loss: 2.019304
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(8.6790e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.439326
Average KL loss: 0.570887
Average total loss: 2.010213
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.3874e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.447679
Average KL loss: 0.570882
Average total loss: 2.018561
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.2237e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.451394
Average KL loss: 0.570879
Average total loss: 2.022273
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.2425e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.451340
Average KL loss: 0.570875
Average total loss: 2.022215
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(6.6918e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.445443
Average KL loss: 0.570871
Average total loss: 2.016315
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.8153e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.447950
Average KL loss: 0.570867
Average total loss: 2.018817
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.8584e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.447219
Average KL loss: 0.570863
Average total loss: 2.018082
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(2.7878e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.439419
Average KL loss: 0.570859
Average total loss: 2.010277
tensor(0.0003, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(5.6036e-09, device='cuda:0')
 Percentile value: 0.2715595394372939
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =      22 /    1728             (  1.27%) | total_pruned =    1706 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      27 /   36864             (  0.07%) | total_pruned =   36837 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      90 /   36864             (  0.24%) | total_pruned =   36774 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     116 /   36864             (  0.31%) | total_pruned =   36748 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     267 /   36864             (  0.72%) | total_pruned =   36597 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     683 /   73728             (  0.93%) | total_pruned =   73045 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     926 /  147456             (  0.63%) | total_pruned =  146530 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      36 /    8192             (  0.44%) | total_pruned =    8156 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     112 /  147456             (  0.08%) | total_pruned =  147344 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =      56 /  147456             (  0.04%) | total_pruned =  147400 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1348 /  294912             (  0.46%) | total_pruned =  293564 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1529 /  589824             (  0.26%) | total_pruned =  588295 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      65 /     256             ( 25.39%) | total_pruned =     191 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      58 /   32768             (  0.18%) | total_pruned =   32710 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     540 /  589824             (  0.09%) | total_pruned =  589284 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     191 /  589824             (  0.03%) | total_pruned =  589633 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     764 / 1179648             (  0.06%) | total_pruned = 1178884 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      67 /     512             ( 13.09%) | total_pruned =     445 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     463 / 2359296             (  0.02%) | total_pruned = 2358833 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      37 /  131072             (  0.03%) | total_pruned =  131035 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     129 / 2359296             (  0.01%) | total_pruned = 2359167 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      63 / 2359296             (  0.00%) | total_pruned = 2359233 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
linear.weight        | nonzeros =      40 /    5120             (  0.78%) | total_pruned =    5080 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 179/200 Loss: 0.594718 Accuracy: 73.19 79.80 % Best test Accuracy: 73.75%
