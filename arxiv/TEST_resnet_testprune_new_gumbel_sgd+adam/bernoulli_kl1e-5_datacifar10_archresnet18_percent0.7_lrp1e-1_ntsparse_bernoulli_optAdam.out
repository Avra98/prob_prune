Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(2.2858e-06, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.427859
Average KL loss: 24.475323
Average total loss: 25.903181
tensor(-2.6658, device='cuda:0') tensor(1.0850, device='cuda:0') tensor(6.6712e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.975640
Average KL loss: 8.567855
Average total loss: 9.543495
tensor(-3.5107, device='cuda:0') tensor(1.4869, device='cuda:0') tensor(3.9976e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.801338
Average KL loss: 5.844136
Average total loss: 6.645473
tensor(-3.9914, device='cuda:0') tensor(1.6730, device='cuda:0') tensor(2.9207e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.703863
Average KL loss: 4.563307
Average total loss: 5.267170
tensor(-4.3441, device='cuda:0') tensor(1.8088, device='cuda:0') tensor(2.2821e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.644561
Average KL loss: 3.795215
Average total loss: 4.439776
tensor(-4.6254, device='cuda:0') tensor(1.9150, device='cuda:0') tensor(1.8507e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.614952
Average KL loss: 3.279434
Average total loss: 3.894386
tensor(-4.8601, device='cuda:0') tensor(2.0112, device='cuda:0') tensor(1.6363e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.578438
Average KL loss: 2.913968
Average total loss: 3.492406
tensor(-5.0623, device='cuda:0') tensor(2.0927, device='cuda:0') tensor(1.4859e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.566051
Average KL loss: 2.637422
Average total loss: 3.203473
tensor(-5.2404, device='cuda:0') tensor(2.1665, device='cuda:0') tensor(1.2723e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.529497
Average KL loss: 2.418420
Average total loss: 2.947917
tensor(-5.3997, device='cuda:0') tensor(2.2271, device='cuda:0') tensor(1.0465e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.519156
Average KL loss: 2.239531
Average total loss: 2.758687
tensor(-5.5441, device='cuda:0') tensor(2.2836, device='cuda:0') tensor(1.0450e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.496007
Average KL loss: 2.096308
Average total loss: 2.592315
tensor(-5.6761, device='cuda:0') tensor(2.3357, device='cuda:0') tensor(9.6836e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.479302
Average KL loss: 1.969824
Average total loss: 2.449126
tensor(-5.7983, device='cuda:0') tensor(2.3787, device='cuda:0') tensor(8.4402e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.465615
Average KL loss: 1.861752
Average total loss: 2.327366
tensor(-5.9116, device='cuda:0') tensor(2.4195, device='cuda:0') tensor(8.0558e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.450814
Average KL loss: 1.767076
Average total loss: 2.217891
tensor(-6.0176, device='cuda:0') tensor(2.4559, device='cuda:0') tensor(8.3224e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.447322
Average KL loss: 1.685801
Average total loss: 2.133123
tensor(-6.1174, device='cuda:0') tensor(2.4911, device='cuda:0') tensor(7.0562e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.431861
Average KL loss: 1.615296
Average total loss: 2.047156
tensor(-6.2116, device='cuda:0') tensor(2.5246, device='cuda:0') tensor(6.0537e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.420669
Average KL loss: 1.553363
Average total loss: 1.974031
tensor(-6.3007, device='cuda:0') tensor(2.5569, device='cuda:0') tensor(7.0796e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.416689
Average KL loss: 1.498437
Average total loss: 1.915125
tensor(-6.3856, device='cuda:0') tensor(2.5878, device='cuda:0') tensor(6.1953e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.404642
Average KL loss: 1.449803
Average total loss: 1.854445
tensor(-6.4666, device='cuda:0') tensor(2.6149, device='cuda:0') tensor(5.5246e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.394230
Average KL loss: 1.404339
Average total loss: 1.798569
tensor(-6.5439, device='cuda:0') tensor(2.6430, device='cuda:0') tensor(4.9728e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.376904
Average KL loss: 1.363245
Average total loss: 1.740149
tensor(-6.6182, device='cuda:0') tensor(2.6657, device='cuda:0') tensor(4.9316e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.370171
Average KL loss: 1.322524
Average total loss: 1.692696
tensor(-6.6895, device='cuda:0') tensor(2.6877, device='cuda:0') tensor(4.4392e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.363987
Average KL loss: 1.286941
Average total loss: 1.650929
tensor(-6.7579, device='cuda:0') tensor(2.7099, device='cuda:0') tensor(4.7026e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.356287
Average KL loss: 1.255571
Average total loss: 1.611858
tensor(-6.8239, device='cuda:0') tensor(2.7317, device='cuda:0') tensor(4.3283e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.351689
Average KL loss: 1.227037
Average total loss: 1.578726
tensor(-6.8876, device='cuda:0') tensor(2.7542, device='cuda:0') tensor(4.0771e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.341743
Average KL loss: 1.200454
Average total loss: 1.542197
tensor(-6.9495, device='cuda:0') tensor(2.7729, device='cuda:0') tensor(3.7488e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.329618
Average KL loss: 1.173905
Average total loss: 1.503524
tensor(-7.0093, device='cuda:0') tensor(2.7903, device='cuda:0') tensor(3.5093e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.327395
Average KL loss: 1.149217
Average total loss: 1.476612
tensor(-7.0674, device='cuda:0') tensor(2.8080, device='cuda:0') tensor(3.9677e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.318383
Average KL loss: 1.126751
Average total loss: 1.445134
tensor(-7.1237, device='cuda:0') tensor(2.8257, device='cuda:0') tensor(3.3608e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.311867
Average KL loss: 1.107716
Average total loss: 1.419583
tensor(-7.1783, device='cuda:0') tensor(2.8446, device='cuda:0') tensor(3.7653e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.314507
Average KL loss: 1.090124
Average total loss: 1.404631
tensor(-7.2316, device='cuda:0') tensor(2.8628, device='cuda:0') tensor(3.4663e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.301912
Average KL loss: 1.073376
Average total loss: 1.375288
tensor(-7.2835, device='cuda:0') tensor(2.8799, device='cuda:0') tensor(3.3503e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.295801
Average KL loss: 1.056760
Average total loss: 1.352561
tensor(-7.3343, device='cuda:0') tensor(2.8957, device='cuda:0') tensor(2.7143e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.288588
Average KL loss: 1.041291
Average total loss: 1.329879
tensor(-7.3838, device='cuda:0') tensor(2.9110, device='cuda:0') tensor(3.1174e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.279274
Average KL loss: 1.025672
Average total loss: 1.304947
tensor(-7.4323, device='cuda:0') tensor(2.9241, device='cuda:0') tensor(2.8696e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.276624
Average KL loss: 1.010266
Average total loss: 1.286890
tensor(-7.4796, device='cuda:0') tensor(2.9381, device='cuda:0') tensor(2.6649e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.276498
Average KL loss: 0.997071
Average total loss: 1.273569
tensor(-7.5259, device='cuda:0') tensor(2.9525, device='cuda:0') tensor(2.7341e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.264531
Average KL loss: 0.984780
Average total loss: 1.249311
tensor(-7.5713, device='cuda:0') tensor(2.9651, device='cuda:0') tensor(2.4011e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.261839
Average KL loss: 0.972334
Average total loss: 1.234173
tensor(-7.6157, device='cuda:0') tensor(2.9785, device='cuda:0') tensor(2.4761e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.255405
Average KL loss: 0.960781
Average total loss: 1.216186
tensor(-7.6592, device='cuda:0') tensor(2.9913, device='cuda:0') tensor(2.4778e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.250326
Average KL loss: 0.948849
Average total loss: 1.199175
tensor(-7.7019, device='cuda:0') tensor(3.0037, device='cuda:0') tensor(2.2954e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.242255
Average KL loss: 0.937579
Average total loss: 1.179835
tensor(-7.7439, device='cuda:0') tensor(3.0145, device='cuda:0') tensor(2.4111e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.242475
Average KL loss: 0.927196
Average total loss: 1.169671
tensor(-7.7852, device='cuda:0') tensor(3.0271, device='cuda:0') tensor(1.9568e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.237566
Average KL loss: 0.918372
Average total loss: 1.155938
tensor(-7.8257, device='cuda:0') tensor(3.0402, device='cuda:0') tensor(1.8565e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.231139
Average KL loss: 0.909178
Average total loss: 1.140317
tensor(-7.8657, device='cuda:0') tensor(3.0509, device='cuda:0') tensor(2.2341e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.230029
Average KL loss: 0.900959
Average total loss: 1.130988
tensor(-7.9050, device='cuda:0') tensor(3.0637, device='cuda:0') tensor(1.7827e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.222732
Average KL loss: 0.893591
Average total loss: 1.116323
tensor(-7.9436, device='cuda:0') tensor(3.0754, device='cuda:0') tensor(1.8981e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.219608
Average KL loss: 0.885450
Average total loss: 1.105058
tensor(-7.9816, device='cuda:0') tensor(3.0876, device='cuda:0') tensor(1.7393e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.218403
Average KL loss: 0.878401
Average total loss: 1.096804
tensor(-8.0191, device='cuda:0') tensor(3.0993, device='cuda:0') tensor(2.0889e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.214640
Average KL loss: 0.871187
Average total loss: 1.085827
tensor(-8.0560, device='cuda:0') tensor(3.1107, device='cuda:0') tensor(1.6254e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.208348
Average KL loss: 0.864896
Average total loss: 1.073245
tensor(-8.0924, device='cuda:0') tensor(3.1220, device='cuda:0') tensor(1.7457e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.206843
Average KL loss: 0.858217
Average total loss: 1.065060
tensor(-8.1284, device='cuda:0') tensor(3.1326, device='cuda:0') tensor(1.8687e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.203412
Average KL loss: 0.852110
Average total loss: 1.055522
tensor(-8.1639, device='cuda:0') tensor(3.1439, device='cuda:0') tensor(1.4495e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.195823
Average KL loss: 0.846795
Average total loss: 1.042618
tensor(-8.1989, device='cuda:0') tensor(3.1554, device='cuda:0') tensor(1.6222e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.190919
Average KL loss: 0.841551
Average total loss: 1.032471
tensor(-8.2334, device='cuda:0') tensor(3.1658, device='cuda:0') tensor(1.6198e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.191086
Average KL loss: 0.835999
Average total loss: 1.027085
tensor(-8.2675, device='cuda:0') tensor(3.1767, device='cuda:0') tensor(1.7072e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.185522
Average KL loss: 0.829733
Average total loss: 1.015255
tensor(-8.3013, device='cuda:0') tensor(3.1853, device='cuda:0') tensor(1.4239e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.182728
Average KL loss: 0.824259
Average total loss: 1.006987
tensor(-8.3345, device='cuda:0') tensor(3.1961, device='cuda:0') tensor(1.5898e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.176660
Average KL loss: 0.819025
Average total loss: 0.995686
tensor(-8.3674, device='cuda:0') tensor(3.2054, device='cuda:0') tensor(1.6058e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.175863
Average KL loss: 0.814106
Average total loss: 0.989969
tensor(-8.4001, device='cuda:0') tensor(3.2155, device='cuda:0') tensor(1.1990e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.169908
Average KL loss: 0.809097
Average total loss: 0.979004
tensor(-8.4323, device='cuda:0') tensor(3.2246, device='cuda:0') tensor(1.3994e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.167881
Average KL loss: 0.804506
Average total loss: 0.972387
tensor(-8.4641, device='cuda:0') tensor(3.2351, device='cuda:0') tensor(1.1096e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.167963
Average KL loss: 0.800733
Average total loss: 0.968697
tensor(-8.4956, device='cuda:0') tensor(3.2458, device='cuda:0') tensor(1.1753e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.164849
Average KL loss: 0.796947
Average total loss: 0.961797
tensor(-8.5269, device='cuda:0') tensor(3.2558, device='cuda:0') tensor(1.2795e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.164058
Average KL loss: 0.792719
Average total loss: 0.956777
tensor(-8.5577, device='cuda:0') tensor(3.2659, device='cuda:0') tensor(1.3105e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.159488
Average KL loss: 0.789211
Average total loss: 0.948699
tensor(-8.5883, device='cuda:0') tensor(3.2756, device='cuda:0') tensor(1.2144e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.151825
Average KL loss: 0.785248
Average total loss: 0.937074
tensor(-8.6185, device='cuda:0') tensor(3.2841, device='cuda:0') tensor(1.2407e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.154453
Average KL loss: 0.781465
Average total loss: 0.935918
tensor(-8.6486, device='cuda:0') tensor(3.2933, device='cuda:0') tensor(1.2391e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.149175
Average KL loss: 0.778141
Average total loss: 0.927316
tensor(-8.6784, device='cuda:0') tensor(3.3025, device='cuda:0') tensor(1.2600e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.147331
Average KL loss: 0.774754
Average total loss: 0.922085
tensor(-8.7079, device='cuda:0') tensor(3.3115, device='cuda:0') tensor(9.3331e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.142825
Average KL loss: 0.771560
Average total loss: 0.914385
tensor(-8.7371, device='cuda:0') tensor(3.3209, device='cuda:0') tensor(1.0405e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.143828
Average KL loss: 0.768036
Average total loss: 0.911864
tensor(-8.7661, device='cuda:0') tensor(3.3302, device='cuda:0') tensor(9.7146e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.139256
Average KL loss: 0.765119
Average total loss: 0.904375
tensor(-8.7947, device='cuda:0') tensor(3.3399, device='cuda:0') tensor(1.1350e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.138984
Average KL loss: 0.761811
Average total loss: 0.900795
tensor(-8.8233, device='cuda:0') tensor(3.3494, device='cuda:0') tensor(1.0335e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.136708
Average KL loss: 0.758446
Average total loss: 0.895154
tensor(-8.8516, device='cuda:0') tensor(3.3574, device='cuda:0') tensor(1.1472e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.135392
Average KL loss: 0.755418
Average total loss: 0.890810
tensor(-8.8797, device='cuda:0') tensor(3.3664, device='cuda:0') tensor(9.1829e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.131555
Average KL loss: 0.752769
Average total loss: 0.884324
tensor(-8.9076, device='cuda:0') tensor(3.3747, device='cuda:0') tensor(9.8631e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.130298
Average KL loss: 0.749783
Average total loss: 0.880082
tensor(-8.9354, device='cuda:0') tensor(3.3830, device='cuda:0') tensor(1.1978e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.128878
Average KL loss: 0.747109
Average total loss: 0.875987
tensor(-8.9629, device='cuda:0') tensor(3.3916, device='cuda:0') tensor(9.0632e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.128389
Average KL loss: 0.743997
Average total loss: 0.872386
tensor(-8.9903, device='cuda:0') tensor(3.3995, device='cuda:0') tensor(8.4263e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.123650
Average KL loss: 0.741267
Average total loss: 0.864916
tensor(-9.0173, device='cuda:0') tensor(3.4084, device='cuda:0') tensor(9.9939e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.122917
Average KL loss: 0.738660
Average total loss: 0.861578
tensor(-9.0442, device='cuda:0') tensor(3.4167, device='cuda:0') tensor(7.2708e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.121657
Average KL loss: 0.736074
Average total loss: 0.857731
tensor(-9.0709, device='cuda:0') tensor(3.4251, device='cuda:0') tensor(8.8201e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.119503
Average KL loss: 0.733479
Average total loss: 0.852981
tensor(-9.0975, device='cuda:0') tensor(3.4330, device='cuda:0') tensor(8.6908e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.116645
Average KL loss: 0.730243
Average total loss: 0.846888
tensor(-9.1239, device='cuda:0') tensor(3.4400, device='cuda:0') tensor(8.8216e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.115904
Average KL loss: 0.727561
Average total loss: 0.843465
tensor(-9.1502, device='cuda:0') tensor(3.4477, device='cuda:0') tensor(7.5549e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.111937
Average KL loss: 0.725231
Average total loss: 0.837167
tensor(-9.1762, device='cuda:0') tensor(3.4548, device='cuda:0') tensor(8.4730e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.113022
Average KL loss: 0.722908
Average total loss: 0.835929
tensor(-9.2021, device='cuda:0') tensor(3.4624, device='cuda:0') tensor(9.1949e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.107388
Average KL loss: 0.720558
Average total loss: 0.827946
tensor(-9.2279, device='cuda:0') tensor(3.4696, device='cuda:0') tensor(7.9791e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.109031
Average KL loss: 0.718294
Average total loss: 0.827325
tensor(-9.2534, device='cuda:0') tensor(3.4773, device='cuda:0') tensor(6.3037e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.107041
Average KL loss: 0.716130
Average total loss: 0.823171
tensor(-9.2788, device='cuda:0') tensor(3.4848, device='cuda:0') tensor(6.8442e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.104107
Average KL loss: 0.713867
Average total loss: 0.817974
tensor(-9.3040, device='cuda:0') tensor(3.4927, device='cuda:0') tensor(6.1214e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.101475
Average KL loss: 0.711787
Average total loss: 0.813262
tensor(-9.3291, device='cuda:0') tensor(3.5003, device='cuda:0') tensor(6.9876e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.100394
Average KL loss: 0.709635
Average total loss: 0.810029
tensor(-9.3540, device='cuda:0') tensor(3.5080, device='cuda:0') tensor(7.0000e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.098241
Average KL loss: 0.707697
Average total loss: 0.805937
tensor(-9.3788, device='cuda:0') tensor(3.5151, device='cuda:0') tensor(5.7345e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.099468
Average KL loss: 0.705778
Average total loss: 0.805246
tensor(-9.4035, device='cuda:0') tensor(3.5225, device='cuda:0') tensor(8.9757e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.099585
Average KL loss: 0.703904
Average total loss: 0.803488
tensor(-9.4280, device='cuda:0') tensor(3.5292, device='cuda:0') tensor(6.5078e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.096131
Average KL loss: 0.701818
Average total loss: 0.797949
tensor(-9.4525, device='cuda:0') tensor(3.5357, device='cuda:0') tensor(5.5981e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.094523
Average KL loss: 0.699460
Average total loss: 0.793983
tensor(-9.4768, device='cuda:0') tensor(3.5420, device='cuda:0') tensor(6.3383e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.094032
Average KL loss: 0.697608
Average total loss: 0.791640
tensor(-9.5009, device='cuda:0') tensor(3.5492, device='cuda:0') tensor(5.3630e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.093307
Average KL loss: 0.695714
Average total loss: 0.789021
tensor(-9.5249, device='cuda:0') tensor(3.5559, device='cuda:0') tensor(5.5832e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.092910
Average KL loss: 0.694028
Average total loss: 0.786938
tensor(-9.5488, device='cuda:0') tensor(3.5634, device='cuda:0') tensor(5.7115e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.089384
Average KL loss: 0.692420
Average total loss: 0.781804
tensor(-9.5726, device='cuda:0') tensor(3.5700, device='cuda:0') tensor(5.2471e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.087852
Average KL loss: 0.690526
Average total loss: 0.778379
tensor(-9.5963, device='cuda:0') tensor(3.5761, device='cuda:0') tensor(5.9356e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.088251
Average KL loss: 0.688524
Average total loss: 0.776775
tensor(-9.6199, device='cuda:0') tensor(3.5824, device='cuda:0') tensor(5.8424e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.085647
Average KL loss: 0.686745
Average total loss: 0.772392
tensor(-9.6434, device='cuda:0') tensor(3.5884, device='cuda:0') tensor(5.0897e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.086856
Average KL loss: 0.684676
Average total loss: 0.771531
tensor(-9.6667, device='cuda:0') tensor(3.5952, device='cuda:0') tensor(7.5511e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.084987
Average KL loss: 0.683173
Average total loss: 0.768160
tensor(-9.6899, device='cuda:0') tensor(3.6019, device='cuda:0') tensor(6.6901e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.084114
Average KL loss: 0.681413
Average total loss: 0.765527
tensor(-9.7130, device='cuda:0') tensor(3.6081, device='cuda:0') tensor(4.9751e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.085540
Average KL loss: 0.679477
Average total loss: 0.765017
tensor(-9.7360, device='cuda:0') tensor(3.6146, device='cuda:0') tensor(6.0626e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.083101
Average KL loss: 0.677741
Average total loss: 0.760842
tensor(-9.7589, device='cuda:0') tensor(3.6202, device='cuda:0') tensor(4.6878e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.081298
Average KL loss: 0.676115
Average total loss: 0.757414
tensor(-9.7817, device='cuda:0') tensor(3.6262, device='cuda:0') tensor(5.9859e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.080489
Average KL loss: 0.674291
Average total loss: 0.754780
tensor(-9.8044, device='cuda:0') tensor(3.6320, device='cuda:0') tensor(5.5357e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.079414
Average KL loss: 0.672820
Average total loss: 0.752234
tensor(-9.8270, device='cuda:0') tensor(3.6372, device='cuda:0') tensor(4.9812e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.080172
Average KL loss: 0.671324
Average total loss: 0.751495
tensor(-9.8495, device='cuda:0') tensor(3.6431, device='cuda:0') tensor(4.6059e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.079787
Average KL loss: 0.669669
Average total loss: 0.749456
tensor(-9.8719, device='cuda:0') tensor(3.6484, device='cuda:0') tensor(3.7666e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.079310
Average KL loss: 0.667865
Average total loss: 0.747174
tensor(-9.8943, device='cuda:0') tensor(3.6542, device='cuda:0') tensor(4.2543e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.078433
Average KL loss: 0.666438
Average total loss: 0.744871
tensor(-9.9166, device='cuda:0') tensor(3.6589, device='cuda:0') tensor(5.1719e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.076218
Average KL loss: 0.664610
Average total loss: 0.740828
tensor(-9.9388, device='cuda:0') tensor(3.6635, device='cuda:0') tensor(4.1103e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.074962
Average KL loss: 0.662954
Average total loss: 0.737916
tensor(-9.9608, device='cuda:0') tensor(3.6689, device='cuda:0') tensor(3.9024e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.074371
Average KL loss: 0.661423
Average total loss: 0.735795
tensor(-9.9828, device='cuda:0') tensor(3.6739, device='cuda:0') tensor(5.6894e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.073134
Average KL loss: 0.659597
Average total loss: 0.732732
tensor(-10.0046, device='cuda:0') tensor(3.6791, device='cuda:0') tensor(3.0541e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.073931
Average KL loss: 0.658471
Average total loss: 0.732402
tensor(-10.0263, device='cuda:0') tensor(3.6849, device='cuda:0') tensor(4.6222e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.072937
Average KL loss: 0.656972
Average total loss: 0.729910
tensor(-10.0480, device='cuda:0') tensor(3.6888, device='cuda:0') tensor(4.9806e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.071728
Average KL loss: 0.655414
Average total loss: 0.727141
tensor(-10.0696, device='cuda:0') tensor(3.6935, device='cuda:0') tensor(3.8203e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.070955
Average KL loss: 0.653989
Average total loss: 0.724944
tensor(-10.0911, device='cuda:0') tensor(3.6975, device='cuda:0') tensor(4.7765e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.069796
Average KL loss: 0.652417
Average total loss: 0.722213
tensor(-10.1124, device='cuda:0') tensor(3.7022, device='cuda:0') tensor(3.8939e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.070490
Average KL loss: 0.650955
Average total loss: 0.721445
tensor(-10.1336, device='cuda:0') tensor(3.7069, device='cuda:0') tensor(3.7164e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.068646
Average KL loss: 0.649660
Average total loss: 0.718306
tensor(-10.1547, device='cuda:0') tensor(3.7116, device='cuda:0') tensor(4.7299e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.068314
Average KL loss: 0.648208
Average total loss: 0.716522
tensor(-10.1758, device='cuda:0') tensor(3.7160, device='cuda:0') tensor(3.5691e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.067383
Average KL loss: 0.647071
Average total loss: 0.714455
tensor(-10.1968, device='cuda:0') tensor(3.7204, device='cuda:0') tensor(3.8840e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.068792
Average KL loss: 0.645799
Average total loss: 0.714592
tensor(-10.2177, device='cuda:0') tensor(3.7255, device='cuda:0') tensor(3.7164e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.067488
Average KL loss: 0.644724
Average total loss: 0.712212
tensor(-10.2386, device='cuda:0') tensor(3.7302, device='cuda:0') tensor(4.4974e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.066441
Average KL loss: 0.643047
Average total loss: 0.709488
tensor(-10.2594, device='cuda:0') tensor(3.7339, device='cuda:0') tensor(3.4156e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.067509
Average KL loss: 0.641596
Average total loss: 0.709105
tensor(-10.2800, device='cuda:0') tensor(3.7384, device='cuda:0') tensor(4.3881e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.068024
Average KL loss: 0.640653
Average total loss: 0.708676
tensor(-10.3006, device='cuda:0') tensor(3.7430, device='cuda:0') tensor(2.4641e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.066715
Average KL loss: 0.639812
Average total loss: 0.706526
tensor(-10.3212, device='cuda:0') tensor(3.7478, device='cuda:0') tensor(4.0578e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.063916
Average KL loss: 0.638820
Average total loss: 0.702736
tensor(-10.3416, device='cuda:0') tensor(3.7518, device='cuda:0') tensor(3.9978e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.063877
Average KL loss: 0.637564
Average total loss: 0.701441
tensor(-10.3619, device='cuda:0') tensor(3.7551, device='cuda:0') tensor(3.1251e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.064081
Average KL loss: 0.636390
Average total loss: 0.700471
tensor(-10.3822, device='cuda:0') tensor(3.7590, device='cuda:0') tensor(2.8793e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.064074
Average KL loss: 0.635387
Average total loss: 0.699461
tensor(-10.4023, device='cuda:0') tensor(3.7633, device='cuda:0') tensor(3.1435e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.064951
Average KL loss: 0.634385
Average total loss: 0.699336
tensor(-10.4224, device='cuda:0') tensor(3.7674, device='cuda:0') tensor(2.9993e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.063469
Average KL loss: 0.633283
Average total loss: 0.696752
tensor(-10.4424, device='cuda:0') tensor(3.7717, device='cuda:0') tensor(3.1270e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.063294
Average KL loss: 0.632554
Average total loss: 0.695848
tensor(-10.4624, device='cuda:0') tensor(3.7760, device='cuda:0') tensor(3.3336e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.062040
Average KL loss: 0.631745
Average total loss: 0.693785
tensor(-10.4822, device='cuda:0') tensor(3.7798, device='cuda:0') tensor(1.7561e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.060494
Average KL loss: 0.630566
Average total loss: 0.691060
tensor(-10.5020, device='cuda:0') tensor(3.7825, device='cuda:0') tensor(3.1267e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.061363
Average KL loss: 0.629441
Average total loss: 0.690804
tensor(-10.5218, device='cuda:0') tensor(3.7855, device='cuda:0') tensor(3.0090e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.061381
Average KL loss: 0.628633
Average total loss: 0.690014
tensor(-10.5414, device='cuda:0') tensor(3.7897, device='cuda:0') tensor(2.6519e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.060242
Average KL loss: 0.627933
Average total loss: 0.688175
tensor(-10.5610, device='cuda:0') tensor(3.7926, device='cuda:0') tensor(2.8977e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.060606
Average KL loss: 0.626629
Average total loss: 0.687235
tensor(-10.5805, device='cuda:0') tensor(3.7957, device='cuda:0') tensor(2.6826e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.060138
Average KL loss: 0.625696
Average total loss: 0.685834
tensor(-10.5999, device='cuda:0') tensor(3.7987, device='cuda:0') tensor(2.6268e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.060140
Average KL loss: 0.624781
Average total loss: 0.684921
tensor(-10.6192, device='cuda:0') tensor(3.8016, device='cuda:0') tensor(2.8269e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.058969
Average KL loss: 0.624016
Average total loss: 0.682984
tensor(-10.6385, device='cuda:0') tensor(3.8044, device='cuda:0') tensor(2.7015e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.058435
Average KL loss: 0.623122
Average total loss: 0.681557
tensor(-10.6576, device='cuda:0') tensor(3.8074, device='cuda:0') tensor(1.9974e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.058734
Average KL loss: 0.622297
Average total loss: 0.681030
tensor(-10.6767, device='cuda:0') tensor(3.8100, device='cuda:0') tensor(2.5193e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.056751
Average KL loss: 0.621328
Average total loss: 0.678078
tensor(-10.6957, device='cuda:0') tensor(3.8119, device='cuda:0') tensor(2.0492e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.057878
Average KL loss: 0.620432
Average total loss: 0.678310
tensor(-10.7146, device='cuda:0') tensor(3.8148, device='cuda:0') tensor(2.8917e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.056382
Average KL loss: 0.619759
Average total loss: 0.676141
tensor(-10.7334, device='cuda:0') tensor(3.8171, device='cuda:0') tensor(2.5462e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.056544
Average KL loss: 0.618788
Average total loss: 0.675332
tensor(-10.7523, device='cuda:0') tensor(3.8194, device='cuda:0') tensor(2.1878e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.056278
Average KL loss: 0.617916
Average total loss: 0.674194
tensor(-10.7710, device='cuda:0') tensor(3.8216, device='cuda:0') tensor(1.5195e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.056448
Average KL loss: 0.617003
Average total loss: 0.673450
tensor(-10.7896, device='cuda:0') tensor(3.8242, device='cuda:0') tensor(1.9176e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.054865
Average KL loss: 0.616004
Average total loss: 0.670869
tensor(-10.8082, device='cuda:0') tensor(3.8261, device='cuda:0') tensor(2.5714e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.055446
Average KL loss: 0.614899
Average total loss: 0.670344
tensor(-10.8266, device='cuda:0') tensor(3.8277, device='cuda:0') tensor(2.3940e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.054867
Average KL loss: 0.613993
Average total loss: 0.668860
tensor(-10.8451, device='cuda:0') tensor(3.8293, device='cuda:0') tensor(2.4847e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.054687
Average KL loss: 0.612984
Average total loss: 0.667672
tensor(-10.8634, device='cuda:0') tensor(3.8311, device='cuda:0') tensor(2.0288e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.054721
Average KL loss: 0.612128
Average total loss: 0.666849
tensor(-10.8816, device='cuda:0') tensor(3.8330, device='cuda:0') tensor(2.3911e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.055689
Average KL loss: 0.611332
Average total loss: 0.667021
tensor(-10.8998, device='cuda:0') tensor(3.8351, device='cuda:0') tensor(2.0960e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.054203
Average KL loss: 0.610766
Average total loss: 0.664969
tensor(-10.9178, device='cuda:0') tensor(3.8375, device='cuda:0') tensor(2.2535e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.055127
Average KL loss: 0.610043
Average total loss: 0.665170
tensor(-10.9359, device='cuda:0') tensor(3.8395, device='cuda:0') tensor(2.2266e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.053741
Average KL loss: 0.609363
Average total loss: 0.663104
tensor(-10.9538, device='cuda:0') tensor(3.8409, device='cuda:0') tensor(1.7414e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.053889
Average KL loss: 0.608788
Average total loss: 0.662677
tensor(-10.9717, device='cuda:0') tensor(3.8421, device='cuda:0') tensor(1.3238e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.054397
Average KL loss: 0.608170
Average total loss: 0.662567
tensor(-10.9894, device='cuda:0') tensor(3.8441, device='cuda:0') tensor(2.5522e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.053472
Average KL loss: 0.607807
Average total loss: 0.661279
tensor(-11.0072, device='cuda:0') tensor(3.8453, device='cuda:0') tensor(1.2427e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.053296
Average KL loss: 0.607094
Average total loss: 0.660390
tensor(-11.0248, device='cuda:0') tensor(3.8475, device='cuda:0') tensor(2.4546e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.053663
Average KL loss: 0.606518
Average total loss: 0.660181
tensor(-11.0423, device='cuda:0') tensor(3.8491, device='cuda:0') tensor(2.4573e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.052992
Average KL loss: 0.605896
Average total loss: 0.658888
tensor(-11.0599, device='cuda:0') tensor(3.8494, device='cuda:0') tensor(2.0498e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.052148
Average KL loss: 0.605161
Average total loss: 0.657309
tensor(-11.0773, device='cuda:0') tensor(3.8502, device='cuda:0') tensor(2.0731e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.050332
Average KL loss: 0.604346
Average total loss: 0.654678
tensor(-11.0947, device='cuda:0') tensor(3.8503, device='cuda:0') tensor(2.2147e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.050750
Average KL loss: 0.603316
Average total loss: 0.654067
tensor(-11.1120, device='cuda:0') tensor(3.8506, device='cuda:0') tensor(1.9881e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.051738
Average KL loss: 0.602512
Average total loss: 0.654250
tensor(-11.1292, device='cuda:0') tensor(3.8513, device='cuda:0') tensor(1.9192e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.052153
Average KL loss: 0.601699
Average total loss: 0.653852
tensor(-11.1463, device='cuda:0') tensor(3.8519, device='cuda:0') tensor(1.5695e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.051168
Average KL loss: 0.601068
Average total loss: 0.652236
tensor(-11.1634, device='cuda:0') tensor(3.8522, device='cuda:0') tensor(1.4442e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.051038
Average KL loss: 0.600485
Average total loss: 0.651523
tensor(-11.1804, device='cuda:0') tensor(3.8524, device='cuda:0') tensor(1.4501e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.049823
Average KL loss: 0.599672
Average total loss: 0.649495
tensor(-11.1973, device='cuda:0') tensor(3.8529, device='cuda:0') tensor(1.5218e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.049836
Average KL loss: 0.598894
Average total loss: 0.648730
tensor(-11.2142, device='cuda:0') tensor(3.8524, device='cuda:0') tensor(1.4604e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.049819
Average KL loss: 0.597987
Average total loss: 0.647806
tensor(-11.2310, device='cuda:0') tensor(3.8522, device='cuda:0') tensor(1.6903e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.050187
Average KL loss: 0.597276
Average total loss: 0.647463
tensor(-11.2477, device='cuda:0') tensor(3.8524, device='cuda:0') tensor(1.5458e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.049218
Average KL loss: 0.596622
Average total loss: 0.645840
tensor(-11.2643, device='cuda:0') tensor(3.8521, device='cuda:0') tensor(2.5535e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.050404
Average KL loss: 0.596015
Average total loss: 0.646419
tensor(-11.2809, device='cuda:0') tensor(3.8521, device='cuda:0') tensor(1.5688e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.050216
Average KL loss: 0.595344
Average total loss: 0.645561
tensor(-11.2974, device='cuda:0') tensor(3.8516, device='cuda:0') tensor(1.4328e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.049468
Average KL loss: 0.594678
Average total loss: 0.644146
tensor(-11.3138, device='cuda:0') tensor(3.8516, device='cuda:0') tensor(1.1293e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.048860
Average KL loss: 0.594163
Average total loss: 0.643023
tensor(-11.3302, device='cuda:0') tensor(3.8516, device='cuda:0') tensor(1.4296e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.049948
Average KL loss: 0.593515
Average total loss: 0.643463
tensor(-11.3464, device='cuda:0') tensor(3.8510, device='cuda:0') tensor(1.6543e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.049272
Average KL loss: 0.593029
Average total loss: 0.642300
tensor(-11.3627, device='cuda:0') tensor(3.8504, device='cuda:0') tensor(1.2376e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.050145
Average KL loss: 0.592558
Average total loss: 0.642703
tensor(-11.3787, device='cuda:0') tensor(3.8503, device='cuda:0') tensor(1.8667e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.048604
Average KL loss: 0.591985
Average total loss: 0.640589
tensor(-11.3948, device='cuda:0') tensor(3.8494, device='cuda:0') tensor(1.2072e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.048510
Average KL loss: 0.591197
Average total loss: 0.639706
tensor(-11.4107, device='cuda:0') tensor(3.8486, device='cuda:0') tensor(1.1957e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.049269
Average KL loss: 0.590502
Average total loss: 0.639771
tensor(-11.4266, device='cuda:0') tensor(3.8479, device='cuda:0') tensor(1.1664e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.048033
Average KL loss: 0.589971
Average total loss: 0.638005
tensor(-11.4425, device='cuda:0') tensor(3.8470, device='cuda:0') tensor(1.8186e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.048185
Average KL loss: 0.589490
Average total loss: 0.637675
 Percentile value: -9.447117805480957
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1688 /    1728             ( 97.69%) | total_pruned =      40 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   29549 /   36864             ( 80.16%) | total_pruned =    7315 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   29833 /   36864             ( 80.93%) | total_pruned =    7031 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   28940 /   36864             ( 78.50%) | total_pruned =    7924 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   27680 /   36864             ( 75.09%) | total_pruned =    9184 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   55336 /   73728             ( 75.05%) | total_pruned =   18392 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   99664 /  147456             ( 67.59%) | total_pruned =   47792 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7573 /    8192             ( 92.44%) | total_pruned =     619 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   90917 /  147456             ( 61.66%) | total_pruned =   56539 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   88894 /  147456             ( 60.29%) | total_pruned =   58562 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  183904 /  294912             ( 62.36%) | total_pruned =  111008 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  319784 /  589824             ( 54.22%) | total_pruned =  270040 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   26818 /   32768             ( 81.84%) | total_pruned =    5950 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  230630 /  589824             ( 39.10%) | total_pruned =  359194 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  224541 /  589824             ( 38.07%) | total_pruned =  365283 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  511200 / 1179648             ( 43.33%) | total_pruned =  668448 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  607036 / 2359296             ( 25.73%) | total_pruned = 1752260 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   82898 /  131072             ( 63.25%) | total_pruned =   48174 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  363213 / 2359296             ( 15.39%) | total_pruned = 1996083 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     494 /     512             ( 96.48%) | total_pruned =      18 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  328948 / 2359296             ( 13.94%) | total_pruned = 2030348 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
linear.weight        | nonzeros =    5053 /    5120             ( 98.69%) | total_pruned =      67 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 32/200 Loss: 0.000023 Accuracy: 86.89 100.00 % Best test Accuracy: 86.91%
tensor(-11.4582, device='cuda:0') tensor(3.8461, device='cuda:0') tensor(4.9639e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.206259
Average KL loss: 0.580109
Average total loss: 0.786368
tensor(-11.5799, device='cuda:0') tensor(3.0931, device='cuda:0') tensor(-1.7379e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.211027
Average KL loss: 0.567181
Average total loss: 0.778208
tensor(-11.6601, device='cuda:0') tensor(2.7446, device='cuda:0') tensor(-2.7539e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.225578
Average KL loss: 0.555603
Average total loss: 0.781180
tensor(-11.7238, device='cuda:0') tensor(2.5454, device='cuda:0') tensor(-3.6155e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.226910
Average KL loss: 0.547695
Average total loss: 0.774605
tensor(-11.7785, device='cuda:0') tensor(2.4148, device='cuda:0') tensor(-8.9968e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.226042
Average KL loss: 0.541995
Average total loss: 0.768036
tensor(-11.8271, device='cuda:0') tensor(2.3218, device='cuda:0') tensor(-5.6585e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.224139
Average KL loss: 0.537502
Average total loss: 0.761640
tensor(-11.8713, device='cuda:0') tensor(2.2522, device='cuda:0') tensor(-1.5132e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.219368
Average KL loss: 0.533962
Average total loss: 0.753329
tensor(-11.9120, device='cuda:0') tensor(2.1979, device='cuda:0') tensor(-2.4639e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.212232
Average KL loss: 0.530752
Average total loss: 0.742983
tensor(-11.9500, device='cuda:0') tensor(2.1546, device='cuda:0') tensor(-3.0910e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.212575
Average KL loss: 0.528313
Average total loss: 0.740888
tensor(-11.9856, device='cuda:0') tensor(2.1209, device='cuda:0') tensor(-6.5248e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.204737
Average KL loss: 0.526389
Average total loss: 0.731126
tensor(-12.0192, device='cuda:0') tensor(2.0927, device='cuda:0') tensor(-7.9626e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.196104
Average KL loss: 0.524537
Average total loss: 0.720640
tensor(-12.0512, device='cuda:0') tensor(2.0695, device='cuda:0') tensor(-1.5736e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.186677
Average KL loss: 0.523141
Average total loss: 0.709818
tensor(-12.0817, device='cuda:0') tensor(2.0505, device='cuda:0') tensor(-6.5245e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.186251
Average KL loss: 0.521511
Average total loss: 0.707762
tensor(-12.1108, device='cuda:0') tensor(2.0343, device='cuda:0') tensor(-1.9214e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.180537
Average KL loss: 0.520100
Average total loss: 0.700636
tensor(-12.1388, device='cuda:0') tensor(2.0204, device='cuda:0') tensor(-1.8292e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.176833
Average KL loss: 0.518663
Average total loss: 0.695496
tensor(-12.1657, device='cuda:0') tensor(2.0091, device='cuda:0') tensor(-5.9910e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.175557
Average KL loss: 0.517267
Average total loss: 0.692823
tensor(-12.1916, device='cuda:0') tensor(2.0004, device='cuda:0') tensor(-3.3988e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.168061
Average KL loss: 0.516076
Average total loss: 0.684137
tensor(-12.2166, device='cuda:0') tensor(1.9923, device='cuda:0') tensor(2.2702e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.164468
Average KL loss: 0.514908
Average total loss: 0.679376
tensor(-12.2408, device='cuda:0') tensor(1.9853, device='cuda:0') tensor(-1.9026e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.164434
Average KL loss: 0.513612
Average total loss: 0.678046
tensor(-12.2643, device='cuda:0') tensor(1.9793, device='cuda:0') tensor(-1.2512e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.161455
Average KL loss: 0.512533
Average total loss: 0.673988
tensor(-12.2871, device='cuda:0') tensor(1.9752, device='cuda:0') tensor(-1.5455e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.157341
Average KL loss: 0.511605
Average total loss: 0.668945
tensor(-12.3091, device='cuda:0') tensor(1.9717, device='cuda:0') tensor(2.6858e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.155446
Average KL loss: 0.510589
Average total loss: 0.666035
tensor(-12.3306, device='cuda:0') tensor(1.9690, device='cuda:0') tensor(-1.7312e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.153028
Average KL loss: 0.509857
Average total loss: 0.662885
tensor(-12.3515, device='cuda:0') tensor(1.9677, device='cuda:0') tensor(-7.5051e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.146386
Average KL loss: 0.509194
Average total loss: 0.655580
tensor(-12.3720, device='cuda:0') tensor(1.9662, device='cuda:0') tensor(-2.4678e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.147740
Average KL loss: 0.508438
Average total loss: 0.656179
tensor(-12.3919, device='cuda:0') tensor(1.9650, device='cuda:0') tensor(-2.4921e-11, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.143734
Average KL loss: 0.507530
Average total loss: 0.651264
tensor(-12.4113, device='cuda:0') tensor(1.9641, device='cuda:0') tensor(-4.7380e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.141726
Average KL loss: 0.506716
Average total loss: 0.648442
tensor(-12.4303, device='cuda:0') tensor(1.9642, device='cuda:0') tensor(2.6894e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.140162
Average KL loss: 0.506111
Average total loss: 0.646273
tensor(-12.4488, device='cuda:0') tensor(1.9647, device='cuda:0') tensor(-1.5260e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.136712
Average KL loss: 0.505514
Average total loss: 0.642227
tensor(-12.4670, device='cuda:0') tensor(1.9652, device='cuda:0') tensor(-2.9637e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.134914
Average KL loss: 0.505020
Average total loss: 0.639934
tensor(-12.4847, device='cuda:0') tensor(1.9669, device='cuda:0') tensor(-1.7381e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.132520
Average KL loss: 0.504436
Average total loss: 0.636955
tensor(-12.5021, device='cuda:0') tensor(1.9679, device='cuda:0') tensor(-1.1224e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.130273
Average KL loss: 0.503635
Average total loss: 0.633907
tensor(-12.5192, device='cuda:0') tensor(1.9692, device='cuda:0') tensor(-2.2454e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.126428
Average KL loss: 0.502953
Average total loss: 0.629381
tensor(-12.5359, device='cuda:0') tensor(1.9706, device='cuda:0') tensor(-3.3146e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.129919
Average KL loss: 0.502219
Average total loss: 0.632138
tensor(-12.5524, device='cuda:0') tensor(1.9722, device='cuda:0') tensor(-6.0068e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.125651
Average KL loss: 0.501582
Average total loss: 0.627233
tensor(-12.5684, device='cuda:0') tensor(1.9742, device='cuda:0') tensor(-2.3676e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.123651
Average KL loss: 0.501044
Average total loss: 0.624695
tensor(-12.5842, device='cuda:0') tensor(1.9768, device='cuda:0') tensor(-7.6736e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.121152
Average KL loss: 0.500312
Average total loss: 0.621464
tensor(-12.5997, device='cuda:0') tensor(1.9786, device='cuda:0') tensor(3.9954e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.120799
Average KL loss: 0.499586
Average total loss: 0.620384
tensor(-12.6150, device='cuda:0') tensor(1.9806, device='cuda:0') tensor(-1.2188e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.120383
Average KL loss: 0.499102
Average total loss: 0.619485
tensor(-12.6300, device='cuda:0') tensor(1.9826, device='cuda:0') tensor(1.2719e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.119647
Average KL loss: 0.498563
Average total loss: 0.618210
tensor(-12.6448, device='cuda:0') tensor(1.9850, device='cuda:0') tensor(-2.7693e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.116081
Average KL loss: 0.497998
Average total loss: 0.614079
tensor(-12.6593, device='cuda:0') tensor(1.9878, device='cuda:0') tensor(4.8034e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.116644
Average KL loss: 0.497457
Average total loss: 0.614101
tensor(-12.6735, device='cuda:0') tensor(1.9906, device='cuda:0') tensor(-2.4329e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.114954
Average KL loss: 0.496890
Average total loss: 0.611845
tensor(-12.6876, device='cuda:0') tensor(1.9932, device='cuda:0') tensor(-1.4260e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.114517
Average KL loss: 0.496266
Average total loss: 0.610783
tensor(-12.7015, device='cuda:0') tensor(1.9953, device='cuda:0') tensor(-8.8546e-11, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.112279
Average KL loss: 0.495695
Average total loss: 0.607973
tensor(-12.7151, device='cuda:0') tensor(1.9975, device='cuda:0') tensor(-1.6697e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.111806
Average KL loss: 0.495180
Average total loss: 0.606986
tensor(-12.7285, device='cuda:0') tensor(2.0005, device='cuda:0') tensor(-3.0280e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.114086
Average KL loss: 0.494694
Average total loss: 0.608780
tensor(-12.7417, device='cuda:0') tensor(2.0039, device='cuda:0') tensor(-1.3036e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.111109
Average KL loss: 0.494325
Average total loss: 0.605434
tensor(-12.7547, device='cuda:0') tensor(2.0075, device='cuda:0') tensor(-6.0180e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.109286
Average KL loss: 0.493954
Average total loss: 0.603240
tensor(-12.7676, device='cuda:0') tensor(2.0105, device='cuda:0') tensor(-1.6563e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.107405
Average KL loss: 0.493382
Average total loss: 0.600787
tensor(-12.7803, device='cuda:0') tensor(2.0134, device='cuda:0') tensor(-1.0249e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.107318
Average KL loss: 0.492941
Average total loss: 0.600259
tensor(-12.7928, device='cuda:0') tensor(2.0168, device='cuda:0') tensor(3.7175e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.106454
Average KL loss: 0.492528
Average total loss: 0.598982
tensor(-12.8051, device='cuda:0') tensor(2.0196, device='cuda:0') tensor(-1.2045e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.103813
Average KL loss: 0.492118
Average total loss: 0.595931
tensor(-12.8173, device='cuda:0') tensor(2.0226, device='cuda:0') tensor(-1.5715e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.103987
Average KL loss: 0.491706
Average total loss: 0.595693
tensor(-12.8293, device='cuda:0') tensor(2.0263, device='cuda:0') tensor(-8.7407e-11, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.103473
Average KL loss: 0.491360
Average total loss: 0.594834
tensor(-12.8412, device='cuda:0') tensor(2.0295, device='cuda:0') tensor(-5.4806e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.104188
Average KL loss: 0.491033
Average total loss: 0.595221
tensor(-12.8529, device='cuda:0') tensor(2.0329, device='cuda:0') tensor(1.7610e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.102169
Average KL loss: 0.490750
Average total loss: 0.592919
tensor(-12.8644, device='cuda:0') tensor(2.0368, device='cuda:0') tensor(-7.2498e-11, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.100920
Average KL loss: 0.490470
Average total loss: 0.591390
tensor(-12.8759, device='cuda:0') tensor(2.0400, device='cuda:0') tensor(-1.0329e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.098677
Average KL loss: 0.490286
Average total loss: 0.588963
tensor(-12.8871, device='cuda:0') tensor(2.0435, device='cuda:0') tensor(-5.2406e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.099203
Average KL loss: 0.490088
Average total loss: 0.589291
tensor(-12.8983, device='cuda:0') tensor(2.0466, device='cuda:0') tensor(-1.2583e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.097740
Average KL loss: 0.489581
Average total loss: 0.587321
tensor(-12.9093, device='cuda:0') tensor(2.0501, device='cuda:0') tensor(2.2883e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.097656
Average KL loss: 0.489298
Average total loss: 0.586953
tensor(-12.9202, device='cuda:0') tensor(2.0533, device='cuda:0') tensor(-4.8727e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.096935
Average KL loss: 0.489066
Average total loss: 0.586002
tensor(-12.9310, device='cuda:0') tensor(2.0561, device='cuda:0') tensor(-3.7225e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.096561
Average KL loss: 0.488703
Average total loss: 0.585264
tensor(-12.9417, device='cuda:0') tensor(2.0593, device='cuda:0') tensor(-2.5887e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.094028
Average KL loss: 0.488539
Average total loss: 0.582567
tensor(-12.9522, device='cuda:0') tensor(2.0621, device='cuda:0') tensor(1.0248e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.096060
Average KL loss: 0.488217
Average total loss: 0.584277
tensor(-12.9626, device='cuda:0') tensor(2.0656, device='cuda:0') tensor(-3.3641e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.094478
Average KL loss: 0.487914
Average total loss: 0.582391
tensor(-12.9729, device='cuda:0') tensor(2.0692, device='cuda:0') tensor(-7.7744e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.093535
Average KL loss: 0.487789
Average total loss: 0.581324
tensor(-12.9831, device='cuda:0') tensor(2.0730, device='cuda:0') tensor(-5.9214e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.092253
Average KL loss: 0.487498
Average total loss: 0.579751
tensor(-12.9931, device='cuda:0') tensor(2.0761, device='cuda:0') tensor(-1.4546e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.092226
Average KL loss: 0.487116
Average total loss: 0.579342
tensor(-13.0031, device='cuda:0') tensor(2.0795, device='cuda:0') tensor(-9.0973e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.092038
Average KL loss: 0.486838
Average total loss: 0.578876
tensor(-13.0130, device='cuda:0') tensor(2.0826, device='cuda:0') tensor(4.1147e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.091107
Average KL loss: 0.486627
Average total loss: 0.577734
tensor(-13.0228, device='cuda:0') tensor(2.0859, device='cuda:0') tensor(7.6335e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.090751
Average KL loss: 0.486308
Average total loss: 0.577059
tensor(-13.0325, device='cuda:0') tensor(2.0887, device='cuda:0') tensor(-5.2529e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.090567
Average KL loss: 0.485993
Average total loss: 0.576560
tensor(-13.0421, device='cuda:0') tensor(2.0919, device='cuda:0') tensor(3.0891e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.089431
Average KL loss: 0.485777
Average total loss: 0.575207
tensor(-13.0516, device='cuda:0') tensor(2.0953, device='cuda:0') tensor(-2.5764e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.088994
Average KL loss: 0.485537
Average total loss: 0.574532
tensor(-13.0609, device='cuda:0') tensor(2.0984, device='cuda:0') tensor(-8.2709e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.089253
Average KL loss: 0.485262
Average total loss: 0.574515
tensor(-13.0702, device='cuda:0') tensor(2.1016, device='cuda:0') tensor(-9.5239e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.088607
Average KL loss: 0.485122
Average total loss: 0.573729
tensor(-13.0794, device='cuda:0') tensor(2.1050, device='cuda:0') tensor(-7.2131e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.087911
Average KL loss: 0.484926
Average total loss: 0.572837
tensor(-13.0886, device='cuda:0') tensor(2.1083, device='cuda:0') tensor(-1.6140e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.086613
Average KL loss: 0.484657
Average total loss: 0.571270
tensor(-13.0976, device='cuda:0') tensor(2.1118, device='cuda:0') tensor(-2.5731e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.086750
Average KL loss: 0.484399
Average total loss: 0.571150
tensor(-13.1066, device='cuda:0') tensor(2.1146, device='cuda:0') tensor(1.5408e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.086828
Average KL loss: 0.484153
Average total loss: 0.570981
tensor(-13.1155, device='cuda:0') tensor(2.1173, device='cuda:0') tensor(-4.8976e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.086703
Average KL loss: 0.483841
Average total loss: 0.570545
tensor(-13.1242, device='cuda:0') tensor(2.1204, device='cuda:0') tensor(5.5992e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.085940
Average KL loss: 0.483611
Average total loss: 0.569551
tensor(-13.1330, device='cuda:0') tensor(2.1233, device='cuda:0') tensor(-6.3800e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.086186
Average KL loss: 0.483290
Average total loss: 0.569477
tensor(-13.1416, device='cuda:0') tensor(2.1261, device='cuda:0') tensor(-2.4874e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.085956
Average KL loss: 0.482994
Average total loss: 0.568950
tensor(-13.1502, device='cuda:0') tensor(2.1291, device='cuda:0') tensor(7.0988e-12, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.085654
Average KL loss: 0.482762
Average total loss: 0.568416
tensor(-13.1587, device='cuda:0') tensor(2.1325, device='cuda:0') tensor(-1.0514e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.085532
Average KL loss: 0.482463
Average total loss: 0.567995
tensor(-13.1671, device='cuda:0') tensor(2.1359, device='cuda:0') tensor(6.8851e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.085088
Average KL loss: 0.482292
Average total loss: 0.567380
tensor(-13.1754, device='cuda:0') tensor(2.1393, device='cuda:0') tensor(-2.3720e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.083405
Average KL loss: 0.482125
Average total loss: 0.565530
tensor(-13.1837, device='cuda:0') tensor(2.1425, device='cuda:0') tensor(-1.0114e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.084461
Average KL loss: 0.481894
Average total loss: 0.566356
tensor(-13.1919, device='cuda:0') tensor(2.1456, device='cuda:0') tensor(-1.7456e-11, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.083555
Average KL loss: 0.481700
Average total loss: 0.565255
tensor(-13.2001, device='cuda:0') tensor(2.1487, device='cuda:0') tensor(-6.3079e-11, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.083456
Average KL loss: 0.481491
Average total loss: 0.564946
tensor(-13.2081, device='cuda:0') tensor(2.1517, device='cuda:0') tensor(2.6684e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.082835
Average KL loss: 0.481254
Average total loss: 0.564089
tensor(-13.2161, device='cuda:0') tensor(2.1549, device='cuda:0') tensor(-7.9828e-11, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.082685
Average KL loss: 0.481066
Average total loss: 0.563751
tensor(-13.2241, device='cuda:0') tensor(2.1578, device='cuda:0') tensor(-3.0881e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.082484
Average KL loss: 0.480884
Average total loss: 0.563367
tensor(-13.2320, device='cuda:0') tensor(2.1607, device='cuda:0') tensor(-1.8642e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.082520
Average KL loss: 0.480662
Average total loss: 0.563182
tensor(-13.2398, device='cuda:0') tensor(2.1639, device='cuda:0') tensor(1.0344e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.082734
Average KL loss: 0.480492
Average total loss: 0.563226
tensor(-13.2475, device='cuda:0') tensor(2.1669, device='cuda:0') tensor(-4.1198e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.081189
Average KL loss: 0.480228
Average total loss: 0.561417
tensor(-13.2552, device='cuda:0') tensor(2.1698, device='cuda:0') tensor(5.5313e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.080727
Average KL loss: 0.480055
Average total loss: 0.560781
tensor(-13.2629, device='cuda:0') tensor(2.1727, device='cuda:0') tensor(3.5765e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.082139
Average KL loss: 0.479762
Average total loss: 0.561901
tensor(-13.2705, device='cuda:0') tensor(2.1759, device='cuda:0') tensor(-6.7055e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.080894
Average KL loss: 0.479553
Average total loss: 0.560447
tensor(-13.2780, device='cuda:0') tensor(2.1788, device='cuda:0') tensor(-6.7723e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.080625
Average KL loss: 0.479348
Average total loss: 0.559973
tensor(-13.2854, device='cuda:0') tensor(2.1816, device='cuda:0') tensor(-8.7936e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.081106
Average KL loss: 0.479175
Average total loss: 0.560281
tensor(-13.2929, device='cuda:0') tensor(2.1842, device='cuda:0') tensor(3.7083e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.079909
Average KL loss: 0.478989
Average total loss: 0.558898
tensor(-13.3002, device='cuda:0') tensor(2.1870, device='cuda:0') tensor(-2.2232e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.080235
Average KL loss: 0.478728
Average total loss: 0.558963
tensor(-13.3075, device='cuda:0') tensor(2.1897, device='cuda:0') tensor(8.4477e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.079729
Average KL loss: 0.478606
Average total loss: 0.558335
tensor(-13.3147, device='cuda:0') tensor(2.1927, device='cuda:0') tensor(-7.4333e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.079863
Average KL loss: 0.478479
Average total loss: 0.558342
tensor(-13.3219, device='cuda:0') tensor(2.1954, device='cuda:0') tensor(-2.5020e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.080350
Average KL loss: 0.478264
Average total loss: 0.558614
tensor(-13.3290, device='cuda:0') tensor(2.1983, device='cuda:0') tensor(2.2549e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.079051
Average KL loss: 0.478072
Average total loss: 0.557123
tensor(-13.3361, device='cuda:0') tensor(2.2010, device='cuda:0') tensor(-2.0721e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.078825
Average KL loss: 0.477939
Average total loss: 0.556765
tensor(-13.3432, device='cuda:0') tensor(2.2044, device='cuda:0') tensor(3.1633e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.077468
Average KL loss: 0.477881
Average total loss: 0.555350
tensor(-13.3501, device='cuda:0') tensor(2.2071, device='cuda:0') tensor(1.9142e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.078879
Average KL loss: 0.477703
Average total loss: 0.556582
tensor(-13.3571, device='cuda:0') tensor(2.2100, device='cuda:0') tensor(-1.4663e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.079108
Average KL loss: 0.477524
Average total loss: 0.556633
tensor(-13.3640, device='cuda:0') tensor(2.2129, device='cuda:0') tensor(-6.0275e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.079466
Average KL loss: 0.477326
Average total loss: 0.556792
tensor(-13.3708, device='cuda:0') tensor(2.2158, device='cuda:0') tensor(5.9937e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.078063
Average KL loss: 0.477236
Average total loss: 0.555299
tensor(-13.3776, device='cuda:0') tensor(2.2188, device='cuda:0') tensor(-3.7702e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.078082
Average KL loss: 0.477164
Average total loss: 0.555246
tensor(-13.3843, device='cuda:0') tensor(2.2218, device='cuda:0') tensor(-2.0574e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.077334
Average KL loss: 0.477041
Average total loss: 0.554374
tensor(-13.3910, device='cuda:0') tensor(2.2245, device='cuda:0') tensor(-2.8458e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.078099
Average KL loss: 0.476780
Average total loss: 0.554879
tensor(-13.3977, device='cuda:0') tensor(2.2274, device='cuda:0') tensor(-1.5030e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.077720
Average KL loss: 0.476582
Average total loss: 0.554302
tensor(-13.4043, device='cuda:0') tensor(2.2305, device='cuda:0') tensor(5.2843e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.077534
Average KL loss: 0.476464
Average total loss: 0.553998
tensor(-13.4108, device='cuda:0') tensor(2.2335, device='cuda:0') tensor(1.5613e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.075914
Average KL loss: 0.476256
Average total loss: 0.552170
tensor(-13.4174, device='cuda:0') tensor(2.2361, device='cuda:0') tensor(4.2548e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.077288
Average KL loss: 0.476093
Average total loss: 0.553381
tensor(-13.4239, device='cuda:0') tensor(2.2384, device='cuda:0') tensor(1.1249e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.076811
Average KL loss: 0.475925
Average total loss: 0.552736
tensor(-13.4303, device='cuda:0') tensor(2.2408, device='cuda:0') tensor(-3.3890e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.076829
Average KL loss: 0.475674
Average total loss: 0.552504
tensor(-13.4367, device='cuda:0') tensor(2.2437, device='cuda:0') tensor(-1.5103e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.077409
Average KL loss: 0.475493
Average total loss: 0.552902
tensor(-13.4431, device='cuda:0') tensor(2.2466, device='cuda:0') tensor(-1.6405e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.076919
Average KL loss: 0.475307
Average total loss: 0.552226
tensor(-13.4494, device='cuda:0') tensor(2.2491, device='cuda:0') tensor(2.1039e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.076240
Average KL loss: 0.475119
Average total loss: 0.551358
tensor(-13.4557, device='cuda:0') tensor(2.2519, device='cuda:0') tensor(-5.2000e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.075847
Average KL loss: 0.475096
Average total loss: 0.550943
tensor(-13.4619, device='cuda:0') tensor(2.2548, device='cuda:0') tensor(-2.3525e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.075821
Average KL loss: 0.475084
Average total loss: 0.550906
tensor(-13.4681, device='cuda:0') tensor(2.2575, device='cuda:0') tensor(1.0627e-12, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.076043
Average KL loss: 0.474871
Average total loss: 0.550914
tensor(-13.4743, device='cuda:0') tensor(2.2601, device='cuda:0') tensor(-1.8202e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 133
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 134
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 135
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 136
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 137
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 138
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 139
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 140
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 141
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 142
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 143
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 144
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 145
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 146
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 147
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 148
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 149
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 150
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 151
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 152
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 153
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 154
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 155
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 156
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 157
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 158
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 159
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 160
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 161
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 162
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 163
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 164
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 165
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 166
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 167
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 168
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 169
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 170
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 171
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 172
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 173
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 174
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 175
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 176
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 177
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 178
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 179
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 180
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 181
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 182
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 183
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  221898 / 2359296             (  9.41%) | total_pruned = 2137398 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   82898 /  131072             ( 63.25%) | total_pruned =   48174 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  363213 / 2359296             ( 15.39%) | total_pruned = 1996083 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     494 /     512             ( 96.48%) | total_pruned =      18 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  328948 / 2359296             ( 13.94%) | total_pruned = 2030348 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
linear.weight        | nonzeros =    5053 /    5120             ( 98.69%) | total_pruned =      67 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 34/200 Loss: 2.302581 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  295747 / 2359296             ( 12.54%) | total_pruned = 2063549 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
linear.weight        | nonzeros =    5053 /    5120             ( 98.69%) | total_pruned =      67 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 34/200 Loss: 2.302474 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   84469 / 2359296             (  3.58%) | total_pruned = 2274827 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
linear.weight        | nonzeros =    5053 /    5120             ( 98.69%) | total_pruned =      67 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 34/200 Loss: 2.302641 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   21085 / 2359296             (  0.89%) | total_pruned = 2338211 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
linear.weight        | nonzeros =    5053 /    5120             ( 98.69%) | total_pruned =      67 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 34/200 Loss: 2.302565 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2070 / 2359296             (  0.09%) | total_pruned = 2357226 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
linear.weight        | nonzeros =    5053 /    5120             ( 98.69%) | total_pruned =      67 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 34/200 Loss: 2.302526 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
